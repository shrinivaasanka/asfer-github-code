16/03/17 11:56:02 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458195962517
16/03/17 11:56:02 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 11:56:02 INFO Executor: Starting executor ID driver on host localhost
16/03/17 11:56:02 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49369.
16/03/17 11:56:02 INFO NettyBlockTransferService: Server created on 49369
16/03/17 11:56:02 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 11:56:02 INFO BlockManagerMasterEndpoint: Registering block manager localhost:49369 with 1080.8 MB RAM, BlockManagerId(driver, localhost, 49369)
16/03/17 11:56:02 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): belong
16/03/17 11:56:02 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:56:02 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:56:02 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:56:02 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:56:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 11:56:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 11:56:02 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:56:02 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1133311426
16/03/17 11:56:02 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1080.8 MB)
16/03/17 11:56:02 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6568, maxMem=1133311426
16/03/17 11:56:02 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 1080.8 MB)
16/03/17 11:56:02 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:49369 (size: 4.1 KB, free: 1080.8 MB)
16/03/17 11:56:02 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 11:56:02 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:56:02 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 11:56:02 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/17 11:56:02 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 11:56:02 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458195962517
16/03/17 11:56:02 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-dc189226-810b-44ae-a803-a0f3e9faaa0a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: area
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: issue
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: planning
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: permission
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: economy
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: composition
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: agency
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 11:56:10 INFO PythonRunner: Times: total = 8064, boot = 505, init = 371, finish = 7188
16/03/17 11:56:10 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/17 11:56:10 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/17 11:56:10 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 11:56:10 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8145 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: set
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  Synset('set.n.01') ; keyword:  belong  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: bend
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: giant
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: astatine
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: present
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: area
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
16/03/17 11:56:11 INFO PythonRunner: Times: total = 296, boot = 187, init = 0, finish = 109
16/03/17 11:56:11 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/17 11:56:11 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 325 ms on localhost (2/2)
16/03/17 11:56:11 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 11:56:11 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.461 s
16/03/17 11:56:11 INFO DAGScheduler: looking for newly runnable stages
16/03/17 11:56:11 INFO DAGScheduler: running: Set()
16/03/17 11:56:11 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 11:56:11 INFO DAGScheduler: failed: Set()
16/03/17 11:56:11 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 11:56:11 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 11:56:11 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10717, maxMem=1133311426
16/03/17 11:56:11 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1080.8 MB)
16/03/17 11:56:11 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15701, maxMem=1133311426
16/03/17 11:56:11 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1080.8 MB)
16/03/17 11:56:11 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:49369 (size: 3.0 KB, free: 1080.8 MB)
16/03/17 11:56:11 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 11:56:11 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:56:11 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 11:56:11 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:56:11 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 11:56:11 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:56:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/17 11:56:11 INFO PythonRunner: Times: total = 163, boot = 162, init = 0, finish = 1
16/03/17 11:56:11 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 11:56:11 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:56:11 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 11:56:11 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:56:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 11:56:11 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 192 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'set']
16/03/17 11:56:11 INFO PythonRunner: Times: total = 195, boot = 194, init = 0, finish = 1
16/03/17 11:56:11 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1271 bytes result sent to driver
16/03/17 11:56:11 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 208 ms on localhost (2/2)
16/03/17 11:56:11 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 11:56:11 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.391 s
16/03/17 11:56:11 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.883749 s
16/03/17 11:56:11 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:56:11 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:56:11 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:56:11 INFO DAGScheduler: Parents of final stage: List()
16/03/17 11:56:11 INFO DAGScheduler: Missing parents: List()
16/03/17 11:56:11 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:56:11 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18757, maxMem=1133311426
16/03/17 11:56:11 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1080.8 MB)
16/03/17 11:56:11 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24573, maxMem=1133311426
16/03/17 11:56:11 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1080.8 MB)
16/03/17 11:56:11 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:49369 (size: 3.3 KB, free: 1080.8 MB)
16/03/17 11:56:11 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 11:56:11 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:56:11 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 11:56:11 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 11:56:11 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 11:56:11 INFO PythonRunner: Times: total = 54, boot = 54, init = 0, finish = 0
16/03/17 11:56:11 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 11:56:11 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/17 11:56:11 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 61 ms on localhost (1/2)
16/03/17 11:56:11 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 11:56:12 INFO PythonRunner: Times: total = 238, boot = 237, init = 1, finish = 0
16/03/17 11:56:12 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1336 bytes result sent to driver
16/03/17 11:56:12 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 245 ms on localhost (2/2)
16/03/17 11:56:12 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 11:56:12 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.298 s
16/03/17 11:56:12 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.329958 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/17 11:56:12 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 11:56:12 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 11:56:12 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 11:56:12 INFO MemoryStore: MemoryStore cleared
16/03/17 11:56:12 INFO BlockManager: BlockManager stopped
16/03/17 11:56:12 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 11:56:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 11:56:12 INFO SparkContext: Successfully stopped SparkContext
16/03/17 11:56:12 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 11:56:12 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 11:56:12 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'set']
16/03/17 11:56:13 INFO SparkContext: Running Spark version 1.5.2
16/03/17 11:56:13 INFO SecurityManager: Changing view acls to: root
16/03/17 11:56:13 INFO SecurityManager: Changing modify acls to: root
16/03/17 11:56:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 11:56:13 INFO Slf4jLogger: Slf4jLogger started
16/03/17 11:56:13 INFO Remoting: Starting remoting
16/03/17 11:56:13 INFO Utils: Successfully started service 'sparkDriver' on port 33394.
16/03/17 11:56:13 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:33394]
16/03/17 11:56:13 INFO SparkEnv: Registering MapOutputTracker
16/03/17 11:56:13 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 11:56:13 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3509a684-0bea-4d7e-a8b2-c73c9ae2290b
16/03/17 11:56:13 INFO MemoryStore: MemoryStore started with capacity 1080.8 MB
16/03/17 11:56:13 INFO HttpFileServer: HTTP File server directory is /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/httpd-cd5e91d9-4a0c-4fa5-897c-2af5c99f71f3
16/03/17 11:56:13 INFO HttpServer: Starting HTTP Server
16/03/17 11:56:13 INFO Utils: Successfully started service 'HTTP file server' on port 47688.
16/03/17 11:56:13 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 11:56:13 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 11:56:13 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 11:56:13 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-cc2da17b-1820-447f-9aa0-22364829481a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 11:56:13 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458195973429
16/03/17 11:56:13 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 11:56:13 INFO Executor: Starting executor ID driver on host localhost
16/03/17 11:56:13 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49257.
16/03/17 11:56:13 INFO NettyBlockTransferService: Server created on 49257
16/03/17 11:56:13 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 11:56:13 INFO BlockManagerMasterEndpoint: Registering block manager localhost:49257 with 1080.8 MB RAM, BlockManagerId(driver, localhost, 49257)
16/03/17 11:56:13 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): uranium
16/03/17 11:56:13 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:56:13 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:56:13 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:56:13 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:56:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 11:56:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 11:56:13 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:56:13 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1133311426
16/03/17 11:56:13 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1080.8 MB)
16/03/17 11:56:13 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6568, maxMem=1133311426
16/03/17 11:56:13 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 1080.8 MB)
16/03/17 11:56:13 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:49257 (size: 4.1 KB, free: 1080.8 MB)
16/03/17 11:56:13 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 11:56:13 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:56:13 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 11:56:13 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/17 11:56:13 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 11:56:13 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458195973429
16/03/17 11:56:13 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-cc2da17b-1820-447f-9aa0-22364829481a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: area
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: issue
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: planning
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: permission
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: economy
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: composition
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: agency
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 11:56:21 INFO PythonRunner: Times: total = 8138, boot = 499, init = 384, finish = 7255
16/03/17 11:56:21 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/17 11:56:21 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/17 11:56:21 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 11:56:21 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8239 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: set
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: bend
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: giant
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: astatine
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  uranium  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: present
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: area
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/17 11:56:22 INFO PythonRunner: Times: total = 325, boot = 162, init = 1, finish = 162
16/03/17 11:56:22 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/17 11:56:22 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 361 ms on localhost (2/2)
16/03/17 11:56:22 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 11:56:22 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.601 s
16/03/17 11:56:22 INFO DAGScheduler: looking for newly runnable stages
16/03/17 11:56:22 INFO DAGScheduler: running: Set()
16/03/17 11:56:22 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 11:56:22 INFO DAGScheduler: failed: Set()
16/03/17 11:56:22 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 11:56:22 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 11:56:22 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10717, maxMem=1133311426
16/03/17 11:56:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1080.8 MB)
16/03/17 11:56:22 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15701, maxMem=1133311426
16/03/17 11:56:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1080.8 MB)
16/03/17 11:56:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:49257 (size: 3.0 KB, free: 1080.8 MB)
16/03/17 11:56:22 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 11:56:22 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:56:22 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 11:56:22 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:56:22 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 11:56:22 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:56:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 11:56:22 INFO PythonRunner: Times: total = 167, boot = 167, init = 0, finish = 0
16/03/17 11:56:22 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 11:56:22 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:56:22 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 11:56:22 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:56:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 11:56:22 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 203 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/03/17 11:56:22 INFO PythonRunner: Times: total = 173, boot = 173, init = 0, finish = 0
16/03/17 11:56:22 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/03/17 11:56:22 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.372 s
16/03/17 11:56:22 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.016959 s
16/03/17 11:56:22 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 201 ms on localhost (2/2)
16/03/17 11:56:22 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 11:56:22 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:56:22 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:56:22 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:56:22 INFO DAGScheduler: Parents of final stage: List()
16/03/17 11:56:22 INFO DAGScheduler: Missing parents: List()
16/03/17 11:56:22 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:56:22 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18757, maxMem=1133311426
16/03/17 11:56:22 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1080.8 MB)
16/03/17 11:56:22 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24573, maxMem=1133311426
16/03/17 11:56:22 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1080.8 MB)
16/03/17 11:56:22 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:49257 (size: 3.3 KB, free: 1080.8 MB)
16/03/17 11:56:22 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 11:56:22 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:56:22 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 11:56:22 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 11:56:22 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 11:56:22 INFO PythonRunner: Times: total = 177, boot = 177, init = 0, finish = 0
16/03/17 11:56:22 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 11:56:22 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/03/17 11:56:22 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 185 ms on localhost (1/2)
16/03/17 11:56:22 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 11:56:23 INFO PythonRunner: Times: total = 193, boot = 192, init = 1, finish = 0
16/03/17 11:56:23 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/03/17 11:56:23 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 200 ms on localhost (2/2)
16/03/17 11:56:23 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 11:56:23 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.379 s
16/03/17 11:56:23 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.423394 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/17 11:56:23 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 11:56:23 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 11:56:23 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 11:56:23 INFO MemoryStore: MemoryStore cleared
16/03/17 11:56:23 INFO BlockManager: BlockManager stopped
16/03/17 11:56:23 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 11:56:23 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 11:56:23 INFO SparkContext: Successfully stopped SparkContext
16/03/17 11:56:23 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 11:56:23 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 11:56:23 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'astatine']
16/03/17 11:56:24 INFO SparkContext: Running Spark version 1.5.2
16/03/17 11:56:24 INFO SecurityManager: Changing view acls to: root
16/03/17 11:56:24 INFO SecurityManager: Changing modify acls to: root
16/03/17 11:56:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 11:56:24 INFO Slf4jLogger: Slf4jLogger started
16/03/17 11:56:24 INFO Remoting: Starting remoting
16/03/17 11:56:24 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:52119]
16/03/17 11:56:24 INFO Utils: Successfully started service 'sparkDriver' on port 52119.
16/03/17 11:56:24 INFO SparkEnv: Registering MapOutputTracker
16/03/17 11:56:24 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 11:56:24 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-653a8143-66b8-4cae-a453-1a753fbcf05e
16/03/17 11:56:24 INFO MemoryStore: MemoryStore started with capacity 1080.8 MB
16/03/17 11:56:24 INFO HttpFileServer: HTTP File server directory is /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/httpd-76dccbef-c1f7-4229-9d03-4bb9e4262f6b
16/03/17 11:56:24 INFO HttpServer: Starting HTTP Server
16/03/17 11:56:24 INFO Utils: Successfully started service 'HTTP file server' on port 40042.
16/03/17 11:56:24 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 11:56:24 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 11:56:24 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 11:56:24 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-f06d6904-21db-40d6-b7b0-486e11c890b8/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 11:56:24 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458195984513
16/03/17 11:56:24 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 11:56:24 INFO Executor: Starting executor ID driver on host localhost
16/03/17 11:56:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54943.
16/03/17 11:56:24 INFO NettyBlockTransferService: Server created on 54943
16/03/17 11:56:24 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 11:56:24 INFO BlockManagerMasterEndpoint: Registering block manager localhost:54943 with 1080.8 MB RAM, BlockManagerId(driver, localhost, 54943)
16/03/17 11:56:24 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): arrangement
16/03/17 11:56:24 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:56:24 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:56:24 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:56:24 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:56:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 11:56:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 11:56:24 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:56:24 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1133311426
16/03/17 11:56:24 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1080.8 MB)
16/03/17 11:56:24 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6568, maxMem=1133311426
16/03/17 11:56:24 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 1080.8 MB)
16/03/17 11:56:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:54943 (size: 4.1 KB, free: 1080.8 MB)
16/03/17 11:56:24 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 11:56:24 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:56:24 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 11:56:24 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/17 11:56:24 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 11:56:24 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458195984513
16/03/17 11:56:24 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-f06d6904-21db-40d6-b7b0-486e11c890b8/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: area
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: issue
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: planning
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: permission
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: economy
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: composition
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  arrangement  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: agency
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/17 11:56:32 INFO PythonRunner: Times: total = 8089, boot = 480, init = 370, finish = 7239
16/03/17 11:56:32 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/17 11:56:32 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/17 11:56:32 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 11:56:32 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8211 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: set
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: bend
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: giant
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: astatine
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: present
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: area
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 11:56:33 INFO PythonRunner: Times: total = 374, boot = 198, init = 1, finish = 175
16/03/17 11:56:33 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/17 11:56:33 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 402 ms on localhost (2/2)
16/03/17 11:56:33 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 11:56:33 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.601 s
16/03/17 11:56:33 INFO DAGScheduler: looking for newly runnable stages
16/03/17 11:56:33 INFO DAGScheduler: running: Set()
16/03/17 11:56:33 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 11:56:33 INFO DAGScheduler: failed: Set()
16/03/17 11:56:33 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 11:56:33 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 11:56:33 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10717, maxMem=1133311426
16/03/17 11:56:33 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1080.8 MB)
16/03/17 11:56:33 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15701, maxMem=1133311426
16/03/17 11:56:33 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1080.8 MB)
16/03/17 11:56:33 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:54943 (size: 3.0 KB, free: 1080.8 MB)
16/03/17 11:56:33 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 11:56:33 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:56:33 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 11:56:33 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:56:33 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 11:56:33 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:56:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 11:56:33 INFO PythonRunner: Times: total = 161, boot = 160, init = 1, finish = 0
16/03/17 11:56:33 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 11:56:33 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:56:33 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 11:56:33 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:56:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 11:56:33 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 193 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'composition', 'None']
16/03/17 11:56:33 INFO PythonRunner: Times: total = 207, boot = 206, init = 0, finish = 1
16/03/17 11:56:33 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1287 bytes result sent to driver
16/03/17 11:56:33 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.404 s
16/03/17 11:56:33 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.061378 s
16/03/17 11:56:33 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 234 ms on localhost (2/2)
16/03/17 11:56:33 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 11:56:33 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:56:33 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:56:33 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:56:33 INFO DAGScheduler: Parents of final stage: List()
16/03/17 11:56:33 INFO DAGScheduler: Missing parents: List()
16/03/17 11:56:33 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:56:33 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18757, maxMem=1133311426
16/03/17 11:56:33 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1080.8 MB)
16/03/17 11:56:33 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24573, maxMem=1133311426
16/03/17 11:56:33 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1080.8 MB)
16/03/17 11:56:33 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:54943 (size: 3.3 KB, free: 1080.8 MB)
16/03/17 11:56:33 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 11:56:33 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:56:33 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 11:56:33 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 11:56:33 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 11:56:34 INFO PythonRunner: Times: total = 90, boot = 90, init = 0, finish = 0
16/03/17 11:56:34 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 11:56:34 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2368 bytes)
16/03/17 11:56:34 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 97 ms on localhost (1/2)
16/03/17 11:56:34 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 11:56:34 INFO PythonRunner: Times: total = 211, boot = 211, init = 0, finish = 0
16/03/17 11:56:34 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1355 bytes result sent to driver
16/03/17 11:56:34 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 218 ms on localhost (2/2)
16/03/17 11:56:34 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 11:56:34 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.308 s
16/03/17 11:56:34 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.338578 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/17 11:56:34 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 11:56:34 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 11:56:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 11:56:34 INFO MemoryStore: MemoryStore cleared
16/03/17 11:56:34 INFO BlockManager: BlockManager stopped
16/03/17 11:56:34 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 11:56:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 11:56:34 INFO SparkContext: Successfully stopped SparkContext
16/03/17 11:56:34 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 11:56:34 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'composition', u'None']
16/03/17 11:56:35 INFO SparkContext: Running Spark version 1.5.2
16/03/17 11:56:35 INFO SecurityManager: Changing view acls to: root
16/03/17 11:56:35 INFO SecurityManager: Changing modify acls to: root
16/03/17 11:56:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 11:56:35 INFO Slf4jLogger: Slf4jLogger started
16/03/17 11:56:35 INFO Remoting: Starting remoting
16/03/17 11:56:35 INFO Utils: Successfully started service 'sparkDriver' on port 37297.
16/03/17 11:56:35 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:37297]
16/03/17 11:56:35 INFO SparkEnv: Registering MapOutputTracker
16/03/17 11:56:35 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 11:56:35 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-eefd49c2-8047-466b-ad3d-3e9f992c5c4b
16/03/17 11:56:35 INFO MemoryStore: MemoryStore started with capacity 1080.8 MB
16/03/17 11:56:35 INFO HttpFileServer: HTTP File server directory is /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/httpd-31345a9c-8901-4af8-b73d-8e06aa359167
16/03/17 11:56:35 INFO HttpServer: Starting HTTP Server
16/03/17 11:56:35 INFO Utils: Successfully started service 'HTTP file server' on port 45526.
16/03/17 11:56:35 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 11:56:35 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 11:56:35 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 11:56:35 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-3d6db9ab-29da-4e7e-9217-6a1b28d5cb4b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 11:56:35 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458195995532
16/03/17 11:56:35 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 11:56:35 INFO Executor: Starting executor ID driver on host localhost
16/03/17 11:56:35 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54626.
16/03/17 11:56:35 INFO NettyBlockTransferService: Server created on 54626
16/03/17 11:56:35 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 11:56:35 INFO BlockManagerMasterEndpoint: Registering block manager localhost:54626 with 1080.8 MB RAM, BlockManagerId(driver, localhost, 54626)
16/03/17 11:56:35 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): parts
16/03/17 11:56:35 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:56:35 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:56:35 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:56:35 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:56:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 11:56:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 11:56:35 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:56:35 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1133311426
16/03/17 11:56:35 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1080.8 MB)
16/03/17 11:56:35 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6568, maxMem=1133311426
16/03/17 11:56:35 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 1080.8 MB)
16/03/17 11:56:35 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:54626 (size: 4.1 KB, free: 1080.8 MB)
16/03/17 11:56:35 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 11:56:35 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:56:35 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 11:56:35 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/17 11:56:35 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 11:56:35 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458195995532
16/03/17 11:56:35 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-3d6db9ab-29da-4e7e-9217-6a1b28d5cb4b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: area
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: issue
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: planning
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: permission
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: economy
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: composition
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  parts  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: agency
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/17 11:56:44 INFO PythonRunner: Times: total = 8242, boot = 488, init = 356, finish = 7398
16/03/17 11:56:44 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/17 11:56:44 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/17 11:56:44 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 11:56:44 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8368 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: set
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: bend
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: giant
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: astatine
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: present
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: area
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 11:56:44 INFO PythonRunner: Times: total = 345, boot = 239, init = 1, finish = 105
16/03/17 11:56:44 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/17 11:56:44 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 367 ms on localhost (2/2)
16/03/17 11:56:44 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.730 s
16/03/17 11:56:44 INFO DAGScheduler: looking for newly runnable stages
16/03/17 11:56:44 INFO DAGScheduler: running: Set()
16/03/17 11:56:44 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 11:56:44 INFO DAGScheduler: failed: Set()
16/03/17 11:56:44 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 11:56:44 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 11:56:44 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 11:56:44 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10717, maxMem=1133311426
16/03/17 11:56:44 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1080.8 MB)
16/03/17 11:56:44 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15701, maxMem=1133311426
16/03/17 11:56:44 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1080.8 MB)
16/03/17 11:56:44 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:54626 (size: 3.0 KB, free: 1080.8 MB)
16/03/17 11:56:44 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 11:56:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:56:44 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 11:56:44 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:56:44 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 11:56:44 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:56:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 11:56:44 INFO PythonRunner: Times: total = 175, boot = 174, init = 0, finish = 1
16/03/17 11:56:44 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 11:56:44 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:56:44 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 11:56:44 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:56:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 11:56:44 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 205 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'composition', 'None']
16/03/17 11:56:44 INFO PythonRunner: Times: total = 220, boot = 219, init = 0, finish = 1
16/03/17 11:56:44 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1287 bytes result sent to driver
16/03/17 11:56:44 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.416 s
16/03/17 11:56:44 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 239 ms on localhost (2/2)
16/03/17 11:56:44 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 11:56:44 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.185803 s
16/03/17 11:56:44 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:56:44 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:56:44 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:56:44 INFO DAGScheduler: Parents of final stage: List()
16/03/17 11:56:44 INFO DAGScheduler: Missing parents: List()
16/03/17 11:56:44 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:56:44 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18757, maxMem=1133311426
16/03/17 11:56:44 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1080.8 MB)
16/03/17 11:56:44 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24573, maxMem=1133311426
16/03/17 11:56:44 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1080.8 MB)
16/03/17 11:56:44 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:54626 (size: 3.3 KB, free: 1080.8 MB)
16/03/17 11:56:44 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 11:56:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:56:45 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 11:56:45 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 11:56:45 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 11:56:45 INFO PythonRunner: Times: total = 96, boot = 96, init = 0, finish = 0
16/03/17 11:56:45 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 11:56:45 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2368 bytes)
16/03/17 11:56:45 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 11:56:45 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 103 ms on localhost (1/2)
16/03/17 11:56:45 INFO PythonRunner: Times: total = 237, boot = 237, init = 0, finish = 0
16/03/17 11:56:45 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1355 bytes result sent to driver
16/03/17 11:56:45 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 244 ms on localhost (2/2)
16/03/17 11:56:45 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.348 s
16/03/17 11:56:45 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.380947 s
16/03/17 11:56:45 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/17 11:56:45 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 11:56:45 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 11:56:45 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 11:56:45 INFO MemoryStore: MemoryStore cleared
16/03/17 11:56:45 INFO BlockManager: BlockManager stopped
16/03/17 11:56:45 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 11:56:45 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 11:56:45 INFO SparkContext: Successfully stopped SparkContext
16/03/17 11:56:45 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 11:56:45 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'composition', u'None']
16/03/17 11:56:46 INFO SparkContext: Running Spark version 1.5.2
16/03/17 11:56:46 INFO SecurityManager: Changing view acls to: root
16/03/17 11:56:46 INFO SecurityManager: Changing modify acls to: root
16/03/17 11:56:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 11:56:46 INFO Slf4jLogger: Slf4jLogger started
16/03/17 11:56:46 INFO Remoting: Starting remoting
16/03/17 11:56:46 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:44211]
16/03/17 11:56:46 INFO Utils: Successfully started service 'sparkDriver' on port 44211.
16/03/17 11:56:46 INFO SparkEnv: Registering MapOutputTracker
16/03/17 11:56:46 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 11:56:46 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c528d06c-7d18-4c26-9249-e7bca6b699e3
16/03/17 11:56:46 INFO MemoryStore: MemoryStore started with capacity 1080.8 MB
16/03/17 11:56:46 INFO HttpFileServer: HTTP File server directory is /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/httpd-13044c23-cd39-4a0a-8009-4e3875f6943a
16/03/17 11:56:46 INFO HttpServer: Starting HTTP Server
16/03/17 11:56:46 INFO Utils: Successfully started service 'HTTP file server' on port 45773.
16/03/17 11:56:46 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 11:56:46 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 11:56:46 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 11:56:46 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-53da1773-077f-46f5-9918-a9d9eac93cc0/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 11:56:46 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196006619
16/03/17 11:56:46 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 11:56:46 INFO Executor: Starting executor ID driver on host localhost
16/03/17 11:56:47 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35814.
16/03/17 11:56:47 INFO NettyBlockTransferService: Server created on 35814
16/03/17 11:56:47 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 11:56:47 INFO BlockManagerMasterEndpoint: Registering block manager localhost:35814 with 1080.8 MB RAM, BlockManagerId(driver, localhost, 35814)
16/03/17 11:56:47 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): speech
16/03/17 11:56:47 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:56:47 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:56:47 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:56:47 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:56:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 11:56:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 11:56:47 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:56:47 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1133311426
16/03/17 11:56:47 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1080.8 MB)
16/03/17 11:56:47 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6568, maxMem=1133311426
16/03/17 11:56:47 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 1080.8 MB)
16/03/17 11:56:47 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:35814 (size: 4.1 KB, free: 1080.8 MB)
16/03/17 11:56:47 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 11:56:47 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:56:47 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 11:56:47 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/17 11:56:47 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 11:56:47 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196006619
16/03/17 11:56:47 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-53da1773-077f-46f5-9918-a9d9eac93cc0/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: area
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: issue
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: planning
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: permission
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: economy
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: composition
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: agency
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 11:56:55 INFO PythonRunner: Times: total = 8140, boot = 492, init = 367, finish = 7281
16/03/17 11:56:55 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/17 11:56:55 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/17 11:56:55 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 11:56:55 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8224 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: set
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: bend
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: giant
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: astatine
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: present
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  speech  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: area
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/17 11:56:55 INFO PythonRunner: Times: total = 298, boot = 193, init = 1, finish = 104
16/03/17 11:56:55 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/17 11:56:55 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.532 s
16/03/17 11:56:55 INFO DAGScheduler: looking for newly runnable stages
16/03/17 11:56:55 INFO DAGScheduler: running: Set()
16/03/17 11:56:55 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 11:56:55 INFO DAGScheduler: failed: Set()
16/03/17 11:56:55 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 11:56:55 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 11:56:55 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10717, maxMem=1133311426
16/03/17 11:56:55 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1080.8 MB)
16/03/17 11:56:55 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15701, maxMem=1133311426
16/03/17 11:56:55 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1080.8 MB)
16/03/17 11:56:55 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 309 ms on localhost (2/2)
16/03/17 11:56:55 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 11:56:55 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:35814 (size: 3.0 KB, free: 1080.8 MB)
16/03/17 11:56:55 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 11:56:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:56:55 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 11:56:55 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:56:55 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 11:56:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:56:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 11:56:55 INFO PythonRunner: Times: total = 210, boot = 209, init = 0, finish = 1
16/03/17 11:56:55 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 11:56:55 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:56:55 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 11:56:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:56:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
16/03/17 11:56:55 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 235 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'present']
16/03/17 11:56:56 INFO PythonRunner: Times: total = 198, boot = 197, init = 0, finish = 1
16/03/17 11:56:56 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/17 11:56:56 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 210 ms on localhost (2/2)
16/03/17 11:56:56 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 11:56:56 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.426 s
16/03/17 11:56:56 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.997841 s
16/03/17 11:56:56 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:56:56 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:56:56 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:56:56 INFO DAGScheduler: Parents of final stage: List()
16/03/17 11:56:56 INFO DAGScheduler: Missing parents: List()
16/03/17 11:56:56 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:56:56 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18757, maxMem=1133311426
16/03/17 11:56:56 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1080.8 MB)
16/03/17 11:56:56 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24573, maxMem=1133311426
16/03/17 11:56:56 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1080.8 MB)
16/03/17 11:56:56 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:35814 (size: 3.3 KB, free: 1080.8 MB)
16/03/17 11:56:56 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 11:56:56 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:56:56 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 11:56:56 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 11:56:56 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 11:56:56 INFO PythonRunner: Times: total = 84, boot = 84, init = 0, finish = 0
16/03/17 11:56:56 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 11:56:56 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/17 11:56:56 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 91 ms on localhost (1/2)
16/03/17 11:56:56 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 11:56:56 INFO PythonRunner: Times: total = 200, boot = 199, init = 0, finish = 1
16/03/17 11:56:56 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1351 bytes result sent to driver
16/03/17 11:56:56 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 206 ms on localhost (2/2)
16/03/17 11:56:56 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 11:56:56 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.297 s
16/03/17 11:56:56 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.349972 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/17 11:56:56 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 11:56:56 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 11:56:56 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 11:56:56 INFO MemoryStore: MemoryStore cleared
16/03/17 11:56:56 INFO BlockManager: BlockManager stopped
16/03/17 11:56:56 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 11:56:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 11:56:56 INFO SparkContext: Successfully stopped SparkContext
16/03/17 11:56:56 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 11:56:56 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 11:56:56 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'present']
16/03/17 11:56:57 INFO SparkContext: Running Spark version 1.5.2
16/03/17 11:56:57 INFO SecurityManager: Changing view acls to: root
16/03/17 11:56:57 INFO SecurityManager: Changing modify acls to: root
16/03/17 11:56:57 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 11:56:57 INFO Slf4jLogger: Slf4jLogger started
16/03/17 11:56:57 INFO Remoting: Starting remoting
16/03/17 11:56:57 INFO Utils: Successfully started service 'sparkDriver' on port 35547.
16/03/17 11:56:57 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:35547]
16/03/17 11:56:57 INFO SparkEnv: Registering MapOutputTracker
16/03/17 11:56:57 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 11:56:57 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1c132859-8369-4c8e-b7ff-1d2530fee814
16/03/17 11:56:57 INFO MemoryStore: MemoryStore started with capacity 1082.3 MB
16/03/17 11:56:57 INFO HttpFileServer: HTTP File server directory is /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/httpd-d99e0d3d-3a2b-4c74-a9ed-82f0de8b8983
16/03/17 11:56:57 INFO HttpServer: Starting HTTP Server
16/03/17 11:56:57 INFO Utils: Successfully started service 'HTTP file server' on port 60965.
16/03/17 11:56:57 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 11:56:57 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 11:56:57 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 11:56:57 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-8303583d-6248-46d3-b100-cd72a7291e58/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 11:56:57 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196017853
16/03/17 11:56:57 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 11:56:57 INFO Executor: Starting executor ID driver on host localhost
16/03/17 11:56:57 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36638.
16/03/17 11:56:57 INFO NettyBlockTransferService: Server created on 36638
16/03/17 11:56:57 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 11:56:57 INFO BlockManagerMasterEndpoint: Registering block manager localhost:36638 with 1082.3 MB RAM, BlockManagerId(driver, localhost, 36638)
16/03/17 11:56:57 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): geographical
16/03/17 11:56:58 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:56:58 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:56:58 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:56:58 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:56:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 11:56:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 11:56:58 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:56:58 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1134868561
16/03/17 11:56:58 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1082.3 MB)
16/03/17 11:56:58 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6568, maxMem=1134868561
16/03/17 11:56:58 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 1082.3 MB)
16/03/17 11:56:58 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:36638 (size: 4.1 KB, free: 1082.3 MB)
16/03/17 11:56:58 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 11:56:58 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:56:58 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 11:56:58 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/17 11:56:58 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 11:56:58 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196017853
16/03/17 11:56:58 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-8303583d-6248-46d3-b100-cd72a7291e58/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: area
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  geographical  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: issue
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: planning
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: permission
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: economy
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: composition
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: agency
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/17 11:57:06 INFO PythonRunner: Times: total = 8196, boot = 486, init = 411, finish = 7299
16/03/17 11:57:06 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/17 11:57:06 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/17 11:57:06 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8274 ms on localhost (1/2)
16/03/17 11:57:06 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: set
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: bend
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: giant
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: astatine
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: present
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: area
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  geographical  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/17 11:57:06 INFO PythonRunner: Times: total = 305, boot = 192, init = 1, finish = 112
16/03/17 11:57:06 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/17 11:57:06 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 332 ms on localhost (2/2)
16/03/17 11:57:06 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 11:57:06 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.610 s
16/03/17 11:57:06 INFO DAGScheduler: looking for newly runnable stages
16/03/17 11:57:06 INFO DAGScheduler: running: Set()
16/03/17 11:57:06 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 11:57:06 INFO DAGScheduler: failed: Set()
16/03/17 11:57:06 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 11:57:06 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 11:57:06 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10717, maxMem=1134868561
16/03/17 11:57:06 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1082.3 MB)
16/03/17 11:57:06 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15701, maxMem=1134868561
16/03/17 11:57:06 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1082.3 MB)
16/03/17 11:57:06 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:36638 (size: 3.0 KB, free: 1082.3 MB)
16/03/17 11:57:06 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 11:57:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:57:06 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 11:57:06 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:57:06 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 11:57:06 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:57:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 11:57:06 INFO PythonRunner: Times: total = 205, boot = 204, init = 1, finish = 0
16/03/17 11:57:06 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 11:57:06 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:57:06 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 11:57:06 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:57:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 11:57:06 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 233 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'area', 'None', u'area']
16/03/17 11:57:07 INFO PythonRunner: Times: total = 204, boot = 203, init = 0, finish = 1
16/03/17 11:57:07 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/17 11:57:07 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.419 s
16/03/17 11:57:07 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.072831 s
16/03/17 11:57:07 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 215 ms on localhost (2/2)
16/03/17 11:57:07 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 11:57:07 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:57:07 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:57:07 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:57:07 INFO DAGScheduler: Parents of final stage: List()
16/03/17 11:57:07 INFO DAGScheduler: Missing parents: List()
16/03/17 11:57:07 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:57:07 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18757, maxMem=1134868561
16/03/17 11:57:07 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1082.3 MB)
16/03/17 11:57:07 INFO MemoryStore: ensureFreeSpace(3377) called with curMem=24573, maxMem=1134868561
16/03/17 11:57:07 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1082.3 MB)
16/03/17 11:57:07 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:36638 (size: 3.3 KB, free: 1082.3 MB)
16/03/17 11:57:07 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 11:57:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:57:07 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 11:57:07 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 11:57:07 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 11:57:07 INFO PythonRunner: Times: total = 46, boot = 46, init = 0, finish = 0
16/03/17 11:57:07 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 11:57:07 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/17 11:57:07 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 52 ms on localhost (1/2)
16/03/17 11:57:07 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 11:57:07 INFO PythonRunner: Times: total = 203, boot = 202, init = 1, finish = 0
16/03/17 11:57:07 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/03/17 11:57:07 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 208 ms on localhost (2/2)
16/03/17 11:57:07 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 11:57:07 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.254 s
16/03/17 11:57:07 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.298251 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/17 11:57:07 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 11:57:07 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 11:57:07 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 11:57:07 INFO MemoryStore: MemoryStore cleared
16/03/17 11:57:07 INFO BlockManager: BlockManager stopped
16/03/17 11:57:07 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 11:57:07 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 11:57:07 INFO SparkContext: Successfully stopped SparkContext
16/03/17 11:57:07 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 11:57:07 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 11:57:07 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'area', u'None', u'area']
16/03/17 11:57:08 INFO SparkContext: Running Spark version 1.5.2
16/03/17 11:57:08 INFO SecurityManager: Changing view acls to: root
16/03/17 11:57:08 INFO SecurityManager: Changing modify acls to: root
16/03/17 11:57:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 11:57:08 INFO Slf4jLogger: Slf4jLogger started
16/03/17 11:57:08 INFO Remoting: Starting remoting
16/03/17 11:57:08 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:42021]
16/03/17 11:57:08 INFO Utils: Successfully started service 'sparkDriver' on port 42021.
16/03/17 11:57:08 INFO SparkEnv: Registering MapOutputTracker
16/03/17 11:57:08 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 11:57:08 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f372100c-d417-4553-986a-b084b8d6c411
16/03/17 11:57:08 INFO MemoryStore: MemoryStore started with capacity 1082.3 MB
16/03/17 11:57:08 INFO HttpFileServer: HTTP File server directory is /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/httpd-b84b0884-7386-40fd-ae30-179bddf1beaa
16/03/17 11:57:08 INFO HttpServer: Starting HTTP Server
16/03/17 11:57:08 INFO Utils: Successfully started service 'HTTP file server' on port 41937.
16/03/17 11:57:08 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 11:57:09 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 11:57:09 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 11:57:09 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-90acd462-450a-404b-9533-3baaebdc47d5/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 11:57:09 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196029038
16/03/17 11:57:09 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 11:57:09 INFO Executor: Starting executor ID driver on host localhost
16/03/17 11:57:09 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 48507.
16/03/17 11:57:09 INFO NettyBlockTransferService: Server created on 48507
16/03/17 11:57:09 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 11:57:09 INFO BlockManagerMasterEndpoint: Registering block manager localhost:48507 with 1082.3 MB RAM, BlockManagerId(driver, localhost, 48507)
16/03/17 11:57:09 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): spatial
16/03/17 11:57:09 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:57:09 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:57:09 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:57:09 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:57:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 11:57:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 11:57:09 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:57:09 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1134868561
16/03/17 11:57:09 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1082.3 MB)
16/03/17 11:57:09 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6568, maxMem=1134868561
16/03/17 11:57:09 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 1082.3 MB)
16/03/17 11:57:09 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:48507 (size: 4.1 KB, free: 1082.3 MB)
16/03/17 11:57:09 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 11:57:09 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:57:09 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 11:57:09 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/17 11:57:09 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 11:57:09 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196029038
16/03/17 11:57:09 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-90acd462-450a-404b-9533-3baaebdc47d5/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: area
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: issue
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: planning
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: permission
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: economy
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: composition
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  spatial  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: agency
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/17 11:57:17 INFO PythonRunner: Times: total = 8102, boot = 509, init = 379, finish = 7214
16/03/17 11:57:17 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/17 11:57:17 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/17 11:57:17 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 11:57:17 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8188 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: set
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: bend
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: giant
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: astatine
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: present
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: area
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 11:57:17 INFO PythonRunner: Times: total = 304, boot = 206, init = 1, finish = 97
16/03/17 11:57:17 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/17 11:57:17 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 328 ms on localhost (2/2)
16/03/17 11:57:17 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 11:57:17 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.510 s
16/03/17 11:57:17 INFO DAGScheduler: looking for newly runnable stages
16/03/17 11:57:17 INFO DAGScheduler: running: Set()
16/03/17 11:57:17 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 11:57:17 INFO DAGScheduler: failed: Set()
16/03/17 11:57:17 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 11:57:17 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 11:57:17 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10717, maxMem=1134868561
16/03/17 11:57:17 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1082.3 MB)
16/03/17 11:57:17 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15701, maxMem=1134868561
16/03/17 11:57:17 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1082.3 MB)
16/03/17 11:57:17 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:48507 (size: 3.0 KB, free: 1082.3 MB)
16/03/17 11:57:17 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 11:57:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:57:17 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 11:57:17 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:57:17 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 11:57:17 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/17 11:57:17 INFO PythonRunner: Times: total = 191, boot = 190, init = 1, finish = 0
16/03/17 11:57:17 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 11:57:17 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:57:17 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 11:57:17 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:57:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 11:57:17 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 221 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'composition', 'None']
16/03/17 11:57:18 INFO PythonRunner: Times: total = 191, boot = 190, init = 0, finish = 1
16/03/17 11:57:18 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1287 bytes result sent to driver
16/03/17 11:57:18 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.414 s
16/03/17 11:57:18 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 203 ms on localhost (2/2)
16/03/17 11:57:18 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.954729 s
16/03/17 11:57:18 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 11:57:18 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:57:18 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:57:18 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:57:18 INFO DAGScheduler: Parents of final stage: List()
16/03/17 11:57:18 INFO DAGScheduler: Missing parents: List()
16/03/17 11:57:18 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:57:18 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18757, maxMem=1134868561
16/03/17 11:57:18 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1082.3 MB)
16/03/17 11:57:18 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24573, maxMem=1134868561
16/03/17 11:57:18 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1082.3 MB)
16/03/17 11:57:18 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:48507 (size: 3.3 KB, free: 1082.3 MB)
16/03/17 11:57:18 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 11:57:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:57:18 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 11:57:18 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 11:57:18 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 11:57:18 INFO PythonRunner: Times: total = 132, boot = 132, init = 0, finish = 0
16/03/17 11:57:18 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 11:57:18 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2368 bytes)
16/03/17 11:57:18 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 141 ms on localhost (1/2)
16/03/17 11:57:18 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 11:57:18 INFO PythonRunner: Times: total = 205, boot = 205, init = 0, finish = 0
16/03/17 11:57:18 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1355 bytes result sent to driver
16/03/17 11:57:18 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 214 ms on localhost (2/2)
16/03/17 11:57:18 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.342 s
16/03/17 11:57:18 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 11:57:18 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.374294 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/17 11:57:18 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 11:57:18 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 11:57:18 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 11:57:18 INFO MemoryStore: MemoryStore cleared
16/03/17 11:57:18 INFO BlockManager: BlockManager stopped
16/03/17 11:57:18 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 11:57:18 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 11:57:18 INFO SparkContext: Successfully stopped SparkContext
16/03/17 11:57:18 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 11:57:18 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 11:57:18 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'composition', u'None']
16/03/17 11:57:19 INFO SparkContext: Running Spark version 1.5.2
16/03/17 11:57:19 INFO SecurityManager: Changing view acls to: root
16/03/17 11:57:19 INFO SecurityManager: Changing modify acls to: root
16/03/17 11:57:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 11:57:19 INFO Slf4jLogger: Slf4jLogger started
16/03/17 11:57:19 INFO Remoting: Starting remoting
16/03/17 11:57:19 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:36925]
16/03/17 11:57:19 INFO Utils: Successfully started service 'sparkDriver' on port 36925.
16/03/17 11:57:19 INFO SparkEnv: Registering MapOutputTracker
16/03/17 11:57:19 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 11:57:19 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f313a7eb-429a-42f5-8155-3e9c589597c9
16/03/17 11:57:19 INFO MemoryStore: MemoryStore started with capacity 1082.3 MB
16/03/17 11:57:19 INFO HttpFileServer: HTTP File server directory is /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/httpd-e6492e54-9b3a-4fea-9b34-dad8df50a7f3
16/03/17 11:57:19 INFO HttpServer: Starting HTTP Server
16/03/17 11:57:19 INFO Utils: Successfully started service 'HTTP file server' on port 53715.
16/03/17 11:57:19 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 11:57:20 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 11:57:20 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 11:57:20 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-aa0ad029-8250-493c-a757-d3bec7e6f609/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 11:57:20 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196040070
16/03/17 11:57:20 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 11:57:20 INFO Executor: Starting executor ID driver on host localhost
16/03/17 11:57:20 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51673.
16/03/17 11:57:20 INFO NettyBlockTransferService: Server created on 51673
16/03/17 11:57:20 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 11:57:20 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51673 with 1082.3 MB RAM, BlockManagerId(driver, localhost, 51673)
16/03/17 11:57:20 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): Nadu
16/03/17 11:57:20 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:57:20 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:57:20 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:57:20 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:57:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 11:57:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 11:57:20 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:57:20 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1134868561
16/03/17 11:57:20 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1082.3 MB)
16/03/17 11:57:20 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6568, maxMem=1134868561
16/03/17 11:57:20 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 1082.3 MB)
16/03/17 11:57:20 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51673 (size: 4.1 KB, free: 1082.3 MB)
16/03/17 11:57:20 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 11:57:20 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:57:20 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 11:57:20 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/17 11:57:20 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 11:57:20 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196040070
16/03/17 11:57:20 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-aa0ad029-8250-493c-a757-d3bec7e6f609/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: area
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: issue
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: planning
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: permission
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: economy
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: composition
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: agency
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Nadu  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/17 11:57:28 INFO PythonRunner: Times: total = 7906, boot = 521, init = 377, finish = 7008
16/03/17 11:57:28 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/17 11:57:28 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/17 11:57:28 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 11:57:28 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8012 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: set
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: bend
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: giant
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: astatine
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: present
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Nadu  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: area
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/17 11:57:28 INFO PythonRunner: Times: total = 313, boot = 208, init = 1, finish = 104
16/03/17 11:57:28 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/17 11:57:28 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.355 s
16/03/17 11:57:28 INFO DAGScheduler: looking for newly runnable stages
16/03/17 11:57:28 INFO DAGScheduler: running: Set()
16/03/17 11:57:28 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 11:57:28 INFO DAGScheduler: failed: Set()
16/03/17 11:57:28 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 11:57:28 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 11:57:28 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 348 ms on localhost (2/2)
16/03/17 11:57:28 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 11:57:28 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10717, maxMem=1134868561
16/03/17 11:57:28 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1082.3 MB)
16/03/17 11:57:28 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15701, maxMem=1134868561
16/03/17 11:57:28 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1082.3 MB)
16/03/17 11:57:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51673 (size: 3.0 KB, free: 1082.3 MB)
16/03/17 11:57:28 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 11:57:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:57:28 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 11:57:28 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:57:28 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 11:57:28 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 11:57:28 INFO PythonRunner: Times: total = 230, boot = 230, init = 0, finish = 0
16/03/17 11:57:28 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 11:57:28 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:57:28 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 11:57:28 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:57:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 11:57:28 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 260 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'Chennai', 'None', u'Chennai']
16/03/17 11:57:29 INFO PythonRunner: Times: total = 193, boot = 192, init = 1, finish = 0
16/03/17 11:57:29 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1297 bytes result sent to driver
16/03/17 11:57:29 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.453 s
16/03/17 11:57:29 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.843400 s
16/03/17 11:57:29 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 203 ms on localhost (2/2)
16/03/17 11:57:29 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 11:57:29 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:57:29 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:57:29 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:57:29 INFO DAGScheduler: Parents of final stage: List()
16/03/17 11:57:29 INFO DAGScheduler: Missing parents: List()
16/03/17 11:57:29 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:57:29 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18757, maxMem=1134868561
16/03/17 11:57:29 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1082.3 MB)
16/03/17 11:57:29 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24573, maxMem=1134868561
16/03/17 11:57:29 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1082.3 MB)
16/03/17 11:57:29 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:51673 (size: 3.3 KB, free: 1082.3 MB)
16/03/17 11:57:29 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 11:57:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:57:29 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 11:57:29 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 11:57:29 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 11:57:29 INFO PythonRunner: Times: total = 103, boot = 102, init = 1, finish = 0
16/03/17 11:57:29 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 11:57:29 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2378 bytes)
16/03/17 11:57:29 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 112 ms on localhost (1/2)
16/03/17 11:57:29 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 11:57:29 INFO PythonRunner: Times: total = 232, boot = 232, init = 0, finish = 0
16/03/17 11:57:29 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1365 bytes result sent to driver
16/03/17 11:57:29 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 240 ms on localhost (2/2)
16/03/17 11:57:29 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 11:57:29 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.353 s
16/03/17 11:57:29 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.411163 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/17 11:57:29 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 11:57:29 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 11:57:29 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 11:57:29 INFO MemoryStore: MemoryStore cleared
16/03/17 11:57:29 INFO BlockManager: BlockManager stopped
16/03/17 11:57:29 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 11:57:29 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 11:57:29 INFO SparkContext: Successfully stopped SparkContext
16/03/17 11:57:29 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 11:57:29 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 11:57:29 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'Chennai', u'None', u'Chennai']
16/03/17 11:57:30 INFO SparkContext: Running Spark version 1.5.2
16/03/17 11:57:30 INFO SecurityManager: Changing view acls to: root
16/03/17 11:57:30 INFO SecurityManager: Changing modify acls to: root
16/03/17 11:57:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 11:57:30 INFO Slf4jLogger: Slf4jLogger started
16/03/17 11:57:30 INFO Remoting: Starting remoting
16/03/17 11:57:30 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:37627]
16/03/17 11:57:30 INFO Utils: Successfully started service 'sparkDriver' on port 37627.
16/03/17 11:57:30 INFO SparkEnv: Registering MapOutputTracker
16/03/17 11:57:30 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 11:57:30 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-6d803761-16cc-4a9d-8e6c-4f83a6519f22
16/03/17 11:57:30 INFO MemoryStore: MemoryStore started with capacity 1082.3 MB
16/03/17 11:57:30 INFO HttpFileServer: HTTP File server directory is /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/httpd-80d84eb3-c54a-45a2-85c2-58503bcd57c5
16/03/17 11:57:30 INFO HttpServer: Starting HTTP Server
16/03/17 11:57:30 INFO Utils: Successfully started service 'HTTP file server' on port 44262.
16/03/17 11:57:30 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 11:57:30 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 11:57:30 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 11:57:31 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-c94390a9-2abf-4db2-8caa-f5bf98df2646/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 11:57:31 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196051023
16/03/17 11:57:31 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 11:57:31 INFO Executor: Starting executor ID driver on host localhost
16/03/17 11:57:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58623.
16/03/17 11:57:31 INFO NettyBlockTransferService: Server created on 58623
16/03/17 11:57:31 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 11:57:31 INFO BlockManagerMasterEndpoint: Registering block manager localhost:58623 with 1082.3 MB RAM, BlockManagerId(driver, localhost, 58623)
16/03/17 11:57:31 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): circular
16/03/17 11:57:31 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:57:31 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:57:31 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:57:31 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:57:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 11:57:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 11:57:31 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:57:31 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1134868561
16/03/17 11:57:31 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1082.3 MB)
16/03/17 11:57:31 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6568, maxMem=1134868561
16/03/17 11:57:31 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 1082.3 MB)
16/03/17 11:57:31 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:58623 (size: 4.1 KB, free: 1082.3 MB)
16/03/17 11:57:31 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 11:57:31 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:57:31 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 11:57:31 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/17 11:57:31 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 11:57:31 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196051023
16/03/17 11:57:31 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-c94390a9-2abf-4db2-8caa-f5bf98df2646/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: area
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: issue
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: planning
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: permission
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: economy
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: composition
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: agency
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 11:57:39 INFO PythonRunner: Times: total = 8052, boot = 490, init = 378, finish = 7184
16/03/17 11:57:39 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/17 11:57:39 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/17 11:57:39 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 11:57:39 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8204 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: set
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: bend
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): adding to parents: syn =  Synset('bend.n.01') ; keyword:  circular  in syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= [u'bend']
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: giant
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: astatine
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: present
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: area
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
16/03/17 11:57:39 INFO PythonRunner: Times: total = 365, boot = 247, init = 0, finish = 118
16/03/17 11:57:39 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/17 11:57:39 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 403 ms on localhost (2/2)
16/03/17 11:57:39 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 11:57:39 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.548 s
16/03/17 11:57:39 INFO DAGScheduler: looking for newly runnable stages
16/03/17 11:57:39 INFO DAGScheduler: running: Set()
16/03/17 11:57:39 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 11:57:39 INFO DAGScheduler: failed: Set()
16/03/17 11:57:39 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 11:57:39 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 11:57:39 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10717, maxMem=1134868561
16/03/17 11:57:39 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1082.3 MB)
16/03/17 11:57:39 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15701, maxMem=1134868561
16/03/17 11:57:39 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1082.3 MB)
16/03/17 11:57:39 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:58623 (size: 3.0 KB, free: 1082.3 MB)
16/03/17 11:57:39 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 11:57:39 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:57:39 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 11:57:39 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:57:39 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 11:57:39 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:57:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 11:57:40 INFO PythonRunner: Times: total = 202, boot = 201, init = 0, finish = 1
16/03/17 11:57:40 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 11:57:40 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:57:40 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 11:57:40 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 215 ms on localhost (1/2)
16/03/17 11:57:40 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:57:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'bend']
16/03/17 11:57:40 INFO PythonRunner: Times: total = 180, boot = 178, init = 1, finish = 1
16/03/17 11:57:40 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1272 bytes result sent to driver
16/03/17 11:57:40 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.421 s
16/03/17 11:57:40 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.054184 s
16/03/17 11:57:40 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 197 ms on localhost (2/2)
16/03/17 11:57:40 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 11:57:40 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:57:40 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:57:40 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:57:40 INFO DAGScheduler: Parents of final stage: List()
16/03/17 11:57:40 INFO DAGScheduler: Missing parents: List()
16/03/17 11:57:40 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:57:40 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18757, maxMem=1134868561
16/03/17 11:57:40 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1082.3 MB)
16/03/17 11:57:40 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24573, maxMem=1134868561
16/03/17 11:57:40 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1082.3 MB)
16/03/17 11:57:40 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:58623 (size: 3.3 KB, free: 1082.3 MB)
16/03/17 11:57:40 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 11:57:40 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:57:40 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 11:57:40 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 11:57:40 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 11:57:40 INFO PythonRunner: Times: total = 111, boot = 110, init = 1, finish = 0
16/03/17 11:57:40 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 11:57:40 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2353 bytes)
16/03/17 11:57:40 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 118 ms on localhost (1/2)
16/03/17 11:57:40 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 11:57:40 INFO PythonRunner: Times: total = 209, boot = 208, init = 1, finish = 0
16/03/17 11:57:40 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1337 bytes result sent to driver
16/03/17 11:57:40 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 219 ms on localhost (2/2)
16/03/17 11:57:40 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 11:57:40 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.327 s
16/03/17 11:57:40 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.358460 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/17 11:57:40 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 11:57:40 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 11:57:40 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 11:57:40 INFO MemoryStore: MemoryStore cleared
16/03/17 11:57:40 INFO BlockManager: BlockManager stopped
16/03/17 11:57:40 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 11:57:40 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 11:57:41 INFO SparkContext: Successfully stopped SparkContext
16/03/17 11:57:41 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 11:57:41 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 11:57:41 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'bend']
16/03/17 11:57:41 INFO SparkContext: Running Spark version 1.5.2
16/03/17 11:57:41 INFO SecurityManager: Changing view acls to: root
16/03/17 11:57:41 INFO SecurityManager: Changing modify acls to: root
16/03/17 11:57:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 11:57:41 INFO Slf4jLogger: Slf4jLogger started
16/03/17 11:57:41 INFO Remoting: Starting remoting
16/03/17 11:57:41 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:55198]
16/03/17 11:57:41 INFO Utils: Successfully started service 'sparkDriver' on port 55198.
16/03/17 11:57:41 INFO SparkEnv: Registering MapOutputTracker
16/03/17 11:57:41 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 11:57:41 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-894d2382-739a-4684-b6e8-91b35b9f3989
16/03/17 11:57:41 INFO MemoryStore: MemoryStore started with capacity 1082.3 MB
16/03/17 11:57:41 INFO HttpFileServer: HTTP File server directory is /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/httpd-6c701cae-0c8b-4192-aaf4-744fdb5492b0
16/03/17 11:57:41 INFO HttpServer: Starting HTTP Server
16/03/17 11:57:42 INFO Utils: Successfully started service 'HTTP file server' on port 36079.
16/03/17 11:57:42 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 11:57:42 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 11:57:42 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 11:57:42 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-3ec93b4a-6f3f-46b3-857c-6358dd627050/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 11:57:42 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196062135
16/03/17 11:57:42 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 11:57:42 INFO Executor: Starting executor ID driver on host localhost
16/03/17 11:57:42 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44416.
16/03/17 11:57:42 INFO NettyBlockTransferService: Server created on 44416
16/03/17 11:57:42 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 11:57:42 INFO BlockManagerMasterEndpoint: Registering block manager localhost:44416 with 1082.3 MB RAM, BlockManagerId(driver, localhost, 44416)
16/03/17 11:57:42 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): product
16/03/17 11:57:42 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:57:42 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:57:42 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:57:42 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:57:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 11:57:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 11:57:42 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:57:42 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1134868561
16/03/17 11:57:42 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1082.3 MB)
16/03/17 11:57:42 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6568, maxMem=1134868561
16/03/17 11:57:42 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 1082.3 MB)
16/03/17 11:57:42 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:44416 (size: 4.1 KB, free: 1082.3 MB)
16/03/17 11:57:42 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 11:57:42 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:57:42 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 11:57:42 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/17 11:57:42 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 11:57:42 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196062135
16/03/17 11:57:42 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-3ec93b4a-6f3f-46b3-857c-6358dd627050/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: area
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: issue
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: planning
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: permission
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: economy
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: composition
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: agency
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 11:57:50 INFO PythonRunner: Times: total = 8040, boot = 514, init = 379, finish = 7147
16/03/17 11:57:50 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/17 11:57:50 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/17 11:57:50 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 11:57:50 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8130 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: set
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: bend
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: giant
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: astatine
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  product  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: present
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: area
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/17 11:57:50 INFO PythonRunner: Times: total = 308, boot = 189, init = 0, finish = 119
16/03/17 11:57:50 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/17 11:57:50 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.456 s
16/03/17 11:57:50 INFO DAGScheduler: looking for newly runnable stages
16/03/17 11:57:50 INFO DAGScheduler: running: Set()
16/03/17 11:57:50 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 11:57:50 INFO DAGScheduler: failed: Set()
16/03/17 11:57:50 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 11:57:50 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 11:57:50 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10717, maxMem=1134868561
16/03/17 11:57:50 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1082.3 MB)
16/03/17 11:57:50 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 332 ms on localhost (2/2)
16/03/17 11:57:50 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 11:57:50 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15701, maxMem=1134868561
16/03/17 11:57:50 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1082.3 MB)
16/03/17 11:57:50 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:44416 (size: 3.0 KB, free: 1082.3 MB)
16/03/17 11:57:50 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 11:57:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:57:50 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 11:57:50 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:57:50 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 11:57:50 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:57:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 11:57:51 INFO PythonRunner: Times: total = 175, boot = 174, init = 0, finish = 1
16/03/17 11:57:51 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 11:57:51 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:57:51 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 11:57:51 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:57:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
16/03/17 11:57:51 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 211 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/03/17 11:57:51 INFO PythonRunner: Times: total = 200, boot = 199, init = 0, finish = 1
16/03/17 11:57:51 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/03/17 11:57:51 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 213 ms on localhost (2/2)
16/03/17 11:57:51 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 11:57:51 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.401 s
16/03/17 11:57:51 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.911170 s
16/03/17 11:57:51 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:57:51 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:57:51 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:57:51 INFO DAGScheduler: Parents of final stage: List()
16/03/17 11:57:51 INFO DAGScheduler: Missing parents: List()
16/03/17 11:57:51 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:57:51 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18757, maxMem=1134868561
16/03/17 11:57:51 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1082.3 MB)
16/03/17 11:57:51 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24573, maxMem=1134868561
16/03/17 11:57:51 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1082.3 MB)
16/03/17 11:57:51 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:44416 (size: 3.3 KB, free: 1082.3 MB)
16/03/17 11:57:51 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 11:57:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:57:51 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 11:57:51 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 11:57:51 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 11:57:51 INFO PythonRunner: Times: total = 16, boot = -19, init = 35, finish = 0
16/03/17 11:57:51 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 11:57:51 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/03/17 11:57:51 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 66 ms on localhost (1/2)
16/03/17 11:57:51 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 11:57:51 INFO PythonRunner: Times: total = 193, boot = 193, init = 0, finish = 0
16/03/17 11:57:51 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/03/17 11:57:51 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 206 ms on localhost (2/2)
16/03/17 11:57:51 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 11:57:51 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.269 s
16/03/17 11:57:51 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.289137 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/17 11:57:51 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 11:57:51 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 11:57:51 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 11:57:51 INFO MemoryStore: MemoryStore cleared
16/03/17 11:57:51 INFO BlockManager: BlockManager stopped
16/03/17 11:57:51 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 11:57:51 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 11:57:51 INFO SparkContext: Successfully stopped SparkContext
16/03/17 11:57:51 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 11:57:51 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 11:57:51 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'astatine']
16/03/17 11:57:52 INFO SparkContext: Running Spark version 1.5.2
16/03/17 11:57:52 INFO SecurityManager: Changing view acls to: root
16/03/17 11:57:52 INFO SecurityManager: Changing modify acls to: root
16/03/17 11:57:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 11:57:52 INFO Slf4jLogger: Slf4jLogger started
16/03/17 11:57:52 INFO Remoting: Starting remoting
16/03/17 11:57:52 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:49037]
16/03/17 11:57:52 INFO Utils: Successfully started service 'sparkDriver' on port 49037.
16/03/17 11:57:52 INFO SparkEnv: Registering MapOutputTracker
16/03/17 11:57:52 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 11:57:52 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-dbb4b8d7-b4a6-4287-ac9d-25e19545652d
16/03/17 11:57:52 INFO MemoryStore: MemoryStore started with capacity 1082.3 MB
16/03/17 11:57:52 INFO HttpFileServer: HTTP File server directory is /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/httpd-38fe5252-ec23-4e8e-8e55-618044d5ac38
16/03/17 11:57:52 INFO HttpServer: Starting HTTP Server
16/03/17 11:57:52 INFO Utils: Successfully started service 'HTTP file server' on port 57625.
16/03/17 11:57:53 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 11:57:53 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 11:57:53 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 11:57:53 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-b874349b-2988-42fb-a9d4-620a686df285/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 11:57:53 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196073092
16/03/17 11:57:53 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 11:57:53 INFO Executor: Starting executor ID driver on host localhost
16/03/17 11:57:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36092.
16/03/17 11:57:53 INFO NettyBlockTransferService: Server created on 36092
16/03/17 11:57:53 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 11:57:53 INFO BlockManagerMasterEndpoint: Registering block manager localhost:36092 with 1082.3 MB RAM, BlockManagerId(driver, localhost, 36092)
16/03/17 11:57:53 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): used
16/03/17 11:57:53 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:57:53 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:57:53 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:57:53 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:57:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 11:57:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 11:57:53 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:57:53 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1134868561
16/03/17 11:57:53 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1082.3 MB)
16/03/17 11:57:53 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6568, maxMem=1134868561
16/03/17 11:57:53 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 1082.3 MB)
16/03/17 11:57:53 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:36092 (size: 4.1 KB, free: 1082.3 MB)
16/03/17 11:57:53 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 11:57:53 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:57:53 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 11:57:53 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/17 11:57:53 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 11:57:53 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196073092
16/03/17 11:57:53 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-b874349b-2988-42fb-a9d4-620a686df285/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: area
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: issue
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: planning
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: permission
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: economy
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: composition
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: agency
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 11:58:01 INFO PythonRunner: Times: total = 8043, boot = 492, init = 380, finish = 7171
16/03/17 11:58:01 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/17 11:58:01 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/17 11:58:01 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 11:58:01 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8136 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: set
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  Synset('set.n.01') ; keyword:  used  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: bend
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: giant
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: astatine
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: present
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: area
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
16/03/17 11:58:02 INFO PythonRunner: Times: total = 321, boot = 201, init = 0, finish = 120
16/03/17 11:58:02 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/17 11:58:02 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 341 ms on localhost (2/2)
16/03/17 11:58:02 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 11:58:02 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.469 s
16/03/17 11:58:02 INFO DAGScheduler: looking for newly runnable stages
16/03/17 11:58:02 INFO DAGScheduler: running: Set()
16/03/17 11:58:02 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 11:58:02 INFO DAGScheduler: failed: Set()
16/03/17 11:58:02 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 11:58:02 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 11:58:02 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10717, maxMem=1134868561
16/03/17 11:58:02 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1082.3 MB)
16/03/17 11:58:02 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15701, maxMem=1134868561
16/03/17 11:58:02 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1082.3 MB)
16/03/17 11:58:02 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:36092 (size: 3.0 KB, free: 1082.3 MB)
16/03/17 11:58:02 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 11:58:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:02 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 11:58:02 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:58:02 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 11:58:02 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:58:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 11:58:02 INFO PythonRunner: Times: total = 166, boot = 165, init = 0, finish = 1
16/03/17 11:58:02 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 11:58:02 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:58:02 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 11:58:02 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 177 ms on localhost (1/2)
16/03/17 11:58:02 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:58:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'set']
16/03/17 11:58:02 INFO PythonRunner: Times: total = 200, boot = 199, init = 1, finish = 0
16/03/17 11:58:02 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1271 bytes result sent to driver
16/03/17 11:58:02 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.387 s
16/03/17 11:58:02 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.891672 s
16/03/17 11:58:02 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 210 ms on localhost (2/2)
16/03/17 11:58:02 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 11:58:02 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:58:02 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:58:02 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:02 INFO DAGScheduler: Parents of final stage: List()
16/03/17 11:58:02 INFO DAGScheduler: Missing parents: List()
16/03/17 11:58:02 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:58:02 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18757, maxMem=1134868561
16/03/17 11:58:02 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1082.3 MB)
16/03/17 11:58:02 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24573, maxMem=1134868561
16/03/17 11:58:02 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1082.3 MB)
16/03/17 11:58:02 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:36092 (size: 3.3 KB, free: 1082.3 MB)
16/03/17 11:58:02 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 11:58:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:02 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 11:58:02 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 11:58:02 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 11:58:02 INFO PythonRunner: Times: total = 83, boot = 83, init = 0, finish = 0
16/03/17 11:58:02 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 11:58:02 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/17 11:58:02 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 96 ms on localhost (1/2)
16/03/17 11:58:02 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 11:58:02 INFO PythonRunner: Times: total = 189, boot = 188, init = 1, finish = 0
16/03/17 11:58:02 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1336 bytes result sent to driver
16/03/17 11:58:02 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 203 ms on localhost (2/2)
16/03/17 11:58:02 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 11:58:02 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.300 s
16/03/17 11:58:02 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.322433 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/17 11:58:03 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 11:58:03 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 11:58:03 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 11:58:03 INFO MemoryStore: MemoryStore cleared
16/03/17 11:58:03 INFO BlockManager: BlockManager stopped
16/03/17 11:58:03 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 11:58:03 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 11:58:03 INFO SparkContext: Successfully stopped SparkContext
16/03/17 11:58:03 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 11:58:03 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 11:58:03 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'set']
16/03/17 11:58:03 INFO SparkContext: Running Spark version 1.5.2
16/03/17 11:58:03 INFO SecurityManager: Changing view acls to: root
16/03/17 11:58:03 INFO SecurityManager: Changing modify acls to: root
16/03/17 11:58:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 11:58:04 INFO Slf4jLogger: Slf4jLogger started
16/03/17 11:58:04 INFO Remoting: Starting remoting
16/03/17 11:58:04 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:48498]
16/03/17 11:58:04 INFO Utils: Successfully started service 'sparkDriver' on port 48498.
16/03/17 11:58:04 INFO SparkEnv: Registering MapOutputTracker
16/03/17 11:58:04 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 11:58:04 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-dd78c66e-973d-4105-81c8-a7e3da130bd3
16/03/17 11:58:04 INFO MemoryStore: MemoryStore started with capacity 1073.1 MB
16/03/17 11:58:04 INFO HttpFileServer: HTTP File server directory is /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/httpd-d305e541-a35d-4248-93cd-328cc246b6cf
16/03/17 11:58:04 INFO HttpServer: Starting HTTP Server
16/03/17 11:58:04 INFO Utils: Successfully started service 'HTTP file server' on port 46193.
16/03/17 11:58:04 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 11:58:04 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 11:58:04 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 11:58:04 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-659a31b5-cf58-460b-93ad-b542e55a9963/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 11:58:04 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196084278
16/03/17 11:58:04 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 11:58:04 INFO Executor: Starting executor ID driver on host localhost
16/03/17 11:58:04 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56556.
16/03/17 11:58:04 INFO NettyBlockTransferService: Server created on 56556
16/03/17 11:58:04 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 11:58:04 INFO BlockManagerMasterEndpoint: Registering block manager localhost:56556 with 1073.1 MB RAM, BlockManagerId(driver, localhost, 56556)
16/03/17 11:58:04 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): usually
16/03/17 11:58:04 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:58:04 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:04 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:58:04 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 11:58:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 11:58:04 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:58:04 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1125242634
16/03/17 11:58:04 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1073.1 MB)
16/03/17 11:58:04 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6568, maxMem=1125242634
16/03/17 11:58:04 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 1073.1 MB)
16/03/17 11:58:04 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:56556 (size: 4.1 KB, free: 1073.1 MB)
16/03/17 11:58:04 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 11:58:04 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:04 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 11:58:04 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/17 11:58:04 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 11:58:04 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196084278
16/03/17 11:58:04 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-659a31b5-cf58-460b-93ad-b542e55a9963/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: area
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  usually  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: issue
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: planning
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: permission
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: economy
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: composition
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: agency
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/17 11:58:12 INFO PythonRunner: Times: total = 7966, boot = 486, init = 361, finish = 7119
16/03/17 11:58:12 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/17 11:58:12 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/17 11:58:12 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 11:58:12 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8042 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: set
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: bend
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: giant
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: astatine
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: present
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: area
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  usually  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/17 11:58:12 INFO PythonRunner: Times: total = 352, boot = 188, init = 1, finish = 163
16/03/17 11:58:12 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/17 11:58:12 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 375 ms on localhost (2/2)
16/03/17 11:58:12 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 11:58:12 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.404 s
16/03/17 11:58:12 INFO DAGScheduler: looking for newly runnable stages
16/03/17 11:58:12 INFO DAGScheduler: running: Set()
16/03/17 11:58:12 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 11:58:12 INFO DAGScheduler: failed: Set()
16/03/17 11:58:12 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 11:58:12 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 11:58:12 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10717, maxMem=1125242634
16/03/17 11:58:12 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1073.1 MB)
16/03/17 11:58:12 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15701, maxMem=1125242634
16/03/17 11:58:12 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1073.1 MB)
16/03/17 11:58:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:56556 (size: 3.0 KB, free: 1073.1 MB)
16/03/17 11:58:12 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 11:58:12 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:12 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 11:58:12 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:58:12 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 11:58:12 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:58:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 11:58:13 INFO PythonRunner: Times: total = 202, boot = 202, init = 0, finish = 0
16/03/17 11:58:13 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 11:58:13 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:58:13 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 11:58:13 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:58:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 11:58:13 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 229 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'area', 'None', u'area']
16/03/17 11:58:13 INFO PythonRunner: Times: total = 171, boot = 170, init = 0, finish = 1
16/03/17 11:58:13 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/17 11:58:13 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 184 ms on localhost (2/2)
16/03/17 11:58:13 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 11:58:13 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.388 s
16/03/17 11:58:13 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.841589 s
16/03/17 11:58:13 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:58:13 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:58:13 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:13 INFO DAGScheduler: Parents of final stage: List()
16/03/17 11:58:13 INFO DAGScheduler: Missing parents: List()
16/03/17 11:58:13 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:58:13 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18757, maxMem=1125242634
16/03/17 11:58:13 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1073.1 MB)
16/03/17 11:58:13 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24573, maxMem=1125242634
16/03/17 11:58:13 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1073.1 MB)
16/03/17 11:58:13 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:56556 (size: 3.3 KB, free: 1073.1 MB)
16/03/17 11:58:13 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 11:58:13 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:13 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 11:58:13 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 11:58:13 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 11:58:13 INFO PythonRunner: Times: total = 143, boot = 142, init = 1, finish = 0
16/03/17 11:58:13 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 11:58:13 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/17 11:58:13 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 149 ms on localhost (1/2)
16/03/17 11:58:13 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 11:58:13 INFO PythonRunner: Times: total = 190, boot = 189, init = 1, finish = 0
16/03/17 11:58:13 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/03/17 11:58:13 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 196 ms on localhost (2/2)
16/03/17 11:58:13 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 11:58:13 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.337 s
16/03/17 11:58:13 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.369977 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/17 11:58:13 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 11:58:13 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 11:58:13 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 11:58:13 INFO MemoryStore: MemoryStore cleared
16/03/17 11:58:13 INFO BlockManager: BlockManager stopped
16/03/17 11:58:13 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 11:58:13 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 11:58:13 INFO SparkContext: Successfully stopped SparkContext
16/03/17 11:58:13 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 11:58:13 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 11:58:13 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'area', u'None', u'area']
16/03/17 11:58:14 INFO SparkContext: Running Spark version 1.5.2
16/03/17 11:58:14 INFO SecurityManager: Changing view acls to: root
16/03/17 11:58:14 INFO SecurityManager: Changing modify acls to: root
16/03/17 11:58:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 11:58:14 INFO Slf4jLogger: Slf4jLogger started
16/03/17 11:58:14 INFO Remoting: Starting remoting
16/03/17 11:58:14 INFO Utils: Successfully started service 'sparkDriver' on port 55305.
16/03/17 11:58:14 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:55305]
16/03/17 11:58:14 INFO SparkEnv: Registering MapOutputTracker
16/03/17 11:58:14 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 11:58:14 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a8cf1b75-bd73-4a79-b54a-2d67a6971095
16/03/17 11:58:14 INFO MemoryStore: MemoryStore started with capacity 1073.1 MB
16/03/17 11:58:14 INFO HttpFileServer: HTTP File server directory is /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/httpd-ee0661bf-0a21-43f8-805c-dc52f3a1b115
16/03/17 11:58:14 INFO HttpServer: Starting HTTP Server
16/03/17 11:58:15 INFO Utils: Successfully started service 'HTTP file server' on port 45877.
16/03/17 11:58:15 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 11:58:15 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 11:58:15 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 11:58:15 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-d3c3b2cb-bd1f-4721-ab48-724055df39a3/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 11:58:15 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196095103
16/03/17 11:58:15 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 11:58:15 INFO Executor: Starting executor ID driver on host localhost
16/03/17 11:58:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 47847.
16/03/17 11:58:15 INFO NettyBlockTransferService: Server created on 47847
16/03/17 11:58:15 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 11:58:15 INFO BlockManagerMasterEndpoint: Registering block manager localhost:47847 with 1073.1 MB RAM, BlockManagerId(driver, localhost, 47847)
16/03/17 11:58:15 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): moment
16/03/17 11:58:15 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:58:15 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:15 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:58:15 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 11:58:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 11:58:15 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:58:15 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1125242634
16/03/17 11:58:15 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1073.1 MB)
16/03/17 11:58:15 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=1125242634
16/03/17 11:58:15 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 1073.1 MB)
16/03/17 11:58:15 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:47847 (size: 4.1 KB, free: 1073.1 MB)
16/03/17 11:58:15 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 11:58:15 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:15 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 11:58:15 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/17 11:58:15 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 11:58:15 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196095103
16/03/17 11:58:15 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-d3c3b2cb-bd1f-4721-ab48-724055df39a3/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: area
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: issue
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: planning
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: permission
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: economy
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: composition
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: agency
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 11:58:23 INFO PythonRunner: Times: total = 8076, boot = 590, init = 388, finish = 7098
16/03/17 11:58:23 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/17 11:58:23 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/17 11:58:23 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 11:58:23 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8185 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: set
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: bend
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: giant
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: astatine
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: present
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  moment  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: area
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/17 11:58:23 INFO PythonRunner: Times: total = 271, boot = 173, init = 1, finish = 97
16/03/17 11:58:23 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/17 11:58:23 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.453 s
16/03/17 11:58:23 INFO DAGScheduler: looking for newly runnable stages
16/03/17 11:58:23 INFO DAGScheduler: running: Set()
16/03/17 11:58:23 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 11:58:23 INFO DAGScheduler: failed: Set()
16/03/17 11:58:23 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 11:58:23 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 11:58:23 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=1125242634
16/03/17 11:58:23 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1073.1 MB)
16/03/17 11:58:23 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=15700, maxMem=1125242634
16/03/17 11:58:23 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1073.1 MB)
16/03/17 11:58:23 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 285 ms on localhost (2/2)
16/03/17 11:58:23 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 11:58:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:47847 (size: 3.0 KB, free: 1073.1 MB)
16/03/17 11:58:23 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 11:58:23 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:23 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 11:58:23 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:58:23 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 11:58:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:58:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 11:58:24 INFO PythonRunner: Times: total = 236, boot = 235, init = 1, finish = 0
16/03/17 11:58:24 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 11:58:24 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:58:24 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 11:58:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:58:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/03/17 11:58:24 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 253 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'present']
16/03/17 11:58:24 INFO PythonRunner: Times: total = 182, boot = 181, init = 0, finish = 1
16/03/17 11:58:24 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/17 11:58:24 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 195 ms on localhost (2/2)
16/03/17 11:58:24 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 11:58:24 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.437 s
16/03/17 11:58:24 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.952604 s
16/03/17 11:58:24 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:58:24 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:58:24 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:24 INFO DAGScheduler: Parents of final stage: List()
16/03/17 11:58:24 INFO DAGScheduler: Missing parents: List()
16/03/17 11:58:24 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:58:24 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18755, maxMem=1125242634
16/03/17 11:58:24 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1073.1 MB)
16/03/17 11:58:24 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24571, maxMem=1125242634
16/03/17 11:58:24 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1073.1 MB)
16/03/17 11:58:24 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:47847 (size: 3.3 KB, free: 1073.1 MB)
16/03/17 11:58:24 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 11:58:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:24 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 11:58:24 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 11:58:24 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 11:58:24 INFO PythonRunner: Times: total = 194, boot = 194, init = 0, finish = 0
16/03/17 11:58:24 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 11:58:24 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/17 11:58:24 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 201 ms on localhost (1/2)
16/03/17 11:58:24 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 11:58:24 INFO PythonRunner: Times: total = 181, boot = 181, init = 0, finish = 0
16/03/17 11:58:24 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1351 bytes result sent to driver
16/03/17 11:58:24 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 190 ms on localhost (2/2)
16/03/17 11:58:24 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 11:58:24 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.381 s
16/03/17 11:58:24 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.422706 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/17 11:58:24 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 11:58:24 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 11:58:24 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 11:58:24 INFO MemoryStore: MemoryStore cleared
16/03/17 11:58:24 INFO BlockManager: BlockManager stopped
16/03/17 11:58:24 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 11:58:24 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 11:58:24 INFO SparkContext: Successfully stopped SparkContext
16/03/17 11:58:24 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 11:58:24 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 11:58:24 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'present']
16/03/17 11:58:25 INFO SparkContext: Running Spark version 1.5.2
16/03/17 11:58:25 INFO SecurityManager: Changing view acls to: root
16/03/17 11:58:25 INFO SecurityManager: Changing modify acls to: root
16/03/17 11:58:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 11:58:25 INFO Slf4jLogger: Slf4jLogger started
16/03/17 11:58:25 INFO Remoting: Starting remoting
16/03/17 11:58:25 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:53134]
16/03/17 11:58:25 INFO Utils: Successfully started service 'sparkDriver' on port 53134.
16/03/17 11:58:25 INFO SparkEnv: Registering MapOutputTracker
16/03/17 11:58:25 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 11:58:25 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-4df47e04-1780-4eb3-bde5-b82bda4986cb
16/03/17 11:58:25 INFO MemoryStore: MemoryStore started with capacity 1073.1 MB
16/03/17 11:58:25 INFO HttpFileServer: HTTP File server directory is /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/httpd-c2fe5379-3570-4cdd-b8d4-72469add6326
16/03/17 11:58:25 INFO HttpServer: Starting HTTP Server
16/03/17 11:58:26 INFO Utils: Successfully started service 'HTTP file server' on port 51983.
16/03/17 11:58:26 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 11:58:26 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 11:58:26 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 11:58:26 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-e4dced5d-8eb3-40f9-9ad3-cf4b49ffd79b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 11:58:26 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196106195
16/03/17 11:58:26 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 11:58:26 INFO Executor: Starting executor ID driver on host localhost
16/03/17 11:58:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39385.
16/03/17 11:58:26 INFO NettyBlockTransferService: Server created on 39385
16/03/17 11:58:26 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 11:58:26 INFO BlockManagerMasterEndpoint: Registering block manager localhost:39385 with 1073.1 MB RAM, BlockManagerId(driver, localhost, 39385)
16/03/17 11:58:26 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): purpose
16/03/17 11:58:26 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:58:26 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:26 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:58:26 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 11:58:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 11:58:26 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:58:26 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1125242634
16/03/17 11:58:26 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1073.1 MB)
16/03/17 11:58:26 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6568, maxMem=1125242634
16/03/17 11:58:26 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 1073.1 MB)
16/03/17 11:58:26 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:39385 (size: 4.1 KB, free: 1073.1 MB)
16/03/17 11:58:26 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 11:58:26 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:26 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 11:58:26 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/17 11:58:26 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 11:58:26 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196106195
16/03/17 11:58:26 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-e4dced5d-8eb3-40f9-9ad3-cf4b49ffd79b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: area
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  purpose  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: issue
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: planning
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: permission
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: economy
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: composition
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: agency
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/17 11:58:34 INFO PythonRunner: Times: total = 8025, boot = 559, init = 390, finish = 7076
16/03/17 11:58:34 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/17 11:58:34 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/17 11:58:34 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 11:58:34 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8153 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: set
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: bend
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: giant
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: astatine
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: present
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: area
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  purpose  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/17 11:58:34 INFO PythonRunner: Times: total = 345, boot = 183, init = 0, finish = 162
16/03/17 11:58:34 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/17 11:58:35 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 369 ms on localhost (2/2)
16/03/17 11:58:35 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 11:58:35 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.511 s
16/03/17 11:58:35 INFO DAGScheduler: looking for newly runnable stages
16/03/17 11:58:35 INFO DAGScheduler: running: Set()
16/03/17 11:58:35 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 11:58:35 INFO DAGScheduler: failed: Set()
16/03/17 11:58:35 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 11:58:35 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 11:58:35 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10717, maxMem=1125242634
16/03/17 11:58:35 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1073.1 MB)
16/03/17 11:58:35 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15701, maxMem=1125242634
16/03/17 11:58:35 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1073.1 MB)
16/03/17 11:58:35 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:39385 (size: 3.0 KB, free: 1073.1 MB)
16/03/17 11:58:35 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 11:58:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:35 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 11:58:35 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:58:35 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 11:58:35 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:58:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 11:58:35 INFO PythonRunner: Times: total = 182, boot = 182, init = 0, finish = 0
16/03/17 11:58:35 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 11:58:35 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:58:35 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 11:58:35 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:58:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 11:58:35 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 213 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'area', 'None', u'area']
16/03/17 11:58:35 INFO PythonRunner: Times: total = 216, boot = 212, init = 1, finish = 3
16/03/17 11:58:35 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/17 11:58:35 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 235 ms on localhost (2/2)
16/03/17 11:58:35 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 11:58:35 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.418 s
16/03/17 11:58:35 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.992911 s
16/03/17 11:58:35 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:58:35 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:58:35 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:35 INFO DAGScheduler: Parents of final stage: List()
16/03/17 11:58:35 INFO DAGScheduler: Missing parents: List()
16/03/17 11:58:35 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:58:35 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18757, maxMem=1125242634
16/03/17 11:58:35 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1073.1 MB)
16/03/17 11:58:35 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24573, maxMem=1125242634
16/03/17 11:58:35 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1073.1 MB)
16/03/17 11:58:35 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:39385 (size: 3.3 KB, free: 1073.1 MB)
16/03/17 11:58:35 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 11:58:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:35 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 11:58:35 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 11:58:35 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 11:58:35 INFO PythonRunner: Times: total = 124, boot = 124, init = 0, finish = 0
16/03/17 11:58:35 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 11:58:35 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/17 11:58:35 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 132 ms on localhost (1/2)
16/03/17 11:58:35 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 11:58:35 INFO PythonRunner: Times: total = 190, boot = 190, init = 0, finish = 0
16/03/17 11:58:35 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/03/17 11:58:35 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 198 ms on localhost (2/2)
16/03/17 11:58:35 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.316 s
16/03/17 11:58:35 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 11:58:35 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.349746 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/17 11:58:36 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 11:58:36 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 11:58:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 11:58:36 INFO MemoryStore: MemoryStore cleared
16/03/17 11:58:36 INFO BlockManager: BlockManager stopped
16/03/17 11:58:36 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 11:58:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 11:58:36 INFO SparkContext: Successfully stopped SparkContext
16/03/17 11:58:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 11:58:36 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 11:58:36 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'area', u'None', u'area']
16/03/17 11:58:36 INFO SparkContext: Running Spark version 1.5.2
16/03/17 11:58:36 INFO SecurityManager: Changing view acls to: root
16/03/17 11:58:36 INFO SecurityManager: Changing modify acls to: root
16/03/17 11:58:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 11:58:37 INFO Slf4jLogger: Slf4jLogger started
16/03/17 11:58:37 INFO Remoting: Starting remoting
16/03/17 11:58:37 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:46656]
16/03/17 11:58:37 INFO Utils: Successfully started service 'sparkDriver' on port 46656.
16/03/17 11:58:37 INFO SparkEnv: Registering MapOutputTracker
16/03/17 11:58:37 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 11:58:37 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-45896d4a-ecd6-4b50-b32c-21f55c3a994e
16/03/17 11:58:37 INFO MemoryStore: MemoryStore started with capacity 1073.1 MB
16/03/17 11:58:37 INFO HttpFileServer: HTTP File server directory is /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/httpd-7dbd481e-8e2e-4e5f-874d-425a31c179a1
16/03/17 11:58:37 INFO HttpServer: Starting HTTP Server
16/03/17 11:58:37 INFO Utils: Successfully started service 'HTTP file server' on port 49817.
16/03/17 11:58:37 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 11:58:37 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 11:58:37 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 11:58:37 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-1c3f4d73-576d-49a9-ad6f-e6d3eb67d7d1/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 11:58:37 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196117346
16/03/17 11:58:37 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 11:58:37 INFO Executor: Starting executor ID driver on host localhost
16/03/17 11:58:37 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51983.
16/03/17 11:58:37 INFO NettyBlockTransferService: Server created on 51983
16/03/17 11:58:37 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 11:58:37 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51983 with 1073.1 MB RAM, BlockManagerId(driver, localhost, 51983)
16/03/17 11:58:37 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): segment
16/03/17 11:58:37 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:58:37 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:37 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:58:37 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 11:58:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 11:58:37 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:58:37 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1125242634
16/03/17 11:58:37 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1073.1 MB)
16/03/17 11:58:37 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6568, maxMem=1125242634
16/03/17 11:58:37 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 1073.1 MB)
16/03/17 11:58:37 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51983 (size: 4.1 KB, free: 1073.1 MB)
16/03/17 11:58:37 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 11:58:37 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:37 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 11:58:37 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/17 11:58:37 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 11:58:37 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196117346
16/03/17 11:58:37 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-1c3f4d73-576d-49a9-ad6f-e6d3eb67d7d1/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: area
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: issue
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: planning
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: permission
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: economy
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: composition
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: agency
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 11:58:45 INFO PythonRunner: Times: total = 7938, boot = 508, init = 366, finish = 7064
16/03/17 11:58:45 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/17 11:58:45 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/17 11:58:45 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8008 ms on localhost (1/2)
16/03/17 11:58:45 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: set
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: bend
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): adding to parents: syn =  Synset('bend.n.01') ; keyword:  segment  in syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= [u'bend']
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: giant
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: astatine
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: present
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: area
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
16/03/17 11:58:45 INFO PythonRunner: Times: total = 328, boot = 185, init = 0, finish = 143
16/03/17 11:58:45 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/17 11:58:45 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 350 ms on localhost (2/2)
16/03/17 11:58:45 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 11:58:45 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.359 s
16/03/17 11:58:45 INFO DAGScheduler: looking for newly runnable stages
16/03/17 11:58:45 INFO DAGScheduler: running: Set()
16/03/17 11:58:45 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 11:58:45 INFO DAGScheduler: failed: Set()
16/03/17 11:58:45 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 11:58:45 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 11:58:45 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10717, maxMem=1125242634
16/03/17 11:58:45 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1073.1 MB)
16/03/17 11:58:45 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15701, maxMem=1125242634
16/03/17 11:58:45 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1073.1 MB)
16/03/17 11:58:45 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51983 (size: 3.0 KB, free: 1073.1 MB)
16/03/17 11:58:45 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 11:58:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:45 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 11:58:45 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:58:45 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 11:58:45 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:58:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 11:58:46 INFO PythonRunner: Times: total = 197, boot = 197, init = 0, finish = 0
16/03/17 11:58:46 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 11:58:46 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:58:46 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 11:58:46 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:58:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 11:58:46 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 221 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'bend']
16/03/17 11:58:46 INFO PythonRunner: Times: total = 185, boot = 183, init = 0, finish = 2
16/03/17 11:58:46 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1272 bytes result sent to driver
16/03/17 11:58:46 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 217 ms on localhost (2/2)
16/03/17 11:58:46 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 11:58:46 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.438 s
16/03/17 11:58:46 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.823871 s
16/03/17 11:58:46 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:58:46 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:58:46 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:46 INFO DAGScheduler: Parents of final stage: List()
16/03/17 11:58:46 INFO DAGScheduler: Missing parents: List()
16/03/17 11:58:46 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:58:46 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18757, maxMem=1125242634
16/03/17 11:58:46 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1073.1 MB)
16/03/17 11:58:46 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24573, maxMem=1125242634
16/03/17 11:58:46 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1073.1 MB)
16/03/17 11:58:46 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:51983 (size: 3.3 KB, free: 1073.1 MB)
16/03/17 11:58:46 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 11:58:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:46 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 11:58:46 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 11:58:46 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 11:58:46 INFO PythonRunner: Times: total = 116, boot = 115, init = 1, finish = 0
16/03/17 11:58:46 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 11:58:46 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2353 bytes)
16/03/17 11:58:46 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 122 ms on localhost (1/2)
16/03/17 11:58:46 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 11:58:46 INFO PythonRunner: Times: total = 206, boot = 206, init = 0, finish = 0
16/03/17 11:58:46 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1337 bytes result sent to driver
16/03/17 11:58:46 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 213 ms on localhost (2/2)
16/03/17 11:58:46 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 11:58:46 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.332 s
16/03/17 11:58:46 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.357695 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/17 11:58:46 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 11:58:46 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 11:58:47 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 11:58:47 INFO MemoryStore: MemoryStore cleared
16/03/17 11:58:47 INFO BlockManager: BlockManager stopped
16/03/17 11:58:47 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 11:58:47 INFO SparkContext: Successfully stopped SparkContext
16/03/17 11:58:47 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 11:58:47 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 11:58:47 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 11:58:47 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'bend']
16/03/17 11:58:47 INFO SparkContext: Running Spark version 1.5.2
16/03/17 11:58:47 INFO SecurityManager: Changing view acls to: root
16/03/17 11:58:47 INFO SecurityManager: Changing modify acls to: root
16/03/17 11:58:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 11:58:47 INFO Slf4jLogger: Slf4jLogger started
16/03/17 11:58:47 INFO Remoting: Starting remoting
16/03/17 11:58:48 INFO Utils: Successfully started service 'sparkDriver' on port 49397.
16/03/17 11:58:48 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:49397]
16/03/17 11:58:48 INFO SparkEnv: Registering MapOutputTracker
16/03/17 11:58:48 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 11:58:48 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0c7fa0d2-409a-4b49-8208-24ecbe2cff8e
16/03/17 11:58:48 INFO MemoryStore: MemoryStore started with capacity 1073.1 MB
16/03/17 11:58:48 INFO HttpFileServer: HTTP File server directory is /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/httpd-c7602df0-f13d-4e86-8f9f-89521140c5e8
16/03/17 11:58:48 INFO HttpServer: Starting HTTP Server
16/03/17 11:58:48 INFO Utils: Successfully started service 'HTTP file server' on port 46101.
16/03/17 11:58:48 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 11:58:48 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 11:58:48 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 11:58:48 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-52ccdbf1-ed08-4bc0-86cd-930c060d96a2/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 11:58:48 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196128237
16/03/17 11:58:48 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 11:58:48 INFO Executor: Starting executor ID driver on host localhost
16/03/17 11:58:48 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38727.
16/03/17 11:58:48 INFO NettyBlockTransferService: Server created on 38727
16/03/17 11:58:48 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 11:58:48 INFO BlockManagerMasterEndpoint: Registering block manager localhost:38727 with 1073.1 MB RAM, BlockManagerId(driver, localhost, 38727)
16/03/17 11:58:48 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): radioactive
16/03/17 11:58:48 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:58:48 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:48 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:58:48 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 11:58:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 11:58:48 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:58:48 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1125242634
16/03/17 11:58:48 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1073.1 MB)
16/03/17 11:58:48 INFO MemoryStore: ensureFreeSpace(4147) called with curMem=6568, maxMem=1125242634
16/03/17 11:58:48 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1073.1 MB)
16/03/17 11:58:48 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:38727 (size: 4.0 KB, free: 1073.1 MB)
16/03/17 11:58:48 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 11:58:48 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:48 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 11:58:48 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/17 11:58:48 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 11:58:48 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196128237
16/03/17 11:58:48 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-52ccdbf1-ed08-4bc0-86cd-930c060d96a2/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: area
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: issue
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: planning
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: permission
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: economy
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: composition
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: agency
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 11:58:56 INFO PythonRunner: Times: total = 8047, boot = 483, init = 394, finish = 7170
16/03/17 11:58:56 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/17 11:58:56 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/17 11:58:56 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 11:58:56 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8139 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: set
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: bend
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: giant
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: astatine
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  radioactive  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: present
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: area
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/17 11:58:56 INFO PythonRunner: Times: total = 348, boot = 193, init = 0, finish = 155
16/03/17 11:58:57 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/17 11:58:57 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.491 s
16/03/17 11:58:57 INFO DAGScheduler: looking for newly runnable stages
16/03/17 11:58:57 INFO DAGScheduler: running: Set()
16/03/17 11:58:57 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 11:58:57 INFO DAGScheduler: failed: Set()
16/03/17 11:58:57 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 11:58:57 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 11:58:57 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10715, maxMem=1125242634
16/03/17 11:58:57 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1073.1 MB)
16/03/17 11:58:57 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15699, maxMem=1125242634
16/03/17 11:58:57 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1073.1 MB)
16/03/17 11:58:57 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:38727 (size: 3.0 KB, free: 1073.1 MB)
16/03/17 11:58:57 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 11:58:57 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 368 ms on localhost (2/2)
16/03/17 11:58:57 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 11:58:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:57 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 11:58:57 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:58:57 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 11:58:57 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:58:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 11:58:57 INFO PythonRunner: Times: total = 188, boot = 188, init = 0, finish = 0
16/03/17 11:58:57 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 11:58:57 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:58:57 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 11:58:57 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:58:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 11:58:57 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 217 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/03/17 11:58:57 INFO PythonRunner: Times: total = 183, boot = 182, init = 0, finish = 1
16/03/17 11:58:57 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/03/17 11:58:57 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.400 s
16/03/17 11:58:57 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.943394 s
16/03/17 11:58:57 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 200 ms on localhost (2/2)
16/03/17 11:58:57 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 11:58:57 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:58:57 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:58:57 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:57 INFO DAGScheduler: Parents of final stage: List()
16/03/17 11:58:57 INFO DAGScheduler: Missing parents: List()
16/03/17 11:58:57 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:58:57 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18755, maxMem=1125242634
16/03/17 11:58:57 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1073.1 MB)
16/03/17 11:58:57 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24571, maxMem=1125242634
16/03/17 11:58:57 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1073.1 MB)
16/03/17 11:58:57 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:38727 (size: 3.3 KB, free: 1073.1 MB)
16/03/17 11:58:57 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 11:58:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:57 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 11:58:57 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 11:58:57 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 11:58:57 INFO PythonRunner: Times: total = 153, boot = 153, init = 0, finish = 0
16/03/17 11:58:57 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 11:58:57 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/03/17 11:58:57 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 162 ms on localhost (1/2)
16/03/17 11:58:57 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 11:58:58 INFO PythonRunner: Times: total = 302, boot = 302, init = 0, finish = 0
16/03/17 11:58:58 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/03/17 11:58:58 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 317 ms on localhost (2/2)
16/03/17 11:58:58 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 11:58:58 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.470 s
16/03/17 11:58:58 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.488868 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/17 11:58:58 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 11:58:58 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 11:58:58 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 11:58:58 INFO MemoryStore: MemoryStore cleared
16/03/17 11:58:58 INFO BlockManager: BlockManager stopped
16/03/17 11:58:58 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 11:58:58 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 11:58:58 INFO SparkContext: Successfully stopped SparkContext
16/03/17 11:58:58 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 11:58:58 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 11:58:58 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'astatine']
16/03/17 11:58:59 INFO SparkContext: Running Spark version 1.5.2
16/03/17 11:58:59 INFO SecurityManager: Changing view acls to: root
16/03/17 11:58:59 INFO SecurityManager: Changing modify acls to: root
16/03/17 11:58:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 11:58:59 INFO Slf4jLogger: Slf4jLogger started
16/03/17 11:58:59 INFO Remoting: Starting remoting
16/03/17 11:58:59 INFO Utils: Successfully started service 'sparkDriver' on port 51391.
16/03/17 11:58:59 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:51391]
16/03/17 11:58:59 INFO SparkEnv: Registering MapOutputTracker
16/03/17 11:58:59 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 11:58:59 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-46e66b24-a03c-4790-8173-3526df5208c9
16/03/17 11:58:59 INFO MemoryStore: MemoryStore started with capacity 1072.6 MB
16/03/17 11:58:59 INFO HttpFileServer: HTTP File server directory is /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/httpd-de0881c6-3ccd-4249-9010-c5688ddcf6f7
16/03/17 11:58:59 INFO HttpServer: Starting HTTP Server
16/03/17 11:58:59 INFO Utils: Successfully started service 'HTTP file server' on port 50437.
16/03/17 11:58:59 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 11:58:59 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 11:58:59 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 11:58:59 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-0418e595-538e-44fd-bc31-e00c58558b06/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 11:58:59 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196139668
16/03/17 11:58:59 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 11:58:59 INFO Executor: Starting executor ID driver on host localhost
16/03/17 11:58:59 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50506.
16/03/17 11:58:59 INFO NettyBlockTransferService: Server created on 50506
16/03/17 11:58:59 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 11:58:59 INFO BlockManagerMasterEndpoint: Registering block manager localhost:50506 with 1072.6 MB RAM, BlockManagerId(driver, localhost, 50506)
16/03/17 11:58:59 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): happening
16/03/17 11:58:59 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:58:59 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:59 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:58:59 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 11:58:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 11:58:59 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:58:59 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124676403
16/03/17 11:58:59 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.6 MB)
16/03/17 11:58:59 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6568, maxMem=1124676403
16/03/17 11:58:59 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 1072.6 MB)
16/03/17 11:58:59 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:50506 (size: 4.1 KB, free: 1072.6 MB)
16/03/17 11:58:59 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 11:58:59 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:58:59 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 11:58:59 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/17 11:58:59 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 11:58:59 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196139668
16/03/17 11:58:59 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-0418e595-538e-44fd-bc31-e00c58558b06/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: area
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: issue
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: planning
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: permission
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: economy
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: composition
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: agency
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 11:59:08 INFO PythonRunner: Times: total = 8406, boot = 753, init = 414, finish = 7239
16/03/17 11:59:08 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/17 11:59:08 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/17 11:59:08 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 11:59:08 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8588 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: set
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: bend
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: giant
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: astatine
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: present
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  happening  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: area
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/17 11:59:08 INFO PythonRunner: Times: total = 313, boot = 199, init = 1, finish = 113
16/03/17 11:59:08 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/17 11:59:08 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.915 s
16/03/17 11:59:08 INFO DAGScheduler: looking for newly runnable stages
16/03/17 11:59:08 INFO DAGScheduler: running: Set()
16/03/17 11:59:08 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 11:59:08 INFO DAGScheduler: failed: Set()
16/03/17 11:59:08 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 11:59:08 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 11:59:08 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10717, maxMem=1124676403
16/03/17 11:59:08 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.6 MB)
16/03/17 11:59:08 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15701, maxMem=1124676403
16/03/17 11:59:08 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.6 MB)
16/03/17 11:59:08 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 337 ms on localhost (2/2)
16/03/17 11:59:08 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:50506 (size: 3.0 KB, free: 1072.6 MB)
16/03/17 11:59:08 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 11:59:08 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 11:59:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:59:08 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 11:59:08 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:59:08 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 11:59:08 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:59:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 11:59:08 INFO PythonRunner: Times: total = 172, boot = 171, init = 1, finish = 0
16/03/17 11:59:08 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 11:59:08 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:59:08 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 188 ms on localhost (1/2)
16/03/17 11:59:08 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 11:59:08 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:59:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
reduceFunction_Parents(): returns= ['None', 'None', u'present']
16/03/17 11:59:09 INFO PythonRunner: Times: total = 184, boot = 183, init = 0, finish = 1
16/03/17 11:59:09 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/17 11:59:09 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.389 s
16/03/17 11:59:09 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.346150 s
16/03/17 11:59:09 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 201 ms on localhost (2/2)
16/03/17 11:59:09 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 11:59:09 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:59:09 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:59:09 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:59:09 INFO DAGScheduler: Parents of final stage: List()
16/03/17 11:59:09 INFO DAGScheduler: Missing parents: List()
16/03/17 11:59:09 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:59:09 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18757, maxMem=1124676403
16/03/17 11:59:09 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.6 MB)
16/03/17 11:59:09 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24573, maxMem=1124676403
16/03/17 11:59:09 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.5 MB)
16/03/17 11:59:09 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:50506 (size: 3.3 KB, free: 1072.6 MB)
16/03/17 11:59:09 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 11:59:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:59:09 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 11:59:09 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 11:59:09 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 11:59:09 INFO PythonRunner: Times: total = 94, boot = 94, init = 0, finish = 0
16/03/17 11:59:09 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 11:59:09 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/17 11:59:09 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 104 ms on localhost (1/2)
16/03/17 11:59:09 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 11:59:09 INFO PythonRunner: Times: total = 214, boot = 213, init = 1, finish = 0
16/03/17 11:59:09 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1351 bytes result sent to driver
16/03/17 11:59:09 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 222 ms on localhost (2/2)
16/03/17 11:59:09 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 11:59:09 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.317 s
16/03/17 11:59:09 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.351140 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/17 11:59:09 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 11:59:09 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 11:59:09 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 11:59:09 INFO MemoryStore: MemoryStore cleared
16/03/17 11:59:09 INFO BlockManager: BlockManager stopped
16/03/17 11:59:09 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 11:59:09 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 11:59:09 INFO SparkContext: Successfully stopped SparkContext
16/03/17 11:59:09 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 11:59:09 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 11:59:09 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'present']
16/03/17 11:59:10 INFO SparkContext: Running Spark version 1.5.2
16/03/17 11:59:10 INFO SecurityManager: Changing view acls to: root
16/03/17 11:59:10 INFO SecurityManager: Changing modify acls to: root
16/03/17 11:59:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 11:59:10 INFO Slf4jLogger: Slf4jLogger started
16/03/17 11:59:10 INFO Remoting: Starting remoting
16/03/17 11:59:10 INFO Utils: Successfully started service 'sparkDriver' on port 37570.
16/03/17 11:59:10 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:37570]
16/03/17 11:59:10 INFO SparkEnv: Registering MapOutputTracker
16/03/17 11:59:10 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 11:59:10 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-decaddbb-1570-437b-bd49-fe121ded7a85
16/03/17 11:59:10 INFO MemoryStore: MemoryStore started with capacity 1072.6 MB
16/03/17 11:59:10 INFO HttpFileServer: HTTP File server directory is /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/httpd-1b595534-fd9a-4680-ac2e-49aa89e7d401
16/03/17 11:59:10 INFO HttpServer: Starting HTTP Server
16/03/17 11:59:10 INFO Utils: Successfully started service 'HTTP file server' on port 51341.
16/03/17 11:59:10 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 11:59:11 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 11:59:11 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 11:59:11 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-767d4707-0905-4b26-a2cb-e38401efa5a2/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 11:59:11 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196151073
16/03/17 11:59:11 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 11:59:11 INFO Executor: Starting executor ID driver on host localhost
16/03/17 11:59:11 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41395.
16/03/17 11:59:11 INFO NettyBlockTransferService: Server created on 41395
16/03/17 11:59:11 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 11:59:11 INFO BlockManagerMasterEndpoint: Registering block manager localhost:41395 with 1072.6 MB RAM, BlockManagerId(driver, localhost, 41395)
16/03/17 11:59:11 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): curve
16/03/17 11:59:11 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:59:11 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:59:11 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:59:11 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:59:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 11:59:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 11:59:11 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:59:11 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124676403
16/03/17 11:59:11 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.6 MB)
16/03/17 11:59:11 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6568, maxMem=1124676403
16/03/17 11:59:11 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 1072.6 MB)
16/03/17 11:59:11 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:41395 (size: 4.1 KB, free: 1072.6 MB)
16/03/17 11:59:11 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 11:59:11 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:59:11 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 11:59:11 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/17 11:59:11 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 11:59:11 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196151073
16/03/17 11:59:11 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-767d4707-0905-4b26-a2cb-e38401efa5a2/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: area
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: issue
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: planning
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: permission
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: economy
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: composition
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: agency
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 11:59:19 INFO PythonRunner: Times: total = 8173, boot = 575, init = 403, finish = 7195
16/03/17 11:59:19 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/17 11:59:19 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/17 11:59:19 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 11:59:19 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8303 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: set
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: bend
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): adding to parents: syn =  Synset('bend.n.01') ; keyword:  curve  in syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= [u'bend']
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: giant
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: astatine
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: present
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: area
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
16/03/17 11:59:19 INFO PythonRunner: Times: total = 313, boot = 182, init = 1, finish = 130
16/03/17 11:59:19 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/17 11:59:19 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 353 ms on localhost (2/2)
16/03/17 11:59:19 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.654 s
16/03/17 11:59:19 INFO DAGScheduler: looking for newly runnable stages
16/03/17 11:59:19 INFO DAGScheduler: running: Set()
16/03/17 11:59:19 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 11:59:19 INFO DAGScheduler: failed: Set()
16/03/17 11:59:19 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 11:59:19 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 11:59:19 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10717, maxMem=1124676403
16/03/17 11:59:19 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.6 MB)
16/03/17 11:59:19 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15701, maxMem=1124676403
16/03/17 11:59:19 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.6 MB)
16/03/17 11:59:19 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 11:59:19 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:41395 (size: 3.0 KB, free: 1072.6 MB)
16/03/17 11:59:19 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 11:59:19 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:59:19 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 11:59:19 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:59:19 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 11:59:19 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:59:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 11:59:20 INFO PythonRunner: Times: total = 194, boot = 193, init = 0, finish = 1
16/03/17 11:59:20 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 11:59:20 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:59:20 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 11:59:20 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:59:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 11:59:20 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 215 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'bend']
16/03/17 11:59:20 INFO PythonRunner: Times: total = 178, boot = 177, init = 0, finish = 1
16/03/17 11:59:20 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1272 bytes result sent to driver
16/03/17 11:59:20 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 193 ms on localhost (2/2)
16/03/17 11:59:20 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 11:59:20 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.394 s
16/03/17 11:59:20 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.090841 s
16/03/17 11:59:20 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:59:20 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:59:20 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:59:20 INFO DAGScheduler: Parents of final stage: List()
16/03/17 11:59:20 INFO DAGScheduler: Missing parents: List()
16/03/17 11:59:20 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:59:20 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18757, maxMem=1124676403
16/03/17 11:59:20 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.6 MB)
16/03/17 11:59:20 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24573, maxMem=1124676403
16/03/17 11:59:20 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.5 MB)
16/03/17 11:59:20 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:41395 (size: 3.3 KB, free: 1072.6 MB)
16/03/17 11:59:20 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 11:59:20 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:59:20 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 11:59:20 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 11:59:20 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 11:59:20 INFO PythonRunner: Times: total = 138, boot = 138, init = 0, finish = 0
16/03/17 11:59:20 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 11:59:20 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2353 bytes)
16/03/17 11:59:20 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 149 ms on localhost (1/2)
16/03/17 11:59:20 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 11:59:20 INFO PythonRunner: Times: total = 182, boot = 182, init = 0, finish = 0
16/03/17 11:59:20 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1337 bytes result sent to driver
16/03/17 11:59:20 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 189 ms on localhost (2/2)
16/03/17 11:59:20 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 11:59:20 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.337 s
16/03/17 11:59:20 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.357195 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/17 11:59:20 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 11:59:20 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 11:59:20 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 11:59:20 INFO MemoryStore: MemoryStore cleared
16/03/17 11:59:20 INFO BlockManager: BlockManager stopped
16/03/17 11:59:20 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 11:59:20 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 11:59:20 INFO SparkContext: Successfully stopped SparkContext
16/03/17 11:59:20 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 11:59:20 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 11:59:20 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'bend']
16/03/17 11:59:21 INFO SparkContext: Running Spark version 1.5.2
16/03/17 11:59:21 INFO SecurityManager: Changing view acls to: root
16/03/17 11:59:21 INFO SecurityManager: Changing modify acls to: root
16/03/17 11:59:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 11:59:21 INFO Slf4jLogger: Slf4jLogger started
16/03/17 11:59:21 INFO Remoting: Starting remoting
16/03/17 11:59:22 INFO Utils: Successfully started service 'sparkDriver' on port 47981.
16/03/17 11:59:22 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:47981]
16/03/17 11:59:22 INFO SparkEnv: Registering MapOutputTracker
16/03/17 11:59:22 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 11:59:22 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e7a2a868-2a85-499f-be24-721cf19652c0
16/03/17 11:59:22 INFO MemoryStore: MemoryStore started with capacity 1072.6 MB
16/03/17 11:59:22 INFO HttpFileServer: HTTP File server directory is /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/httpd-d8e3d1ad-c5b4-474f-8b6f-661fc7989ae4
16/03/17 11:59:22 INFO HttpServer: Starting HTTP Server
16/03/17 11:59:22 INFO Utils: Successfully started service 'HTTP file server' on port 40607.
16/03/17 11:59:22 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 11:59:22 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 11:59:22 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 11:59:22 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-2eb01688-017a-4e1c-bd06-59ef845ef4e1/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 11:59:22 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196162256
16/03/17 11:59:22 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 11:59:22 INFO Executor: Starting executor ID driver on host localhost
16/03/17 11:59:22 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44540.
16/03/17 11:59:22 INFO NettyBlockTransferService: Server created on 44540
16/03/17 11:59:22 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 11:59:22 INFO BlockManagerMasterEndpoint: Registering block manager localhost:44540 with 1072.6 MB RAM, BlockManagerId(driver, localhost, 44540)
16/03/17 11:59:22 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): together
16/03/17 11:59:22 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:59:22 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:59:22 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:59:22 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:59:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 11:59:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 11:59:22 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:59:22 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124676403
16/03/17 11:59:22 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.6 MB)
16/03/17 11:59:22 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6568, maxMem=1124676403
16/03/17 11:59:22 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 1072.6 MB)
16/03/17 11:59:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:44540 (size: 4.1 KB, free: 1072.6 MB)
16/03/17 11:59:22 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 11:59:22 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:59:22 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 11:59:22 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/17 11:59:22 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 11:59:22 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196162256
16/03/17 11:59:22 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-2eb01688-017a-4e1c-bd06-59ef845ef4e1/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: area
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: issue
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: planning
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: permission
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: economy
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: composition
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: agency
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 11:59:30 INFO PythonRunner: Times: total = 8070, boot = 493, init = 392, finish = 7185
16/03/17 11:59:30 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/17 11:59:30 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/17 11:59:30 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 11:59:30 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8155 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: set
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  Synset('set.n.01') ; keyword:  together  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: bend
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: giant
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: astatine
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: present
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: area
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
16/03/17 11:59:30 INFO PythonRunner: Times: total = 302, boot = 188, init = 0, finish = 114
16/03/17 11:59:30 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/17 11:59:30 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.495 s
16/03/17 11:59:30 INFO DAGScheduler: looking for newly runnable stages
16/03/17 11:59:30 INFO DAGScheduler: running: Set()
16/03/17 11:59:30 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 11:59:30 INFO DAGScheduler: failed: Set()
16/03/17 11:59:30 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 11:59:30 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 11:59:30 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10717, maxMem=1124676403
16/03/17 11:59:30 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.6 MB)
16/03/17 11:59:30 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 346 ms on localhost (2/2)
16/03/17 11:59:30 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 11:59:30 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15701, maxMem=1124676403
16/03/17 11:59:30 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.6 MB)
16/03/17 11:59:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:44540 (size: 3.0 KB, free: 1072.6 MB)
16/03/17 11:59:30 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 11:59:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:59:30 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 11:59:30 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:59:30 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 11:59:30 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:59:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 11:59:31 INFO PythonRunner: Times: total = 194, boot = 193, init = 1, finish = 0
16/03/17 11:59:31 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 11:59:31 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:59:31 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 11:59:31 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:59:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/03/17 11:59:31 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 226 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'set']
16/03/17 11:59:31 INFO PythonRunner: Times: total = 191, boot = 190, init = 0, finish = 1
16/03/17 11:59:31 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1271 bytes result sent to driver
16/03/17 11:59:31 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.416 s
16/03/17 11:59:31 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.941610 s
16/03/17 11:59:31 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 212 ms on localhost (2/2)
16/03/17 11:59:31 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 11:59:31 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:59:31 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:59:31 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:59:31 INFO DAGScheduler: Parents of final stage: List()
16/03/17 11:59:31 INFO DAGScheduler: Missing parents: List()
16/03/17 11:59:31 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:59:31 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18757, maxMem=1124676403
16/03/17 11:59:31 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.6 MB)
16/03/17 11:59:31 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24573, maxMem=1124676403
16/03/17 11:59:31 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.5 MB)
16/03/17 11:59:31 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:44540 (size: 3.3 KB, free: 1072.6 MB)
16/03/17 11:59:31 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 11:59:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:59:31 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 11:59:31 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 11:59:31 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 11:59:31 INFO PythonRunner: Times: total = 114, boot = 114, init = 0, finish = 0
16/03/17 11:59:31 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 11:59:31 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/17 11:59:31 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 123 ms on localhost (1/2)
16/03/17 11:59:31 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 11:59:31 INFO PythonRunner: Times: total = 204, boot = 203, init = 1, finish = 0
16/03/17 11:59:31 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1336 bytes result sent to driver
16/03/17 11:59:31 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 224 ms on localhost (2/2)
16/03/17 11:59:31 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 11:59:31 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.345 s
16/03/17 11:59:31 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.364466 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/17 11:59:31 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 11:59:31 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 11:59:32 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 11:59:32 INFO MemoryStore: MemoryStore cleared
16/03/17 11:59:32 INFO BlockManager: BlockManager stopped
16/03/17 11:59:32 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 11:59:32 INFO SparkContext: Successfully stopped SparkContext
16/03/17 11:59:32 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 11:59:32 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 11:59:32 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 11:59:32 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'set']
16/03/17 11:59:32 INFO SparkContext: Running Spark version 1.5.2
16/03/17 11:59:32 INFO SecurityManager: Changing view acls to: root
16/03/17 11:59:32 INFO SecurityManager: Changing modify acls to: root
16/03/17 11:59:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 11:59:33 INFO Slf4jLogger: Slf4jLogger started
16/03/17 11:59:33 INFO Remoting: Starting remoting
16/03/17 11:59:33 INFO Utils: Successfully started service 'sparkDriver' on port 57457.
16/03/17 11:59:33 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:57457]
16/03/17 11:59:33 INFO SparkEnv: Registering MapOutputTracker
16/03/17 11:59:33 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 11:59:33 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c4b67597-190b-4ffd-a244-f50b136be21e
16/03/17 11:59:33 INFO MemoryStore: MemoryStore started with capacity 1072.6 MB
16/03/17 11:59:33 INFO HttpFileServer: HTTP File server directory is /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/httpd-ce215e40-2305-4f19-8d80-fd3bbb3605e6
16/03/17 11:59:33 INFO HttpServer: Starting HTTP Server
16/03/17 11:59:33 INFO Utils: Successfully started service 'HTTP file server' on port 43259.
16/03/17 11:59:33 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 11:59:33 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 11:59:33 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 11:59:33 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-1c02fc06-5cb7-423f-b3c4-6f9c28a87054/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 11:59:33 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196173278
16/03/17 11:59:33 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 11:59:33 INFO Executor: Starting executor ID driver on host localhost
16/03/17 11:59:33 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60110.
16/03/17 11:59:33 INFO NettyBlockTransferService: Server created on 60110
16/03/17 11:59:33 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 11:59:33 INFO BlockManagerMasterEndpoint: Registering block manager localhost:60110 with 1072.6 MB RAM, BlockManagerId(driver, localhost, 60110)
16/03/17 11:59:33 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): element
16/03/17 11:59:33 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:59:33 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:59:33 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:59:33 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:59:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 11:59:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 11:59:33 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:59:33 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124676403
16/03/17 11:59:33 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.6 MB)
16/03/17 11:59:33 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6568, maxMem=1124676403
16/03/17 11:59:33 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 1072.6 MB)
16/03/17 11:59:33 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:60110 (size: 4.1 KB, free: 1072.6 MB)
16/03/17 11:59:33 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 11:59:33 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:59:33 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 11:59:33 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/17 11:59:33 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 11:59:33 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196173278
16/03/17 11:59:33 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-1c02fc06-5cb7-423f-b3c4-6f9c28a87054/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: area
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: issue
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: planning
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: permission
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: economy
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: composition
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: agency
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 11:59:41 INFO PythonRunner: Times: total = 8203, boot = 533, init = 361, finish = 7309
16/03/17 11:59:41 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/17 11:59:41 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/17 11:59:41 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8282 ms on localhost (1/2)
16/03/17 11:59:41 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: set
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: bend
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: giant
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: astatine
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  element  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: present
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: area
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/17 11:59:42 INFO PythonRunner: Times: total = 290, boot = 187, init = 1, finish = 102
16/03/17 11:59:42 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/17 11:59:42 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 310 ms on localhost (2/2)
16/03/17 11:59:42 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.585 s
16/03/17 11:59:42 INFO DAGScheduler: looking for newly runnable stages
16/03/17 11:59:42 INFO DAGScheduler: running: Set()
16/03/17 11:59:42 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 11:59:42 INFO DAGScheduler: failed: Set()
16/03/17 11:59:42 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 11:59:42 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 11:59:42 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 11:59:42 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10717, maxMem=1124676403
16/03/17 11:59:42 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.6 MB)
16/03/17 11:59:42 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15701, maxMem=1124676403
16/03/17 11:59:42 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.6 MB)
16/03/17 11:59:42 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:60110 (size: 3.0 KB, free: 1072.6 MB)
16/03/17 11:59:42 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 11:59:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:59:42 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 11:59:42 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:59:42 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 11:59:42 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:59:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 11:59:42 INFO PythonRunner: Times: total = 159, boot = 158, init = 1, finish = 0
16/03/17 11:59:42 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 11:59:42 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:59:42 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 11:59:42 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 171 ms on localhost (1/2)
16/03/17 11:59:42 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:59:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/03/17 11:59:42 INFO PythonRunner: Times: total = 172, boot = 171, init = 1, finish = 0
16/03/17 11:59:42 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/03/17 11:59:42 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.368 s
16/03/17 11:59:42 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.013518 s
16/03/17 11:59:42 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 198 ms on localhost (2/2)
16/03/17 11:59:42 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 11:59:42 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:59:42 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:59:42 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:59:42 INFO DAGScheduler: Parents of final stage: List()
16/03/17 11:59:42 INFO DAGScheduler: Missing parents: List()
16/03/17 11:59:42 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:59:42 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18757, maxMem=1124676403
16/03/17 11:59:42 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.6 MB)
16/03/17 11:59:42 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24573, maxMem=1124676403
16/03/17 11:59:42 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.5 MB)
16/03/17 11:59:42 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:60110 (size: 3.3 KB, free: 1072.6 MB)
16/03/17 11:59:42 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 11:59:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:59:42 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 11:59:42 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 11:59:42 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 11:59:42 INFO PythonRunner: Times: total = 93, boot = 92, init = 1, finish = 0
16/03/17 11:59:42 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 11:59:42 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/03/17 11:59:42 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 100 ms on localhost (1/2)
16/03/17 11:59:42 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 11:59:42 INFO PythonRunner: Times: total = 216, boot = 216, init = 0, finish = 0
16/03/17 11:59:42 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/03/17 11:59:42 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 226 ms on localhost (2/2)
16/03/17 11:59:42 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 11:59:42 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.317 s
16/03/17 11:59:42 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.351565 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/17 11:59:43 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 11:59:43 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 11:59:43 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 11:59:43 INFO MemoryStore: MemoryStore cleared
16/03/17 11:59:43 INFO BlockManager: BlockManager stopped
16/03/17 11:59:43 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 11:59:43 INFO SparkContext: Successfully stopped SparkContext
16/03/17 11:59:43 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 11:59:43 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 11:59:43 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 11:59:43 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'astatine']
16/03/17 11:59:43 INFO SparkContext: Running Spark version 1.5.2
16/03/17 11:59:43 INFO SecurityManager: Changing view acls to: root
16/03/17 11:59:43 INFO SecurityManager: Changing modify acls to: root
16/03/17 11:59:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 11:59:44 INFO Slf4jLogger: Slf4jLogger started
16/03/17 11:59:44 INFO Remoting: Starting remoting
16/03/17 11:59:44 INFO Utils: Successfully started service 'sparkDriver' on port 53642.
16/03/17 11:59:44 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:53642]
16/03/17 11:59:44 INFO SparkEnv: Registering MapOutputTracker
16/03/17 11:59:44 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 11:59:44 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-dabe2385-8d68-49e5-bd83-d449dabfb43c
16/03/17 11:59:44 INFO MemoryStore: MemoryStore started with capacity 1072.6 MB
16/03/17 11:59:44 INFO HttpFileServer: HTTP File server directory is /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/httpd-0f6c5707-8354-49e9-a75c-d328875b1d0b
16/03/17 11:59:44 INFO HttpServer: Starting HTTP Server
16/03/17 11:59:44 INFO Utils: Successfully started service 'HTTP file server' on port 53497.
16/03/17 11:59:44 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 11:59:44 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 11:59:44 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 11:59:44 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-feb19819-334b-41f9-b576-918e0b20aa11/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 11:59:44 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196184323
16/03/17 11:59:44 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 11:59:44 INFO Executor: Starting executor ID driver on host localhost
16/03/17 11:59:44 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45934.
16/03/17 11:59:44 INFO NettyBlockTransferService: Server created on 45934
16/03/17 11:59:44 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 11:59:44 INFO BlockManagerMasterEndpoint: Registering block manager localhost:45934 with 1072.6 MB RAM, BlockManagerId(driver, localhost, 45934)
16/03/17 11:59:44 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): person
16/03/17 11:59:44 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:59:44 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:59:44 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:59:44 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:59:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 11:59:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 11:59:44 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:59:44 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124676403
16/03/17 11:59:44 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.6 MB)
16/03/17 11:59:44 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6568, maxMem=1124676403
16/03/17 11:59:44 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 1072.6 MB)
16/03/17 11:59:44 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:45934 (size: 4.1 KB, free: 1072.6 MB)
16/03/17 11:59:44 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 11:59:44 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:59:44 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 11:59:44 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/17 11:59:44 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 11:59:44 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196184323
16/03/17 11:59:44 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-feb19819-334b-41f9-b576-918e0b20aa11/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: area
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: issue
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: planning
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: permission
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: economy
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: composition
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: agency
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 11:59:52 INFO PythonRunner: Times: total = 8221, boot = 511, init = 378, finish = 7332
16/03/17 11:59:52 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/17 11:59:52 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/17 11:59:52 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 11:59:52 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8296 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: set
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: bend
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: giant
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): adding to parents: syn =  Synset('colossus.n.02') ; keyword:  person  in syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= [u'giant']
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: astatine
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: present
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: area
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
16/03/17 11:59:53 INFO PythonRunner: Times: total = 339, boot = 193, init = 0, finish = 146
16/03/17 11:59:53 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/17 11:59:53 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 367 ms on localhost (2/2)
16/03/17 11:59:53 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 11:59:53 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.657 s
16/03/17 11:59:53 INFO DAGScheduler: looking for newly runnable stages
16/03/17 11:59:53 INFO DAGScheduler: running: Set()
16/03/17 11:59:53 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 11:59:53 INFO DAGScheduler: failed: Set()
16/03/17 11:59:53 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 11:59:53 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 11:59:53 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10717, maxMem=1124676403
16/03/17 11:59:53 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.6 MB)
16/03/17 11:59:53 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15701, maxMem=1124676403
16/03/17 11:59:53 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.6 MB)
16/03/17 11:59:53 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:45934 (size: 3.0 KB, free: 1072.6 MB)
16/03/17 11:59:53 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 11:59:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:59:53 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 11:59:53 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:59:53 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 11:59:53 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:59:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 11:59:53 INFO PythonRunner: Times: total = 141, boot = 141, init = 0, finish = 0
16/03/17 11:59:53 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 11:59:53 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 11:59:53 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 11:59:53 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 11:59:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 11:59:53 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 169 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'giant']
16/03/17 11:59:53 INFO PythonRunner: Times: total = 243, boot = 238, init = 0, finish = 5
16/03/17 11:59:53 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1281 bytes result sent to driver
16/03/17 11:59:53 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 268 ms on localhost (2/2)
16/03/17 11:59:53 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 11:59:53 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.415 s
16/03/17 11:59:53 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.132264 s
16/03/17 11:59:53 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:59:53 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:59:53 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:59:53 INFO DAGScheduler: Parents of final stage: List()
16/03/17 11:59:53 INFO DAGScheduler: Missing parents: List()
16/03/17 11:59:53 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:59:53 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18757, maxMem=1124676403
16/03/17 11:59:53 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.6 MB)
16/03/17 11:59:53 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24573, maxMem=1124676403
16/03/17 11:59:53 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.5 MB)
16/03/17 11:59:53 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:45934 (size: 3.3 KB, free: 1072.6 MB)
16/03/17 11:59:53 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 11:59:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:59:53 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 11:59:53 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 11:59:53 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 11:59:53 INFO PythonRunner: Times: total = 154, boot = 153, init = 0, finish = 1
16/03/17 11:59:53 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 11:59:53 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2362 bytes)
16/03/17 11:59:53 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 160 ms on localhost (1/2)
16/03/17 11:59:53 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 11:59:54 INFO PythonRunner: Times: total = 188, boot = 188, init = 0, finish = 0
16/03/17 11:59:54 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1349 bytes result sent to driver
16/03/17 11:59:54 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 196 ms on localhost (2/2)
16/03/17 11:59:54 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 11:59:54 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.348 s
16/03/17 11:59:54 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.389320 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/17 11:59:54 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 11:59:54 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 11:59:54 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 11:59:54 INFO MemoryStore: MemoryStore cleared
16/03/17 11:59:54 INFO BlockManager: BlockManager stopped
16/03/17 11:59:54 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 11:59:54 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 11:59:54 INFO SparkContext: Successfully stopped SparkContext
16/03/17 11:59:54 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 11:59:54 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 11:59:54 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'giant']
16/03/17 11:59:55 INFO SparkContext: Running Spark version 1.5.2
16/03/17 11:59:55 INFO SecurityManager: Changing view acls to: root
16/03/17 11:59:55 INFO SecurityManager: Changing modify acls to: root
16/03/17 11:59:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 11:59:55 INFO Slf4jLogger: Slf4jLogger started
16/03/17 11:59:55 INFO Remoting: Starting remoting
16/03/17 11:59:55 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:45671]
16/03/17 11:59:55 INFO Utils: Successfully started service 'sparkDriver' on port 45671.
16/03/17 11:59:55 INFO SparkEnv: Registering MapOutputTracker
16/03/17 11:59:55 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 11:59:55 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3e8e2db3-3795-4a4c-8525-18bd125f8e34
16/03/17 11:59:55 INFO MemoryStore: MemoryStore started with capacity 1072.6 MB
16/03/17 11:59:55 INFO HttpFileServer: HTTP File server directory is /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/httpd-ab2b1aaa-83e9-4468-aaef-1cb5ef4cff7a
16/03/17 11:59:55 INFO HttpServer: Starting HTTP Server
16/03/17 11:59:55 INFO Utils: Successfully started service 'HTTP file server' on port 42938.
16/03/17 11:59:55 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 11:59:55 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 11:59:55 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 11:59:55 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-7f80aafd-96ca-48bd-a47c-251d85e6611b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 11:59:55 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196195496
16/03/17 11:59:55 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 11:59:55 INFO Executor: Starting executor ID driver on host localhost
16/03/17 11:59:55 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 48747.
16/03/17 11:59:55 INFO NettyBlockTransferService: Server created on 48747
16/03/17 11:59:55 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 11:59:55 INFO BlockManagerMasterEndpoint: Registering block manager localhost:48747 with 1072.6 MB RAM, BlockManagerId(driver, localhost, 48747)
16/03/17 11:59:55 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): reputation
16/03/17 11:59:55 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 11:59:55 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:59:55 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 11:59:55 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:59:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 11:59:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 11:59:55 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 11:59:55 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124676403
16/03/17 11:59:55 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.6 MB)
16/03/17 11:59:55 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6568, maxMem=1124676403
16/03/17 11:59:55 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 1072.6 MB)
16/03/17 11:59:55 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:48747 (size: 4.1 KB, free: 1072.6 MB)
16/03/17 11:59:55 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 11:59:55 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 11:59:55 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 11:59:55 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/17 11:59:55 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 11:59:55 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196195496
16/03/17 11:59:55 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-7f80aafd-96ca-48bd-a47c-251d85e6611b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: area
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: issue
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: planning
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: permission
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: economy
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: composition
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: agency
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 12:00:04 INFO PythonRunner: Times: total = 8308, boot = 500, init = 413, finish = 7395
16/03/17 12:00:04 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/17 12:00:04 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/17 12:00:04 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 12:00:04 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8686 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: set
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: bend
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: giant
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): adding to parents: syn =  Synset('colossus.n.02') ; keyword:  reputation  in syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= [u'giant']
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: astatine
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: present
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: area
16/03/17 12:00:04 INFO PythonRunner: Times: total = 338, boot = 242, init = 0, finish = 96
16/03/17 12:00:04 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
16/03/17 12:00:04 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 359 ms on localhost (2/2)
16/03/17 12:00:04 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 12:00:04 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.039 s
16/03/17 12:00:04 INFO DAGScheduler: looking for newly runnable stages
16/03/17 12:00:04 INFO DAGScheduler: running: Set()
16/03/17 12:00:04 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 12:00:04 INFO DAGScheduler: failed: Set()
16/03/17 12:00:04 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 12:00:04 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 12:00:04 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10717, maxMem=1124676403
16/03/17 12:00:04 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.6 MB)
16/03/17 12:00:04 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15701, maxMem=1124676403
16/03/17 12:00:04 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.6 MB)
16/03/17 12:00:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:48747 (size: 3.0 KB, free: 1072.6 MB)
16/03/17 12:00:04 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 12:00:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 12:00:04 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 12:00:04 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 12:00:04 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 12:00:04 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 12:00:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 12:00:04 INFO PythonRunner: Times: total = 205, boot = 204, init = 0, finish = 1
16/03/17 12:00:04 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 12:00:04 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 12:00:04 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 12:00:05 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 12:00:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 12:00:05 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 233 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'giant']
16/03/17 12:00:05 INFO PythonRunner: Times: total = 206, boot = 205, init = 1, finish = 0
16/03/17 12:00:05 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1281 bytes result sent to driver
16/03/17 12:00:05 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 225 ms on localhost (2/2)
16/03/17 12:00:05 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.450 s
16/03/17 12:00:05 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 12:00:05 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.537788 s
16/03/17 12:00:05 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 12:00:05 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 12:00:05 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 12:00:05 INFO DAGScheduler: Parents of final stage: List()
16/03/17 12:00:05 INFO DAGScheduler: Missing parents: List()
16/03/17 12:00:05 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 12:00:05 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18757, maxMem=1124676403
16/03/17 12:00:05 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.6 MB)
16/03/17 12:00:05 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24573, maxMem=1124676403
16/03/17 12:00:05 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.5 MB)
16/03/17 12:00:05 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:48747 (size: 3.3 KB, free: 1072.6 MB)
16/03/17 12:00:05 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 12:00:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 12:00:05 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 12:00:05 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 12:00:05 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 12:00:05 INFO PythonRunner: Times: total = 129, boot = 129, init = 0, finish = 0
16/03/17 12:00:05 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 12:00:05 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2362 bytes)
16/03/17 12:00:05 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 136 ms on localhost (1/2)
16/03/17 12:00:05 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 12:00:05 INFO PythonRunner: Times: total = 240, boot = 240, init = 0, finish = 0
16/03/17 12:00:05 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1349 bytes result sent to driver
16/03/17 12:00:05 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 247 ms on localhost (2/2)
16/03/17 12:00:05 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 12:00:05 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.374 s
16/03/17 12:00:05 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.404075 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/17 12:00:05 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 12:00:05 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 12:00:05 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 12:00:05 INFO MemoryStore: MemoryStore cleared
16/03/17 12:00:05 INFO BlockManager: BlockManager stopped
16/03/17 12:00:05 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 12:00:05 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 12:00:05 INFO SparkContext: Successfully stopped SparkContext
16/03/17 12:00:05 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 12:00:05 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 12:00:05 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'giant']
16/03/17 12:00:06 INFO SparkContext: Running Spark version 1.5.2
16/03/17 12:00:06 INFO SecurityManager: Changing view acls to: root
16/03/17 12:00:06 INFO SecurityManager: Changing modify acls to: root
16/03/17 12:00:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 12:00:06 INFO Slf4jLogger: Slf4jLogger started
16/03/17 12:00:06 INFO Remoting: Starting remoting
16/03/17 12:00:06 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:40342]
16/03/17 12:00:06 INFO Utils: Successfully started service 'sparkDriver' on port 40342.
16/03/17 12:00:06 INFO SparkEnv: Registering MapOutputTracker
16/03/17 12:00:06 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 12:00:06 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f81ce21c-6f7c-48b4-8846-dd28b6b05b6c
16/03/17 12:00:06 INFO MemoryStore: MemoryStore started with capacity 1072.7 MB
16/03/17 12:00:06 INFO HttpFileServer: HTTP File server directory is /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/httpd-f853dd45-87ac-4cae-bb2d-d87c325a9e49
16/03/17 12:00:06 INFO HttpServer: Starting HTTP Server
16/03/17 12:00:06 INFO Utils: Successfully started service 'HTTP file server' on port 46485.
16/03/17 12:00:06 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 12:00:07 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 12:00:07 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 12:00:07 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-7afe43de-e24f-41cb-9340-17bc8e96ec1d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 12:00:07 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196207077
16/03/17 12:00:07 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 12:00:07 INFO Executor: Starting executor ID driver on host localhost
16/03/17 12:00:07 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51237.
16/03/17 12:00:07 INFO NettyBlockTransferService: Server created on 51237
16/03/17 12:00:07 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 12:00:07 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51237 with 1072.7 MB RAM, BlockManagerId(driver, localhost, 51237)
16/03/17 12:00:07 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): time
16/03/17 12:00:07 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 12:00:07 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 12:00:07 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 12:00:07 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 12:00:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 12:00:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 12:00:07 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 12:00:07 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124817960
16/03/17 12:00:07 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.7 MB)
16/03/17 12:00:07 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6568, maxMem=1124817960
16/03/17 12:00:07 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 1072.7 MB)
16/03/17 12:00:07 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51237 (size: 4.1 KB, free: 1072.7 MB)
16/03/17 12:00:07 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 12:00:07 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 12:00:07 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 12:00:07 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/17 12:00:07 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 12:00:07 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196207077
16/03/17 12:00:07 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-7afe43de-e24f-41cb-9340-17bc8e96ec1d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: area
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: issue
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: planning
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: permission
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: economy
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: composition
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: agency
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 12:00:16 INFO PythonRunner: Times: total = 8927, boot = 503, init = 387, finish = 8037
16/03/17 12:00:16 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/17 12:00:16 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/17 12:00:16 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 12:00:16 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9017 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: set
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: bend
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: giant
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: astatine
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: present
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  time  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: area
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/17 12:00:16 INFO PythonRunner: Times: total = 282, boot = 184, init = 1, finish = 97
16/03/17 12:00:16 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/17 12:00:16 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 307 ms on localhost (2/2)
16/03/17 12:00:16 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 12:00:16 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.301 s
16/03/17 12:00:16 INFO DAGScheduler: looking for newly runnable stages
16/03/17 12:00:16 INFO DAGScheduler: running: Set()
16/03/17 12:00:16 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 12:00:16 INFO DAGScheduler: failed: Set()
16/03/17 12:00:16 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 12:00:16 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 12:00:16 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10717, maxMem=1124817960
16/03/17 12:00:16 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.7 MB)
16/03/17 12:00:16 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15701, maxMem=1124817960
16/03/17 12:00:16 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.7 MB)
16/03/17 12:00:16 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51237 (size: 3.0 KB, free: 1072.7 MB)
16/03/17 12:00:16 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 12:00:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 12:00:16 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 12:00:16 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 12:00:16 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 12:00:16 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 12:00:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 12:00:16 INFO PythonRunner: Times: total = 201, boot = 201, init = 0, finish = 0
16/03/17 12:00:16 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 12:00:16 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 12:00:16 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 12:00:16 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 12:00:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 12:00:16 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 231 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'present']
16/03/17 12:00:17 INFO PythonRunner: Times: total = 204, boot = 204, init = 0, finish = 0
16/03/17 12:00:17 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/17 12:00:17 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 227 ms on localhost (2/2)
16/03/17 12:00:17 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 12:00:17 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.447 s
16/03/17 12:00:17 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.773191 s
16/03/17 12:00:17 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 12:00:17 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 12:00:17 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 12:00:17 INFO DAGScheduler: Parents of final stage: List()
16/03/17 12:00:17 INFO DAGScheduler: Missing parents: List()
16/03/17 12:00:17 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 12:00:17 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18757, maxMem=1124817960
16/03/17 12:00:17 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.7 MB)
16/03/17 12:00:17 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24573, maxMem=1124817960
16/03/17 12:00:17 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.7 MB)
16/03/17 12:00:17 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:51237 (size: 3.3 KB, free: 1072.7 MB)
16/03/17 12:00:17 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 12:00:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 12:00:17 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 12:00:17 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 12:00:17 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 12:00:17 INFO PythonRunner: Times: total = 151, boot = 150, init = 1, finish = 0
16/03/17 12:00:17 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 12:00:17 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/17 12:00:17 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 12:00:17 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 157 ms on localhost (1/2)
16/03/17 12:00:17 INFO PythonRunner: Times: total = 220, boot = 220, init = 0, finish = 0
16/03/17 12:00:17 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1351 bytes result sent to driver
16/03/17 12:00:17 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 230 ms on localhost (2/2)
16/03/17 12:00:17 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 12:00:17 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.375 s
16/03/17 12:00:17 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.406450 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/17 12:00:17 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 12:00:17 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 12:00:17 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 12:00:17 INFO MemoryStore: MemoryStore cleared
16/03/17 12:00:17 INFO BlockManager: BlockManager stopped
16/03/17 12:00:17 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 12:00:17 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 12:00:17 INFO SparkContext: Successfully stopped SparkContext
16/03/17 12:00:17 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 12:00:17 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 12:00:17 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'present']
16/03/17 12:00:18 INFO SparkContext: Running Spark version 1.5.2
16/03/17 12:00:18 INFO SecurityManager: Changing view acls to: root
16/03/17 12:00:18 INFO SecurityManager: Changing modify acls to: root
16/03/17 12:00:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 12:00:18 INFO Slf4jLogger: Slf4jLogger started
16/03/17 12:00:18 INFO Remoting: Starting remoting
16/03/17 12:00:18 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:42850]
16/03/17 12:00:18 INFO Utils: Successfully started service 'sparkDriver' on port 42850.
16/03/17 12:00:18 INFO SparkEnv: Registering MapOutputTracker
16/03/17 12:00:18 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 12:00:18 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ac955ccd-8417-414f-9f19-2d4c0a3d1f3c
16/03/17 12:00:18 INFO MemoryStore: MemoryStore started with capacity 1072.7 MB
16/03/17 12:00:18 INFO HttpFileServer: HTTP File server directory is /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/httpd-3b9d0f52-fc03-4d69-a787-4f252026495e
16/03/17 12:00:18 INFO HttpServer: Starting HTTP Server
16/03/17 12:00:18 INFO Utils: Successfully started service 'HTTP file server' on port 56611.
16/03/17 12:00:18 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 12:00:18 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 12:00:18 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 12:00:18 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-26bdf888-26a4-4693-8244-d99f1245dde5/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 12:00:18 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196218891
16/03/17 12:00:18 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 12:00:18 INFO Executor: Starting executor ID driver on host localhost
16/03/17 12:00:18 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59953.
16/03/17 12:00:18 INFO NettyBlockTransferService: Server created on 59953
16/03/17 12:00:18 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 12:00:18 INFO BlockManagerMasterEndpoint: Registering block manager localhost:59953 with 1072.7 MB RAM, BlockManagerId(driver, localhost, 59953)
16/03/17 12:00:18 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): position
16/03/17 12:00:19 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 12:00:19 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 12:00:19 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 12:00:19 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 12:00:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 12:00:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 12:00:19 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 12:00:19 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124817960
16/03/17 12:00:19 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.7 MB)
16/03/17 12:00:19 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6568, maxMem=1124817960
16/03/17 12:00:19 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 1072.7 MB)
16/03/17 12:00:19 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:59953 (size: 4.1 KB, free: 1072.7 MB)
16/03/17 12:00:19 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 12:00:19 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 12:00:19 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 12:00:19 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/17 12:00:19 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 12:00:19 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196218891
16/03/17 12:00:19 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-26bdf888-26a4-4693-8244-d99f1245dde5/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: area
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: issue
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: planning
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: permission
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: economy
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: composition
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: agency
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 12:00:27 INFO PythonRunner: Times: total = 8288, boot = 597, init = 675, finish = 7016
16/03/17 12:00:27 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/17 12:00:27 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/17 12:00:27 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 12:00:27 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8354 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: set
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: bend
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: giant
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: astatine
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: present
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  position  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: area
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
16/03/17 12:00:27 INFO PythonRunner: Times: total = 326, boot = 218, init = 0, finish = 108
16/03/17 12:00:27 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/17 12:00:27 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.687 s
16/03/17 12:00:27 INFO DAGScheduler: looking for newly runnable stages
16/03/17 12:00:27 INFO DAGScheduler: running: Set()
16/03/17 12:00:27 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 12:00:27 INFO DAGScheduler: failed: Set()
16/03/17 12:00:27 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 12:00:27 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 12:00:27 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10717, maxMem=1124817960
16/03/17 12:00:27 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.7 MB)
16/03/17 12:00:27 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15701, maxMem=1124817960
16/03/17 12:00:27 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.7 MB)
16/03/17 12:00:27 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 341 ms on localhost (2/2)
16/03/17 12:00:27 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 12:00:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:59953 (size: 3.0 KB, free: 1072.7 MB)
16/03/17 12:00:27 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 12:00:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 12:00:27 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 12:00:27 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 12:00:27 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 12:00:27 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 12:00:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 12:00:27 INFO PythonRunner: Times: total = 184, boot = 183, init = 0, finish = 1
16/03/17 12:00:27 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 12:00:27 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 12:00:27 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 12:00:27 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 12:00:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/03/17 12:00:27 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 206 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'metropolitan']
16/03/17 12:00:28 INFO PythonRunner: Times: total = 216, boot = 215, init = 1, finish = 0
16/03/17 12:00:28 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1288 bytes result sent to driver
16/03/17 12:00:28 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.416 s
16/03/17 12:00:28 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.148646 s
16/03/17 12:00:28 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 231 ms on localhost (2/2)
16/03/17 12:00:28 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 12:00:28 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 12:00:28 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 12:00:28 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 12:00:28 INFO DAGScheduler: Parents of final stage: List()
16/03/17 12:00:28 INFO DAGScheduler: Missing parents: List()
16/03/17 12:00:28 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 12:00:28 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18757, maxMem=1124817960
16/03/17 12:00:28 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.7 MB)
16/03/17 12:00:28 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24573, maxMem=1124817960
16/03/17 12:00:28 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.7 MB)
16/03/17 12:00:28 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:59953 (size: 3.3 KB, free: 1072.7 MB)
16/03/17 12:00:28 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 12:00:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 12:00:28 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 12:00:28 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 12:00:28 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 12:00:28 INFO PythonRunner: Times: total = 137, boot = 136, init = 1, finish = 0
16/03/17 12:00:28 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 12:00:28 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2369 bytes)
16/03/17 12:00:28 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 12:00:28 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 143 ms on localhost (1/2)
16/03/17 12:00:28 INFO PythonRunner: Times: total = 197, boot = 196, init = 1, finish = 0
16/03/17 12:00:28 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1356 bytes result sent to driver
16/03/17 12:00:28 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 209 ms on localhost (2/2)
16/03/17 12:00:28 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 12:00:28 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.352 s
16/03/17 12:00:28 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.370459 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/17 12:00:28 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 12:00:28 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 12:00:28 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 12:00:28 INFO MemoryStore: MemoryStore cleared
16/03/17 12:00:28 INFO BlockManager: BlockManager stopped
16/03/17 12:00:28 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 12:00:28 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 12:00:28 INFO SparkContext: Successfully stopped SparkContext
16/03/17 12:00:28 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 12:00:28 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 12:00:28 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'metropolitan']
16/03/17 12:00:29 INFO SparkContext: Running Spark version 1.5.2
16/03/17 12:00:29 INFO SecurityManager: Changing view acls to: root
16/03/17 12:00:29 INFO SecurityManager: Changing modify acls to: root
16/03/17 12:00:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 12:00:29 INFO Slf4jLogger: Slf4jLogger started
16/03/17 12:00:29 INFO Remoting: Starting remoting
16/03/17 12:00:29 INFO Utils: Successfully started service 'sparkDriver' on port 44708.
16/03/17 12:00:29 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:44708]
16/03/17 12:00:29 INFO SparkEnv: Registering MapOutputTracker
16/03/17 12:00:29 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 12:00:29 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0cf2465b-5c42-48e2-a973-683a71b72651
16/03/17 12:00:29 INFO MemoryStore: MemoryStore started with capacity 1072.7 MB
16/03/17 12:00:29 INFO HttpFileServer: HTTP File server directory is /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/httpd-b0fbe728-77a6-420a-be59-1668fcad805b
16/03/17 12:00:29 INFO HttpServer: Starting HTTP Server
16/03/17 12:00:29 INFO Utils: Successfully started service 'HTTP file server' on port 43353.
16/03/17 12:00:29 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 12:00:29 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 12:00:29 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 12:00:29 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-a20c96b2-d681-4837-8983-1ae7ee0b00cf/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 12:00:29 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196229967
16/03/17 12:00:30 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 12:00:30 INFO Executor: Starting executor ID driver on host localhost
16/03/17 12:00:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44820.
16/03/17 12:00:30 INFO NettyBlockTransferService: Server created on 44820
16/03/17 12:00:30 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 12:00:30 INFO BlockManagerMasterEndpoint: Registering block manager localhost:44820 with 1072.7 MB RAM, BlockManagerId(driver, localhost, 44820)
16/03/17 12:00:30 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): quantity
16/03/17 12:00:30 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 12:00:30 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 12:00:30 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 12:00:30 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 12:00:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 12:00:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 12:00:30 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 12:00:30 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124817960
16/03/17 12:00:30 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.7 MB)
16/03/17 12:00:30 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6568, maxMem=1124817960
16/03/17 12:00:30 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 1072.7 MB)
16/03/17 12:00:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:44820 (size: 4.1 KB, free: 1072.7 MB)
16/03/17 12:00:30 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 12:00:30 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 12:00:30 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 12:00:30 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/17 12:00:30 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 12:00:30 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196229967
16/03/17 12:00:30 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-a20c96b2-d681-4837-8983-1ae7ee0b00cf/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: area
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: issue
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: planning
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: permission
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: economy
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: composition
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: agency
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 12:00:38 INFO PythonRunner: Times: total = 8073, boot = 488, init = 385, finish = 7200
16/03/17 12:00:38 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/17 12:00:38 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/17 12:00:38 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 12:00:38 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8157 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: set
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: bend
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: giant
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: astatine
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: present
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: area
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 12:00:38 INFO PythonRunner: Times: total = 326, boot = 185, init = 0, finish = 141
16/03/17 12:00:38 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/17 12:00:38 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.488 s
16/03/17 12:00:38 INFO DAGScheduler: looking for newly runnable stages
16/03/17 12:00:38 INFO DAGScheduler: running: Set()
16/03/17 12:00:38 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 12:00:38 INFO DAGScheduler: failed: Set()
16/03/17 12:00:38 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 12:00:38 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 12:00:38 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10717, maxMem=1124817960
16/03/17 12:00:38 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.7 MB)
16/03/17 12:00:38 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15701, maxMem=1124817960
16/03/17 12:00:38 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.7 MB)
16/03/17 12:00:38 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 345 ms on localhost (2/2)
16/03/17 12:00:38 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 12:00:38 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:44820 (size: 3.0 KB, free: 1072.7 MB)
16/03/17 12:00:38 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 12:00:38 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 12:00:38 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 12:00:38 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 12:00:38 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 12:00:38 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 12:00:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 12:00:38 INFO PythonRunner: Times: total = 192, boot = 191, init = 0, finish = 1
16/03/17 12:00:38 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 12:00:38 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 12:00:38 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 12:00:38 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 12:00:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
16/03/17 12:00:38 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 216 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None']
16/03/17 12:00:39 INFO PythonRunner: Times: total = 177, boot = 175, init = 1, finish = 1
16/03/17 12:00:39 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1269 bytes result sent to driver
16/03/17 12:00:39 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.394 s
16/03/17 12:00:39 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.917939 s
16/03/17 12:00:39 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 199 ms on localhost (2/2)
16/03/17 12:00:39 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 12:00:39 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 12:00:39 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 12:00:39 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 12:00:39 INFO DAGScheduler: Parents of final stage: List()
16/03/17 12:00:39 INFO DAGScheduler: Missing parents: List()
16/03/17 12:00:39 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 12:00:39 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18757, maxMem=1124817960
16/03/17 12:00:39 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.7 MB)
16/03/17 12:00:39 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24573, maxMem=1124817960
16/03/17 12:00:39 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.7 MB)
16/03/17 12:00:39 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:44820 (size: 3.3 KB, free: 1072.7 MB)
16/03/17 12:00:39 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 12:00:39 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 12:00:39 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 12:00:39 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 12:00:39 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 12:00:39 INFO PythonRunner: Times: total = 149, boot = 149, init = 0, finish = 0
16/03/17 12:00:39 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 12:00:39 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2350 bytes)
16/03/17 12:00:39 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 154 ms on localhost (1/2)
16/03/17 12:00:39 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 12:00:39 INFO PythonRunner: Times: total = 174, boot = 174, init = 0, finish = 0
16/03/17 12:00:39 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1337 bytes result sent to driver
16/03/17 12:00:39 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 184 ms on localhost (2/2)
16/03/17 12:00:39 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 12:00:39 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.329 s
16/03/17 12:00:39 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.348046 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/17 12:00:39 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 12:00:39 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 12:00:39 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 12:00:39 INFO MemoryStore: MemoryStore cleared
16/03/17 12:00:39 INFO BlockManager: BlockManager stopped
16/03/17 12:00:39 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 12:00:39 INFO SparkContext: Successfully stopped SparkContext
16/03/17 12:00:39 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 12:00:39 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 12:00:39 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 12:00:39 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None']
InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:freqterms1= [u'serving', u'Madras', u'Bengal', u'course', u'relation', u'geography', u'group', u'decay', u'program', u'Tamil', u'exceptional', u'Bay', u'formulating', u'serves', u'item', u'miles', u'unstable', u'including', u'people', u'series', u'Christianity', u'culture', u'meters', u'special', u'0.621371', u'Orthodox', u'definite', u'boundary', u'business', u'importance', u'equivalent', u'thorium', u'approval', u'providing', u'region', u'title', u'equal', u'length', u'resulting', u'act', u'action', u'whole', u'businesses', u'1000', u'formerly', u'period', u'highly', u'production', u'indefinite', u'unit', u'city', u'use', u'consumption', u'Eastern', u'stretch', u'archbishop', u'system', u'halogen', u'continuous', u'western', u'particular', u'given', u'kind', u'official', u'patriarch', u'Church', u'distribution', u'property', u'distinguished', u'metric', u'heaviest', u'purposes', u'general', u'something', u'bishop', u'things', u'belong', u'uranium', u'arrangement', u'parts', u'speech', u'geographical', u'spatial', u'Nadu', u'circular', u'product', u'used', u'usually', u'moment', u'purpose', u'segment', u'radioactive', u'happening', u'curve', u'together', u'element', u'person', u'reputation', u'time', u'position', u'quantity']
16/03/17 12:00:40 INFO SparkContext: Running Spark version 1.5.2
16/03/17 12:00:40 INFO SecurityManager: Changing view acls to: root
16/03/17 12:00:40 INFO SecurityManager: Changing modify acls to: root
16/03/17 12:00:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 12:00:40 INFO Slf4jLogger: Slf4jLogger started
16/03/17 12:00:40 INFO Remoting: Starting remoting
16/03/17 12:00:40 INFO Utils: Successfully started service 'sparkDriver' on port 58138.
16/03/17 12:00:40 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:58138]
16/03/17 12:00:40 INFO SparkEnv: Registering MapOutputTracker
16/03/17 12:00:40 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 12:00:40 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-297e84a2-d0ec-474c-8ea5-2f1eb8ad150f
16/03/17 12:00:40 INFO MemoryStore: MemoryStore started with capacity 1072.7 MB
16/03/17 12:00:40 INFO HttpFileServer: HTTP File server directory is /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/httpd-50a09010-c9ad-45f2-b325-8b2f950361d9
16/03/17 12:00:40 INFO HttpServer: Starting HTTP Server
16/03/17 12:00:40 INFO Utils: Successfully started service 'HTTP file server' on port 35318.
16/03/17 12:00:40 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 12:00:40 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 12:00:40 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 12:00:40 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-6b80e661-6e31-4c97-a868-02be0583be95/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 12:00:40 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196240913
16/03/17 12:00:40 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 12:00:40 INFO Executor: Starting executor ID driver on host localhost
16/03/17 12:00:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43809.
16/03/17 12:00:41 INFO NettyBlockTransferService: Server created on 43809
16/03/17 12:00:41 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 12:00:41 INFO BlockManagerMasterEndpoint: Registering block manager localhost:43809 with 1072.7 MB RAM, BlockManagerId(driver, localhost, 43809)
16/03/17 12:00:41 INFO BlockManagerMaster: Registered BlockManager
Spark_MapReduce(): wordsatthislevel: [u'serving', u'Madras', u'Bengal', u'course', u'relation', u'geography', u'group', u'decay', u'program', u'Tamil', u'exceptional', u'Bay', u'formulating', u'serves', u'item', u'miles', u'unstable', u'including', u'people', u'series', u'Christianity', u'culture', u'meters', u'special', u'0.621371', u'Orthodox', u'definite', u'boundary', u'business', u'importance', u'equivalent', u'thorium', u'approval', u'providing', u'region', u'title', u'equal', u'length', u'resulting', u'act', u'action', u'whole', u'businesses', u'1000', u'formerly', u'period', u'highly', u'production', u'indefinite', u'unit', u'city', u'use', u'consumption', u'Eastern', u'stretch', u'archbishop', u'system', u'halogen', u'continuous', u'western', u'particular', u'given', u'kind', u'official', u'patriarch', u'Church', u'distribution', u'property', u'distinguished', u'metric', u'heaviest', u'purposes', u'general', u'something', u'bishop', u'things', u'belong', u'uranium', u'arrangement', u'parts', u'speech', u'geographical', u'spatial', u'Nadu', u'circular', u'product', u'used', u'usually', u'moment', u'purpose', u'segment', u'radioactive', u'happening', u'curve', u'together', u'element', u'person', u'reputation', u'time', u'position', u'quantity']
16/03/17 12:00:41 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230
16/03/17 12:00:41 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/17 12:00:41 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) with 2 output partitions
16/03/17 12:00:41 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/17 12:00:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 12:00:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 12:00:41 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230), which has no missing parents
16/03/17 12:00:41 INFO MemoryStore: ensureFreeSpace(6552) called with curMem=0, maxMem=1124817960
16/03/17 12:00:41 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.7 MB)
16/03/17 12:00:41 INFO MemoryStore: ensureFreeSpace(4140) called with curMem=6552, maxMem=1124817960
16/03/17 12:00:41 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.7 MB)
16/03/17 12:00:41 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:43809 (size: 4.0 KB, free: 1072.7 MB)
16/03/17 12:00:41 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 12:00:41 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/17 12:00:41 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 3016 bytes)
16/03/17 12:00:41 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 12:00:41 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458196240913
16/03/17 12:00:41 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-9a00a89e-a973-4031-b24e-c567c2478a23/userFiles-6b80e661-6e31-4c97-a868-02be0583be95/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
mapFunction(): freqterms1: serving
mapFunction(): freqterms1: Madras
mapFunction(): freqterms1: Bengal
mapFunction(): freqterms1: course
mapFunction(): freqterms1: relation
mapFunction(): freqterms1: geography
mapFunction(): freqterms1: group
mapFunction(): freqterms1: decay
mapFunction(): freqterms1: program
mapFunction(): freqterms1: Tamil
mapFunction(): freqterms1: exceptional
mapFunction(): freqterms1: Bay
mapFunction(): freqterms1: formulating
mapFunction(): freqterms1: serves
mapFunction(): freqterms1: item
mapFunction(): freqterms1: miles
mapFunction(): freqterms1: unstable
mapFunction(): freqterms1: including
mapFunction(): freqterms1: people
mapFunction(): freqterms1: series
mapFunction(): freqterms1: Christianity
mapFunction(): freqterms1: culture
mapFunction(): freqterms1: meters
mapFunction(): freqterms1: special
mapFunction(): freqterms1: 0.621371
mapFunction(): freqterms1: Orthodox
mapFunction(): freqterms1: definite
mapFunction(): freqterms1: boundary
mapFunction(): freqterms1: business
mapFunction(): freqterms1: importance
mapFunction(): freqterms1: equivalent
mapFunction(): freqterms1: thorium
mapFunction(): freqterms1: approval
mapFunction(): freqterms1: providing
mapFunction(): freqterms1: region
mapFunction(): freqterms1: title
mapFunction(): freqterms1: equal
mapFunction(): freqterms1: length
mapFunction(): freqterms1: resulting
mapFunction(): freqterms1: act
mapFunction(): freqterms1: action
mapFunction(): freqterms1: whole
mapFunction(): freqterms1: businesses
mapFunction(): freqterms1: 1000
mapFunction(): freqterms1: formerly
mapFunction(): freqterms1: period
mapFunction(): freqterms1: highly
mapFunction(): freqterms1: production
mapFunction(): freqterms1: indefinite
mapFunction(): freqterms1: unit
16/03/17 12:00:51 INFO PythonRunner: Times: total = 9680, boot = 475, init = 413, finish = 8792
16/03/17 12:00:51 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/17 12:00:51 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 3065 bytes)
16/03/17 12:00:51 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 12:00:51 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9804 ms on localhost (1/2)
mapFunction(): freqterms1: city
mapFunction(): freqterms1: use
mapFunction(): freqterms1: consumption
mapFunction(): freqterms1: Eastern
mapFunction(): freqterms1: stretch
mapFunction(): freqterms1: archbishop
mapFunction(): freqterms1: system
mapFunction(): freqterms1: halogen
mapFunction(): freqterms1: continuous
mapFunction(): freqterms1: western
mapFunction(): freqterms1: particular
mapFunction(): freqterms1: given
mapFunction(): freqterms1: kind
mapFunction(): freqterms1: official
mapFunction(): freqterms1: patriarch
mapFunction(): freqterms1: Church
mapFunction(): freqterms1: distribution
mapFunction(): freqterms1: property
mapFunction(): freqterms1: distinguished
mapFunction(): freqterms1: metric
mapFunction(): freqterms1: heaviest
mapFunction(): freqterms1: purposes
mapFunction(): freqterms1: general
mapFunction(): freqterms1: something
mapFunction(): freqterms1: bishop
mapFunction(): freqterms1: things
mapFunction(): freqterms1: belong
mapFunction(): freqterms1: uranium
mapFunction(): freqterms1: arrangement
mapFunction(): freqterms1: parts
mapFunction(): freqterms1: speech
mapFunction(): freqterms1: geographical
mapFunction(): freqterms1: spatial
mapFunction(): freqterms1: Nadu
mapFunction(): freqterms1: circular
mapFunction(): freqterms1: product
mapFunction(): freqterms1: used
mapFunction(): freqterms1: usually
mapFunction(): freqterms1: moment
mapFunction(): freqterms1: purpose
mapFunction(): freqterms1: segment
mapFunction(): freqterms1: radioactive
mapFunction(): freqterms1: happening
mapFunction(): freqterms1: curve
mapFunction(): freqterms1: together
mapFunction(): freqterms1: element
mapFunction(): freqterms1: person
mapFunction(): freqterms1: reputation
mapFunction(): freqterms1: time
mapFunction(): freqterms1: position
mapFunction(): freqterms1: quantity
16/03/17 12:00:52 INFO PythonRunner: Times: total = 1718, boot = 211, init = 0, finish = 1507
16/03/17 12:00:52 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/17 12:00:52 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) finished in 11.533 s
16/03/17 12:00:52 INFO DAGScheduler: looking for newly runnable stages
16/03/17 12:00:52 INFO DAGScheduler: running: Set()
16/03/17 12:00:52 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 12:00:52 INFO DAGScheduler: failed: Set()
16/03/17 12:00:52 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 12:00:52 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230), which is now runnable
16/03/17 12:00:52 INFO MemoryStore: ensureFreeSpace(4976) called with curMem=10692, maxMem=1124817960
16/03/17 12:00:52 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.7 MB)
16/03/17 12:00:52 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15668, maxMem=1124817960
16/03/17 12:00:52 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.7 MB)
16/03/17 12:00:52 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1734 ms on localhost (2/2)
16/03/17 12:00:52 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 12:00:52 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:43809 (size: 3.0 KB, free: 1072.7 MB)
16/03/17 12:00:52 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 12:00:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/17 12:00:52 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 12:00:52 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 12:00:52 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 12:00:52 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 12:00:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 12:00:53 INFO PythonRunner: Times: total = 232, boot = 231, init = 0, finish = 1
16/03/17 12:00:53 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 12:00:53 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 12:00:53 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 12:00:53 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 12:00:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 12:00:53 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 259 ms on localhost (1/2)
16/03/17 12:00:53 INFO PythonRunner: Times: total = 218, boot = 215, init = 0, finish = 3
16/03/17 12:00:53 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 11013 bytes result sent to driver
16/03/17 12:00:53 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 235 ms on localhost (2/2)
16/03/17 12:00:53 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 12:00:53 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) finished in 0.490 s
16/03/17 12:00:53 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230, took 12.072045 s
16/03/17 12:00:53 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230
16/03/17 12:00:53 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) with 2 output partitions
16/03/17 12:00:53 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/17 12:00:53 INFO DAGScheduler: Parents of final stage: List()
16/03/17 12:00:53 INFO DAGScheduler: Missing parents: List()
16/03/17 12:00:53 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230), which has no missing parents
16/03/17 12:00:53 INFO MemoryStore: ensureFreeSpace(5872) called with curMem=18716, maxMem=1124817960
16/03/17 12:00:53 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.7 MB)
16/03/17 12:00:53 INFO MemoryStore: ensureFreeSpace(3419) called with curMem=24588, maxMem=1124817960
16/03/17 12:00:53 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.7 MB)
16/03/17 12:00:53 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:43809 (size: 3.3 KB, free: 1072.7 MB)
16/03/17 12:00:53 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 12:00:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/17 12:00:53 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 12:00:53 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 12:00:53 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 12:00:53 INFO PythonRunner: Times: total = 124, boot = 123, init = 1, finish = 0
16/03/17 12:00:53 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 12:00:53 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 11962 bytes)
16/03/17 12:00:53 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 130 ms on localhost (1/2)
16/03/17 12:00:53 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 12:00:53 INFO PythonRunner: Times: total = 221, boot = 220, init = 0, finish = 1
16/03/17 12:00:53 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 11320 bytes result sent to driver
16/03/17 12:00:53 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 269 ms on localhost (2/2)
16/03/17 12:00:53 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 12:00:53 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) finished in 0.391 s
16/03/17 12:00:53 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230, took 0.434281 s
Spark_MapReduce() - SparkSQL DataFrame query results:
Row(tokensatthislevel=[u'individual', u'quantity', u'food', u'drink', u'taken', u'part', u'meal', u'state', u'southeastern', u'India', u'Bay', u'Bengal', u'south', u'Andhra', u'Pradesh', u'formerly', u'Madras', u'region', u'whose', u'eastern', u'part', u'Bangladesh', u'whose', u'western', u'part', u'included', u'India', u'education', u'imparted', u'series', u'lessons', u'meetings', u'act', u'sexual', u'procreation', u'man', u'woman', u'man', u'penis', u'inserted', u'woman', u'vagina', u'excited', u'orgasm', u'ejaculation', u'occur', u'study', u'earth', u'surface', u'includes', u'people', u'responses', u'topography', u'climate', u'soil', u'vegetation', u'number', u'entities', u'members', u'considered', u'unit', u'gradual', u'decrease', u'stored', u'charge', u'current', u'series', u'steps', u'carried', u'goals', u'accomplished', u'member', u'mixed', u'Dravidian', u'Caucasian', u'people', u'southern', u'India', u'Sri', u'Lanka', u'deviating', u'widely', u'norm', u'physical', u'mental', u'ability', u'used', u'especially', u'children', u'normal', u'intelligence', u'indentation', u'shoreline', u'larger', u'cove', u'smaller', u'gulf', u'come', u'idea', u'plan', u'explanation', u'theory', u'principle', u'mental', u'effort', u'sports', u'stroke', u'puts', u'ball', u'play', u'distinct', u'part', u'specified', u'separately', u'group', u'things', u'could', u'enumerated', u'list', u'unit', u'length', u'equal', u'1,760', u'yards', u'5,280', u'feet', u'exactly', u'1609.344', u'meters', u'lacking', u'stability', u'fixity', u'firmness', u'part', u'made', u'plural', u'group', u'human', u'beings', u'men', u'women', u'children', u'collectively', u'similar', u'things', u'placed', u'order', u'happening', u'one', u'another', u'monotheistic', u'system', u'beliefs', u'practices', u'based', u'Old', u'Testament', u'teachings', u'Jesus', u'embodied', u'New', u'Testament', u'emphasizing', u'role', u'Jesus', u'savior', u'particular', u'society', u'particular', u'time', u'place', u'basic', u'unit', u'length', u'adopted', u'Systeme', u'International', u"d'Unites", u'approximately', u'1.094', u'yards', u'special', u'offering', u'usually', u'temporary', u'reduced', u'price', u'featured', u'advertising', u'pertaining', u'characteristic', u'Judaism', u'precise', u'explicit', u'clearly', u'defined', u'line', u'determining', u'limits', u'area', u'commercial', u'industrial', u'enterprise', u'people', u'constitute', u'prominent', u'status', u'person', u'thing', u'equal', u'another', u'value', u'measure', u'force', u'effect', u'significance', u'etc', u'soft', u'silvery-white', u'tetravalent', u'radioactive', u'metallic', u'element', u'isotope', u'232', u'used', u'power', u'source', u'nuclear', u'reactors', u'occurs', u'thorite', u'monazite', u'sands', u'feeling', u'liking', u'something', u'someone', u'good', u'give', u'something', u'useful', u'necessary', u'extended', u'spatial', u'location', u'something', u'heading', u'names', u'statute', u'legislative', u'bill', u'give', u'brief', u'summary', u'matters', u'deals', u'person', u'equal', u'standing', u'another', u'group', u'linear', u'extent', u'space', u'one', u'end', u'longest', u'dimension', u'something', u'fixed', u'place', u'issue', u'terminate', u'specified', u'way', u'state', u'etc', u'end', u'legal', u'document', u'codifying', u'result', u'deliberations', u'committee', u'society', u'legislative', u'body', u'military', u'engagement', u'something', u'including', u'component', u'elements', u'parts', u'commercial', u'industrial', u'enterprise', u'people', u'constitute', u'cardinal', u'number', u'product', u'10', u'100', u'previous', u'time', u'amount', u'time', u'high', u'degree', u'extent', u'favorably', u'much', u'respect', u'act', u'process', u'producing', u'something', u'vague', u'clearly', u'defined', u'stated', u'division', u'quantity', u'accepted', u'standard', u'measurement', u'exchange', u'large', u'densely', u'populated', u'urban', u'area', u'include', u'several', u'independent', u'administrative', u'districts', u'act', u'using', u'process', u'taking', u'food', u'body', u'mouth', u'eating', u'lying', u'toward', u'situated', u'east', u'large', u'unbroken', u'expanse', u'distance', u'bishop', u'highest', u'rank', u'instrumentality', u'combines', u'interrelated', u'interacting', u'artifacts', u'designed', u'work', u'coherent', u'entity', u'five', u'related', u'nonmetallic', u'elements', u'fluorine', u'chlorine', u'bromine', u'iodine', u'astatine', u'monovalent', u'readily', u'form', u'negative', u'ions', u'continuing', u'time', u'space', u'without', u'interruption', u'film', u'life', u'western', u'United', u'States', u'period', u'exploration', u'development', u'fact', u'part', u'opposed', u'general', u'assumption', u'taken', u'granted', u'category', u'things', u'distinguished', u'common', u'characteristic', u'quality', u'worker', u'holds', u'invested', u'office', u'man', u'older', u'higher', u'rank', u'one', u'groups', u'Christians', u'beliefs', u'forms', u'worship', u'statistics', u'arrangement', u'values', u'variable', u'showing', u'observed', u'theoretical', u'frequency', u'occurrence', u'something', u'owned', u'tangible', u'intangible', u'possession', u'owned', u'someone', u'mark', u'different', u'function', u'topological', u'space', u'gives', u'two', u'points', u'space', u'value', u'equal', u'distance', u'usually', u'describes', u'large', u'person', u'fat', u'large', u'frame', u'carry', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions', u'general', u'officer', u'highest', u'rank', u'senior', u'member', u'Christian', u'clergy', u'spiritual', u'administrative', u'authority', u'appointed', u'Christian', u'churches', u'oversee', u'priests', u'ministers', u'considered', u'churches', u'successors', u'twelve', u'Apostles', u'Christ', u'movable', u'possession', u'especially', u'articles', u'clothing', u'owned', u'possession', u'heavy', u'toxic', u'silvery-white', u'radioactive', u'metallic', u'element', u'occurs', u'many', u'isotopes', u'used', u'nuclear', u'fuels', u'nuclear', u'weapons', u'orderly', u'grouping', u'things', u'persons', u'considered', u'unit', u'result', u'arranging', u'something', u'less', u'whole', u'human', u'artifact', u'act', u'delivering', u'formal', u'spoken', u'communication', u'audience', u'relating', u'science', u'geography', u'pertaining', u'involving', u'nature', u'space', u'advertisement', u'usually', u'printed', u'page', u'leaflet', u'intended', u'wide', u'distribution', u'commodities', u'offered', u'sale', u'put', u'service', u'make', u'work', u'employ', u'particular', u'purpose', u'inherent', u'natural', u'purpose', u'normal', u'conditions', u'particular', u'point', u'time', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions', u'one', u'several', u'parts', u'pieces', u'fit', u'others', u'constitute', u'whole', u'object', u'exhibiting', u'caused', u'radioactivity', u'event', u'happens', u'trace', u'point', u'whose', u'direction', u'motion', u'changes', u'mentally', u'emotionally', u'stable', u'abstract', u'part', u'something', u'human', u'general', u'estimation', u'public', u'person', u'instance', u'single', u'occasion', u'event', u'particular', u'portion', u'space', u'occupied', u'something', u'concept', u'something', u'magnitude', u'represented', u'mathematical', u'expressions', u'constant', u'variable'])
16/03/17 12:00:53 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 12:00:53 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 12:00:54 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 12:00:54 INFO MemoryStore: MemoryStore cleared
16/03/17 12:00:54 INFO BlockManager: BlockManager stopped
16/03/17 12:00:54 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 12:00:54 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 12:00:54 INFO SparkContext: Successfully stopped SparkContext
16/03/17 12:00:54 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 12:00:54 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 12:00:54 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:tokensofthislevel: [u'individual', u'quantity', u'food', u'drink', u'taken', u'part', u'meal', u'state', u'southeastern', u'India', u'Bay', u'Bengal', u'south', u'Andhra', u'Pradesh', u'formerly', u'Madras', u'region', u'whose', u'eastern', u'part', u'Bangladesh', u'whose', u'western', u'part', u'included', u'India', u'education', u'imparted', u'series', u'lessons', u'meetings', u'act', u'sexual', u'procreation', u'man', u'woman', u'man', u'penis', u'inserted', u'woman', u'vagina', u'excited', u'orgasm', u'ejaculation', u'occur', u'study', u'earth', u'surface', u'includes', u'people', u'responses', u'topography', u'climate', u'soil', u'vegetation', u'number', u'entities', u'members', u'considered', u'unit', u'gradual', u'decrease', u'stored', u'charge', u'current', u'series', u'steps', u'carried', u'goals', u'accomplished', u'member', u'mixed', u'Dravidian', u'Caucasian', u'people', u'southern', u'India', u'Sri', u'Lanka', u'deviating', u'widely', u'norm', u'physical', u'mental', u'ability', u'used', u'especially', u'children', u'normal', u'intelligence', u'indentation', u'shoreline', u'larger', u'cove', u'smaller', u'gulf', u'come', u'idea', u'plan', u'explanation', u'theory', u'principle', u'mental', u'effort', u'sports', u'stroke', u'puts', u'ball', u'play', u'distinct', u'part', u'specified', u'separately', u'group', u'things', u'could', u'enumerated', u'list', u'unit', u'length', u'equal', u'1,760', u'yards', u'5,280', u'feet', u'exactly', u'1609.344', u'meters', u'lacking', u'stability', u'fixity', u'firmness', u'part', u'made', u'plural', u'group', u'human', u'beings', u'men', u'women', u'children', u'collectively', u'similar', u'things', u'placed', u'order', u'happening', u'one', u'another', u'monotheistic', u'system', u'beliefs', u'practices', u'based', u'Old', u'Testament', u'teachings', u'Jesus', u'embodied', u'New', u'Testament', u'emphasizing', u'role', u'Jesus', u'savior', u'particular', u'society', u'particular', u'time', u'place', u'basic', u'unit', u'length', u'adopted', u'Systeme', u'International', u"d'Unites", u'approximately', u'1.094', u'yards', u'special', u'offering', u'usually', u'temporary', u'reduced', u'price', u'featured', u'advertising', u'pertaining', u'characteristic', u'Judaism', u'precise', u'explicit', u'clearly', u'defined', u'line', u'determining', u'limits', u'area', u'commercial', u'industrial', u'enterprise', u'people', u'constitute', u'prominent', u'status', u'person', u'thing', u'equal', u'another', u'value', u'measure', u'force', u'effect', u'significance', u'etc', u'soft', u'silvery-white', u'tetravalent', u'radioactive', u'metallic', u'element', u'isotope', u'232', u'used', u'power', u'source', u'nuclear', u'reactors', u'occurs', u'thorite', u'monazite', u'sands', u'feeling', u'liking', u'something', u'someone', u'good', u'give', u'something', u'useful', u'necessary', u'extended', u'spatial', u'location', u'something', u'heading', u'names', u'statute', u'legislative', u'bill', u'give', u'brief', u'summary', u'matters', u'deals', u'person', u'equal', u'standing', u'another', u'group', u'linear', u'extent', u'space', u'one', u'end', u'longest', u'dimension', u'something', u'fixed', u'place', u'issue', u'terminate', u'specified', u'way', u'state', u'etc', u'end', u'legal', u'document', u'codifying', u'result', u'deliberations', u'committee', u'society', u'legislative', u'body', u'military', u'engagement', u'something', u'including', u'component', u'elements', u'parts', u'commercial', u'industrial', u'enterprise', u'people', u'constitute', u'cardinal', u'number', u'product', u'10', u'100', u'previous', u'time', u'amount', u'time', u'high', u'degree', u'extent', u'favorably', u'much', u'respect', u'act', u'process', u'producing', u'something', u'vague', u'clearly', u'defined', u'stated', u'division', u'quantity', u'accepted', u'standard', u'measurement', u'exchange', u'large', u'densely', u'populated', u'urban', u'area', u'include', u'several', u'independent', u'administrative', u'districts', u'act', u'using', u'process', u'taking', u'food', u'body', u'mouth', u'eating', u'lying', u'toward', u'situated', u'east', u'large', u'unbroken', u'expanse', u'distance', u'bishop', u'highest', u'rank', u'instrumentality', u'combines', u'interrelated', u'interacting', u'artifacts', u'designed', u'work', u'coherent', u'entity', u'five', u'related', u'nonmetallic', u'elements', u'fluorine', u'chlorine', u'bromine', u'iodine', u'astatine', u'monovalent', u'readily', u'form', u'negative', u'ions', u'continuing', u'time', u'space', u'without', u'interruption', u'film', u'life', u'western', u'United', u'States', u'period', u'exploration', u'development', u'fact', u'part', u'opposed', u'general', u'assumption', u'taken', u'granted', u'category', u'things', u'distinguished', u'common', u'characteristic', u'quality', u'worker', u'holds', u'invested', u'office', u'man', u'older', u'higher', u'rank', u'one', u'groups', u'Christians', u'beliefs', u'forms', u'worship', u'statistics', u'arrangement', u'values', u'variable', u'showing', u'observed', u'theoretical', u'frequency', u'occurrence', u'something', u'owned', u'tangible', u'intangible', u'possession', u'owned', u'someone', u'mark', u'different', u'function', u'topological', u'space', u'gives', u'two', u'points', u'space', u'value', u'equal', u'distance', u'usually', u'describes', u'large', u'person', u'fat', u'large', u'frame', u'carry', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions', u'general', u'officer', u'highest', u'rank', u'senior', u'member', u'Christian', u'clergy', u'spiritual', u'administrative', u'authority', u'appointed', u'Christian', u'churches', u'oversee', u'priests', u'ministers', u'considered', u'churches', u'successors', u'twelve', u'Apostles', u'Christ', u'movable', u'possession', u'especially', u'articles', u'clothing', u'owned', u'possession', u'heavy', u'toxic', u'silvery-white', u'radioactive', u'metallic', u'element', u'occurs', u'many', u'isotopes', u'used', u'nuclear', u'fuels', u'nuclear', u'weapons', u'orderly', u'grouping', u'things', u'persons', u'considered', u'unit', u'result', u'arranging', u'something', u'less', u'whole', u'human', u'artifact', u'act', u'delivering', u'formal', u'spoken', u'communication', u'audience', u'relating', u'science', u'geography', u'pertaining', u'involving', u'nature', u'space', u'advertisement', u'usually', u'printed', u'page', u'leaflet', u'intended', u'wide', u'distribution', u'commodities', u'offered', u'sale', u'put', u'service', u'make', u'work', u'employ', u'particular', u'purpose', u'inherent', u'natural', u'purpose', u'normal', u'conditions', u'particular', u'point', u'time', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions', u'one', u'several', u'parts', u'pieces', u'fit', u'others', u'constitute', u'whole', u'object', u'exhibiting', u'caused', u'radioactivity', u'event', u'happens', u'trace', u'point', u'whose', u'direction', u'motion', u'changes', u'mentally', u'emotionally', u'stable', u'abstract', u'part', u'something', u'human', u'general', u'estimation', u'public', u'person', u'instance', u'single', u'occasion', u'event', u'particular', u'portion', u'space', u'occupied', u'something', u'concept', u'something', u'magnitude', u'represented', u'mathematical', u'expressions', u'constant', u'variable']
prevlevelsynsets: [Synset('helping.n.01'), Synset('tamil_nadu.n.01'), Synset('bengal.n.01'), Synset('course.n.01'), Synset('sexual_intercourse.n.01'), Synset('geography.n.01'), Synset('group.n.01'), Synset('decay.n.01'), Synset('plan.n.01'), Synset('tamil.n.01'), Synset('exceeding.s.01'), Synset('bay.n.01'), Synset('invent.v.01'), Synset('serve.n.01'), Synset('item.n.01'), Synset('mile.n.01'), Synset('unstable.a.01'), Synset('include.v.01'), Synset('people.n.01'), Synset('series.n.01'), Synset('christianity.n.01'), Synset('culture.n.01'), Synset('meter.n.01'), Synset('special.n.01'), Synset('orthodox.a.01'), Synset('definite.a.01'), Synset('boundary.n.01'), Synset('business.n.01'), Synset('importance.n.01'), Synset('equivalent.n.01'), Synset('thorium.n.01'), Synset('blessing.n.01'), Synset('supply.n.01'), Synset('region.n.01'), Synset('title.n.01'), Synset('peer.n.01'), Synset('length.n.01'), Synset('consequence.n.01'), Synset('act.n.01'), Synset('military_action.n.01'), Synset('whole.n.01'), Synset('business.n.01'), Synset('thousand.n.01'), Synset('once.r.01'), Synset('time_period.n.01'), Synset('highly.r.01'), Synset('production.n.01'), Synset('indefinite.a.01'), Synset('unit_of_measurement.n.01'), Synset('city.n.01'), Synset('use.n.01'), Synset('consumption.n.01'), Synset('eastern.s.01'), Synset('stretch.n.01'), Synset('archbishop.n.01'), Synset('system.n.01'), Synset('halogen.n.01'), Synset('continuous.a.01'), Synset('western.n.01'), Synset('particular.n.01'), Synset('given.n.01'), Synset('kind.n.01'), Synset('official.n.01'), Synset('patriarch.n.01'), Synset('church.n.01'), Synset('distribution.n.01'), Synset('property.n.01'), Synset('distinguish.v.01'), Synset('metric_function.n.01'), Synset('fleshy.s.01'), Synset('purpose.n.01'), Synset('general.n.01'), Synset('bishop.n.01'), Synset('things.n.01'), Synset('belong.v.01'), Synset('uranium.n.01'), Synset('agreement.n.04'), Synset('part.n.01'), Synset('address.n.01'), Synset('geographic.a.01'), Synset('spatial.a.01'), Synset('circular.n.01'), Synset('merchandise.n.01'), Synset('use.n.01'), Synset('normally.r.01'), Synset('moment.n.01'), Synset('purpose.n.01'), Synset('section.n.01'), Synset('radioactive.a.01'), Synset('happening.n.01'), Synset('curve.n.01'), Synset('together.s.01'), Synset('component.n.01'), Synset('person.n.01'), Synset('repute.n.01'), Synset('time.n.01'), Synset('position.n.01'), Synset('measure.n.02')]
defaultdict(<type 'list'>, {u'serving': [u'area', u'None', u'area'], u'Madras': [u'None', u'Chennai', u'None', u'Chennai'], u'Bengal': [u'None', u'Chennai', u'None', u'Chennai'], u'course': [u'None', u'planning', u'None'], u'relation': [u'None', u'composition', u'None'], u'geography': [u'area', u'None', u'area'], u'group': [u'None', u'set'], u'decay': [u'None', u'None', u'astatine'], u'halogen': [u'None', u'None', u'astatine'], u'Tamil': [u'None', u'Chennai', u'None', u'Chennai'], u'exceptional': [u'None', u'None', u'giant'], u'Bay': [u'None', u'Chennai', u'None', u'Chennai'], u'formulating': [u'None', u'planning', u'None'], u'serves': [u'None', u'agency', u'None'], u'item': [u'None', u'None'], u'miles': [u'None', u'kilometer', u'None', u'kilometer'], u'unstable': [u'None', u'None', u'astatine'], u'including': [u'None', u'None', u'present'], u'people': [u'area', u'None', u'area'], u'series': [u'None', u'None', u'astatine'], u'Christianity': [u'None', u'None', u'metropolitan'], u'culture': [u'area', u'None', u'area'], u'meters': [u'None', u'kilometer', u'None', u'kilometer'], u'special': [u'area', u'None', u'area'], u'0.621371': [u'None', u'kilometer', u'None', u'kilometer'], u'Orthodox': [u'None', u'None', u'metropolitan'], u'definite': [u'None', u'planning', u'None'], u'boundary': [u'area', u'None', u'area'], u'business': [u'None', u'agency', u'None'], u'importance': [u'None', u'None', u'giant'], u'equivalent': [u'None', u'None', u'metropolitan'], u'thorium': [u'None', u'None', u'astatine'], u'approval': [u'None', u'permission', u'None'], u'providing': [u'None', u'None'], u'region': [u'area', u'None', u'area'], u'title': [u'None', u'None', u'metropolitan'], u'equal': [u'None', u'kilometer', u'None', u'kilometer'], u'length': [u'None', u'kilometer', u'None', u'kilometer'], u'resulting': [u'None', u'composition', u'None'], u'act': [u'None', u'planning', u'None'], u'action': [u'None', u'planning', u'None'], u'whole': [u'None', u'composition', u'None'], u'businesses': [u'None', u'agency', u'None'], u'1000': [u'None', u'kilometer', u'None', u'kilometer'], u'formerly': [u'None', u'Chennai', u'None', u'Chennai'], u'period': [u'None', u'None', u'present'], u'highly': [u'None', u'None', u'astatine'], u'production': [u'None', u'economy', u'None'], u'indefinite': [u'area', u'None', u'area'], u'unit': [u'None', u'kilometer', u'None', u'kilometer'], u'city': [u'None', u'Chennai', u'None', u'Chennai'], u'use': [u'None', u'None'], u'consumption': [u'None', u'economy', u'None'], u'Eastern': [u'None', u'None', u'metropolitan'], u'stretch': [u'None', u'None', u'present'], u'archbishop': [u'None', u'None', u'metropolitan'], u'system': [u'None', u'economy', u'None'], u'program': [u'None', u'planning', u'None'], u'continuous': [u'None', u'None', u'present'], u'western': [u'None', u'None', u'metropolitan'], u'particular': [u'area', u'None', u'area'], u'given': [u'None', u'None', u'metropolitan'], u'kind': [u'None', u'set'], u'official': [u'None', u'None'], u'patriarch': [u'None', u'None', u'metropolitan'], u'Church': [u'None', u'None', u'metropolitan'], u'distribution': [u'None', u'economy', u'None'], u'property': [u'None', u'composition', u'None'], u'distinguished': [u'area', u'None', u'area'], u'metric': [u'None', u'kilometer', u'None', u'kilometer'], u'heaviest': [u'None', u'None', u'astatine'], u'purposes': [u'None', u'None'], u'general': [u'None', u'None'], u'something': [u'None', u'permission', u'None'], u'bishop': [u'None', u'None', u'metropolitan'], u'things': [u'None', u'set'], u'belong': [u'None', u'set'], u'uranium': [u'None', u'None', u'astatine'], u'arrangement': [u'None', u'composition', u'None'], u'parts': [u'None', u'composition', u'None'], u'speech': [u'None', u'None', u'present'], u'geographical': [u'area', u'None', u'area'], u'spatial': [u'None', u'composition', u'None'], u'Nadu': [u'None', u'Chennai', u'None', u'Chennai'], u'circular': [u'None', u'bend'], u'product': [u'None', u'None', u'astatine'], u'used': [u'None', u'set'], u'usually': [u'area', u'None', u'area'], u'moment': [u'None', u'None', u'present'], u'purpose': [u'area', u'None', u'area'], u'segment': [u'None', u'bend'], u'radioactive': [u'None', u'None', u'astatine'], u'happening': [u'None', u'None', u'present'], u'curve': [u'None', u'bend'], u'together': [u'None', u'set'], u'element': [u'None', u'None', u'astatine'], u'person': [u'None', u'None', u'giant'], u'reputation': [u'None', u'None', u'giant'], u'time': [u'None', u'None', u'present'], u'position': [u'None', u'None', u'metropolitan'], u'quantity': [u'None', u'None']})
ksynset= Synset('helping.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('helping.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('helping.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('course.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('course.n.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('course.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('relation.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('relation.n.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('relation.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('group.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('group.n.01')
lsynset= Synset('set.n.01')
ksynset= Synset('decay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('decay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('decay.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('halogen.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('halogen.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('halogen.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('exceeding.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('exceeding.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('exceeding.s.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('explicate.v.02')
lsynset= Synset('none.n.01')
ksynset= Synset('explicate.v.02')
lsynset= Synset('planning.n.01')
ksynset= Synset('explicate.v.02')
lsynset= Synset('none.n.01')
ksynset= Synset('serve.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('serve.n.01')
lsynset= Synset('agency.n.01')
ksynset= Synset('serve.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('item.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('item.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('unstable.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unstable.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unstable.a.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('include.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('include.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('include.v.01')
lsynset= Synset('present.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('series.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('series.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('series.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('definite.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('definite.a.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('definite.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('agency.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('importance.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('importance.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('importance.n.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('thorium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thorium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thorium.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('blessing.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('blessing.n.01')
lsynset= Synset('permission.n.01')
ksynset= Synset('blessing.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('supply.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('supply.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('result.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('result.v.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('result.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('act.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('act.n.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('act.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('action.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('action.n.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('action.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('whole.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('whole.n.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('whole.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('agency.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('none.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('chennai.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('none.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('chennai.n.01')
ksynset= Synset('time_period.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time_period.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time_period.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('highly.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('highly.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('highly.r.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('production.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('production.n.01')
lsynset= Synset('economy.n.01')
ksynset= Synset('production.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('use.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('use.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('consumption.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('consumption.n.01')
lsynset= Synset('economy.n.01')
ksynset= Synset('consumption.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('stretch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('stretch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('stretch.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('system.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('system.n.01')
lsynset= Synset('economy.n.01')
ksynset= Synset('system.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('plan.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('plan.n.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('plan.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('continuous.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('continuous.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('continuous.a.01')
lsynset= Synset('present.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('kind.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('kind.n.01')
lsynset= Synset('set.n.01')
ksynset= Synset('official.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('official.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('distribution.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distribution.n.01')
lsynset= Synset('economy.n.01')
ksynset= Synset('distribution.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('property.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('property.n.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('property.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('area.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('area.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('heavy.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('heavy.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('heavy.a.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('general.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('general.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('things.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('things.n.01')
lsynset= Synset('set.n.01')
ksynset= Synset('belong.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('belong.v.01')
lsynset= Synset('set.n.01')
ksynset= Synset('uranium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('uranium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('uranium.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('agreement.n.04')
lsynset= Synset('none.n.01')
ksynset= Synset('agreement.n.04')
lsynset= Synset('composition.n.01')
ksynset= Synset('agreement.n.04')
lsynset= Synset('none.n.01')
ksynset= Synset('parts.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('parts.n.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('parts.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('address.n.03')
lsynset= Synset('none.n.01')
ksynset= Synset('address.n.03')
lsynset= Synset('none.n.01')
ksynset= Synset('address.n.03')
lsynset= Synset('present.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('spatial.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('spatial.a.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('spatial.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('circular.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('circular.n.01')
lsynset= Synset('bend.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('use.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('use.v.01')
lsynset= Synset('set.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('area.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('area.n.01')
ksynset= Synset('moment.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('moment.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('moment.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('section.n.04')
lsynset= Synset('none.n.01')
ksynset= Synset('section.n.04')
lsynset= Synset('bend.n.01')
ksynset= Synset('radioactive.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('radioactive.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('radioactive.a.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('happening.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('happening.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('happening.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('curve.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('curve.n.01')
lsynset= Synset('bend.n.01')
ksynset= Synset('together.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('together.s.01')
lsynset= Synset('set.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('repute.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('repute.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('repute.n.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('time.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('measure.n.02')
lsynset= Synset('none.n.01')
ksynset= Synset('measure.n.02')
lsynset= Synset('none.n.01')
Core number (sorted) : [(u'area', 13), (u'metropolitan', 12), (u'astatine', 11), (u'kilometer', 8), (u'present', 8), (u'Chennai', 7), (u'composition', 7), (u'planning', 6), (u'set', 6), (u'giant', 4), (u'economy', 4), (u'bend', 3), (u'agency', 3), (u'serving', 2), (u'Madras', 2), (u'Bengal', 2), (u'course', 2), (u'relation', 2), (u'geography', 2), (u'group', 2), (u'title', 2), (u'halogen', 2), (u'Tamil', 2), (u'permission', 2), (u'Bay', 2), (u'formulating', 2), (u'serves', 2), (u'miles', 2), (u'unstable', 2), (u'including', 2), (u'people', 2), (u'series', 2), (u'Christianity', 2), (u'culture', 2), (u'meters', 2), (u'special', 2), (u'0.621371', 2), (u'Orthodox', 2), (u'definite', 2), (u'boundary', 2), (u'business', 2), (u'importance', 2), (u'equivalent', 2), (u'thorium', 2), (u'approval', 2), (u'region', 2), (u'decay', 2), (u'equal', 2), (u'length', 2), (u'resulting', 2), (u'act', 2), (u'action', 2), (u'whole', 2), (u'businesses', 2), (u'1000', 2), (u'formerly', 2), (u'period', 2), (u'highly', 2), (u'production', 2), (u'indefinite', 2), (u'unit', 2), (u'city', 2), (u'given', 2), (u'consumption', 2), (u'stretch', 2), (u'archbishop', 2), (u'system', 2), (u'program', 2), (u'exceptional', 2), (u'continuous', 2), (u'western', 2), (u'particular', 2), (u'kind', 2), (u'patriarch', 2), (u'Eastern', 2), (u'Church', 2), (u'distribution', 2), (u'property', 2), (u'distinguished', 2), (u'something', 2), (u'metric', 2), (u'heaviest', 2), (u'bishop', 2), (u'things', 2), (u'belong', 2), (u'uranium', 2), (u'arrangement', 2), (u'parts', 2), (u'speech', 2), (u'geographical', 2), (u'spatial', 2), (u'Nadu', 2), (u'circular', 2), (u'product', 2), (u'used', 2), (u'usually', 2), (u'moment', 2), (u'purpose', 2), (u'segment', 2), (u'radioactive', 2), (u'happening', 2), (u'curve', 2), (u'together', 2), (u'element', 2), (u'person', 2), (u'reputation', 2), (u'time', 2), (u'position', 2), (u'item', 0), (u'None', 0), (u'use', 0), (u'providing', 0), (u'official', 0), (u'purposes', 0), (u'general', 0), (u'quantity', 0)]
=============================================================================================================
Unsupervised Classification based on top percentile Core numbers of the definition graph(subgraph of WordNet)
=============================================================================================================
This document belongs to class: area ,core number= 13
This document belongs to class: metropolitan ,core number= 12
This document belongs to class: astatine ,core number= 11
This document belongs to class: kilometer ,core number= 8
This document belongs to class: present ,core number= 8
This document belongs to class: Chennai ,core number= 7
This document belongs to class: composition ,core number= 7
This document belongs to class: planning ,core number= 6
This document belongs to class: set ,core number= 6
This document belongs to class: giant ,core number= 4
This document belongs to class: economy ,core number= 4
This document belongs to class: bend ,core number= 3
This document belongs to class: agency ,core number= 3
max_core_number 13
===================================================================
Page Rank of the vertices of RGO Definition Graph
===================================================================
[(u'area', 0.05964397617197671), (u'metropolitan', 0.05543677058743772), (u'astatine', 0.051229565002898755), (u'kilometer', 0.03860794824928188), (u'present', 0.03860794824928188), (u'Chennai', 0.034400742664742925), (u'composition', 0.034400742664742925), (u'planning', 0.030193537080203968), (u'set', 0.030193537080203968), (u'giant', 0.021779125911126046), (u'economy', 0.02177912591112604), (u'agency', 0.01757192032658708), (u'bend', 0.017571920326587075), (u'permission', 0.013364714742048119), (u'approval', 0.0070539063652396775), (u'something', 0.0070539063652396775), (u'serves', 0.006352705434483184), (u'business', 0.006352705434483184), (u'businesses', 0.006352705434483184), (u'circular', 0.006352705434483183), (u'segment', 0.006352705434483183), (u'curve', 0.006352705434483183), (u'importance', 0.006002104969104938), (u'production', 0.006002104969104938), (u'consumption', 0.006002104969104938), (u'system', 0.006002104969104938), (u'distribution', 0.006002104969104938), (u'exceptional', 0.006002104969104938), (u'person', 0.006002104969104938), (u'reputation', 0.006002104969104938), (u'course', 0.0056515045037266905), (u'group', 0.0056515045037266905), (u'program', 0.0056515045037266905), (u'formulating', 0.0056515045037266905), (u'definite', 0.0056515045037266905), (u'act', 0.0056515045037266905), (u'action', 0.0056515045037266905), (u'belong', 0.0056515045037266905), (u'kind', 0.0056515045037266905), (u'things', 0.0056515045037266905), (u'used', 0.0056515045037266905), (u'together', 0.0056515045037266905), (u'Madras', 0.005551332942190048), (u'Bengal', 0.005551332942190048), (u'relation', 0.005551332942190048), (u'Tamil', 0.005551332942190048), (u'Bay', 0.005551332942190048), (u'resulting', 0.005551332942190048), (u'whole', 0.005551332942190048), (u'formerly', 0.005551332942190048), (u'city', 0.005551332942190048), (u'property', 0.005551332942190048), (u'arrangement', 0.005551332942190048), (u'parts', 0.005551332942190048), (u'spatial', 0.005551332942190048), (u'Nadu', 0.005551332942190048), (u'miles', 0.0054762042710375675), (u'including', 0.0054762042710375675), (u'meters', 0.0054762042710375675), (u'0.621371', 0.0054762042710375675), (u'equal', 0.0054762042710375675), (u'length', 0.0054762042710375675), (u'1000', 0.0054762042710375675), (u'period', 0.0054762042710375675), (u'unit', 0.0054762042710375675), (u'stretch', 0.0054762042710375675), (u'continuous', 0.0054762042710375675), (u'metric', 0.0054762042710375675), (u'speech', 0.0054762042710375675), (u'moment', 0.0054762042710375675), (u'happening', 0.0054762042710375675), (u'time', 0.0054762042710375675), (u'unstable', 0.005332776807928284), (u'series', 0.005332776807928284), (u'thorium', 0.005332776807928284), (u'decay', 0.005332776807928284), (u'highly', 0.005332776807928284), (u'halogen', 0.005332776807928284), (u'heaviest', 0.005332776807928284), (u'uranium', 0.005332776807928284), (u'product', 0.005332776807928284), (u'radioactive', 0.005332776807928284), (u'element', 0.005332776807928284), (u'title', 0.005300904038348444), (u'Christianity', 0.005300904038348444), (u'Orthodox', 0.005300904038348444), (u'equivalent', 0.005300904038348444), (u'given', 0.005300904038348444), (u'archbishop', 0.005300904038348444), (u'western', 0.005300904038348444), (u'patriarch', 0.005300904038348444), (u'Eastern', 0.005300904038348444), (u'Church', 0.005300904038348444), (u'bishop', 0.005300904038348444), (u'position', 0.005300904038348444), (u'serving', 0.005273934771780889), (u'geography', 0.005273934771780889), (u'people', 0.005273934771780889), (u'culture', 0.005273934771780889), (u'special', 0.005273934771780889), (u'boundary', 0.005273934771780889), (u'region', 0.005273934771780889), (u'indefinite', 0.005273934771780889), (u'particular', 0.005273934771780889), (u'distinguished', 0.005273934771780889), (u'geographical', 0.005273934771780889), (u'usually', 0.005273934771780889), (u'purpose', 0.005273934771780889), (u'item', 0.001373626373626374), (u'None', 0.001373626373626374), (u'use', 0.001373626373626374), (u'providing', 0.001373626373626374), (u'official', 0.001373626373626374), (u'purposes', 0.001373626373626374), (u'general', 0.001373626373626374), (u'quantity', 0.001373626373626374)]
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - connectivity of RGO Definition Graph - Mengers Theorem
==========================================================================================================
0
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - Maxflow-Mincut of RGO Definition Graph - Minimum Edge Cut
==========================================================================================================
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - Maxflow-Mincut of RGO Definition Graph - Stoer-Wagner
==========================================================================================================
16/03/17 12:03:52 INFO ShutdownHookManager: Shutdown hook called

