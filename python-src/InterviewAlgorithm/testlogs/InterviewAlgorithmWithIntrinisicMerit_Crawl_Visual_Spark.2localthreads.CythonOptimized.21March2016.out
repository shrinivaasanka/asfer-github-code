Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
16/03/21 17:16:32 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:16:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/03/21 17:16:34 WARN Utils: Your hostname, shrinivaasanka-Inspiron-1545 resolves to a loopback address: 127.0.1.1; using 192.168.43.22 instead (on interface wlan0)
16/03/21 17:16:34 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
16/03/21 17:16:35 INFO SecurityManager: Changing view acls to: root
16/03/21 17:16:35 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:16:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:16:38 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:16:38 INFO Remoting: Starting remoting
16/03/21 17:16:39 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.43.22:52131]
16/03/21 17:16:39 INFO Utils: Successfully started service 'sparkDriver' on port 52131.
16/03/21 17:16:39 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:16:39 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:16:39 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9755d71e-32cc-465b-8ed9-e3d13e482915
16/03/21 17:16:39 INFO MemoryStore: MemoryStore started with capacity 794.9 MB
16/03/21 17:16:40 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-29031c0a-fef2-45ac-9690-88feac10a29d
16/03/21 17:16:40 INFO HttpServer: Starting HTTP Server
16/03/21 17:16:40 INFO Utils: Successfully started service 'HTTP file server' on port 43828.
16/03/21 17:16:40 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:16:41 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:16:41 INFO SparkUI: Started SparkUI at http://192.168.43.22:4040
16/03/21 17:16:42 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-5b7da2d1-3305-42c0-8853-b61495316532/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:16:42 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560802203
16/03/21 17:16:42 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:16:42 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:16:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44845.
16/03/21 17:16:43 INFO NettyBlockTransferService: Server created on 44845
16/03/21 17:16:43 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:16:43 INFO BlockManagerMasterEndpoint: Registering block manager localhost:44845 with 794.9 MB RAM, BlockManagerId(driver, localhost, 44845)
16/03/21 17:16:43 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:16:44 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458560802686
16/03/21 17:16:47 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230
16/03/21 17:16:47 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/21 17:16:47 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) with 2 output partitions
16/03/21 17:16:47 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/21 17:16:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:16:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:16:47 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230), which has no missing parents
16/03/21 17:16:48 WARN SizeEstimator: Failed to check whether UseCompressedOops is set; assuming yes
16/03/21 17:16:48 INFO MemoryStore: ensureFreeSpace(6560) called with curMem=0, maxMem=833527480
16/03/21 17:16:48 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 794.9 MB)
16/03/21 17:16:49 INFO MemoryStore: ensureFreeSpace(4140) called with curMem=6560, maxMem=833527480
16/03/21 17:16:49 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 794.9 MB)
16/03/21 17:16:49 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:44845 (size: 4.0 KB, free: 794.9 MB)
16/03/21 17:16:49 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:16:49 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/21 17:16:49 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:16:49 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2414 bytes)
16/03/21 17:16:49 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:16:49 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560802203
16/03/21 17:16:49 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:16:49 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-5b7da2d1-3305-42c0-8853-b61495316532/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:16:49 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:16:49 INFO MemoryStore: ensureFreeSpace(214) called with curMem=10700, maxMem=833527480
16/03/21 17:16:49 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 214.0 B, free 794.9 MB)
16/03/21 17:16:49 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:44845 (size: 214.0 B, free: 794.9 MB)
mapFunction(): freqterms1: Area
mapFunction(): freqterms1: issuance
mapFunction(): freqterms1: planning
mapFunction(): freqterms1: permission
mapFunction(): freqterms1: ...
mapFunction(): freqterms1: Economy
mapFunction(): freqterms1: Composition
mapFunction(): freqterms1: Nodal
mapFunction(): freqterms1: agencies
mapFunction(): freqterms1: ProfileWith
mapFunction(): freqterms1: 8,878
mapFunction(): freqterms1: sq
mapFunction(): freqterms1: km
mapFunction(): freqterms1: Chennai
16/03/21 17:16:58 INFO PythonRunner: Times: total = 9037, boot = 674, init = 363, finish = 8000
16/03/21 17:16:59 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:16:59 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2411 bytes)
16/03/21 17:16:59 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:16:59 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:16:59 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9885 ms on localhost (1/2)
16/03/21 17:16:59 INFO MemoryStore: ensureFreeSpace(207) called with curMem=10914, maxMem=833527480
16/03/21 17:16:59 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 207.0 B, free 794.9 MB)
16/03/21 17:16:59 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:44845 (size: 207.0 B, free: 794.9 MB)
mapFunction(): freqterms1: Set
mapFunction(): freqterms1: Turn
mapFunction(): freqterms1: Giant
mapFunction(): freqterms1: Megapolis
mapFunction(): freqterms1: At
mapFunction(): freqterms1: present
mapFunction(): freqterms1: Chennai
mapFunction(): freqterms1: Metropolitan
mapFunction(): freqterms1: Area
mapFunction(): freqterms1: 1,189
mapFunction(): freqterms1: sq
mapFunction(): freqterms1: km
mapFunction(): freqterms1: 7,700
mapFunction(): freqterms1: sq
mapFunction(): freqterms1: ...
16/03/21 17:16:59 INFO PythonRunner: Times: total = 392, boot = 92, init = 0, finish = 300
16/03/21 17:16:59 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:16:59 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) finished in 10.499 s
16/03/21 17:16:59 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:16:59 INFO DAGScheduler: running: Set()
16/03/21 17:17:00 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:17:00 INFO DAGScheduler: failed: Set()
16/03/21 17:17:00 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 666 ms on localhost (2/2)
16/03/21 17:17:00 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:17:00 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:17:00 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230), which is now runnable
16/03/21 17:17:00 INFO MemoryStore: ensureFreeSpace(4976) called with curMem=11121, maxMem=833527480
16/03/21 17:17:00 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 794.9 MB)
16/03/21 17:17:00 INFO MemoryStore: ensureFreeSpace(3039) called with curMem=16097, maxMem=833527480
16/03/21 17:17:00 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 794.9 MB)
16/03/21 17:17:00 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:44845 (size: 3.0 KB, free: 794.9 MB)
16/03/21 17:17:00 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:17:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/21 17:17:00 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:17:00 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:17:00 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:17:00 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:17:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 31 ms
16/03/21 17:17:00 INFO PythonRunner: Times: total = 101, boot = 100, init = 1, finish = 0
16/03/21 17:17:00 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:17:00 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:17:00 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:17:00 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:17:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:17:00 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 359 ms on localhost (1/2)
16/03/21 17:17:00 INFO PythonRunner: Times: total = 154, boot = 152, init = 0, finish = 2
16/03/21 17:17:00 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 3149 bytes result sent to driver
16/03/21 17:17:00 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) finished in 0.592 s
16/03/21 17:17:00 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 290 ms on localhost (2/2)
16/03/21 17:17:00 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:17:00 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230, took 13.574397 s
16/03/21 17:17:06 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230
16/03/21 17:17:06 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) with 2 output partitions
16/03/21 17:17:06 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/21 17:17:06 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:17:06 INFO DAGScheduler: Missing parents: List()
16/03/21 17:17:06 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230), which has no missing parents
16/03/21 17:17:06 INFO MemoryStore: ensureFreeSpace(5872) called with curMem=19136, maxMem=833527480
16/03/21 17:17:06 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 794.9 MB)
16/03/21 17:17:06 INFO MemoryStore: ensureFreeSpace(3414) called with curMem=25008, maxMem=833527480
16/03/21 17:17:06 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 794.9 MB)
16/03/21 17:17:06 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:44845 (size: 3.3 KB, free: 794.9 MB)
16/03/21 17:17:06 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:17:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/21 17:17:06 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:17:06 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:17:06 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:17:06 INFO PythonRunner: Times: total = 4, boot = -5445, init = 5449, finish = 0
16/03/21 17:17:06 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:17:06 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 4107 bytes)
16/03/21 17:17:06 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 89 ms on localhost (1/2)
16/03/21 17:17:06 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:17:06 INFO PythonRunner: Times: total = 137, boot = 137, init = 0, finish = 0
16/03/21 17:17:06 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 3456 bytes result sent to driver
16/03/21 17:17:06 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) finished in 0.356 s
16/03/21 17:17:06 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230, took 0.386585 s
16/03/21 17:17:06 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 273 ms on localhost (2/2)
16/03/21 17:17:06 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:17:06 INFO SparkUI: Stopped Spark web UI at http://192.168.43.22:4040
16/03/21 17:17:06 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:17:07 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:17:07 INFO MemoryStore: MemoryStore cleared
16/03/21 17:17:07 INFO BlockManager: BlockManager stopped
16/03/21 17:17:07 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:17:07 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:17:07 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:17:07 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:17:07 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:17:07 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:17:15 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:17:15 INFO SecurityManager: Changing view acls to: root
16/03/21 17:17:15 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:17:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:17:15 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:17:15 INFO Remoting: Starting remoting
16/03/21 17:17:15 INFO Utils: Successfully started service 'sparkDriver' on port 50896.
16/03/21 17:17:15 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:50896]
16/03/21 17:17:15 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:17:15 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:17:15 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5f2ab036-fc8f-48cd-aca9-2e58ddf29014
16/03/21 17:17:15 INFO MemoryStore: MemoryStore started with capacity 794.9 MB
16/03/21 17:17:15 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-89e5c010-b3f4-42aa-af7c-1bb84c6ea7a0
16/03/21 17:17:15 INFO HttpServer: Starting HTTP Server
16/03/21 17:17:15 INFO Utils: Successfully started service 'HTTP file server' on port 60365.
16/03/21 17:17:15 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:17:15 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:17:15 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:17:15 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-5d6285b7-364f-4097-b28c-fdb4e25b3147/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:17:15 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560835371
16/03/21 17:17:15 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:17:15 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:17:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37949.
16/03/21 17:17:15 INFO NettyBlockTransferService: Server created on 37949
16/03/21 17:17:15 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:17:15 INFO BlockManagerMasterEndpoint: Registering block manager localhost:37949 with 794.9 MB RAM, BlockManagerId(driver, localhost, 37949)
16/03/21 17:17:15 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:17:15 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458560835392
16/03/21 17:17:15 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:17:15 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:17:15 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:17:15 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:17:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:17:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:17:15 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:17:15 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=833527480
16/03/21 17:17:15 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 794.9 MB)
16/03/21 17:17:15 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=833527480
16/03/21 17:17:15 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 794.9 MB)
16/03/21 17:17:15 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:37949 (size: 4.1 KB, free: 794.9 MB)
16/03/21 17:17:15 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:17:15 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:17:15 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:17:15 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:17:15 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:17:15 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:17:15 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560835371
16/03/21 17:17:15 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-5d6285b7-364f-4097-b28c-fdb4e25b3147/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:17:15 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:17:15 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=833527480
16/03/21 17:17:15 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 794.9 MB)
16/03/21 17:17:15 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:37949 (size: 166.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: area
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  serving  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: issue
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: planning
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: permission
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: economy
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: composition
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: agency
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/21 17:17:23 INFO PythonRunner: Times: total = 7872, boot = 459, init = 369, finish = 7044
16/03/21 17:17:23 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:17:23 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:17:23 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:17:23 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:17:23 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8087 ms on localhost (1/2)
16/03/21 17:17:23 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=833527480
16/03/21 17:17:23 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 794.9 MB)
16/03/21 17:17:23 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:37949 (size: 155.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: set
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: bend
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: giant
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: astatine
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: present
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: area
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  serving  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/21 17:17:23 INFO PythonRunner: Times: total = 197, boot = 103, init = 0, finish = 94
16/03/21 17:17:23 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:17:23 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.381 s
16/03/21 17:17:23 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:17:23 INFO DAGScheduler: running: Set()
16/03/21 17:17:23 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:17:23 INFO DAGScheduler: failed: Set()
16/03/21 17:17:23 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:17:23 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:17:23 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=833527480
16/03/21 17:17:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 794.9 MB)
16/03/21 17:17:24 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 319 ms on localhost (2/2)
16/03/21 17:17:24 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:17:24 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=833527480
16/03/21 17:17:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 794.9 MB)
16/03/21 17:17:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:37949 (size: 3.0 KB, free: 794.9 MB)
16/03/21 17:17:24 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:17:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:17:24 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:17:24 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:17:24 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:17:24 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:17:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:17:24 INFO PythonRunner: Times: total = 93, boot = 92, init = 0, finish = 1
16/03/21 17:17:24 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:17:24 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:17:24 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:17:24 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 125 ms on localhost (1/2)
16/03/21 17:17:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:17:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
reduceFunction_Parents(): returns= [u'area', 'None', u'area']
16/03/21 17:17:24 INFO PythonRunner: Times: total = 191, boot = 190, init = 0, finish = 1
16/03/21 17:17:24 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/21 17:17:24 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.369 s
16/03/21 17:17:24 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.838544 s
16/03/21 17:17:24 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 245 ms on localhost (2/2)
16/03/21 17:17:24 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:17:24 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:17:24 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:17:24 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:17:24 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:17:24 INFO DAGScheduler: Missing parents: List()
16/03/21 17:17:24 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:17:24 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=833527480
16/03/21 17:17:24 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 794.9 MB)
16/03/21 17:17:24 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=833527480
16/03/21 17:17:24 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 794.9 MB)
16/03/21 17:17:24 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:37949 (size: 3.3 KB, free: 794.9 MB)
16/03/21 17:17:24 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:17:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:17:24 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:17:24 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:17:24 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:17:24 INFO PythonRunner: Times: total = 18, boot = 18, init = 0, finish = 0
16/03/21 17:17:24 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:17:24 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/21 17:17:24 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 83 ms on localhost (1/2)
16/03/21 17:17:24 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:17:24 INFO PythonRunner: Times: total = 150, boot = 150, init = 0, finish = 0
16/03/21 17:17:24 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1307 bytes result sent to driver
16/03/21 17:17:24 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.271 s
16/03/21 17:17:24 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.314868 s
16/03/21 17:17:24 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 205 ms on localhost (2/2)
16/03/21 17:17:24 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:17:25 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:17:25 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:17:25 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:17:25 INFO MemoryStore: MemoryStore cleared
16/03/21 17:17:25 INFO BlockManager: BlockManager stopped
16/03/21 17:17:25 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:17:25 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:17:25 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:17:25 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:17:25 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:17:25 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:17:25 INFO SecurityManager: Changing view acls to: root
16/03/21 17:17:25 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:17:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:17:26 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:17:26 INFO Remoting: Starting remoting
16/03/21 17:17:26 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:42299]
16/03/21 17:17:26 INFO Utils: Successfully started service 'sparkDriver' on port 42299.
16/03/21 17:17:26 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:17:26 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:17:26 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-20893cbb-e987-4771-a545-f76e979d075c
16/03/21 17:17:26 INFO MemoryStore: MemoryStore started with capacity 794.9 MB
16/03/21 17:17:26 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-07ad8979-d458-4503-a53c-300b95171d70
16/03/21 17:17:26 INFO HttpServer: Starting HTTP Server
16/03/21 17:17:26 INFO Utils: Successfully started service 'HTTP file server' on port 59687.
16/03/21 17:17:26 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:17:26 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:17:26 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:17:26 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-3b87d4b9-a256-4f99-a3ca-12c594477fc1/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:17:26 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560846807
16/03/21 17:17:26 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:17:26 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:17:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38598.
16/03/21 17:17:26 INFO NettyBlockTransferService: Server created on 38598
16/03/21 17:17:26 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:17:26 INFO BlockManagerMasterEndpoint: Registering block manager localhost:38598 with 794.9 MB RAM, BlockManagerId(driver, localhost, 38598)
16/03/21 17:17:26 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:17:26 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458560846841
16/03/21 17:17:27 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:17:27 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:17:27 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:17:27 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:17:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:17:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:17:27 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:17:27 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=833527480
16/03/21 17:17:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 794.9 MB)
16/03/21 17:17:27 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=833527480
16/03/21 17:17:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 794.9 MB)
16/03/21 17:17:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:38598 (size: 4.1 KB, free: 794.9 MB)
16/03/21 17:17:27 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:17:27 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:17:27 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:17:27 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:17:27 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:17:27 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560846807
16/03/21 17:17:27 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:17:27 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-3b87d4b9-a256-4f99-a3ca-12c594477fc1/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:17:27 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:17:27 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=833527480
16/03/21 17:17:27 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 794.9 MB)
16/03/21 17:17:27 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:38598 (size: 166.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: area
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: issue
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: planning
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: permission
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: economy
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: composition
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: agency
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Madras  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/21 17:17:35 INFO PythonRunner: Times: total = 8024, boot = 470, init = 364, finish = 7190
16/03/21 17:17:35 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:17:35 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:17:35 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:17:35 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:17:35 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=833527480
16/03/21 17:17:35 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 794.9 MB)
16/03/21 17:17:35 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8173 ms on localhost (1/2)
16/03/21 17:17:35 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:38598 (size: 155.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: set
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: bend
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: giant
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: astatine
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: present
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Madras  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: area
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/21 17:17:35 INFO PythonRunner: Times: total = 327, boot = 194, init = 1, finish = 132
16/03/21 17:17:35 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:17:35 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.566 s
16/03/21 17:17:35 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:17:35 INFO DAGScheduler: running: Set()
16/03/21 17:17:35 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:17:35 INFO DAGScheduler: failed: Set()
16/03/21 17:17:35 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:17:35 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:17:35 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=833527480
16/03/21 17:17:35 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 794.9 MB)
16/03/21 17:17:35 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 399 ms on localhost (2/2)
16/03/21 17:17:35 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:17:35 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=833527480
16/03/21 17:17:35 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 794.9 MB)
16/03/21 17:17:35 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:38598 (size: 3.0 KB, free: 794.9 MB)
16/03/21 17:17:35 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:17:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:17:35 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:17:35 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:17:35 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:17:35 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:17:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:17:35 INFO PythonRunner: Times: total = 107, boot = 107, init = 0, finish = 0
16/03/21 17:17:35 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:17:35 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:17:35 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:17:35 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:17:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:17:35 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 216 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'Chennai', 'None', u'Chennai']
16/03/21 17:17:36 INFO PythonRunner: Times: total = 284, boot = 283, init = 0, finish = 1
16/03/21 17:17:36 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1255 bytes result sent to driver
16/03/21 17:17:36 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.463 s
16/03/21 17:17:36 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.165120 s
16/03/21 17:17:36 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 343 ms on localhost (2/2)
16/03/21 17:17:36 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:17:36 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:17:36 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:17:36 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:17:36 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:17:36 INFO DAGScheduler: Missing parents: List()
16/03/21 17:17:36 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:17:36 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=833527480
16/03/21 17:17:36 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 794.9 MB)
16/03/21 17:17:36 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=833527480
16/03/21 17:17:36 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 794.9 MB)
16/03/21 17:17:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:38598 (size: 3.3 KB, free: 794.9 MB)
16/03/21 17:17:36 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:17:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:17:36 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:17:36 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:17:36 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:17:36 INFO PythonRunner: Times: total = 10, boot = -42, init = 52, finish = 0
16/03/21 17:17:36 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:17:36 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2285 bytes)
16/03/21 17:17:36 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 54 ms on localhost (1/2)
16/03/21 17:17:36 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:17:36 INFO PythonRunner: Times: total = 157, boot = 157, init = 0, finish = 0
16/03/21 17:17:36 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1324 bytes result sent to driver
16/03/21 17:17:36 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.239 s
16/03/21 17:17:36 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.323918 s
16/03/21 17:17:36 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 197 ms on localhost (2/2)
16/03/21 17:17:36 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:17:36 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:17:36 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:17:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:17:36 INFO MemoryStore: MemoryStore cleared
16/03/21 17:17:36 INFO BlockManager: BlockManager stopped
16/03/21 17:17:36 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:17:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:17:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:17:36 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:17:36 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:17:37 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:17:37 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:17:37 INFO SecurityManager: Changing view acls to: root
16/03/21 17:17:37 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:17:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:17:37 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:17:37 INFO Remoting: Starting remoting
16/03/21 17:17:37 INFO Utils: Successfully started service 'sparkDriver' on port 49980.
16/03/21 17:17:37 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:49980]
16/03/21 17:17:37 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:17:37 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:17:37 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ec240dbc-82b0-4bc2-b8f0-fa61405fe7bc
16/03/21 17:17:37 INFO MemoryStore: MemoryStore started with capacity 794.9 MB
16/03/21 17:17:37 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-ddda4bf3-ee8d-4abf-af51-74beaca051e4
16/03/21 17:17:37 INFO HttpServer: Starting HTTP Server
16/03/21 17:17:38 INFO Utils: Successfully started service 'HTTP file server' on port 33316.
16/03/21 17:17:38 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:17:38 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:17:38 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:17:38 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-ffce7494-0311-4379-84bd-e3d273776cbb/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:17:38 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560858403
16/03/21 17:17:38 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:17:38 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:17:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51023.
16/03/21 17:17:38 INFO NettyBlockTransferService: Server created on 51023
16/03/21 17:17:38 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:17:38 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51023 with 794.9 MB RAM, BlockManagerId(driver, localhost, 51023)
16/03/21 17:17:38 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:17:38 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458560858427
16/03/21 17:17:38 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:17:38 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:17:38 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:17:38 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:17:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:17:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:17:38 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:17:38 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=833527480
16/03/21 17:17:38 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 794.9 MB)
16/03/21 17:17:38 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=833527480
16/03/21 17:17:38 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 794.9 MB)
16/03/21 17:17:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51023 (size: 4.1 KB, free: 794.9 MB)
16/03/21 17:17:38 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:17:38 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:17:38 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:17:38 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:17:38 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:17:38 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:17:38 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560858403
16/03/21 17:17:38 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-ffce7494-0311-4379-84bd-e3d273776cbb/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:17:38 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:17:38 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=833527480
16/03/21 17:17:38 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 794.9 MB)
16/03/21 17:17:38 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:51023 (size: 166.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: area
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: issue
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: planning
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: permission
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: economy
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: composition
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: agency
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Bengal  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/21 17:17:46 INFO PythonRunner: Times: total = 8035, boot = 478, init = 368, finish = 7189
16/03/21 17:17:46 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:17:46 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:17:46 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:17:46 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8221 ms on localhost (1/2)
16/03/21 17:17:46 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:17:46 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=833527480
16/03/21 17:17:46 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 794.9 MB)
16/03/21 17:17:46 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:51023 (size: 155.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: set
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: bend
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: giant
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: astatine
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: present
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Bengal  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: area
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/21 17:17:47 INFO PythonRunner: Times: total = 292, boot = 142, init = 1, finish = 149
16/03/21 17:17:47 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:17:47 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.585 s
16/03/21 17:17:47 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:17:47 INFO DAGScheduler: running: Set()
16/03/21 17:17:47 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:17:47 INFO DAGScheduler: failed: Set()
16/03/21 17:17:47 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:17:47 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 400 ms on localhost (2/2)
16/03/21 17:17:47 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:17:47 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:17:47 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=833527480
16/03/21 17:17:47 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 794.9 MB)
16/03/21 17:17:47 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=833527480
16/03/21 17:17:47 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 794.9 MB)
16/03/21 17:17:47 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51023 (size: 3.0 KB, free: 794.9 MB)
16/03/21 17:17:47 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:17:47 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:17:47 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:17:47 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:17:47 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:17:47 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:17:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:17:47 INFO PythonRunner: Times: total = 89, boot = 89, init = 0, finish = 0
16/03/21 17:17:47 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:17:47 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:17:47 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:17:47 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:17:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:17:47 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 127 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'Chennai', 'None', u'Chennai']
16/03/21 17:17:47 INFO PythonRunner: Times: total = 174, boot = 173, init = 1, finish = 0
16/03/21 17:17:47 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1255 bytes result sent to driver
16/03/21 17:17:47 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.315 s
16/03/21 17:17:47 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.042966 s
16/03/21 17:17:47 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 213 ms on localhost (2/2)
16/03/21 17:17:47 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:17:47 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:17:47 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:17:47 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:17:47 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:17:47 INFO DAGScheduler: Missing parents: List()
16/03/21 17:17:47 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:17:48 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=833527480
16/03/21 17:17:48 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 794.9 MB)
16/03/21 17:17:48 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=833527480
16/03/21 17:17:48 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 794.9 MB)
16/03/21 17:17:48 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:51023 (size: 3.3 KB, free: 794.9 MB)
16/03/21 17:17:48 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:17:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:17:48 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:17:48 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:17:48 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:17:48 INFO PythonRunner: Times: total = 3, boot = -123, init = 126, finish = 0
16/03/21 17:17:48 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:17:48 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2285 bytes)
16/03/21 17:17:48 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 58 ms on localhost (1/2)
16/03/21 17:17:48 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:17:48 INFO PythonRunner: Times: total = 166, boot = 165, init = 1, finish = 0
16/03/21 17:17:48 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1324 bytes result sent to driver
16/03/21 17:17:48 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 232 ms on localhost (2/2)
16/03/21 17:17:48 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:17:48 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.265 s
16/03/21 17:17:48 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.328532 s
16/03/21 17:17:48 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:17:48 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:17:48 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:17:48 INFO MemoryStore: MemoryStore cleared
16/03/21 17:17:48 INFO BlockManager: BlockManager stopped
16/03/21 17:17:48 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:17:48 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:17:48 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:17:48 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:17:48 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:17:48 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:17:49 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:17:49 INFO SecurityManager: Changing view acls to: root
16/03/21 17:17:49 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:17:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:17:49 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:17:49 INFO Remoting: Starting remoting
16/03/21 17:17:49 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:42898]
16/03/21 17:17:49 INFO Utils: Successfully started service 'sparkDriver' on port 42898.
16/03/21 17:17:49 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:17:49 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:17:49 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-02be28f4-8731-42c7-b52e-087fcf36f399
16/03/21 17:17:49 INFO MemoryStore: MemoryStore started with capacity 794.9 MB
16/03/21 17:17:49 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-eb5b970c-8fea-4f61-9b55-20317ca219fc
16/03/21 17:17:49 INFO HttpServer: Starting HTTP Server
16/03/21 17:17:49 INFO Utils: Successfully started service 'HTTP file server' on port 39247.
16/03/21 17:17:49 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:17:49 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:17:49 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:17:49 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-61468112-6819-43d5-b143-312643d79a2e/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:17:49 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560869670
16/03/21 17:17:49 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:17:49 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:17:49 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59113.
16/03/21 17:17:49 INFO NettyBlockTransferService: Server created on 59113
16/03/21 17:17:49 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:17:49 INFO BlockManagerMasterEndpoint: Registering block manager localhost:59113 with 794.9 MB RAM, BlockManagerId(driver, localhost, 59113)
16/03/21 17:17:49 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:17:49 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458560869688
16/03/21 17:17:49 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:17:49 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:17:49 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:17:49 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:17:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:17:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:17:49 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:17:49 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=833527480
16/03/21 17:17:49 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 794.9 MB)
16/03/21 17:17:49 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6576, maxMem=833527480
16/03/21 17:17:50 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 794.9 MB)
16/03/21 17:17:50 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:59113 (size: 4.1 KB, free: 794.9 MB)
16/03/21 17:17:50 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:17:50 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:17:50 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:17:50 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:17:50 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:17:50 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:17:50 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560869670
16/03/21 17:17:50 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-61468112-6819-43d5-b143-312643d79a2e/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:17:50 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:17:50 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10724, maxMem=833527480
16/03/21 17:17:50 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 794.9 MB)
16/03/21 17:17:50 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:59113 (size: 166.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: area
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: issue
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: planning
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): adding to parents: syn =  Synset('planning.n.01') ; keyword:  course  in syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= [u'planning']
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: permission
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: economy
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: composition
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: agency
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
16/03/21 17:17:58 INFO PythonRunner: Times: total = 7902, boot = 484, init = 357, finish = 7061
16/03/21 17:17:58 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:17:58 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:17:58 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:17:58 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8094 ms on localhost (1/2)
16/03/21 17:17:58 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:17:58 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10890, maxMem=833527480
16/03/21 17:17:58 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 794.9 MB)
16/03/21 17:17:58 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:59113 (size: 155.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: set
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: bend
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: giant
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: astatine
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: present
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: area
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:17:58 INFO PythonRunner: Times: total = 216, boot = 102, init = 1, finish = 113
16/03/21 17:17:58 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:17:58 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 330 ms on localhost (2/2)
16/03/21 17:17:58 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:17:58 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.408 s
16/03/21 17:17:58 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:17:58 INFO DAGScheduler: running: Set()
16/03/21 17:17:58 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:17:58 INFO DAGScheduler: failed: Set()
16/03/21 17:17:58 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:17:58 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:17:58 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11045, maxMem=833527480
16/03/21 17:17:58 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 794.9 MB)
16/03/21 17:17:58 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16029, maxMem=833527480
16/03/21 17:17:58 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 794.9 MB)
16/03/21 17:17:58 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:59113 (size: 3.0 KB, free: 794.9 MB)
16/03/21 17:17:58 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:17:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:17:58 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:17:58 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:17:58 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:17:58 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:17:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:17:58 INFO PythonRunner: Times: total = 112, boot = 111, init = 0, finish = 1
16/03/21 17:17:58 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:17:58 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:17:58 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:17:58 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:17:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:17:58 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 165 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'planning', 'None']
16/03/21 17:17:58 INFO PythonRunner: Times: total = 170, boot = 169, init = 0, finish = 1
16/03/21 17:17:58 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1242 bytes result sent to driver
16/03/21 17:17:58 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.355 s
16/03/21 17:17:58 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.910332 s
16/03/21 17:17:58 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 226 ms on localhost (2/2)
16/03/21 17:17:58 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:17:59 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:17:59 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:17:59 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:17:59 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:17:59 INFO DAGScheduler: Missing parents: List()
16/03/21 17:17:59 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:17:59 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19076, maxMem=833527480
16/03/21 17:17:59 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 794.9 MB)
16/03/21 17:17:59 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24892, maxMem=833527480
16/03/21 17:17:59 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 794.9 MB)
16/03/21 17:17:59 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:59113 (size: 3.3 KB, free: 794.9 MB)
16/03/21 17:17:59 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:17:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:17:59 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:17:59 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:17:59 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:17:59 INFO PythonRunner: Times: total = 20, boot = 19, init = 1, finish = 0
16/03/21 17:17:59 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:17:59 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2272 bytes)
16/03/21 17:17:59 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 56 ms on localhost (1/2)
16/03/21 17:17:59 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:17:59 INFO PythonRunner: Times: total = 129, boot = 128, init = 1, finish = 0
16/03/21 17:17:59 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1311 bytes result sent to driver
16/03/21 17:17:59 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.238 s
16/03/21 17:17:59 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.298411 s
16/03/21 17:17:59 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 191 ms on localhost (2/2)
16/03/21 17:17:59 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:17:59 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:17:59 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:17:59 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:17:59 INFO MemoryStore: MemoryStore cleared
16/03/21 17:17:59 INFO BlockManager: BlockManager stopped
16/03/21 17:17:59 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:17:59 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:17:59 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:17:59 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:17:59 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:17:59 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:18:00 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:18:00 INFO SecurityManager: Changing view acls to: root
16/03/21 17:18:00 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:18:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:18:00 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:18:00 INFO Remoting: Starting remoting
16/03/21 17:18:00 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:59295]
16/03/21 17:18:00 INFO Utils: Successfully started service 'sparkDriver' on port 59295.
16/03/21 17:18:00 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:18:00 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:18:00 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5fb12889-7518-40db-a31e-d555e1d8881a
16/03/21 17:18:00 INFO MemoryStore: MemoryStore started with capacity 794.9 MB
16/03/21 17:18:00 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-6742c6f2-71dd-40c3-8f18-d421396ccc5c
16/03/21 17:18:00 INFO HttpServer: Starting HTTP Server
16/03/21 17:18:00 INFO Utils: Successfully started service 'HTTP file server' on port 41049.
16/03/21 17:18:00 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:18:00 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:18:00 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:18:00 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-89656c06-31a9-4749-93cf-1d7bde8c7386/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:18:00 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560880798
16/03/21 17:18:00 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:18:00 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:18:00 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50108.
16/03/21 17:18:00 INFO NettyBlockTransferService: Server created on 50108
16/03/21 17:18:00 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:18:00 INFO BlockManagerMasterEndpoint: Registering block manager localhost:50108 with 794.9 MB RAM, BlockManagerId(driver, localhost, 50108)
16/03/21 17:18:00 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:18:00 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458560880811
16/03/21 17:18:00 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:18:00 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:18:00 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:18:00 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:18:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:18:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:18:00 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:18:00 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=833527480
16/03/21 17:18:00 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 794.9 MB)
16/03/21 17:18:00 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=833527480
16/03/21 17:18:00 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 794.9 MB)
16/03/21 17:18:00 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:50108 (size: 4.1 KB, free: 794.9 MB)
16/03/21 17:18:00 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:18:00 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:18:00 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:18:00 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:18:00 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:18:00 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:18:00 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560880798
16/03/21 17:18:01 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-89656c06-31a9-4749-93cf-1d7bde8c7386/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:18:01 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:18:01 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=833527480
16/03/21 17:18:01 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 794.9 MB)
16/03/21 17:18:01 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:50108 (size: 166.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: area
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: issue
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: planning
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: permission
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: economy
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: composition
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  relation  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: agency
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/21 17:18:08 INFO PythonRunner: Times: total = 7897, boot = 458, init = 367, finish = 7072
16/03/21 17:18:09 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:18:09 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:18:09 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:18:09 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8051 ms on localhost (1/2)
16/03/21 17:18:09 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:18:09 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=833527480
16/03/21 17:18:09 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 794.9 MB)
16/03/21 17:18:09 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:50108 (size: 155.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: set
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: bend
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: giant
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: astatine
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: present
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: area
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:18:09 INFO PythonRunner: Times: total = 245, boot = 116, init = 1, finish = 128
16/03/21 17:18:09 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:18:09 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 316 ms on localhost (2/2)
16/03/21 17:18:09 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:18:09 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.352 s
16/03/21 17:18:09 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:18:09 INFO DAGScheduler: running: Set()
16/03/21 17:18:09 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:18:09 INFO DAGScheduler: failed: Set()
16/03/21 17:18:09 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:18:09 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:18:09 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=833527480
16/03/21 17:18:09 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 794.9 MB)
16/03/21 17:18:09 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=833527480
16/03/21 17:18:09 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 794.9 MB)
16/03/21 17:18:09 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:50108 (size: 3.0 KB, free: 794.9 MB)
16/03/21 17:18:09 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:18:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:18:09 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:18:09 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:18:09 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:18:09 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:18:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:18:09 INFO PythonRunner: Times: total = 119, boot = 118, init = 1, finish = 0
16/03/21 17:18:09 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:18:09 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:18:09 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:18:09 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:18:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:18:09 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 147 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'composition', 'None']
16/03/21 17:18:09 INFO PythonRunner: Times: total = 277, boot = 276, init = 0, finish = 1
16/03/21 17:18:09 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1245 bytes result sent to driver
16/03/21 17:18:09 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 307 ms on localhost (2/2)
16/03/21 17:18:09 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:18:09 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.444 s
16/03/21 17:18:09 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.902400 s
16/03/21 17:18:09 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:18:09 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:18:09 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:18:09 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:18:09 INFO DAGScheduler: Missing parents: List()
16/03/21 17:18:09 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:18:09 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=833527480
16/03/21 17:18:09 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 794.9 MB)
16/03/21 17:18:10 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=833527480
16/03/21 17:18:10 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 794.9 MB)
16/03/21 17:18:10 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:50108 (size: 3.3 KB, free: 794.9 MB)
16/03/21 17:18:10 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:18:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:18:10 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:18:10 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:18:10 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:18:10 INFO PythonRunner: Times: total = 74, boot = 73, init = 1, finish = 0
16/03/21 17:18:10 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:18:10 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2275 bytes)
16/03/21 17:18:10 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 98 ms on localhost (1/2)
16/03/21 17:18:10 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:18:10 INFO PythonRunner: Times: total = 199, boot = 198, init = 0, finish = 1
16/03/21 17:18:10 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1314 bytes result sent to driver
16/03/21 17:18:10 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.315 s
16/03/21 17:18:10 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.348128 s
16/03/21 17:18:10 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 237 ms on localhost (2/2)
16/03/21 17:18:10 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:18:10 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:18:10 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:18:10 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:18:10 INFO MemoryStore: MemoryStore cleared
16/03/21 17:18:10 INFO BlockManager: BlockManager stopped
16/03/21 17:18:10 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:18:10 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:18:10 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:18:10 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:18:10 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:18:10 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:18:11 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:18:11 INFO SecurityManager: Changing view acls to: root
16/03/21 17:18:11 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:18:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:18:11 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:18:11 INFO Remoting: Starting remoting
16/03/21 17:18:11 INFO Utils: Successfully started service 'sparkDriver' on port 59957.
16/03/21 17:18:11 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:18:11 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:59957]
16/03/21 17:18:11 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:18:11 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f150d421-a2c4-4b4b-9108-9f432f949b40
16/03/21 17:18:11 INFO MemoryStore: MemoryStore started with capacity 794.9 MB
16/03/21 17:18:11 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-46e724d4-cfb4-4ac5-b212-f039ba33c129
16/03/21 17:18:11 INFO HttpServer: Starting HTTP Server
16/03/21 17:18:11 INFO Utils: Successfully started service 'HTTP file server' on port 47419.
16/03/21 17:18:11 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:18:11 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:18:11 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:18:11 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-e3f4e751-8e4c-49c2-ae77-96e82ef2f5d9/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:18:11 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560891643
16/03/21 17:18:11 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:18:11 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:18:11 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59061.
16/03/21 17:18:11 INFO NettyBlockTransferService: Server created on 59061
16/03/21 17:18:11 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:18:11 INFO BlockManagerMasterEndpoint: Registering block manager localhost:59061 with 794.9 MB RAM, BlockManagerId(driver, localhost, 59061)
16/03/21 17:18:11 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:18:11 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458560891663
16/03/21 17:18:11 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:18:11 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:18:11 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:18:11 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:18:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:18:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:18:11 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:18:11 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=833527480
16/03/21 17:18:11 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 794.9 MB)
16/03/21 17:18:11 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=833527480
16/03/21 17:18:11 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 794.9 MB)
16/03/21 17:18:11 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:59061 (size: 4.1 KB, free: 794.9 MB)
16/03/21 17:18:11 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:18:11 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:18:11 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:18:11 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:18:11 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:18:11 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:18:11 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560891643
16/03/21 17:18:11 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-e3f4e751-8e4c-49c2-ae77-96e82ef2f5d9/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:18:11 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:18:11 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=833527480
16/03/21 17:18:11 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 794.9 MB)
16/03/21 17:18:11 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:59061 (size: 166.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: area
mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  geography  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: issue
mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: planning
mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: permission
mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: economy
mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: composition
mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: agency
mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/21 17:18:20 INFO PythonRunner: Times: total = 8128, boot = 472, init = 395, finish = 7261
16/03/21 17:18:20 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:18:20 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:18:20 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:18:20 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8237 ms on localhost (1/2)
16/03/21 17:18:20 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:18:20 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=833527480
16/03/21 17:18:20 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 794.9 MB)
16/03/21 17:18:20 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:59061 (size: 155.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: set
mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: bend
mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: giant
mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: astatine
mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: present
mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: area
mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  geography  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/21 17:18:20 INFO PythonRunner: Times: total = 215, boot = 119, init = 0, finish = 96
16/03/21 17:18:20 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:18:20 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.511 s
16/03/21 17:18:20 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:18:20 INFO DAGScheduler: running: Set()
16/03/21 17:18:20 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:18:20 INFO DAGScheduler: failed: Set()
16/03/21 17:18:20 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:18:20 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:18:20 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=833527480
16/03/21 17:18:20 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 794.9 MB)
16/03/21 17:18:20 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 281 ms on localhost (2/2)
16/03/21 17:18:20 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:18:20 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=833527480
16/03/21 17:18:20 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 794.9 MB)
16/03/21 17:18:20 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:59061 (size: 3.0 KB, free: 794.9 MB)
16/03/21 17:18:20 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:18:20 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:18:20 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:18:20 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:18:20 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:18:20 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:18:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:18:20 INFO PythonRunner: Times: total = 83, boot = 82, init = 0, finish = 1
16/03/21 17:18:20 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:18:20 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:18:20 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:18:20 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:18:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:18:20 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 115 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'area', 'None', u'area']
16/03/21 17:18:20 INFO PythonRunner: Times: total = 158, boot = 157, init = 0, finish = 1
16/03/21 17:18:20 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/21 17:18:20 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.287 s
16/03/21 17:18:20 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.889617 s
16/03/21 17:18:20 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 187 ms on localhost (2/2)
16/03/21 17:18:20 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:18:20 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:18:20 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:18:20 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:18:20 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:18:20 INFO DAGScheduler: Missing parents: List()
16/03/21 17:18:20 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:18:20 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=833527480
16/03/21 17:18:20 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 794.9 MB)
16/03/21 17:18:20 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=833527480
16/03/21 17:18:20 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 794.9 MB)
16/03/21 17:18:20 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:59061 (size: 3.3 KB, free: 794.9 MB)
16/03/21 17:18:20 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:18:20 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:18:20 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:18:20 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:18:20 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:18:20 INFO PythonRunner: Times: total = 73, boot = 72, init = 1, finish = 0
16/03/21 17:18:20 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:18:20 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/21 17:18:20 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 97 ms on localhost (1/2)
16/03/21 17:18:20 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:18:21 INFO PythonRunner: Times: total = 141, boot = 141, init = 0, finish = 0
16/03/21 17:18:21 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1307 bytes result sent to driver
16/03/21 17:18:21 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 181 ms on localhost (2/2)
16/03/21 17:18:21 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.272 s
16/03/21 17:18:21 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:18:21 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.296220 s
16/03/21 17:18:21 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:18:21 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:18:21 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:18:21 INFO MemoryStore: MemoryStore cleared
16/03/21 17:18:21 INFO BlockManager: BlockManager stopped
16/03/21 17:18:21 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:18:21 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:18:21 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:18:21 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:18:21 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:18:21 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:18:22 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:18:22 INFO SecurityManager: Changing view acls to: root
16/03/21 17:18:22 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:18:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:18:22 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:18:22 INFO Remoting: Starting remoting
16/03/21 17:18:22 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:44290]
16/03/21 17:18:22 INFO Utils: Successfully started service 'sparkDriver' on port 44290.
16/03/21 17:18:22 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:18:22 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:18:22 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2af8ac45-7e19-45e8-bcbb-4f62ec727060
16/03/21 17:18:22 INFO MemoryStore: MemoryStore started with capacity 794.9 MB
16/03/21 17:18:22 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-4f04d1f9-fed6-478b-bf84-bd4fb608c2b0
16/03/21 17:18:22 INFO HttpServer: Starting HTTP Server
16/03/21 17:18:22 INFO Utils: Successfully started service 'HTTP file server' on port 35776.
16/03/21 17:18:22 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:18:23 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:18:23 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:18:23 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-2909f37f-3dfc-471e-a190-b9489461b5e4/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:18:23 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560903039
16/03/21 17:18:23 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:18:23 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:18:23 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35036.
16/03/21 17:18:23 INFO NettyBlockTransferService: Server created on 35036
16/03/21 17:18:23 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:18:23 INFO BlockManagerMasterEndpoint: Registering block manager localhost:35036 with 794.9 MB RAM, BlockManagerId(driver, localhost, 35036)
16/03/21 17:18:23 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:18:23 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458560903048
16/03/21 17:18:23 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:18:23 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:18:23 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:18:23 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:18:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:18:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:18:23 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:18:23 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=833527480
16/03/21 17:18:23 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 794.9 MB)
16/03/21 17:18:23 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=833527480
16/03/21 17:18:23 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 794.9 MB)
16/03/21 17:18:23 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:35036 (size: 4.1 KB, free: 794.9 MB)
16/03/21 17:18:23 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:18:23 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:18:23 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:18:23 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:18:23 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:18:23 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:18:23 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560903039
16/03/21 17:18:23 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-2909f37f-3dfc-471e-a190-b9489461b5e4/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:18:23 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:18:23 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=833527480
16/03/21 17:18:23 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 794.9 MB)
16/03/21 17:18:23 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:35036 (size: 166.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: area
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: issue
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: planning
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: permission
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: economy
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: composition
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: agency
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:18:31 INFO PythonRunner: Times: total = 7824, boot = 465, init = 352, finish = 7007
16/03/21 17:18:31 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:18:31 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:18:31 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:18:31 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7939 ms on localhost (1/2)
16/03/21 17:18:31 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:18:31 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=833527480
16/03/21 17:18:31 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 794.9 MB)
16/03/21 17:18:31 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:35036 (size: 155.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: set
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  Synset('set.n.01') ; keyword:  group  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: bend
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: giant
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: astatine
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: present
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: area
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
16/03/21 17:18:31 INFO PythonRunner: Times: total = 241, boot = 131, init = 0, finish = 110
16/03/21 17:18:31 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:18:31 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 311 ms on localhost (2/2)
16/03/21 17:18:31 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.225 s
16/03/21 17:18:31 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:18:31 INFO DAGScheduler: running: Set()
16/03/21 17:18:31 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:18:31 INFO DAGScheduler: failed: Set()
16/03/21 17:18:31 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:18:31 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:18:31 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=833527480
16/03/21 17:18:31 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 794.9 MB)
16/03/21 17:18:31 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=833527480
16/03/21 17:18:31 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 794.9 MB)
16/03/21 17:18:31 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:35036 (size: 3.0 KB, free: 794.9 MB)
16/03/21 17:18:31 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:18:31 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:18:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:18:31 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:18:31 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:18:31 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:18:31 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:18:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:18:31 INFO PythonRunner: Times: total = 121, boot = 121, init = 0, finish = 0
16/03/21 17:18:31 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:18:31 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:18:31 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:18:31 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:18:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:18:31 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 146 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'set']
16/03/21 17:18:31 INFO PythonRunner: Times: total = 168, boot = 167, init = 1, finish = 0
16/03/21 17:18:31 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1229 bytes result sent to driver
16/03/21 17:18:31 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.333 s
16/03/21 17:18:31 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.625923 s
16/03/21 17:18:31 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 194 ms on localhost (2/2)
16/03/21 17:18:31 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:18:31 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:18:31 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:18:31 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:18:31 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:18:31 INFO DAGScheduler: Missing parents: List()
16/03/21 17:18:31 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:18:31 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=833527480
16/03/21 17:18:31 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 794.9 MB)
16/03/21 17:18:32 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=833527480
16/03/21 17:18:32 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 794.9 MB)
16/03/21 17:18:32 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:35036 (size: 3.3 KB, free: 794.9 MB)
16/03/21 17:18:32 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:18:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:18:32 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:18:32 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:18:32 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:18:32 INFO PythonRunner: Times: total = 100, boot = 100, init = 0, finish = 0
16/03/21 17:18:32 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:18:32 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2259 bytes)
16/03/21 17:18:32 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 121 ms on localhost (1/2)
16/03/21 17:18:32 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:18:32 INFO PythonRunner: Times: total = 165, boot = 165, init = 0, finish = 0
16/03/21 17:18:32 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1295 bytes result sent to driver
16/03/21 17:18:32 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.303 s
16/03/21 17:18:32 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.364665 s
16/03/21 17:18:32 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 199 ms on localhost (2/2)
16/03/21 17:18:32 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:18:32 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:18:32 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:18:32 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:18:32 INFO MemoryStore: MemoryStore cleared
16/03/21 17:18:32 INFO BlockManager: BlockManager stopped
16/03/21 17:18:32 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:18:32 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:18:32 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:18:32 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:18:32 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:18:32 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:18:33 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:18:33 INFO SecurityManager: Changing view acls to: root
16/03/21 17:18:33 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:18:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:18:33 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:18:33 INFO Remoting: Starting remoting
16/03/21 17:18:33 INFO Utils: Successfully started service 'sparkDriver' on port 38109.
16/03/21 17:18:33 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:38109]
16/03/21 17:18:33 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:18:33 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:18:33 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-908e81d8-7f5f-4dda-8486-9b7d05a2af87
16/03/21 17:18:33 INFO MemoryStore: MemoryStore started with capacity 794.9 MB
16/03/21 17:18:33 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-611432b0-edab-4c73-8439-f27c2b547ad6
16/03/21 17:18:33 INFO HttpServer: Starting HTTP Server
16/03/21 17:18:33 INFO Utils: Successfully started service 'HTTP file server' on port 54498.
16/03/21 17:18:33 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:18:34 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:18:34 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:18:34 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-989eded5-a148-432b-8bfc-cc176e56add8/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:18:34 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560914086
16/03/21 17:18:34 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:18:34 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:18:34 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51837.
16/03/21 17:18:34 INFO NettyBlockTransferService: Server created on 51837
16/03/21 17:18:34 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:18:34 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51837 with 794.9 MB RAM, BlockManagerId(driver, localhost, 51837)
16/03/21 17:18:34 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:18:34 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458560914094
16/03/21 17:18:34 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:18:34 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:18:34 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:18:34 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:18:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:18:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:18:34 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:18:34 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=833527480
16/03/21 17:18:34 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 794.9 MB)
16/03/21 17:18:34 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=833527480
16/03/21 17:18:34 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 794.9 MB)
16/03/21 17:18:34 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51837 (size: 4.1 KB, free: 794.9 MB)
16/03/21 17:18:34 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:18:34 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:18:34 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:18:34 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:18:34 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:18:34 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:18:34 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560914086
16/03/21 17:18:34 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-989eded5-a148-432b-8bfc-cc176e56add8/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:18:34 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:18:34 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=833527480
16/03/21 17:18:34 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 794.9 MB)
16/03/21 17:18:34 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:51837 (size: 166.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: area
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: issue
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: planning
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: permission
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: economy
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: composition
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: agency
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:18:42 INFO PythonRunner: Times: total = 7874, boot = 457, init = 356, finish = 7061
16/03/21 17:18:42 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:18:42 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:18:42 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:18:42 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7984 ms on localhost (1/2)
16/03/21 17:18:42 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:18:42 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=833527480
16/03/21 17:18:42 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 794.9 MB)
16/03/21 17:18:42 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:51837 (size: 155.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: set
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: bend
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: giant
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: astatine
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  decay  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: present
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: area
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/21 17:18:42 INFO PythonRunner: Times: total = 230, boot = 133, init = 0, finish = 97
16/03/21 17:18:42 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:18:42 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.275 s
16/03/21 17:18:42 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:18:42 INFO DAGScheduler: running: Set()
16/03/21 17:18:42 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:18:42 INFO DAGScheduler: failed: Set()
16/03/21 17:18:42 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:18:42 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:18:42 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=833527480
16/03/21 17:18:42 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 794.9 MB)
16/03/21 17:18:42 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 310 ms on localhost (2/2)
16/03/21 17:18:42 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:18:42 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=833527480
16/03/21 17:18:42 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 794.9 MB)
16/03/21 17:18:42 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51837 (size: 3.0 KB, free: 794.9 MB)
16/03/21 17:18:42 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:18:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:18:42 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:18:42 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:18:42 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:18:42 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:18:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:18:42 INFO PythonRunner: Times: total = 132, boot = 131, init = 0, finish = 1
16/03/21 17:18:42 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:18:42 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:18:42 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 154 ms on localhost (1/2)
16/03/21 17:18:42 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:18:42 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:18:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/03/21 17:18:42 INFO PythonRunner: Times: total = 152, boot = 151, init = 0, finish = 1
16/03/21 17:18:42 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1242 bytes result sent to driver
16/03/21 17:18:42 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.351 s
16/03/21 17:18:42 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.663749 s
16/03/21 17:18:42 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 193 ms on localhost (2/2)
16/03/21 17:18:42 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:18:43 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:18:43 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:18:43 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:18:43 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:18:43 INFO DAGScheduler: Missing parents: List()
16/03/21 17:18:43 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:18:43 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=833527480
16/03/21 17:18:43 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 794.9 MB)
16/03/21 17:18:43 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=833527480
16/03/21 17:18:43 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 794.9 MB)
16/03/21 17:18:43 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:51837 (size: 3.3 KB, free: 794.9 MB)
16/03/21 17:18:43 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:18:43 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:18:43 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:18:43 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:18:43 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:18:43 INFO PythonRunner: Times: total = 3, boot = -32, init = 35, finish = 0
16/03/21 17:18:43 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:18:43 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2272 bytes)
16/03/21 17:18:43 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 25 ms on localhost (1/2)
16/03/21 17:18:43 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:18:43 INFO PythonRunner: Times: total = 192, boot = 191, init = 1, finish = 0
16/03/21 17:18:43 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1311 bytes result sent to driver
16/03/21 17:18:43 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.235 s
16/03/21 17:18:43 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.261327 s
16/03/21 17:18:43 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 217 ms on localhost (2/2)
16/03/21 17:18:43 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:18:43 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:18:43 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:18:43 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:18:43 INFO MemoryStore: MemoryStore cleared
16/03/21 17:18:43 INFO BlockManager: BlockManager stopped
16/03/21 17:18:43 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:18:43 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:18:43 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:18:43 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:18:43 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:18:43 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:18:44 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:18:44 INFO SecurityManager: Changing view acls to: root
16/03/21 17:18:44 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:18:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:18:44 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:18:44 INFO Remoting: Starting remoting
16/03/21 17:18:44 INFO Utils: Successfully started service 'sparkDriver' on port 58241.
16/03/21 17:18:44 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:58241]
16/03/21 17:18:44 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:18:44 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:18:44 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0cdd087a-735d-4d22-8853-90c0e96b3f03
16/03/21 17:18:44 INFO MemoryStore: MemoryStore started with capacity 794.9 MB
16/03/21 17:18:44 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-d59d1e07-655c-464b-82ee-275fb6bf3b78
16/03/21 17:18:44 INFO HttpServer: Starting HTTP Server
16/03/21 17:18:44 INFO Utils: Successfully started service 'HTTP file server' on port 49511.
16/03/21 17:18:44 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:18:44 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:18:44 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:18:44 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-e4c194c5-e002-4601-8381-1b7bf0864bd3/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:18:44 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560924637
16/03/21 17:18:44 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:18:44 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:18:44 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54331.
16/03/21 17:18:44 INFO NettyBlockTransferService: Server created on 54331
16/03/21 17:18:44 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:18:44 INFO BlockManagerMasterEndpoint: Registering block manager localhost:54331 with 794.9 MB RAM, BlockManagerId(driver, localhost, 54331)
16/03/21 17:18:44 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:18:44 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458560924645
16/03/21 17:18:44 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:18:44 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:18:44 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:18:44 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:18:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:18:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:18:44 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:18:44 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=833527480
16/03/21 17:18:44 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 794.9 MB)
16/03/21 17:18:44 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=833527480
16/03/21 17:18:44 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 794.9 MB)
16/03/21 17:18:44 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:54331 (size: 4.1 KB, free: 794.9 MB)
16/03/21 17:18:44 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:18:44 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:18:44 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:18:44 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:18:44 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:18:44 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:18:44 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560924637
16/03/21 17:18:44 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-e4c194c5-e002-4601-8381-1b7bf0864bd3/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:18:44 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:18:44 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=833527480
16/03/21 17:18:44 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 794.9 MB)
16/03/21 17:18:44 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:54331 (size: 166.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: area
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: issue
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: planning
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): adding to parents: syn =  Synset('planning.n.01') ; keyword:  program  in syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= [u'planning']
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: permission
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: economy
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: composition
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: agency
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
16/03/21 17:18:52 INFO PythonRunner: Times: total = 7817, boot = 497, init = 362, finish = 6958
16/03/21 17:18:52 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:18:52 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:18:52 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:18:52 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7954 ms on localhost (1/2)
16/03/21 17:18:52 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:18:52 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=833527480
16/03/21 17:18:52 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 794.9 MB)
16/03/21 17:18:52 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:54331 (size: 155.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: set
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: bend
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: giant
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: astatine
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: present
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: area
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:18:53 INFO PythonRunner: Times: total = 241, boot = 128, init = 1, finish = 112
16/03/21 17:18:53 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:18:53 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.257 s
16/03/21 17:18:53 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:18:53 INFO DAGScheduler: running: Set()
16/03/21 17:18:53 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:18:53 INFO DAGScheduler: failed: Set()
16/03/21 17:18:53 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:18:53 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:18:53 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=833527480
16/03/21 17:18:53 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 794.9 MB)
16/03/21 17:18:53 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=833527480
16/03/21 17:18:53 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 794.9 MB)
16/03/21 17:18:53 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 308 ms on localhost (2/2)
16/03/21 17:18:53 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:18:53 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:54331 (size: 3.0 KB, free: 794.9 MB)
16/03/21 17:18:53 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:18:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:18:53 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:18:53 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:18:53 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:18:53 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:18:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:18:53 INFO PythonRunner: Times: total = 147, boot = 146, init = 0, finish = 1
16/03/21 17:18:53 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:18:53 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:18:53 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:18:53 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:18:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:18:53 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 174 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'planning', 'None']
16/03/21 17:18:53 INFO PythonRunner: Times: total = 174, boot = 172, init = 1, finish = 1
16/03/21 17:18:53 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1242 bytes result sent to driver
16/03/21 17:18:53 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 193 ms on localhost (2/2)
16/03/21 17:18:53 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:18:53 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.361 s
16/03/21 17:18:53 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.671982 s
16/03/21 17:18:53 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:18:53 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:18:53 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:18:53 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:18:53 INFO DAGScheduler: Missing parents: List()
16/03/21 17:18:53 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:18:53 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=833527480
16/03/21 17:18:53 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 794.9 MB)
16/03/21 17:18:53 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=833527480
16/03/21 17:18:53 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 794.9 MB)
16/03/21 17:18:53 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:54331 (size: 3.3 KB, free: 794.9 MB)
16/03/21 17:18:53 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:18:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:18:53 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:18:53 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:18:53 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:18:53 INFO PythonRunner: Times: total = 4, boot = -81, init = 85, finish = 0
16/03/21 17:18:53 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:18:53 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2272 bytes)
16/03/21 17:18:53 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 47 ms on localhost (1/2)
16/03/21 17:18:53 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:18:53 INFO PythonRunner: Times: total = 161, boot = 160, init = 1, finish = 0
16/03/21 17:18:53 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1311 bytes result sent to driver
16/03/21 17:18:53 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.216 s
16/03/21 17:18:53 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.244159 s
16/03/21 17:18:53 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 187 ms on localhost (2/2)
16/03/21 17:18:53 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:18:54 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:18:54 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:18:54 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:18:54 INFO MemoryStore: MemoryStore cleared
16/03/21 17:18:54 INFO BlockManager: BlockManager stopped
16/03/21 17:18:54 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:18:54 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:18:54 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:18:54 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:18:54 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:18:54 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:18:55 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:18:55 INFO SecurityManager: Changing view acls to: root
16/03/21 17:18:55 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:18:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:18:55 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:18:55 INFO Remoting: Starting remoting
16/03/21 17:18:55 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:52502]
16/03/21 17:18:55 INFO Utils: Successfully started service 'sparkDriver' on port 52502.
16/03/21 17:18:55 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:18:55 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:18:55 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5fae5a90-aeb6-4a7e-9a19-685e95f7bffa
16/03/21 17:18:55 INFO MemoryStore: MemoryStore started with capacity 794.9 MB
16/03/21 17:18:55 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-916081f5-d785-4961-8281-3ea7593cbd3f
16/03/21 17:18:55 INFO HttpServer: Starting HTTP Server
16/03/21 17:18:55 INFO Utils: Successfully started service 'HTTP file server' on port 43700.
16/03/21 17:18:55 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:18:55 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:18:55 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:18:55 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-b7a42e26-42ef-489c-b0da-efae711b2f78/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:18:55 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560935252
16/03/21 17:18:55 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:18:55 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:18:55 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59323.
16/03/21 17:18:55 INFO NettyBlockTransferService: Server created on 59323
16/03/21 17:18:55 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:18:55 INFO BlockManagerMasterEndpoint: Registering block manager localhost:59323 with 794.9 MB RAM, BlockManagerId(driver, localhost, 59323)
16/03/21 17:18:55 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:18:55 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458560935271
16/03/21 17:18:55 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:18:55 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:18:55 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:18:55 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:18:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:18:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:18:55 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:18:55 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=833527480
16/03/21 17:18:55 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 794.9 MB)
16/03/21 17:18:55 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=833527480
16/03/21 17:18:55 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 794.9 MB)
16/03/21 17:18:55 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:59323 (size: 4.1 KB, free: 794.9 MB)
16/03/21 17:18:55 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:18:55 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:18:55 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:18:55 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:18:55 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:18:55 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:18:55 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560935252
16/03/21 17:18:55 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-b7a42e26-42ef-489c-b0da-efae711b2f78/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:18:55 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:18:55 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=833527480
16/03/21 17:18:55 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 794.9 MB)
16/03/21 17:18:55 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:59323 (size: 166.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: area
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: issue
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: planning
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: permission
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: economy
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: composition
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: agency
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Tamil  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/21 17:19:03 INFO PythonRunner: Times: total = 7997, boot = 470, init = 357, finish = 7170
16/03/21 17:19:03 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:19:03 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:19:03 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:19:03 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8099 ms on localhost (1/2)
16/03/21 17:19:03 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:19:03 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=833527480
16/03/21 17:19:03 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 794.9 MB)
16/03/21 17:19:03 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:59323 (size: 155.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: set
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: bend
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: giant
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: astatine
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: present
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Tamil  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: area
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/21 17:19:03 INFO PythonRunner: Times: total = 220, boot = 117, init = 0, finish = 103
16/03/21 17:19:03 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:19:03 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.369 s
16/03/21 17:19:03 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:19:03 INFO DAGScheduler: running: Set()
16/03/21 17:19:03 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:19:03 INFO DAGScheduler: failed: Set()
16/03/21 17:19:03 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:19:03 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:19:03 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=833527480
16/03/21 17:19:03 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 794.9 MB)
16/03/21 17:19:03 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 278 ms on localhost (2/2)
16/03/21 17:19:03 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:19:03 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=833527480
16/03/21 17:19:03 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 794.9 MB)
16/03/21 17:19:03 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:59323 (size: 3.0 KB, free: 794.9 MB)
16/03/21 17:19:03 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:19:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:03 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:19:03 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:19:03 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:19:03 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:19:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:19:03 INFO PythonRunner: Times: total = 94, boot = 93, init = 1, finish = 0
16/03/21 17:19:03 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:19:03 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:19:03 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:19:03 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:19:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:19:03 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 126 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'Chennai', 'None', u'Chennai']
16/03/21 17:19:04 INFO PythonRunner: Times: total = 138, boot = 137, init = 0, finish = 1
16/03/21 17:19:04 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1255 bytes result sent to driver
16/03/21 17:19:04 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.289 s
16/03/21 17:19:04 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.744037 s
16/03/21 17:19:04 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 183 ms on localhost (2/2)
16/03/21 17:19:04 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:19:04 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:19:04 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:19:04 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:04 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:19:04 INFO DAGScheduler: Missing parents: List()
16/03/21 17:19:04 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:19:04 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=833527480
16/03/21 17:19:04 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 794.9 MB)
16/03/21 17:19:04 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=833527480
16/03/21 17:19:04 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 794.9 MB)
16/03/21 17:19:04 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:59323 (size: 3.3 KB, free: 794.9 MB)
16/03/21 17:19:04 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:19:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:04 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:19:04 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:19:04 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:19:04 INFO PythonRunner: Times: total = 49, boot = 48, init = 1, finish = 0
16/03/21 17:19:04 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:19:04 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2285 bytes)
16/03/21 17:19:04 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 83 ms on localhost (1/2)
16/03/21 17:19:04 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:19:04 INFO PythonRunner: Times: total = 168, boot = 167, init = 1, finish = 0
16/03/21 17:19:04 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1324 bytes result sent to driver
16/03/21 17:19:04 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.253 s
16/03/21 17:19:04 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.301740 s
16/03/21 17:19:04 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 192 ms on localhost (2/2)
16/03/21 17:19:04 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:19:04 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:19:04 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:19:04 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:19:04 INFO MemoryStore: MemoryStore cleared
16/03/21 17:19:04 INFO BlockManager: BlockManager stopped
16/03/21 17:19:04 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:19:04 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:19:04 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:19:04 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:19:04 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:19:04 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:19:05 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:19:05 INFO SecurityManager: Changing view acls to: root
16/03/21 17:19:05 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:19:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:19:05 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:19:05 INFO Remoting: Starting remoting
16/03/21 17:19:05 INFO Utils: Successfully started service 'sparkDriver' on port 39925.
16/03/21 17:19:05 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:39925]
16/03/21 17:19:05 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:19:05 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:19:05 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-01f01562-6421-4bdb-bde7-73370f737b5e
16/03/21 17:19:05 INFO MemoryStore: MemoryStore started with capacity 794.9 MB
16/03/21 17:19:05 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-fc7803c5-4a85-4522-8769-cbeae4086257
16/03/21 17:19:05 INFO HttpServer: Starting HTTP Server
16/03/21 17:19:05 INFO Utils: Successfully started service 'HTTP file server' on port 44698.
16/03/21 17:19:05 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:19:05 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:19:05 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:19:05 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-07375117-30e2-44e0-854f-033b0b7d5096/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:19:05 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560945892
16/03/21 17:19:05 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:19:05 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:19:05 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39306.
16/03/21 17:19:05 INFO NettyBlockTransferService: Server created on 39306
16/03/21 17:19:05 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:19:05 INFO BlockManagerMasterEndpoint: Registering block manager localhost:39306 with 794.9 MB RAM, BlockManagerId(driver, localhost, 39306)
16/03/21 17:19:05 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:19:05 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458560945904
16/03/21 17:19:06 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:19:06 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:06 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:19:06 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:19:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:19:06 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:19:06 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=833527480
16/03/21 17:19:06 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 794.9 MB)
16/03/21 17:19:06 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=833527480
16/03/21 17:19:06 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 794.9 MB)
16/03/21 17:19:06 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:39306 (size: 4.1 KB, free: 794.9 MB)
16/03/21 17:19:06 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:19:06 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:06 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:19:06 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:19:06 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:19:06 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560945892
16/03/21 17:19:06 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:19:06 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-07375117-30e2-44e0-854f-033b0b7d5096/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:19:06 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:19:06 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=833527480
16/03/21 17:19:06 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 794.9 MB)
16/03/21 17:19:06 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:39306 (size: 166.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: area
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: issue
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: planning
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: permission
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: economy
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: composition
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: agency
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:19:14 INFO PythonRunner: Times: total = 8034, boot = 498, init = 390, finish = 7146
16/03/21 17:19:14 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:19:14 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:19:14 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:19:14 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:19:14 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=833527480
16/03/21 17:19:14 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 794.9 MB)
16/03/21 17:19:14 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8114 ms on localhost (1/2)
16/03/21 17:19:14 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:39306 (size: 155.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: set
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: bend
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: giant
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): adding to parents: syn =  Synset('colossus.n.02') ; keyword:  exceptional  in syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= [u'giant']
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: astatine
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: present
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: area
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
16/03/21 17:19:14 INFO PythonRunner: Times: total = 290, boot = 182, init = 0, finish = 108
16/03/21 17:19:14 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:19:14 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 333 ms on localhost (2/2)
16/03/21 17:19:14 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:19:14 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.439 s
16/03/21 17:19:14 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:19:14 INFO DAGScheduler: running: Set()
16/03/21 17:19:14 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:19:14 INFO DAGScheduler: failed: Set()
16/03/21 17:19:14 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:19:14 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:19:14 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=833527480
16/03/21 17:19:14 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 794.9 MB)
16/03/21 17:19:14 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=833527480
16/03/21 17:19:14 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 794.9 MB)
16/03/21 17:19:14 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:39306 (size: 3.0 KB, free: 794.9 MB)
16/03/21 17:19:14 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:19:14 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:14 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:19:14 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:19:14 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:19:14 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:19:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:19:14 INFO PythonRunner: Times: total = 155, boot = 154, init = 1, finish = 0
16/03/21 17:19:14 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:19:14 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:19:14 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:19:14 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:19:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:19:14 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 191 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'giant']
16/03/21 17:19:14 INFO PythonRunner: Times: total = 154, boot = 153, init = 0, finish = 1
16/03/21 17:19:14 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1239 bytes result sent to driver
16/03/21 17:19:14 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.343 s
16/03/21 17:19:14 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.825939 s
16/03/21 17:19:14 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 176 ms on localhost (2/2)
16/03/21 17:19:14 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:19:15 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:19:15 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:19:15 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:15 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:19:15 INFO DAGScheduler: Missing parents: List()
16/03/21 17:19:15 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:19:15 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=833527480
16/03/21 17:19:15 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 794.9 MB)
16/03/21 17:19:15 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=833527480
16/03/21 17:19:15 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 794.9 MB)
16/03/21 17:19:15 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:39306 (size: 3.3 KB, free: 794.9 MB)
16/03/21 17:19:15 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:19:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:15 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:19:15 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:19:15 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:19:15 INFO PythonRunner: Times: total = 41, boot = 40, init = 1, finish = 0
16/03/21 17:19:15 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:19:15 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2269 bytes)
16/03/21 17:19:15 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:19:15 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 67 ms on localhost (1/2)
16/03/21 17:19:15 INFO PythonRunner: Times: total = 165, boot = 165, init = 0, finish = 0
16/03/21 17:19:15 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1308 bytes result sent to driver
16/03/21 17:19:15 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.236 s
16/03/21 17:19:15 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.279122 s
16/03/21 17:19:15 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 188 ms on localhost (2/2)
16/03/21 17:19:15 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:19:15 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:19:15 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:19:15 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:19:15 INFO MemoryStore: MemoryStore cleared
16/03/21 17:19:15 INFO BlockManager: BlockManager stopped
16/03/21 17:19:15 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:19:15 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:19:15 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:19:15 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:19:15 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:19:15 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:19:16 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:19:16 INFO SecurityManager: Changing view acls to: root
16/03/21 17:19:16 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:19:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:19:16 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:19:16 INFO Remoting: Starting remoting
16/03/21 17:19:16 INFO Utils: Successfully started service 'sparkDriver' on port 35644.
16/03/21 17:19:16 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:35644]
16/03/21 17:19:16 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:19:16 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:19:16 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9f0a3470-fb49-4625-9b77-1b782cdff5e5
16/03/21 17:19:16 INFO MemoryStore: MemoryStore started with capacity 794.9 MB
16/03/21 17:19:16 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-8d64f52b-1bef-4a95-98f8-1eaa51c4284e
16/03/21 17:19:16 INFO HttpServer: Starting HTTP Server
16/03/21 17:19:16 INFO Utils: Successfully started service 'HTTP file server' on port 39813.
16/03/21 17:19:16 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:19:16 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:19:16 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:19:16 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-26dbc8aa-dc7e-405a-8d97-df71688cd20b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:19:16 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560956506
16/03/21 17:19:16 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:19:16 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:19:16 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54642.
16/03/21 17:19:16 INFO NettyBlockTransferService: Server created on 54642
16/03/21 17:19:16 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:19:16 INFO BlockManagerMasterEndpoint: Registering block manager localhost:54642 with 794.9 MB RAM, BlockManagerId(driver, localhost, 54642)
16/03/21 17:19:16 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:19:16 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458560956519
16/03/21 17:19:16 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:19:16 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:16 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:19:16 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:19:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:19:16 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:19:16 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=833527480
16/03/21 17:19:16 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 794.9 MB)
16/03/21 17:19:16 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=833527480
16/03/21 17:19:16 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 794.9 MB)
16/03/21 17:19:16 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:54642 (size: 4.1 KB, free: 794.9 MB)
16/03/21 17:19:16 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:19:16 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:16 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:19:16 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:19:16 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:19:16 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560956506
16/03/21 17:19:16 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:19:16 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-26dbc8aa-dc7e-405a-8d97-df71688cd20b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:19:16 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:19:16 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=833527480
16/03/21 17:19:16 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 794.9 MB)
16/03/21 17:19:16 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:54642 (size: 166.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: area
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: issue
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: planning
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: permission
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: economy
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: composition
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: agency
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Bay  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/21 17:19:24 INFO PythonRunner: Times: total = 7967, boot = 465, init = 343, finish = 7159
16/03/21 17:19:24 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:19:24 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:19:24 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:19:24 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:19:24 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8082 ms on localhost (1/2)
16/03/21 17:19:24 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=833527480
16/03/21 17:19:24 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 794.9 MB)
16/03/21 17:19:24 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:54642 (size: 155.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: set
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: bend
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: giant
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: astatine
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: present
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Bay  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: area
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/21 17:19:25 INFO PythonRunner: Times: total = 285, boot = 191, init = 1, finish = 93
16/03/21 17:19:25 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:19:25 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 341 ms on localhost (2/2)
16/03/21 17:19:25 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:19:25 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.397 s
16/03/21 17:19:25 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:19:25 INFO DAGScheduler: running: Set()
16/03/21 17:19:25 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:19:25 INFO DAGScheduler: failed: Set()
16/03/21 17:19:25 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:19:25 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:19:25 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=833527480
16/03/21 17:19:25 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 794.9 MB)
16/03/21 17:19:25 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=833527480
16/03/21 17:19:25 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 794.9 MB)
16/03/21 17:19:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:54642 (size: 3.0 KB, free: 794.9 MB)
16/03/21 17:19:25 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:19:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:25 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:19:25 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:19:25 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:19:25 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:19:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:19:25 INFO PythonRunner: Times: total = 148, boot = 147, init = 0, finish = 1
16/03/21 17:19:25 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:19:25 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:19:25 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:19:25 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:19:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:19:25 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 180 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'Chennai', 'None', u'Chennai']
16/03/21 17:19:25 INFO PythonRunner: Times: total = 160, boot = 159, init = 0, finish = 1
16/03/21 17:19:25 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1255 bytes result sent to driver
16/03/21 17:19:25 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 174 ms on localhost (2/2)
16/03/21 17:19:25 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:19:25 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.346 s
16/03/21 17:19:25 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.811889 s
16/03/21 17:19:25 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:19:25 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:19:25 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:25 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:19:25 INFO DAGScheduler: Missing parents: List()
16/03/21 17:19:25 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:19:25 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=833527480
16/03/21 17:19:25 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 794.9 MB)
16/03/21 17:19:25 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=833527480
16/03/21 17:19:25 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 794.9 MB)
16/03/21 17:19:25 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:54642 (size: 3.3 KB, free: 794.9 MB)
16/03/21 17:19:25 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:19:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:25 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:19:25 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:19:25 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:19:25 INFO PythonRunner: Times: total = 77, boot = 77, init = 0, finish = 0
16/03/21 17:19:25 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:19:25 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2285 bytes)
16/03/21 17:19:25 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:19:25 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 102 ms on localhost (1/2)
16/03/21 17:19:25 INFO PythonRunner: Times: total = 172, boot = 171, init = 1, finish = 0
16/03/21 17:19:25 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1324 bytes result sent to driver
16/03/21 17:19:25 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.287 s
16/03/21 17:19:25 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 194 ms on localhost (2/2)
16/03/21 17:19:25 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:19:25 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.310352 s
16/03/21 17:19:26 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:19:26 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:19:26 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:19:26 INFO MemoryStore: MemoryStore cleared
16/03/21 17:19:26 INFO BlockManager: BlockManager stopped
16/03/21 17:19:26 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:19:26 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:19:26 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:19:26 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:19:26 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:19:26 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:19:26 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:19:26 INFO SecurityManager: Changing view acls to: root
16/03/21 17:19:26 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:19:26 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:19:27 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:19:27 INFO Remoting: Starting remoting
16/03/21 17:19:27 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:49794]
16/03/21 17:19:27 INFO Utils: Successfully started service 'sparkDriver' on port 49794.
16/03/21 17:19:27 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:19:27 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:19:27 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-497f6bcc-8c5d-4874-813e-7ed663f4340c
16/03/21 17:19:27 INFO MemoryStore: MemoryStore started with capacity 794.9 MB
16/03/21 17:19:27 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-dd230558-37a8-4a21-b5ca-33aebbcc36fa
16/03/21 17:19:27 INFO HttpServer: Starting HTTP Server
16/03/21 17:19:27 INFO Utils: Successfully started service 'HTTP file server' on port 33389.
16/03/21 17:19:27 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:19:27 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:19:27 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:19:27 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-4f49df0f-c0c7-4751-8226-c4580dc87a6a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:19:27 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560967722
16/03/21 17:19:27 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:19:27 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:19:27 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46642.
16/03/21 17:19:27 INFO NettyBlockTransferService: Server created on 46642
16/03/21 17:19:27 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:19:27 INFO BlockManagerMasterEndpoint: Registering block manager localhost:46642 with 794.9 MB RAM, BlockManagerId(driver, localhost, 46642)
16/03/21 17:19:27 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:19:27 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458560967733
16/03/21 17:19:27 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:19:27 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:27 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:19:27 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:19:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:19:27 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:19:27 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=833527480
16/03/21 17:19:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 794.9 MB)
16/03/21 17:19:27 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=833527480
16/03/21 17:19:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 794.9 MB)
16/03/21 17:19:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:46642 (size: 4.1 KB, free: 794.9 MB)
16/03/21 17:19:27 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:19:27 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:27 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:19:27 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:19:27 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:19:27 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:19:27 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560967722
16/03/21 17:19:27 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-4f49df0f-c0c7-4751-8226-c4580dc87a6a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:19:27 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:19:27 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=833527480
16/03/21 17:19:27 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 794.9 MB)
16/03/21 17:19:27 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:46642 (size: 166.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: area
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: issue
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: planning
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): adding to parents: syn =  Synset('planning.n.01') ; keyword:  formulating  in syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= [u'planning']
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: permission
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: economy
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: composition
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: agency
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
16/03/21 17:19:35 INFO PythonRunner: Times: total = 8008, boot = 520, init = 429, finish = 7059
16/03/21 17:19:35 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:19:35 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:19:35 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:19:35 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8107 ms on localhost (1/2)
16/03/21 17:19:36 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:19:36 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=833527480
16/03/21 17:19:36 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 794.9 MB)
16/03/21 17:19:36 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:46642 (size: 155.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: set
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: bend
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: giant
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: astatine
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: present
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: area
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:19:36 INFO PythonRunner: Times: total = 226, boot = 127, init = 0, finish = 99
16/03/21 17:19:36 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:19:36 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.383 s
16/03/21 17:19:36 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:19:36 INFO DAGScheduler: running: Set()
16/03/21 17:19:36 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:19:36 INFO DAGScheduler: failed: Set()
16/03/21 17:19:36 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:19:36 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:19:36 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=833527480
16/03/21 17:19:36 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 794.9 MB)
16/03/21 17:19:36 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 290 ms on localhost (2/2)
16/03/21 17:19:36 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:19:36 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=833527480
16/03/21 17:19:36 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 794.9 MB)
16/03/21 17:19:36 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:46642 (size: 3.0 KB, free: 794.9 MB)
16/03/21 17:19:36 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:19:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:36 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:19:36 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:19:36 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:19:36 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:19:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:19:36 INFO PythonRunner: Times: total = 122, boot = 122, init = 0, finish = 0
16/03/21 17:19:36 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:19:36 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:19:36 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:19:36 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:19:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:19:36 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 162 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'planning', 'None']
16/03/21 17:19:36 INFO PythonRunner: Times: total = 154, boot = 153, init = 1, finish = 0
16/03/21 17:19:36 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1242 bytes result sent to driver
16/03/21 17:19:36 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 176 ms on localhost (2/2)
16/03/21 17:19:36 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:19:36 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.323 s
16/03/21 17:19:36 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.768452 s
16/03/21 17:19:36 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:19:36 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:19:36 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:36 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:19:36 INFO DAGScheduler: Missing parents: List()
16/03/21 17:19:36 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:19:36 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=833527480
16/03/21 17:19:36 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 794.9 MB)
16/03/21 17:19:36 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=833527480
16/03/21 17:19:36 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 794.9 MB)
16/03/21 17:19:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:46642 (size: 3.3 KB, free: 794.9 MB)
16/03/21 17:19:36 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:19:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:36 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:19:36 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:19:36 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:19:36 INFO PythonRunner: Times: total = 2, boot = -23, init = 25, finish = 0
16/03/21 17:19:36 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:19:36 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2272 bytes)
16/03/21 17:19:36 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 39 ms on localhost (1/2)
16/03/21 17:19:36 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:19:36 INFO PythonRunner: Times: total = 136, boot = 136, init = 0, finish = 0
16/03/21 17:19:37 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1311 bytes result sent to driver
16/03/21 17:19:37 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.189 s
16/03/21 17:19:37 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.216265 s
16/03/21 17:19:37 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 167 ms on localhost (2/2)
16/03/21 17:19:37 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:19:37 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:19:37 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:19:37 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:19:37 INFO MemoryStore: MemoryStore cleared
16/03/21 17:19:37 INFO BlockManager: BlockManager stopped
16/03/21 17:19:37 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:19:37 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:19:37 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:19:37 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:19:37 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:19:37 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:19:38 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:19:38 INFO SecurityManager: Changing view acls to: root
16/03/21 17:19:38 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:19:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:19:38 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:19:38 INFO Remoting: Starting remoting
16/03/21 17:19:38 INFO Utils: Successfully started service 'sparkDriver' on port 60735.
16/03/21 17:19:38 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:60735]
16/03/21 17:19:38 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:19:38 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:19:38 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-27e7d08f-0ee2-4c83-9e48-e8b26855366b
16/03/21 17:19:38 INFO MemoryStore: MemoryStore started with capacity 794.9 MB
16/03/21 17:19:38 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-afb68789-76dd-4b6f-bf0e-37bbe284d0d7
16/03/21 17:19:38 INFO HttpServer: Starting HTTP Server
16/03/21 17:19:38 INFO Utils: Successfully started service 'HTTP file server' on port 38278.
16/03/21 17:19:38 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:19:38 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:19:38 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:19:38 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-8e0b4784-8de8-4877-8eea-cd42ae0a0362/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:19:38 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560978222
16/03/21 17:19:38 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:19:38 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:19:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50823.
16/03/21 17:19:38 INFO NettyBlockTransferService: Server created on 50823
16/03/21 17:19:38 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:19:38 INFO BlockManagerMasterEndpoint: Registering block manager localhost:50823 with 794.9 MB RAM, BlockManagerId(driver, localhost, 50823)
16/03/21 17:19:38 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:19:38 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458560978247
16/03/21 17:19:38 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:19:38 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:38 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:19:38 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:19:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:19:38 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:19:38 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=833527480
16/03/21 17:19:38 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 794.9 MB)
16/03/21 17:19:38 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=833527480
16/03/21 17:19:38 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 794.9 MB)
16/03/21 17:19:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:50823 (size: 4.1 KB, free: 794.9 MB)
16/03/21 17:19:38 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:19:38 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:38 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:19:38 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:19:38 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:19:38 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560978222
16/03/21 17:19:38 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:19:38 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-8e0b4784-8de8-4877-8eea-cd42ae0a0362/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:19:38 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:19:38 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=833527480
16/03/21 17:19:38 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 794.9 MB)
16/03/21 17:19:38 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:50823 (size: 166.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: area
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: issue
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: planning
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: permission
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: economy
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: composition
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: agency
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): adding to parents: syn =  Synset('agency.n.02') ; keyword:  serves  in syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= [u'agency']
reduceFunction_Parents(): returns= ['None', u'agency']
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'agency']
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'agency']
16/03/21 17:19:46 INFO PythonRunner: Times: total = 8029, boot = 527, init = 396, finish = 7106
16/03/21 17:19:46 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:19:46 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:19:46 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:19:46 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8137 ms on localhost (1/2)
16/03/21 17:19:46 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:19:46 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=833527480
16/03/21 17:19:46 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 794.9 MB)
16/03/21 17:19:46 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:50823 (size: 155.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: set
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: bend
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: giant
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: astatine
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: present
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: area
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:19:46 INFO PythonRunner: Times: total = 217, boot = 123, init = 1, finish = 93
16/03/21 17:19:46 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:19:46 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.398 s
16/03/21 17:19:46 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:19:46 INFO DAGScheduler: running: Set()
16/03/21 17:19:46 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:19:46 INFO DAGScheduler: failed: Set()
16/03/21 17:19:46 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:19:46 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:19:46 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=833527480
16/03/21 17:19:46 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 794.9 MB)
16/03/21 17:19:46 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 271 ms on localhost (2/2)
16/03/21 17:19:46 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:19:46 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=833527480
16/03/21 17:19:46 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 794.9 MB)
16/03/21 17:19:46 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:50823 (size: 3.0 KB, free: 794.9 MB)
16/03/21 17:19:46 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:19:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:46 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:19:46 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:19:46 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:19:46 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:19:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:19:46 INFO PythonRunner: Times: total = 116, boot = 115, init = 0, finish = 1
16/03/21 17:19:46 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:19:46 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:19:46 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:19:46 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:19:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:19:46 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 133 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'agency', 'None']
16/03/21 17:19:47 INFO PythonRunner: Times: total = 163, boot = 163, init = 0, finish = 0
16/03/21 17:19:47 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1240 bytes result sent to driver
16/03/21 17:19:47 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 181 ms on localhost (2/2)
16/03/21 17:19:47 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:19:47 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.312 s
16/03/21 17:19:47 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.763463 s
16/03/21 17:19:47 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:19:47 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:19:47 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:47 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:19:47 INFO DAGScheduler: Missing parents: List()
16/03/21 17:19:47 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:19:47 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=833527480
16/03/21 17:19:47 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 794.9 MB)
16/03/21 17:19:47 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=833527480
16/03/21 17:19:47 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 794.9 MB)
16/03/21 17:19:47 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:50823 (size: 3.3 KB, free: 794.9 MB)
16/03/21 17:19:47 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:19:47 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:47 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:19:47 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:19:47 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:19:47 INFO PythonRunner: Times: total = 9, boot = -54, init = 63, finish = 0
16/03/21 17:19:47 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:19:47 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2270 bytes)
16/03/21 17:19:47 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 46 ms on localhost (1/2)
16/03/21 17:19:47 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:19:47 INFO PythonRunner: Times: total = 132, boot = 131, init = 1, finish = 0
16/03/21 17:19:47 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1309 bytes result sent to driver
16/03/21 17:19:47 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.202 s
16/03/21 17:19:47 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.224149 s
16/03/21 17:19:47 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 160 ms on localhost (2/2)
16/03/21 17:19:47 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:19:47 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:19:47 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:19:47 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:19:47 INFO MemoryStore: MemoryStore cleared
16/03/21 17:19:47 INFO BlockManager: BlockManager stopped
16/03/21 17:19:47 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:19:47 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:19:47 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:19:47 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:19:47 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:19:47 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:19:48 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:19:48 INFO SecurityManager: Changing view acls to: root
16/03/21 17:19:48 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:19:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:19:48 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:19:48 INFO Remoting: Starting remoting
16/03/21 17:19:48 INFO Utils: Successfully started service 'sparkDriver' on port 53198.
16/03/21 17:19:48 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:53198]
16/03/21 17:19:48 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:19:48 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:19:48 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-aeacc225-f1a0-454f-b8b9-fd2040c5258f
16/03/21 17:19:48 INFO MemoryStore: MemoryStore started with capacity 794.9 MB
16/03/21 17:19:48 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-04a3551e-08aa-4c07-afeb-f3777a125f77
16/03/21 17:19:48 INFO HttpServer: Starting HTTP Server
16/03/21 17:19:48 INFO Utils: Successfully started service 'HTTP file server' on port 33067.
16/03/21 17:19:48 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:19:48 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:19:48 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:19:48 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-a1445186-60b3-4c33-8792-01a85b807d4a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:19:48 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560988881
16/03/21 17:19:48 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:19:48 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:19:48 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57258.
16/03/21 17:19:48 INFO NettyBlockTransferService: Server created on 57258
16/03/21 17:19:48 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:19:48 INFO BlockManagerMasterEndpoint: Registering block manager localhost:57258 with 794.9 MB RAM, BlockManagerId(driver, localhost, 57258)
16/03/21 17:19:48 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:19:48 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458560988890
16/03/21 17:19:49 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:19:49 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:49 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:19:49 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:19:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:19:49 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:19:49 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=833527480
16/03/21 17:19:49 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 794.9 MB)
16/03/21 17:19:49 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=833527480
16/03/21 17:19:49 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 794.9 MB)
16/03/21 17:19:49 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:57258 (size: 4.1 KB, free: 794.9 MB)
16/03/21 17:19:49 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:19:49 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:49 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:19:49 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:19:49 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:19:49 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:19:49 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560988881
16/03/21 17:19:49 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-a1445186-60b3-4c33-8792-01a85b807d4a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:19:49 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:19:49 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=833527480
16/03/21 17:19:49 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 794.9 MB)
16/03/21 17:19:49 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:57258 (size: 166.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: area
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: issue
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: planning
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: permission
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: economy
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: composition
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: agency
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:19:57 INFO PythonRunner: Times: total = 8020, boot = 529, init = 422, finish = 7069
16/03/21 17:19:57 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:19:57 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:19:57 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:19:57 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:19:57 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=833527480
16/03/21 17:19:57 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8119 ms on localhost (1/2)
16/03/21 17:19:57 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 794.9 MB)
16/03/21 17:19:57 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:57258 (size: 155.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: set
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: bend
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: giant
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: astatine
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: present
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: area
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:19:57 INFO PythonRunner: Times: total = 237, boot = 143, init = 0, finish = 94
16/03/21 17:19:57 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:19:57 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 314 ms on localhost (2/2)
16/03/21 17:19:57 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:19:57 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.403 s
16/03/21 17:19:57 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:19:57 INFO DAGScheduler: running: Set()
16/03/21 17:19:57 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:19:57 INFO DAGScheduler: failed: Set()
16/03/21 17:19:57 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:19:57 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:19:57 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=833527480
16/03/21 17:19:57 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 794.9 MB)
16/03/21 17:19:57 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=833527480
16/03/21 17:19:57 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 794.9 MB)
16/03/21 17:19:57 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:57258 (size: 3.0 KB, free: 794.9 MB)
16/03/21 17:19:57 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:19:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:57 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:19:57 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:19:57 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:19:57 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:19:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:19:57 INFO PythonRunner: Times: total = 121, boot = 120, init = 1, finish = 0
16/03/21 17:19:57 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:19:57 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:19:57 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:19:57 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 143 ms on localhost (1/2)
16/03/21 17:19:57 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:19:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', 'None']
16/03/21 17:19:57 INFO PythonRunner: Times: total = 165, boot = 165, init = 0, finish = 0
16/03/21 17:19:57 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1227 bytes result sent to driver
16/03/21 17:19:57 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 188 ms on localhost (2/2)
16/03/21 17:19:57 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:19:57 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.332 s
16/03/21 17:19:57 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.776622 s
16/03/21 17:19:58 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:19:58 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:19:58 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:58 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:19:58 INFO DAGScheduler: Missing parents: List()
16/03/21 17:19:58 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:19:58 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=833527480
16/03/21 17:19:58 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 794.9 MB)
16/03/21 17:19:58 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=833527480
16/03/21 17:19:58 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 794.9 MB)
16/03/21 17:19:58 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:57258 (size: 3.3 KB, free: 794.9 MB)
16/03/21 17:19:58 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:19:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:58 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:19:58 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:19:58 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:19:58 INFO PythonRunner: Times: total = 3, boot = -66, init = 69, finish = 0
16/03/21 17:19:58 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:19:58 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2257 bytes)
16/03/21 17:19:58 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 38 ms on localhost (1/2)
16/03/21 17:19:58 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:19:58 INFO PythonRunner: Times: total = 184, boot = 183, init = 1, finish = 0
16/03/21 17:19:58 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1296 bytes result sent to driver
16/03/21 17:19:58 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.236 s
16/03/21 17:19:58 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 204 ms on localhost (2/2)
16/03/21 17:19:58 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.260888 s
16/03/21 17:19:58 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:19:58 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:19:58 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:19:58 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:19:58 INFO MemoryStore: MemoryStore cleared
16/03/21 17:19:58 INFO BlockManager: BlockManager stopped
16/03/21 17:19:58 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:19:58 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:19:58 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:19:58 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:19:58 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:19:58 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:19:59 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:19:59 INFO SecurityManager: Changing view acls to: root
16/03/21 17:19:59 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:19:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:19:59 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:19:59 INFO Remoting: Starting remoting
16/03/21 17:19:59 INFO Utils: Successfully started service 'sparkDriver' on port 54550.
16/03/21 17:19:59 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:54550]
16/03/21 17:19:59 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:19:59 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:19:59 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2c962206-77b9-482c-a39d-df268789ffab
16/03/21 17:19:59 INFO MemoryStore: MemoryStore started with capacity 794.9 MB
16/03/21 17:19:59 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-d3b769e6-5cea-46db-a346-0c7315f9fa0b
16/03/21 17:19:59 INFO HttpServer: Starting HTTP Server
16/03/21 17:19:59 INFO Utils: Successfully started service 'HTTP file server' on port 37395.
16/03/21 17:19:59 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:19:59 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:19:59 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:19:59 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-fe852ab9-8fce-448a-9a53-1835f8439008/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:19:59 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560999496
16/03/21 17:19:59 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:19:59 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:19:59 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40278.
16/03/21 17:19:59 INFO NettyBlockTransferService: Server created on 40278
16/03/21 17:19:59 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:19:59 INFO BlockManagerMasterEndpoint: Registering block manager localhost:40278 with 794.9 MB RAM, BlockManagerId(driver, localhost, 40278)
16/03/21 17:19:59 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:19:59 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458560999504
16/03/21 17:19:59 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:19:59 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:59 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:19:59 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:19:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:19:59 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:19:59 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=833527480
16/03/21 17:19:59 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 794.9 MB)
16/03/21 17:19:59 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=833527480
16/03/21 17:19:59 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 794.9 MB)
16/03/21 17:19:59 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:40278 (size: 4.1 KB, free: 794.9 MB)
16/03/21 17:19:59 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:19:59 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:19:59 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:19:59 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:19:59 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:19:59 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:19:59 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458560999496
16/03/21 17:19:59 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-fe852ab9-8fce-448a-9a53-1835f8439008/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:19:59 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:19:59 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=833527480
16/03/21 17:19:59 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 794.9 MB)
16/03/21 17:19:59 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:40278 (size: 166.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: area
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: issue
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: planning
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: permission
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: economy
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: composition
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: agency
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): adding to parents: syn =  Synset('kilometer.n.01') ; keyword:  miles  in syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= [u'kilometer']
reduceFunction_Parents(): returns= ['None', u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'kilometer']
16/03/21 17:20:07 INFO PythonRunner: Times: total = 7778, boot = 468, init = 350, finish = 6960
16/03/21 17:20:07 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:20:07 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:20:07 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:20:07 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:20:07 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=833527480
16/03/21 17:20:07 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 794.9 MB)
16/03/21 17:20:07 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7867 ms on localhost (1/2)
16/03/21 17:20:07 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:40278 (size: 155.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: set
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: bend
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: giant
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: astatine
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: present
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: area
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): adding to parents: syn =  Synset('kilometer.n.01') ; keyword:  miles  in syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= [u'kilometer']
reduceFunction_Parents(): returns= ['None', u'kilometer']
16/03/21 17:20:07 INFO PythonRunner: Times: total = 275, boot = 181, init = 0, finish = 94
16/03/21 17:20:07 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:20:07 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 306 ms on localhost (2/2)
16/03/21 17:20:07 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:20:07 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.160 s
16/03/21 17:20:07 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:20:07 INFO DAGScheduler: running: Set()
16/03/21 17:20:07 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:20:07 INFO DAGScheduler: failed: Set()
16/03/21 17:20:07 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:20:07 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:20:07 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=833527480
16/03/21 17:20:07 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 794.9 MB)
16/03/21 17:20:07 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=833527480
16/03/21 17:20:07 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 794.9 MB)
16/03/21 17:20:07 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:40278 (size: 3.0 KB, free: 794.9 MB)
16/03/21 17:20:07 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:20:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:20:07 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:20:07 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:20:07 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:20:07 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:20:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:20:08 INFO PythonRunner: Times: total = 155, boot = 154, init = 0, finish = 1
16/03/21 17:20:08 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:20:08 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:20:08 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:20:08 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:20:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:20:08 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 175 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'kilometer', 'None', u'kilometer']
16/03/21 17:20:08 INFO PythonRunner: Times: total = 168, boot = 166, init = 0, finish = 2
16/03/21 17:20:08 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1259 bytes result sent to driver
16/03/21 17:20:08 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 179 ms on localhost (2/2)
16/03/21 17:20:08 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:20:08 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.342 s
16/03/21 17:20:08 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.558362 s
16/03/21 17:20:08 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:20:08 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:20:08 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:20:08 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:20:08 INFO DAGScheduler: Missing parents: List()
16/03/21 17:20:08 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:20:08 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=833527480
16/03/21 17:20:08 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 794.9 MB)
16/03/21 17:20:08 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=833527480
16/03/21 17:20:08 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 794.9 MB)
16/03/21 17:20:08 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:40278 (size: 3.3 KB, free: 794.9 MB)
16/03/21 17:20:08 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:20:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:20:08 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:20:08 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:20:08 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:20:08 INFO PythonRunner: Times: total = 105, boot = 105, init = 0, finish = 0
16/03/21 17:20:08 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:20:08 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2289 bytes)
16/03/21 17:20:08 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 124 ms on localhost (1/2)
16/03/21 17:20:08 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:20:08 INFO PythonRunner: Times: total = 153, boot = 153, init = 0, finish = 0
16/03/21 17:20:08 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1328 bytes result sent to driver
16/03/21 17:20:08 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.301 s
16/03/21 17:20:08 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.321945 s
16/03/21 17:20:08 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 181 ms on localhost (2/2)
16/03/21 17:20:08 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:20:08 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:20:08 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:20:08 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:20:08 INFO MemoryStore: MemoryStore cleared
16/03/21 17:20:08 INFO BlockManager: BlockManager stopped
16/03/21 17:20:08 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:20:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:20:08 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:20:08 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:20:08 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:20:08 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:20:09 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:20:09 INFO SecurityManager: Changing view acls to: root
16/03/21 17:20:09 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:20:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:20:09 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:20:09 INFO Remoting: Starting remoting
16/03/21 17:20:09 INFO Utils: Successfully started service 'sparkDriver' on port 33463.
16/03/21 17:20:09 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:20:09 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:20:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-39a3833d-345c-421f-9c96-744dd918df72
16/03/21 17:20:09 INFO MemoryStore: MemoryStore started with capacity 794.9 MB
16/03/21 17:20:09 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:33463]
16/03/21 17:20:09 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-6f7600ec-d078-46cf-82ec-b0cf6dd0a2ac
16/03/21 17:20:09 INFO HttpServer: Starting HTTP Server
16/03/21 17:20:09 INFO Utils: Successfully started service 'HTTP file server' on port 43788.
16/03/21 17:20:09 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:20:09 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:20:09 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:20:10 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-81517958-5f5d-42aa-9588-bf82a198ad21/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:20:10 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561010016
16/03/21 17:20:10 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:20:10 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:20:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34590.
16/03/21 17:20:10 INFO NettyBlockTransferService: Server created on 34590
16/03/21 17:20:10 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:20:10 INFO BlockManagerMasterEndpoint: Registering block manager localhost:34590 with 794.9 MB RAM, BlockManagerId(driver, localhost, 34590)
16/03/21 17:20:10 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:20:10 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561010028
16/03/21 17:20:10 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:20:10 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:20:10 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:20:10 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:20:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:20:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:20:10 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:20:10 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=833527480
16/03/21 17:20:10 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 794.9 MB)
16/03/21 17:20:10 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=833527480
16/03/21 17:20:10 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 794.9 MB)
16/03/21 17:20:10 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:34590 (size: 4.1 KB, free: 794.9 MB)
16/03/21 17:20:10 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:20:10 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:20:10 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:20:10 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:20:10 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:20:10 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:20:10 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561010016
16/03/21 17:20:10 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-81517958-5f5d-42aa-9588-bf82a198ad21/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:20:10 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:20:10 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=833527480
16/03/21 17:20:10 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 794.9 MB)
16/03/21 17:20:10 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:34590 (size: 166.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: area
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: issue
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: planning
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: permission
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: economy
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: composition
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: agency
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:20:18 INFO PythonRunner: Times: total = 7901, boot = 486, init = 355, finish = 7060
16/03/21 17:20:18 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:20:18 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:20:18 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:20:18 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8006 ms on localhost (1/2)
16/03/21 17:20:18 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:20:18 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=833527480
16/03/21 17:20:18 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 794.9 MB)
16/03/21 17:20:18 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:34590 (size: 155.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: set
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: bend
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: giant
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: astatine
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  unstable  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: present
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: area
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/21 17:20:18 INFO PythonRunner: Times: total = 215, boot = 119, init = 0, finish = 96
16/03/21 17:20:18 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:20:18 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.272 s
16/03/21 17:20:18 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:20:18 INFO DAGScheduler: running: Set()
16/03/21 17:20:18 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:20:18 INFO DAGScheduler: failed: Set()
16/03/21 17:20:18 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:20:18 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:20:18 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=833527480
16/03/21 17:20:18 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 794.9 MB)
16/03/21 17:20:18 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 282 ms on localhost (2/2)
16/03/21 17:20:18 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:20:18 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=833527480
16/03/21 17:20:18 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 794.9 MB)
16/03/21 17:20:18 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:34590 (size: 3.0 KB, free: 794.9 MB)
16/03/21 17:20:18 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:20:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:20:18 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:20:18 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:20:18 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:20:18 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:20:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:20:18 INFO PythonRunner: Times: total = 148, boot = 147, init = 1, finish = 0
16/03/21 17:20:18 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:20:18 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:20:18 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:20:18 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:20:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:20:18 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 169 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/03/21 17:20:18 INFO PythonRunner: Times: total = 169, boot = 168, init = 1, finish = 0
16/03/21 17:20:18 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1242 bytes result sent to driver
16/03/21 17:20:18 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 189 ms on localhost (2/2)
16/03/21 17:20:18 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:20:18 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.343 s
16/03/21 17:20:18 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.681439 s
16/03/21 17:20:19 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:20:19 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:20:19 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:20:19 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:20:19 INFO DAGScheduler: Missing parents: List()
16/03/21 17:20:19 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:20:19 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=833527480
16/03/21 17:20:19 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 794.9 MB)
16/03/21 17:20:19 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=833527480
16/03/21 17:20:19 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 794.9 MB)
16/03/21 17:20:19 INFO ContextCleaner: Cleaned accumulator 70
16/03/21 17:20:19 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:34590 (size: 3.3 KB, free: 794.9 MB)
16/03/21 17:20:19 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:20:19 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:20:19 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:20:19 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:20:19 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:20:19 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:34590 in memory (size: 3.0 KB, free: 794.9 MB)
16/03/21 17:20:19 INFO PythonRunner: Times: total = 19, boot = -108, init = 126, finish = 1
16/03/21 17:20:19 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:20:19 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2272 bytes)
16/03/21 17:20:19 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:20:19 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 46 ms on localhost (1/2)
16/03/21 17:20:19 INFO ContextCleaner: Cleaned accumulator 71
16/03/21 17:20:19 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:34590 in memory (size: 4.1 KB, free: 794.9 MB)
16/03/21 17:20:19 INFO PythonRunner: Times: total = 260, boot = 260, init = 0, finish = 0
16/03/21 17:20:19 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1311 bytes result sent to driver
16/03/21 17:20:19 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 286 ms on localhost (2/2)
16/03/21 17:20:19 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:20:19 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.319 s
16/03/21 17:20:19 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.456120 s
16/03/21 17:20:19 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:20:19 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:20:19 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:20:19 INFO MemoryStore: MemoryStore cleared
16/03/21 17:20:19 INFO BlockManager: BlockManager stopped
16/03/21 17:20:19 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:20:19 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:20:19 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:20:19 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:20:19 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:20:19 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:20:20 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:20:20 INFO SecurityManager: Changing view acls to: root
16/03/21 17:20:20 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:20:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:20:20 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:20:20 INFO Remoting: Starting remoting
16/03/21 17:20:20 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:38951]
16/03/21 17:20:20 INFO Utils: Successfully started service 'sparkDriver' on port 38951.
16/03/21 17:20:20 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:20:20 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:20:20 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a8f5fd75-4e3f-44ed-9eba-e4faf86b9ab2
16/03/21 17:20:20 INFO MemoryStore: MemoryStore started with capacity 794.9 MB
16/03/21 17:20:20 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-2ec9b256-f982-4ea4-bde0-fbbb2ad3cf16
16/03/21 17:20:20 INFO HttpServer: Starting HTTP Server
16/03/21 17:20:20 INFO Utils: Successfully started service 'HTTP file server' on port 47271.
16/03/21 17:20:20 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:20:20 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:20:20 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:20:20 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-f6d81ee9-bd08-450e-802f-5b423ed5c029/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:20:20 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561020676
16/03/21 17:20:20 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:20:20 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:20:20 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46472.
16/03/21 17:20:20 INFO NettyBlockTransferService: Server created on 46472
16/03/21 17:20:20 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:20:20 INFO BlockManagerMasterEndpoint: Registering block manager localhost:46472 with 794.9 MB RAM, BlockManagerId(driver, localhost, 46472)
16/03/21 17:20:20 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:20:20 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561020690
16/03/21 17:20:20 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:20:20 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:20:20 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:20:20 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:20:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:20:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:20:20 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:20:20 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=833527480
16/03/21 17:20:20 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 794.9 MB)
16/03/21 17:20:20 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=833527480
16/03/21 17:20:20 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 794.9 MB)
16/03/21 17:20:20 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:46472 (size: 4.1 KB, free: 794.9 MB)
16/03/21 17:20:20 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:20:20 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:20:20 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:20:20 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:20:20 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:20:20 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:20:20 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561020676
16/03/21 17:20:20 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-f6d81ee9-bd08-450e-802f-5b423ed5c029/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:20:20 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:20:20 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=833527480
16/03/21 17:20:20 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 794.9 MB)
16/03/21 17:20:20 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:46472 (size: 166.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: area
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: issue
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: planning
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: permission
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: economy
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: composition
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: agency
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:20:28 INFO PythonRunner: Times: total = 7751, boot = 445, init = 345, finish = 6961
16/03/21 17:20:28 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:20:28 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:20:28 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:20:28 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:20:28 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=833527480
16/03/21 17:20:28 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 794.9 MB)
16/03/21 17:20:28 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7848 ms on localhost (1/2)
16/03/21 17:20:28 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:46472 (size: 155.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: set
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: bend
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: giant
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: astatine
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: present
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  including  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: area
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/21 17:20:28 INFO PythonRunner: Times: total = 250, boot = 156, init = 0, finish = 94
16/03/21 17:20:28 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:20:28 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 290 ms on localhost (2/2)
16/03/21 17:20:28 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:20:28 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.115 s
16/03/21 17:20:28 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:20:28 INFO DAGScheduler: running: Set()
16/03/21 17:20:28 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:20:28 INFO DAGScheduler: failed: Set()
16/03/21 17:20:28 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:20:28 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:20:28 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=833527480
16/03/21 17:20:28 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 794.9 MB)
16/03/21 17:20:28 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=833527480
16/03/21 17:20:28 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 794.9 MB)
16/03/21 17:20:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:46472 (size: 3.0 KB, free: 794.9 MB)
16/03/21 17:20:28 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:20:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:20:28 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:20:28 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:20:28 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:20:28 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:20:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:20:29 INFO PythonRunner: Times: total = 131, boot = 130, init = 1, finish = 0
16/03/21 17:20:29 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:20:29 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:20:29 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:20:29 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:20:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:20:29 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 161 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'present']
16/03/21 17:20:29 INFO PythonRunner: Times: total = 158, boot = 157, init = 0, finish = 1
16/03/21 17:20:29 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/21 17:20:29 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 180 ms on localhost (2/2)
16/03/21 17:20:29 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.326 s
16/03/21 17:20:29 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.489178 s
16/03/21 17:20:29 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:20:29 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:20:29 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:20:29 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:20:29 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:20:29 INFO DAGScheduler: Missing parents: List()
16/03/21 17:20:29 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:20:29 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=833527480
16/03/21 17:20:29 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 794.9 MB)
16/03/21 17:20:29 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=833527480
16/03/21 17:20:29 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 794.9 MB)
16/03/21 17:20:29 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:46472 (size: 3.3 KB, free: 794.9 MB)
16/03/21 17:20:29 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:20:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:20:29 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:20:29 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:20:29 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:20:29 INFO PythonRunner: Times: total = 130, boot = 129, init = 1, finish = 0
16/03/21 17:20:29 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:20:29 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/21 17:20:29 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 152 ms on localhost (1/2)
16/03/21 17:20:29 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:20:29 INFO PythonRunner: Times: total = 183, boot = 183, init = 0, finish = 0
16/03/21 17:20:29 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1310 bytes result sent to driver
16/03/21 17:20:29 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.377 s
16/03/21 17:20:29 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.395368 s
16/03/21 17:20:29 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 230 ms on localhost (2/2)
16/03/21 17:20:29 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:20:29 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:20:29 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:20:29 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:20:29 INFO MemoryStore: MemoryStore cleared
16/03/21 17:20:29 INFO BlockManager: BlockManager stopped
16/03/21 17:20:29 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:20:29 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:20:29 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:20:29 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:20:29 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:20:29 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:20:30 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:20:30 INFO SecurityManager: Changing view acls to: root
16/03/21 17:20:30 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:20:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:20:30 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:20:30 INFO Remoting: Starting remoting
16/03/21 17:20:30 INFO Utils: Successfully started service 'sparkDriver' on port 32942.
16/03/21 17:20:30 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:32942]
16/03/21 17:20:30 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:20:30 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:20:30 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e323804a-c0c6-46dd-a033-3a255e1101a0
16/03/21 17:20:30 INFO MemoryStore: MemoryStore started with capacity 794.9 MB
16/03/21 17:20:30 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-0b223d77-87b4-42f7-9511-4212b3ab9b84
16/03/21 17:20:30 INFO HttpServer: Starting HTTP Server
16/03/21 17:20:30 INFO Utils: Successfully started service 'HTTP file server' on port 33651.
16/03/21 17:20:30 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:20:31 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:20:31 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:20:31 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-efd4fb60-a9c0-4f92-8dce-a53d53bb8765/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:20:31 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561031028
16/03/21 17:20:31 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:20:31 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:20:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 48955.
16/03/21 17:20:31 INFO NettyBlockTransferService: Server created on 48955
16/03/21 17:20:31 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:20:31 INFO BlockManagerMasterEndpoint: Registering block manager localhost:48955 with 794.9 MB RAM, BlockManagerId(driver, localhost, 48955)
16/03/21 17:20:31 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:20:31 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561031037
16/03/21 17:20:31 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:20:31 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:20:31 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:20:31 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:20:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:20:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:20:31 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:20:31 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=833527480
16/03/21 17:20:31 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 794.9 MB)
16/03/21 17:20:31 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=833527480
16/03/21 17:20:31 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 794.9 MB)
16/03/21 17:20:31 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:48955 (size: 4.1 KB, free: 794.9 MB)
16/03/21 17:20:31 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:20:31 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:20:31 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:20:31 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:20:31 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:20:31 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:20:31 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561031028
16/03/21 17:20:31 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-efd4fb60-a9c0-4f92-8dce-a53d53bb8765/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:20:31 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:20:31 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=833527480
16/03/21 17:20:31 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 794.9 MB)
16/03/21 17:20:31 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:48955 (size: 166.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: area
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  people  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: issue
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: planning
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: permission
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: economy
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: composition
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: agency
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/21 17:20:39 INFO PythonRunner: Times: total = 7713, boot = 450, init = 369, finish = 6894
16/03/21 17:20:39 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:20:39 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:20:39 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7826 ms on localhost (1/2)
16/03/21 17:20:39 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:20:39 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:20:39 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=833527480
16/03/21 17:20:39 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 794.9 MB)
16/03/21 17:20:39 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:48955 (size: 155.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: set
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: bend
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: giant
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: astatine
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: present
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: area
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  people  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/21 17:20:39 INFO PythonRunner: Times: total = 272, boot = 175, init = 0, finish = 97
16/03/21 17:20:39 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:20:39 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.157 s
16/03/21 17:20:39 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:20:39 INFO DAGScheduler: running: Set()
16/03/21 17:20:39 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:20:39 INFO DAGScheduler: failed: Set()
16/03/21 17:20:39 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:20:39 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:20:39 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 326 ms on localhost (2/2)
16/03/21 17:20:39 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=833527480
16/03/21 17:20:39 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:20:39 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 794.9 MB)
16/03/21 17:20:39 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=833527480
16/03/21 17:20:39 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 794.9 MB)
16/03/21 17:20:39 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:48955 (size: 3.0 KB, free: 794.9 MB)
16/03/21 17:20:39 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:20:39 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:20:39 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:20:39 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:20:39 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:20:39 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:20:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:20:39 INFO PythonRunner: Times: total = 149, boot = 149, init = 0, finish = 0
16/03/21 17:20:39 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:20:39 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:20:39 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:20:39 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:20:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:20:39 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 171 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'area', 'None', u'area']
16/03/21 17:20:39 INFO PythonRunner: Times: total = 162, boot = 161, init = 0, finish = 1
16/03/21 17:20:39 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/21 17:20:39 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.337 s
16/03/21 17:20:39 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.553965 s
16/03/21 17:20:39 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 177 ms on localhost (2/2)
16/03/21 17:20:39 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:20:39 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:20:39 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:20:39 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:20:39 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:20:39 INFO DAGScheduler: Missing parents: List()
16/03/21 17:20:39 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:20:39 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=833527480
16/03/21 17:20:39 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 794.9 MB)
16/03/21 17:20:39 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=833527480
16/03/21 17:20:39 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 794.9 MB)
16/03/21 17:20:39 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:48955 (size: 3.3 KB, free: 794.9 MB)
16/03/21 17:20:39 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:20:39 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:20:39 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:20:39 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:20:39 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:20:39 INFO PythonRunner: Times: total = 47, boot = 46, init = 1, finish = 0
16/03/21 17:20:40 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:20:40 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/21 17:20:40 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:20:40 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 66 ms on localhost (1/2)
16/03/21 17:20:40 INFO PythonRunner: Times: total = 185, boot = 185, init = 0, finish = 0
16/03/21 17:20:40 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1307 bytes result sent to driver
16/03/21 17:20:40 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.252 s
16/03/21 17:20:40 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.292402 s
16/03/21 17:20:40 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 202 ms on localhost (2/2)
16/03/21 17:20:40 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:20:40 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:20:40 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:20:40 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:20:40 INFO MemoryStore: MemoryStore cleared
16/03/21 17:20:40 INFO BlockManager: BlockManager stopped
16/03/21 17:20:40 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:20:40 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:20:40 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:20:40 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:20:40 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:20:40 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:20:41 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:20:41 INFO SecurityManager: Changing view acls to: root
16/03/21 17:20:41 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:20:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:20:41 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:20:41 INFO Remoting: Starting remoting
16/03/21 17:20:41 INFO Utils: Successfully started service 'sparkDriver' on port 54472.
16/03/21 17:20:41 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:54472]
16/03/21 17:20:41 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:20:41 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:20:41 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-efd6e550-d05a-4893-b89a-bc8a105c4c84
16/03/21 17:20:41 INFO MemoryStore: MemoryStore started with capacity 794.9 MB
16/03/21 17:20:41 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-b11585b4-10c0-4c3e-8ef6-981243af9f54
16/03/21 17:20:41 INFO HttpServer: Starting HTTP Server
16/03/21 17:20:41 INFO Utils: Successfully started service 'HTTP file server' on port 40922.
16/03/21 17:20:41 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:20:41 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:20:41 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:20:41 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-7176d194-5f26-4b1d-aecc-1ee97c1ac17f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:20:41 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561041891
16/03/21 17:20:41 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:20:41 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:20:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57857.
16/03/21 17:20:41 INFO NettyBlockTransferService: Server created on 57857
16/03/21 17:20:41 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:20:41 INFO BlockManagerMasterEndpoint: Registering block manager localhost:57857 with 794.9 MB RAM, BlockManagerId(driver, localhost, 57857)
16/03/21 17:20:41 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:20:41 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561041902
16/03/21 17:20:42 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:20:42 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:20:42 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:20:42 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:20:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:20:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:20:42 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:20:42 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=833527480
16/03/21 17:20:42 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 794.9 MB)
16/03/21 17:20:42 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=833527480
16/03/21 17:20:42 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 794.9 MB)
16/03/21 17:20:42 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:57857 (size: 4.1 KB, free: 794.9 MB)
16/03/21 17:20:42 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:20:42 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:20:42 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:20:42 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:20:42 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:20:42 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:20:42 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561041891
16/03/21 17:20:42 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-7176d194-5f26-4b1d-aecc-1ee97c1ac17f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:20:42 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:20:42 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=833527480
16/03/21 17:20:42 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 794.9 MB)
16/03/21 17:20:42 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:57857 (size: 166.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: area
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: issue
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: planning
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: permission
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: economy
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: composition
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: agency
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:20:49 INFO PythonRunner: Times: total = 7838, boot = 467, init = 351, finish = 7020
16/03/21 17:20:49 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:20:49 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:20:49 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:20:49 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:20:49 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=833527480
16/03/21 17:20:49 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 794.9 MB)
16/03/21 17:20:49 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7931 ms on localhost (1/2)
16/03/21 17:20:49 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:57857 (size: 155.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: set
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: bend
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: giant
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: astatine
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  series  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: present
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: area
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/21 17:20:50 INFO PythonRunner: Times: total = 265, boot = 170, init = 0, finish = 95
16/03/21 17:20:50 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:20:50 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 302 ms on localhost (2/2)
16/03/21 17:20:50 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:20:50 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.220 s
16/03/21 17:20:50 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:20:50 INFO DAGScheduler: running: Set()
16/03/21 17:20:50 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:20:50 INFO DAGScheduler: failed: Set()
16/03/21 17:20:50 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:20:50 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:20:50 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=833527480
16/03/21 17:20:50 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 794.9 MB)
16/03/21 17:20:50 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=833527480
16/03/21 17:20:50 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 794.9 MB)
16/03/21 17:20:50 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:57857 (size: 3.0 KB, free: 794.9 MB)
16/03/21 17:20:50 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:20:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:20:50 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:20:50 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:20:50 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:20:50 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:20:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:20:50 INFO PythonRunner: Times: total = 147, boot = 146, init = 0, finish = 1
16/03/21 17:20:50 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:20:50 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:20:50 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:20:50 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:20:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:20:50 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 167 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/03/21 17:20:50 INFO PythonRunner: Times: total = 165, boot = 164, init = 0, finish = 1
16/03/21 17:20:50 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1242 bytes result sent to driver
16/03/21 17:20:50 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.348 s
16/03/21 17:20:50 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.606523 s
16/03/21 17:20:50 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 195 ms on localhost (2/2)
16/03/21 17:20:50 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:20:50 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:20:50 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:20:50 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:20:50 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:20:50 INFO DAGScheduler: Missing parents: List()
16/03/21 17:20:50 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:20:50 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=833527480
16/03/21 17:20:50 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 794.9 MB)
16/03/21 17:20:50 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=833527480
16/03/21 17:20:50 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 794.9 MB)
16/03/21 17:20:50 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:57857 (size: 3.3 KB, free: 794.9 MB)
16/03/21 17:20:50 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:20:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:20:50 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:20:50 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:20:50 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:20:50 INFO PythonRunner: Times: total = 3, boot = -6, init = 9, finish = 0
16/03/21 17:20:50 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:20:50 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2272 bytes)
16/03/21 17:20:50 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:20:50 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 39 ms on localhost (1/2)
16/03/21 17:20:51 INFO PythonRunner: Times: total = 154, boot = 154, init = 0, finish = 0
16/03/21 17:20:51 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1311 bytes result sent to driver
16/03/21 17:20:51 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 180 ms on localhost (2/2)
16/03/21 17:20:51 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:20:51 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.210 s
16/03/21 17:20:51 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.236948 s
16/03/21 17:20:51 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:20:51 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:20:51 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:20:51 INFO MemoryStore: MemoryStore cleared
16/03/21 17:20:51 INFO BlockManager: BlockManager stopped
16/03/21 17:20:51 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:20:51 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:20:51 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:20:51 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:20:51 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:20:51 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:20:52 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:20:52 INFO SecurityManager: Changing view acls to: root
16/03/21 17:20:52 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:20:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:20:52 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:20:52 INFO Remoting: Starting remoting
16/03/21 17:20:52 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:53406]
16/03/21 17:20:52 INFO Utils: Successfully started service 'sparkDriver' on port 53406.
16/03/21 17:20:52 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:20:52 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:20:52 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3ec493db-0ae3-47bf-a4b6-48f18f86dc0e
16/03/21 17:20:52 INFO MemoryStore: MemoryStore started with capacity 794.9 MB
16/03/21 17:20:52 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-cd27d54d-9674-43fa-852a-710963cee292
16/03/21 17:20:52 INFO HttpServer: Starting HTTP Server
16/03/21 17:20:52 INFO Utils: Successfully started service 'HTTP file server' on port 44012.
16/03/21 17:20:52 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:20:52 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:20:52 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:20:52 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-26441411-a14f-4b43-baa2-6672216f824f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:20:52 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561052244
16/03/21 17:20:52 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:20:52 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:20:52 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49986.
16/03/21 17:20:52 INFO NettyBlockTransferService: Server created on 49986
16/03/21 17:20:52 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:20:52 INFO BlockManagerMasterEndpoint: Registering block manager localhost:49986 with 794.9 MB RAM, BlockManagerId(driver, localhost, 49986)
16/03/21 17:20:52 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:20:52 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561052255
16/03/21 17:20:52 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:20:52 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:20:52 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:20:52 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:20:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:20:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:20:52 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:20:52 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=833527480
16/03/21 17:20:52 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 794.9 MB)
16/03/21 17:20:52 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=833527480
16/03/21 17:20:52 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 794.9 MB)
16/03/21 17:20:52 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:49986 (size: 4.1 KB, free: 794.9 MB)
16/03/21 17:20:52 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:20:52 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:20:52 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:20:52 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:20:52 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:20:52 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:20:52 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561052244
16/03/21 17:20:52 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-26441411-a14f-4b43-baa2-6672216f824f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:20:52 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:20:52 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=833527480
16/03/21 17:20:52 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 794.9 MB)
16/03/21 17:20:52 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:49986 (size: 166.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: area
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: issue
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: planning
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: permission
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: economy
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: composition
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: agency
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:21:00 INFO PythonRunner: Times: total = 7718, boot = 444, init = 350, finish = 6924
16/03/21 17:21:00 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:21:00 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:21:00 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:21:00 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7817 ms on localhost (1/2)
16/03/21 17:21:00 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:21:00 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=833527480
16/03/21 17:21:00 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 794.9 MB)
16/03/21 17:21:00 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:49986 (size: 155.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: set
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: bend
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: giant
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: astatine
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: present
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  Christianity  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: area
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
16/03/21 17:21:00 INFO PythonRunner: Times: total = 235, boot = 141, init = 0, finish = 94
16/03/21 17:21:00 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:21:00 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 278 ms on localhost (2/2)
16/03/21 17:21:00 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:21:00 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.088 s
16/03/21 17:21:00 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:21:00 INFO DAGScheduler: running: Set()
16/03/21 17:21:00 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:21:00 INFO DAGScheduler: failed: Set()
16/03/21 17:21:00 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:21:00 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:21:00 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=833527480
16/03/21 17:21:00 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 794.9 MB)
16/03/21 17:21:00 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=833527480
16/03/21 17:21:00 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 794.9 MB)
16/03/21 17:21:00 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:49986 (size: 3.0 KB, free: 794.9 MB)
16/03/21 17:21:00 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:21:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:00 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:21:00 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:21:00 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:21:00 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:21:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:21:00 INFO PythonRunner: Times: total = 154, boot = 153, init = 1, finish = 0
16/03/21 17:21:00 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:21:00 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:21:00 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:21:00 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:21:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:21:00 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 183 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'metropolitan']
16/03/21 17:21:00 INFO PythonRunner: Times: total = 174, boot = 173, init = 1, finish = 0
16/03/21 17:21:00 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1246 bytes result sent to driver
16/03/21 17:21:00 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.376 s
16/03/21 17:21:00 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.501385 s
16/03/21 17:21:00 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 203 ms on localhost (2/2)
16/03/21 17:21:00 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:21:01 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:21:01 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:21:01 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:01 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:21:01 INFO DAGScheduler: Missing parents: List()
16/03/21 17:21:01 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:21:01 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=833527480
16/03/21 17:21:01 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 794.9 MB)
16/03/21 17:21:01 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=833527480
16/03/21 17:21:01 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 794.9 MB)
16/03/21 17:21:01 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:49986 (size: 3.3 KB, free: 794.9 MB)
16/03/21 17:21:01 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:21:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:01 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:21:01 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:21:01 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:21:01 INFO PythonRunner: Times: total = 63, boot = 62, init = 1, finish = 0
16/03/21 17:21:01 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:21:01 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2276 bytes)
16/03/21 17:21:01 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:21:01 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 87 ms on localhost (1/2)
16/03/21 17:21:01 INFO PythonRunner: Times: total = 172, boot = 171, init = 0, finish = 1
16/03/21 17:21:01 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1315 bytes result sent to driver
16/03/21 17:21:01 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 187 ms on localhost (2/2)
16/03/21 17:21:01 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:21:01 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.257 s
16/03/21 17:21:01 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.293408 s
16/03/21 17:21:01 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:21:01 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:21:01 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:21:01 INFO MemoryStore: MemoryStore cleared
16/03/21 17:21:01 INFO BlockManager: BlockManager stopped
16/03/21 17:21:01 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:21:01 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:21:01 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:21:01 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:21:01 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:21:01 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:21:02 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:21:02 INFO SecurityManager: Changing view acls to: root
16/03/21 17:21:02 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:21:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:21:02 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:21:02 INFO Remoting: Starting remoting
16/03/21 17:21:02 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:34620]
16/03/21 17:21:02 INFO Utils: Successfully started service 'sparkDriver' on port 34620.
16/03/21 17:21:02 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:21:02 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:21:02 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1ce15a8c-1217-4d5d-9945-17de6cec5541
16/03/21 17:21:02 INFO MemoryStore: MemoryStore started with capacity 794.9 MB
16/03/21 17:21:02 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-6faf0f53-c761-4eee-8e35-6c5539dac894
16/03/21 17:21:02 INFO HttpServer: Starting HTTP Server
16/03/21 17:21:02 INFO Utils: Successfully started service 'HTTP file server' on port 37264.
16/03/21 17:21:02 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:21:02 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:21:02 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:21:02 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-b0dce4c4-4503-4c01-ae5d-8a2ae40ca1cf/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:21:02 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561062517
16/03/21 17:21:02 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:21:02 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:21:02 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 48972.
16/03/21 17:21:02 INFO NettyBlockTransferService: Server created on 48972
16/03/21 17:21:02 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:21:02 INFO BlockManagerMasterEndpoint: Registering block manager localhost:48972 with 794.9 MB RAM, BlockManagerId(driver, localhost, 48972)
16/03/21 17:21:02 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:21:02 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561062529
16/03/21 17:21:02 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:21:02 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:02 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:21:02 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:21:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:21:02 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:21:02 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=833527480
16/03/21 17:21:02 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 794.9 MB)
16/03/21 17:21:02 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=833527480
16/03/21 17:21:02 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 794.9 MB)
16/03/21 17:21:02 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:48972 (size: 4.1 KB, free: 794.9 MB)
16/03/21 17:21:02 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:21:02 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:02 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:21:02 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:21:02 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:21:02 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:21:02 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561062517
16/03/21 17:21:02 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-b0dce4c4-4503-4c01-ae5d-8a2ae40ca1cf/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:21:02 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:21:02 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=833527480
16/03/21 17:21:02 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 794.9 MB)
16/03/21 17:21:02 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:48972 (size: 166.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: area
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  culture  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: issue
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: planning
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: permission
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: economy
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: composition
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: agency
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/21 17:21:10 INFO PythonRunner: Times: total = 7871, boot = 462, init = 363, finish = 7046
16/03/21 17:21:10 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:21:10 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:21:10 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:21:10 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:21:10 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=833527480
16/03/21 17:21:10 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 794.9 MB)
16/03/21 17:21:10 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:48972 (size: 155.0 B, free: 794.9 MB)
16/03/21 17:21:10 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7960 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: set
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: bend
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: giant
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: astatine
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: present
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: area
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  culture  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/21 17:21:10 INFO PythonRunner: Times: total = 272, boot = 156, init = 1, finish = 115
16/03/21 17:21:10 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:21:10 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 308 ms on localhost (2/2)
16/03/21 17:21:10 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:21:10 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.243 s
16/03/21 17:21:10 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:21:10 INFO DAGScheduler: running: Set()
16/03/21 17:21:10 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:21:10 INFO DAGScheduler: failed: Set()
16/03/21 17:21:10 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:21:10 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:21:10 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=833527480
16/03/21 17:21:10 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 794.9 MB)
16/03/21 17:21:10 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=833527480
16/03/21 17:21:10 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 794.9 MB)
16/03/21 17:21:10 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:48972 (size: 3.0 KB, free: 794.9 MB)
16/03/21 17:21:10 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:21:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:10 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:21:10 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:21:10 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:21:10 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:21:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:21:11 INFO PythonRunner: Times: total = 157, boot = 156, init = 0, finish = 1
16/03/21 17:21:11 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:21:11 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:21:11 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:21:11 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:21:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:21:11 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 178 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'area', 'None', u'area']
16/03/21 17:21:11 INFO PythonRunner: Times: total = 160, boot = 159, init = 0, finish = 1
16/03/21 17:21:11 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/21 17:21:11 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.335 s
16/03/21 17:21:11 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.623811 s
16/03/21 17:21:11 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 173 ms on localhost (2/2)
16/03/21 17:21:11 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:21:11 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:21:11 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:21:11 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:11 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:21:11 INFO DAGScheduler: Missing parents: List()
16/03/21 17:21:11 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:21:11 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=833527480
16/03/21 17:21:11 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 794.9 MB)
16/03/21 17:21:11 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=833527480
16/03/21 17:21:11 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 794.9 MB)
16/03/21 17:21:11 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:48972 (size: 3.3 KB, free: 794.9 MB)
16/03/21 17:21:11 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:21:11 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:11 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:21:11 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:21:11 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:21:11 INFO PythonRunner: Times: total = 133, boot = 133, init = 0, finish = 0
16/03/21 17:21:11 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:21:11 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/21 17:21:11 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:21:11 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 153 ms on localhost (1/2)
16/03/21 17:21:11 INFO PythonRunner: Times: total = 158, boot = 157, init = 1, finish = 0
16/03/21 17:21:11 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1307 bytes result sent to driver
16/03/21 17:21:11 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.323 s
16/03/21 17:21:11 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.339788 s
16/03/21 17:21:11 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 177 ms on localhost (2/2)
16/03/21 17:21:11 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:21:11 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:21:11 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:21:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:21:11 INFO MemoryStore: MemoryStore cleared
16/03/21 17:21:11 INFO BlockManager: BlockManager stopped
16/03/21 17:21:11 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:21:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:21:11 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:21:11 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:21:11 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:21:11 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:21:12 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:21:12 INFO SecurityManager: Changing view acls to: root
16/03/21 17:21:12 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:21:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:21:12 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:21:12 INFO Remoting: Starting remoting
16/03/21 17:21:12 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:32914]
16/03/21 17:21:12 INFO Utils: Successfully started service 'sparkDriver' on port 32914.
16/03/21 17:21:12 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:21:12 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:21:12 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-414996dc-59f7-4bd0-9de7-6ff15779b5d1
16/03/21 17:21:12 INFO MemoryStore: MemoryStore started with capacity 794.9 MB
16/03/21 17:21:12 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-2285aa7a-22cc-42c2-83bd-6bab0085dbdb
16/03/21 17:21:12 INFO HttpServer: Starting HTTP Server
16/03/21 17:21:12 INFO Utils: Successfully started service 'HTTP file server' on port 46076.
16/03/21 17:21:12 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:21:12 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:21:12 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:21:12 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-91edca3b-e76b-472e-96c7-bf9e13cc9eb4/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:21:12 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561072882
16/03/21 17:21:12 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:21:12 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:21:12 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43977.
16/03/21 17:21:12 INFO NettyBlockTransferService: Server created on 43977
16/03/21 17:21:12 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:21:12 INFO BlockManagerMasterEndpoint: Registering block manager localhost:43977 with 794.9 MB RAM, BlockManagerId(driver, localhost, 43977)
16/03/21 17:21:12 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:21:12 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561072899
16/03/21 17:21:13 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:21:13 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:13 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:21:13 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:21:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:21:13 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:21:13 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=833527480
16/03/21 17:21:13 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 794.9 MB)
16/03/21 17:21:13 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=833527480
16/03/21 17:21:13 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 794.9 MB)
16/03/21 17:21:13 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:43977 (size: 4.1 KB, free: 794.9 MB)
16/03/21 17:21:13 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:21:13 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:13 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:21:13 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:21:13 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:21:13 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:21:13 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561072882
16/03/21 17:21:13 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-91edca3b-e76b-472e-96c7-bf9e13cc9eb4/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:21:13 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:21:13 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=833527480
16/03/21 17:21:13 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 794.9 MB)
16/03/21 17:21:13 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:43977 (size: 166.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: area
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: issue
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: planning
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: permission
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: economy
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: composition
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: agency
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): adding to parents: syn =  Synset('kilometer.n.01') ; keyword:  meters  in syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= [u'kilometer']
reduceFunction_Parents(): returns= ['None', u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'kilometer']
16/03/21 17:21:20 INFO PythonRunner: Times: total = 7815, boot = 471, init = 347, finish = 6997
16/03/21 17:21:20 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:21:20 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:21:20 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:21:20 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:21:20 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7908 ms on localhost (1/2)
16/03/21 17:21:20 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=833527480
16/03/21 17:21:20 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 794.9 MB)
16/03/21 17:21:20 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:43977 (size: 155.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: set
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: bend
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: giant
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: astatine
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: present
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: area
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): adding to parents: syn =  Synset('kilometer.n.01') ; keyword:  meters  in syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= [u'kilometer']
reduceFunction_Parents(): returns= ['None', u'kilometer']
16/03/21 17:21:21 INFO PythonRunner: Times: total = 249, boot = 130, init = 1, finish = 118
16/03/21 17:21:21 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:21:21 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 294 ms on localhost (2/2)
16/03/21 17:21:21 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:21:21 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.188 s
16/03/21 17:21:21 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:21:21 INFO DAGScheduler: running: Set()
16/03/21 17:21:21 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:21:21 INFO DAGScheduler: failed: Set()
16/03/21 17:21:21 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:21:21 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:21:21 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=833527480
16/03/21 17:21:21 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 794.9 MB)
16/03/21 17:21:21 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=833527480
16/03/21 17:21:21 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 794.9 MB)
16/03/21 17:21:21 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:43977 (size: 3.0 KB, free: 794.9 MB)
16/03/21 17:21:21 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:21:21 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:21 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:21:21 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:21:21 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:21:21 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:21:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:21:21 INFO PythonRunner: Times: total = 152, boot = 151, init = 1, finish = 0
16/03/21 17:21:21 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:21:21 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:21:21 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:21:21 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:21:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:21:21 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 173 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'kilometer', 'None', u'kilometer']
16/03/21 17:21:21 INFO PythonRunner: Times: total = 156, boot = 155, init = 0, finish = 1
16/03/21 17:21:21 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1259 bytes result sent to driver
16/03/21 17:21:21 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 171 ms on localhost (2/2)
16/03/21 17:21:21 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:21:21 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.337 s
16/03/21 17:21:21 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.559677 s
16/03/21 17:21:21 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:21:21 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:21:21 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:21 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:21:21 INFO DAGScheduler: Missing parents: List()
16/03/21 17:21:21 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:21:21 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=833527480
16/03/21 17:21:21 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 794.9 MB)
16/03/21 17:21:21 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=833527480
16/03/21 17:21:21 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 794.9 MB)
16/03/21 17:21:21 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:43977 (size: 3.3 KB, free: 794.9 MB)
16/03/21 17:21:21 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:21:21 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:21 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:21:21 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:21:21 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:21:21 INFO PythonRunner: Times: total = 17, boot = 16, init = 1, finish = 0
16/03/21 17:21:21 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:21:21 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2289 bytes)
16/03/21 17:21:21 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 38 ms on localhost (1/2)
16/03/21 17:21:21 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:21:21 INFO PythonRunner: Times: total = 163, boot = 162, init = 1, finish = 0
16/03/21 17:21:21 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1328 bytes result sent to driver
16/03/21 17:21:21 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.220 s
16/03/21 17:21:21 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.254448 s
16/03/21 17:21:21 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 189 ms on localhost (2/2)
16/03/21 17:21:21 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:21:22 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:21:22 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:21:22 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:21:22 INFO MemoryStore: MemoryStore cleared
16/03/21 17:21:22 INFO BlockManager: BlockManager stopped
16/03/21 17:21:22 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:21:22 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:21:22 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:21:22 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:21:22 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:21:23 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:21:23 INFO SecurityManager: Changing view acls to: root
16/03/21 17:21:23 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:21:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:21:23 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:21:23 INFO Remoting: Starting remoting
16/03/21 17:21:23 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:39533]
16/03/21 17:21:23 INFO Utils: Successfully started service 'sparkDriver' on port 39533.
16/03/21 17:21:23 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:21:23 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:21:23 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0918d11e-589e-41aa-a88e-81fdee4acce8
16/03/21 17:21:23 INFO MemoryStore: MemoryStore started with capacity 794.9 MB
16/03/21 17:21:23 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-059181c1-3bba-4723-a290-b8d57bd2b4e7
16/03/21 17:21:23 INFO HttpServer: Starting HTTP Server
16/03/21 17:21:23 INFO Utils: Successfully started service 'HTTP file server' on port 60225.
16/03/21 17:21:23 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:21:23 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:21:23 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:21:23 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-8e1ffb37-ffeb-454f-8856-335ec7fe8461/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:21:23 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561083203
16/03/21 17:21:23 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:21:23 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:21:23 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38381.
16/03/21 17:21:23 INFO NettyBlockTransferService: Server created on 38381
16/03/21 17:21:23 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:21:23 INFO BlockManagerMasterEndpoint: Registering block manager localhost:38381 with 794.9 MB RAM, BlockManagerId(driver, localhost, 38381)
16/03/21 17:21:23 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:21:23 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561083220
16/03/21 17:21:23 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:21:23 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:23 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:21:23 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:21:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:21:23 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:21:23 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=833527480
16/03/21 17:21:23 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 794.9 MB)
16/03/21 17:21:23 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=833527480
16/03/21 17:21:23 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 794.9 MB)
16/03/21 17:21:23 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:38381 (size: 4.1 KB, free: 794.9 MB)
16/03/21 17:21:23 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:21:23 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:23 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:21:23 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:21:23 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:21:23 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:21:23 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561083203
16/03/21 17:21:23 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-8e1ffb37-ffeb-454f-8856-335ec7fe8461/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:21:23 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:21:23 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=833527480
16/03/21 17:21:23 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 794.9 MB)
16/03/21 17:21:23 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:38381 (size: 166.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: area
mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  special  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: issue
mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: planning
mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: permission
mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: economy
mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: composition
mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: agency
mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/21 17:21:31 INFO PythonRunner: Times: total = 7980, boot = 461, init = 361, finish = 7158
16/03/21 17:21:31 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:21:31 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:21:31 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:21:31 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:21:31 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=833527480
16/03/21 17:21:31 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 794.9 MB)
16/03/21 17:21:31 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8058 ms on localhost (1/2)
16/03/21 17:21:31 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:38381 (size: 155.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: set
mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: bend
mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: giant
mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: astatine
mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: present
mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: area
mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  special  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/21 17:21:31 INFO PythonRunner: Times: total = 280, boot = 171, init = 1, finish = 108
16/03/21 17:21:31 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:21:31 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.371 s
16/03/21 17:21:31 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:21:31 INFO DAGScheduler: running: Set()
16/03/21 17:21:31 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:21:31 INFO DAGScheduler: failed: Set()
16/03/21 17:21:31 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:21:31 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:21:31 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=833527480
16/03/21 17:21:31 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 794.9 MB)
16/03/21 17:21:31 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 320 ms on localhost (2/2)
16/03/21 17:21:31 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:21:31 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=833527480
16/03/21 17:21:31 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 794.9 MB)
16/03/21 17:21:31 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:38381 (size: 3.0 KB, free: 794.9 MB)
16/03/21 17:21:31 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:21:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:31 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:21:31 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:21:31 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:21:31 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:21:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:21:31 INFO PythonRunner: Times: total = 145, boot = 145, init = 0, finish = 0
16/03/21 17:21:31 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:21:31 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:21:31 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:21:31 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:21:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:21:31 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 168 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'area', 'None', u'area']
16/03/21 17:21:32 INFO PythonRunner: Times: total = 172, boot = 171, init = 1, finish = 0
16/03/21 17:21:32 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/21 17:21:32 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.344 s
16/03/21 17:21:32 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.748129 s
16/03/21 17:21:32 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 187 ms on localhost (2/2)
16/03/21 17:21:32 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:21:32 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:21:32 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:21:32 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:32 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:21:32 INFO DAGScheduler: Missing parents: List()
16/03/21 17:21:32 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:21:32 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=833527480
16/03/21 17:21:32 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 794.9 MB)
16/03/21 17:21:32 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=833527480
16/03/21 17:21:32 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 794.9 MB)
16/03/21 17:21:32 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:38381 (size: 3.3 KB, free: 794.9 MB)
16/03/21 17:21:32 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:21:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:32 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:21:32 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:21:32 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:21:32 INFO PythonRunner: Times: total = 2, boot = -41, init = 43, finish = 0
16/03/21 17:21:32 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:21:32 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/21 17:21:32 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:21:32 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 24 ms on localhost (1/2)
16/03/21 17:21:32 INFO PythonRunner: Times: total = 156, boot = 156, init = 0, finish = 0
16/03/21 17:21:32 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1307 bytes result sent to driver
16/03/21 17:21:32 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 181 ms on localhost (2/2)
16/03/21 17:21:32 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:21:32 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.199 s
16/03/21 17:21:32 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.219641 s
16/03/21 17:21:32 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:21:32 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:21:32 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:21:32 INFO MemoryStore: MemoryStore cleared
16/03/21 17:21:32 INFO BlockManager: BlockManager stopped
16/03/21 17:21:32 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:21:32 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:21:32 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:21:32 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:21:32 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:21:33 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:21:33 INFO SecurityManager: Changing view acls to: root
16/03/21 17:21:33 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:21:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:21:33 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:21:33 INFO Remoting: Starting remoting
16/03/21 17:21:33 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:52273]
16/03/21 17:21:33 INFO Utils: Successfully started service 'sparkDriver' on port 52273.
16/03/21 17:21:33 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:21:33 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:21:33 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a988837a-6b95-4126-b65c-0dfda7198228
16/03/21 17:21:33 INFO MemoryStore: MemoryStore started with capacity 794.9 MB
16/03/21 17:21:33 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-3b4b0779-2723-4f5d-bebf-ab82af9ff3a4
16/03/21 17:21:33 INFO HttpServer: Starting HTTP Server
16/03/21 17:21:33 INFO Utils: Successfully started service 'HTTP file server' on port 44013.
16/03/21 17:21:33 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:21:34 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:21:34 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:21:34 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-36e00c60-b238-4f15-9c53-284e207ba17c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:21:34 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561094478
16/03/21 17:21:34 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:21:34 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:21:34 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54123.
16/03/21 17:21:34 INFO NettyBlockTransferService: Server created on 54123
16/03/21 17:21:34 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:21:34 INFO BlockManagerMasterEndpoint: Registering block manager localhost:54123 with 794.9 MB RAM, BlockManagerId(driver, localhost, 54123)
16/03/21 17:21:34 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:21:34 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561094493
16/03/21 17:21:34 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:21:34 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:34 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:21:34 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:21:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:21:34 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:21:34 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=833527480
16/03/21 17:21:34 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 794.9 MB)
16/03/21 17:21:34 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=833527480
16/03/21 17:21:34 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 794.9 MB)
16/03/21 17:21:34 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:54123 (size: 4.1 KB, free: 794.9 MB)
16/03/21 17:21:34 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:21:34 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:34 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:21:34 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:21:34 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:21:34 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:21:34 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561094478
16/03/21 17:21:34 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-36e00c60-b238-4f15-9c53-284e207ba17c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:21:34 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:21:34 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=833527480
16/03/21 17:21:34 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 794.9 MB)
16/03/21 17:21:34 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:54123 (size: 166.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: area
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: issue
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: planning
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: permission
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: economy
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: composition
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: agency
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): adding to parents: syn =  Synset('kilometer.n.01') ; keyword:  0.621371  in syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= [u'kilometer']
reduceFunction_Parents(): returns= ['None', u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'kilometer']
16/03/21 17:21:42 INFO PythonRunner: Times: total = 7821, boot = 466, init = 356, finish = 6999
16/03/21 17:21:42 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:21:42 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:21:42 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:21:42 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:21:42 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=833527480
16/03/21 17:21:42 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7915 ms on localhost (1/2)
16/03/21 17:21:42 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 794.9 MB)
16/03/21 17:21:42 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:54123 (size: 155.0 B, free: 794.9 MB)
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: set
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: bend
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: giant
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: astatine
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: present
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: area
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): adding to parents: syn =  Synset('kilometer.n.01') ; keyword:  0.621371  in syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= [u'kilometer']
reduceFunction_Parents(): returns= ['None', u'kilometer']
16/03/21 17:21:42 INFO PythonRunner: Times: total = 232, boot = 136, init = 1, finish = 95
16/03/21 17:21:42 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:21:42 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 286 ms on localhost (2/2)
16/03/21 17:21:42 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:21:42 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.188 s
16/03/21 17:21:42 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:21:42 INFO DAGScheduler: running: Set()
16/03/21 17:21:42 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:21:42 INFO DAGScheduler: failed: Set()
16/03/21 17:21:42 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:21:42 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:21:42 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=833527480
16/03/21 17:21:42 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 794.9 MB)
16/03/21 17:21:42 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=833527480
16/03/21 17:21:42 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 794.9 MB)
16/03/21 17:21:42 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:54123 (size: 3.0 KB, free: 794.9 MB)
16/03/21 17:21:42 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:21:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:42 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:21:42 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:21:42 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:21:42 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:21:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:21:43 INFO PythonRunner: Times: total = 119, boot = 118, init = 0, finish = 1
16/03/21 17:21:43 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:21:43 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:21:43 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:21:43 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:21:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:21:43 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 147 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'kilometer', 'None', u'kilometer']
16/03/21 17:21:43 INFO PythonRunner: Times: total = 164, boot = 162, init = 0, finish = 2
16/03/21 17:21:43 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1259 bytes result sent to driver
16/03/21 17:21:43 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.322 s
16/03/21 17:21:43 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.562795 s
16/03/21 17:21:43 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 189 ms on localhost (2/2)
16/03/21 17:21:43 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:21:43 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:21:43 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:21:43 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:43 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:21:43 INFO DAGScheduler: Missing parents: List()
16/03/21 17:21:43 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:21:43 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=833527480
16/03/21 17:21:43 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 794.9 MB)
16/03/21 17:21:43 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=833527480
16/03/21 17:21:43 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 794.9 MB)
16/03/21 17:21:43 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:54123 (size: 3.3 KB, free: 794.9 MB)
16/03/21 17:21:43 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:21:43 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:43 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:21:43 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:21:43 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:21:43 INFO PythonRunner: Times: total = 86, boot = 85, init = 1, finish = 0
16/03/21 17:21:43 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:21:43 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2289 bytes)
16/03/21 17:21:43 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 102 ms on localhost (1/2)
16/03/21 17:21:43 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:21:43 INFO PythonRunner: Times: total = 177, boot = 177, init = 0, finish = 0
16/03/21 17:21:43 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1328 bytes result sent to driver
16/03/21 17:21:43 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 194 ms on localhost (2/2)
16/03/21 17:21:43 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:21:43 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.283 s
16/03/21 17:21:43 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.318233 s
16/03/21 17:21:43 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:21:43 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:21:43 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:21:43 INFO MemoryStore: MemoryStore cleared
16/03/21 17:21:43 INFO BlockManager: BlockManager stopped
16/03/21 17:21:43 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:21:43 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:21:43 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:21:43 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:21:43 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:21:43 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:21:44 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:21:44 INFO SecurityManager: Changing view acls to: root
16/03/21 17:21:44 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:21:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:21:44 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:21:44 INFO Remoting: Starting remoting
16/03/21 17:21:44 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:38342]
16/03/21 17:21:44 INFO Utils: Successfully started service 'sparkDriver' on port 38342.
16/03/21 17:21:44 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:21:44 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:21:44 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9aa761b4-0793-4c15-a409-1004d0e5346e
16/03/21 17:21:44 INFO MemoryStore: MemoryStore started with capacity 813.9 MB
16/03/21 17:21:44 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-5380f661-b7d9-4ec6-a1c6-82955cf79bb5
16/03/21 17:21:44 INFO HttpServer: Starting HTTP Server
16/03/21 17:21:44 INFO Utils: Successfully started service 'HTTP file server' on port 40741.
16/03/21 17:21:44 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:21:44 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:21:44 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:21:44 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-cb26fd78-d6fc-4b0a-9ec4-d5d11cc1f449/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:21:44 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561104866
16/03/21 17:21:44 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:21:44 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:21:44 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49760.
16/03/21 17:21:44 INFO NettyBlockTransferService: Server created on 49760
16/03/21 17:21:44 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:21:44 INFO BlockManagerMasterEndpoint: Registering block manager localhost:49760 with 813.9 MB RAM, BlockManagerId(driver, localhost, 49760)
16/03/21 17:21:44 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:21:44 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561104877
16/03/21 17:21:44 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:21:44 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:44 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:21:44 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:21:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:21:45 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:21:45 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=853487124
16/03/21 17:21:45 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 813.9 MB)
16/03/21 17:21:45 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=853487124
16/03/21 17:21:45 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 813.9 MB)
16/03/21 17:21:45 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:49760 (size: 4.1 KB, free: 813.9 MB)
16/03/21 17:21:45 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:21:45 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:45 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:21:45 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:21:45 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:21:45 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:21:45 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561104866
16/03/21 17:21:45 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-cb26fd78-d6fc-4b0a-9ec4-d5d11cc1f449/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:21:45 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:21:45 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=853487124
16/03/21 17:21:45 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 813.9 MB)
16/03/21 17:21:45 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:49760 (size: 166.0 B, free: 813.9 MB)
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: area
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: issue
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: planning
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: permission
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: economy
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: composition
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: agency
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:21:52 INFO PythonRunner: Times: total = 7893, boot = 505, init = 424, finish = 6964
16/03/21 17:21:52 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:21:53 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:21:53 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:21:53 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:21:53 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=853487124
16/03/21 17:21:53 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7989 ms on localhost (1/2)
16/03/21 17:21:53 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 813.9 MB)
16/03/21 17:21:53 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:49760 (size: 155.0 B, free: 813.9 MB)
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: set
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: bend
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: giant
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: astatine
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: present
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  Orthodox  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: area
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
16/03/21 17:21:53 INFO PythonRunner: Times: total = 229, boot = 133, init = 1, finish = 95
16/03/21 17:21:53 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:21:53 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.238 s
16/03/21 17:21:53 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:21:53 INFO DAGScheduler: running: Set()
16/03/21 17:21:53 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:21:53 INFO DAGScheduler: failed: Set()
16/03/21 17:21:53 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:21:53 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:21:53 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=853487124
16/03/21 17:21:53 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 813.9 MB)
16/03/21 17:21:53 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 273 ms on localhost (2/2)
16/03/21 17:21:53 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:21:53 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=853487124
16/03/21 17:21:53 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 813.9 MB)
16/03/21 17:21:53 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:49760 (size: 3.0 KB, free: 813.9 MB)
16/03/21 17:21:53 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:21:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:53 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:21:53 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:21:53 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:21:53 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:21:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:21:53 INFO PythonRunner: Times: total = 129, boot = 129, init = 0, finish = 0
16/03/21 17:21:53 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:21:53 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:21:53 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:21:53 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:21:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:21:53 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 155 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'metropolitan']
16/03/21 17:21:53 INFO PythonRunner: Times: total = 156, boot = 154, init = 1, finish = 1
16/03/21 17:21:53 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1246 bytes result sent to driver
16/03/21 17:21:53 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 168 ms on localhost (2/2)
16/03/21 17:21:53 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:21:53 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.307 s
16/03/21 17:21:53 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.607613 s
16/03/21 17:21:53 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:21:53 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:21:53 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:53 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:21:53 INFO DAGScheduler: Missing parents: List()
16/03/21 17:21:53 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:21:53 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=853487124
16/03/21 17:21:53 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 813.9 MB)
16/03/21 17:21:53 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=853487124
16/03/21 17:21:53 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 813.9 MB)
16/03/21 17:21:53 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:49760 (size: 3.3 KB, free: 813.9 MB)
16/03/21 17:21:53 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:21:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:53 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:21:53 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:21:53 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:21:53 INFO PythonRunner: Times: total = 39, boot = 38, init = 0, finish = 1
16/03/21 17:21:53 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:21:53 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2276 bytes)
16/03/21 17:21:53 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 59 ms on localhost (1/2)
16/03/21 17:21:53 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:21:53 INFO PythonRunner: Times: total = 151, boot = 151, init = 0, finish = 0
16/03/21 17:21:53 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1315 bytes result sent to driver
16/03/21 17:21:53 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.225 s
16/03/21 17:21:53 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.244778 s
16/03/21 17:21:53 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 176 ms on localhost (2/2)
16/03/21 17:21:53 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:21:54 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:21:54 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:21:54 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:21:54 INFO MemoryStore: MemoryStore cleared
16/03/21 17:21:54 INFO BlockManager: BlockManager stopped
16/03/21 17:21:54 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:21:54 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:21:54 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:21:54 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:21:54 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:21:54 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:21:55 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:21:55 INFO SecurityManager: Changing view acls to: root
16/03/21 17:21:55 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:21:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:21:55 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:21:55 INFO Remoting: Starting remoting
16/03/21 17:21:55 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:58879]
16/03/21 17:21:55 INFO Utils: Successfully started service 'sparkDriver' on port 58879.
16/03/21 17:21:55 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:21:55 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:21:55 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7b691663-390b-42c3-9fe6-b372cc93b5a8
16/03/21 17:21:55 INFO MemoryStore: MemoryStore started with capacity 813.9 MB
16/03/21 17:21:55 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-7395ae45-dbfc-46ae-bebc-52e9ce9b1f97
16/03/21 17:21:55 INFO HttpServer: Starting HTTP Server
16/03/21 17:21:55 INFO Utils: Successfully started service 'HTTP file server' on port 39774.
16/03/21 17:21:55 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:21:55 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:21:55 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:21:55 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-075bae57-4f6f-4fb2-827c-8927e26d9835/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:21:55 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561115550
16/03/21 17:21:55 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:21:55 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:21:55 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35981.
16/03/21 17:21:55 INFO NettyBlockTransferService: Server created on 35981
16/03/21 17:21:55 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:21:55 INFO BlockManagerMasterEndpoint: Registering block manager localhost:35981 with 813.9 MB RAM, BlockManagerId(driver, localhost, 35981)
16/03/21 17:21:55 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:21:55 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561115560
16/03/21 17:21:55 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:21:55 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:55 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:21:55 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:21:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:21:55 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:21:55 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=853487124
16/03/21 17:21:55 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 813.9 MB)
16/03/21 17:21:55 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=853487124
16/03/21 17:21:55 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 813.9 MB)
16/03/21 17:21:55 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:35981 (size: 4.1 KB, free: 813.9 MB)
16/03/21 17:21:55 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:21:55 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:21:55 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:21:55 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:21:55 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:21:55 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561115550
16/03/21 17:21:55 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:21:55 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-075bae57-4f6f-4fb2-827c-8927e26d9835/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:21:55 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:21:55 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=853487124
16/03/21 17:21:55 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 813.9 MB)
16/03/21 17:21:55 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:35981 (size: 166.0 B, free: 813.9 MB)
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: area
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: issue
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: planning
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): adding to parents: syn =  Synset('planning.n.01') ; keyword:  definite  in syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= [u'planning']
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: permission
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: economy
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: composition
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: agency
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
16/03/21 17:22:03 INFO PythonRunner: Times: total = 7876, boot = 461, init = 360, finish = 7055
16/03/21 17:22:03 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:22:03 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:22:03 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:22:03 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:22:03 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=853487124
16/03/21 17:22:03 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 813.9 MB)
16/03/21 17:22:03 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7955 ms on localhost (1/2)
16/03/21 17:22:03 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:35981 (size: 155.0 B, free: 813.9 MB)
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: set
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: bend
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: giant
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: astatine
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: present
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: area
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:22:03 INFO PythonRunner: Times: total = 247, boot = 150, init = 1, finish = 96
16/03/21 17:22:03 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:22:03 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 294 ms on localhost (2/2)
16/03/21 17:22:03 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:22:03 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.234 s
16/03/21 17:22:03 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:22:03 INFO DAGScheduler: running: Set()
16/03/21 17:22:03 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:22:03 INFO DAGScheduler: failed: Set()
16/03/21 17:22:03 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:22:03 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:22:03 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=853487124
16/03/21 17:22:03 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 813.9 MB)
16/03/21 17:22:03 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=853487124
16/03/21 17:22:03 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 813.9 MB)
16/03/21 17:22:03 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:35981 (size: 3.0 KB, free: 813.9 MB)
16/03/21 17:22:03 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:22:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:03 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:22:03 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:22:03 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:22:03 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:22:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:22:04 INFO PythonRunner: Times: total = 133, boot = 133, init = 0, finish = 0
16/03/21 17:22:04 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:22:04 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:22:04 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:22:04 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:22:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:22:04 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 155 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'planning', 'None']
16/03/21 17:22:04 INFO PythonRunner: Times: total = 159, boot = 159, init = 0, finish = 0
16/03/21 17:22:04 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1242 bytes result sent to driver
16/03/21 17:22:04 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.319 s
16/03/21 17:22:04 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.589999 s
16/03/21 17:22:04 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 174 ms on localhost (2/2)
16/03/21 17:22:04 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:22:04 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:22:04 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:22:04 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:04 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:22:04 INFO DAGScheduler: Missing parents: List()
16/03/21 17:22:04 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:22:04 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=853487124
16/03/21 17:22:04 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 813.9 MB)
16/03/21 17:22:04 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=853487124
16/03/21 17:22:04 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 813.9 MB)
16/03/21 17:22:04 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:35981 (size: 3.3 KB, free: 813.9 MB)
16/03/21 17:22:04 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:22:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:04 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:22:04 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:22:04 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:22:04 INFO PythonRunner: Times: total = 117, boot = 116, init = 1, finish = 0
16/03/21 17:22:04 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:22:04 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2272 bytes)
16/03/21 17:22:04 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 136 ms on localhost (1/2)
16/03/21 17:22:04 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:22:04 INFO PythonRunner: Times: total = 165, boot = 165, init = 0, finish = 0
16/03/21 17:22:04 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1311 bytes result sent to driver
16/03/21 17:22:04 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.307 s
16/03/21 17:22:04 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.331508 s
16/03/21 17:22:04 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 185 ms on localhost (2/2)
16/03/21 17:22:04 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:22:04 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:22:04 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:22:04 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:22:04 INFO MemoryStore: MemoryStore cleared
16/03/21 17:22:04 INFO BlockManager: BlockManager stopped
16/03/21 17:22:04 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:22:04 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:22:04 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:22:04 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:22:04 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:22:04 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:22:05 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:22:05 INFO SecurityManager: Changing view acls to: root
16/03/21 17:22:05 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:22:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:22:05 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:22:05 INFO Remoting: Starting remoting
16/03/21 17:22:05 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:45466]
16/03/21 17:22:05 INFO Utils: Successfully started service 'sparkDriver' on port 45466.
16/03/21 17:22:05 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:22:05 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:22:05 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a3bd3a7b-cf86-422d-995e-1f429716cb5e
16/03/21 17:22:05 INFO MemoryStore: MemoryStore started with capacity 813.9 MB
16/03/21 17:22:05 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-49b77c1c-5fa4-4772-89cd-48c51155e050
16/03/21 17:22:05 INFO HttpServer: Starting HTTP Server
16/03/21 17:22:05 INFO Utils: Successfully started service 'HTTP file server' on port 50929.
16/03/21 17:22:05 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:22:06 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:22:06 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:22:06 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-73576b96-fc79-4b77-8aeb-c70fb01cd2df/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:22:06 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561126292
16/03/21 17:22:06 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:22:06 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:22:06 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44089.
16/03/21 17:22:06 INFO NettyBlockTransferService: Server created on 44089
16/03/21 17:22:06 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:22:06 INFO BlockManagerMasterEndpoint: Registering block manager localhost:44089 with 813.9 MB RAM, BlockManagerId(driver, localhost, 44089)
16/03/21 17:22:06 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:22:06 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561126302
16/03/21 17:22:06 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:22:06 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:06 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:22:06 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:22:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:22:06 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:22:06 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=853487124
16/03/21 17:22:06 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 813.9 MB)
16/03/21 17:22:06 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=853487124
16/03/21 17:22:06 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 813.9 MB)
16/03/21 17:22:06 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:44089 (size: 4.1 KB, free: 813.9 MB)
16/03/21 17:22:06 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:22:06 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:06 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:22:06 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:22:06 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:22:06 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:22:06 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561126292
16/03/21 17:22:06 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-73576b96-fc79-4b77-8aeb-c70fb01cd2df/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:22:06 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:22:06 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=853487124
16/03/21 17:22:06 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 813.9 MB)
16/03/21 17:22:06 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:44089 (size: 166.0 B, free: 813.9 MB)
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: area
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  boundary  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: issue
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: planning
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: permission
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: economy
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: composition
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: agency
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/21 17:22:14 INFO PythonRunner: Times: total = 7822, boot = 443, init = 351, finish = 7028
16/03/21 17:22:14 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:22:14 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:22:14 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:22:14 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:22:14 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=853487124
16/03/21 17:22:14 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 813.9 MB)
16/03/21 17:22:14 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7898 ms on localhost (1/2)
16/03/21 17:22:14 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:44089 (size: 155.0 B, free: 813.9 MB)
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: set
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: bend
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: giant
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: astatine
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: present
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: area
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  boundary  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/21 17:22:14 INFO PythonRunner: Times: total = 252, boot = 155, init = 0, finish = 97
16/03/21 17:22:14 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:22:14 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 306 ms on localhost (2/2)
16/03/21 17:22:14 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:22:14 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.187 s
16/03/21 17:22:14 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:22:14 INFO DAGScheduler: running: Set()
16/03/21 17:22:14 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:22:14 INFO DAGScheduler: failed: Set()
16/03/21 17:22:14 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:22:14 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:22:14 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=853487124
16/03/21 17:22:14 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 813.9 MB)
16/03/21 17:22:14 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=853487124
16/03/21 17:22:14 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 813.9 MB)
16/03/21 17:22:14 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:44089 (size: 3.0 KB, free: 813.9 MB)
16/03/21 17:22:14 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:22:14 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:14 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:22:14 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:22:14 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:22:14 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:22:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:22:14 INFO PythonRunner: Times: total = 152, boot = 148, init = 4, finish = 0
16/03/21 17:22:14 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:22:14 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:22:14 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:22:14 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:22:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:22:14 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 182 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'area', 'None', u'area']
16/03/21 17:22:14 INFO PythonRunner: Times: total = 182, boot = 181, init = 0, finish = 1
16/03/21 17:22:14 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/21 17:22:15 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.363 s
16/03/21 17:22:15 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.600125 s
16/03/21 17:22:15 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 204 ms on localhost (2/2)
16/03/21 17:22:15 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:22:15 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:22:15 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:22:15 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:15 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:22:15 INFO DAGScheduler: Missing parents: List()
16/03/21 17:22:15 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:22:15 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=853487124
16/03/21 17:22:15 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 813.9 MB)
16/03/21 17:22:15 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=853487124
16/03/21 17:22:15 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 813.9 MB)
16/03/21 17:22:15 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:44089 (size: 3.3 KB, free: 813.9 MB)
16/03/21 17:22:15 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:22:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:15 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:22:15 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:22:15 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:22:15 INFO PythonRunner: Times: total = 23, boot = 23, init = 0, finish = 0
16/03/21 17:22:15 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:22:15 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/21 17:22:15 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 44 ms on localhost (1/2)
16/03/21 17:22:15 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:22:15 INFO PythonRunner: Times: total = 173, boot = 172, init = 1, finish = 0
16/03/21 17:22:15 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1307 bytes result sent to driver
16/03/21 17:22:15 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 194 ms on localhost (2/2)
16/03/21 17:22:15 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:22:15 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.231 s
16/03/21 17:22:15 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.251306 s
16/03/21 17:22:15 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:22:15 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:22:15 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:22:15 INFO MemoryStore: MemoryStore cleared
16/03/21 17:22:15 INFO BlockManager: BlockManager stopped
16/03/21 17:22:15 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:22:15 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:22:15 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:22:15 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:22:15 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:22:15 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:22:16 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:22:16 INFO SecurityManager: Changing view acls to: root
16/03/21 17:22:16 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:22:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:22:16 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:22:16 INFO Remoting: Starting remoting
16/03/21 17:22:16 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:37578]
16/03/21 17:22:16 INFO Utils: Successfully started service 'sparkDriver' on port 37578.
16/03/21 17:22:16 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:22:16 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:22:16 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-eaf2182b-a547-4f87-892d-9ae205c23ffd
16/03/21 17:22:16 INFO MemoryStore: MemoryStore started with capacity 813.9 MB
16/03/21 17:22:16 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-496e77a9-4e3e-460d-929c-5e6a79728784
16/03/21 17:22:16 INFO HttpServer: Starting HTTP Server
16/03/21 17:22:16 INFO Utils: Successfully started service 'HTTP file server' on port 43342.
16/03/21 17:22:16 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:22:16 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:22:16 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:22:16 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-250f33c5-24f5-4b79-8aee-c68b0f0a101d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:22:16 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561136747
16/03/21 17:22:16 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:22:16 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:22:16 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54848.
16/03/21 17:22:16 INFO NettyBlockTransferService: Server created on 54848
16/03/21 17:22:16 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:22:16 INFO BlockManagerMasterEndpoint: Registering block manager localhost:54848 with 813.9 MB RAM, BlockManagerId(driver, localhost, 54848)
16/03/21 17:22:16 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:22:16 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561136761
16/03/21 17:22:16 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:22:16 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:16 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:22:16 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:22:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:22:16 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:22:16 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=853487124
16/03/21 17:22:16 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 813.9 MB)
16/03/21 17:22:16 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=853487124
16/03/21 17:22:16 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 813.9 MB)
16/03/21 17:22:16 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:54848 (size: 4.1 KB, free: 813.9 MB)
16/03/21 17:22:16 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:22:16 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:16 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:22:16 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:22:16 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:22:16 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561136747
16/03/21 17:22:16 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:22:16 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-250f33c5-24f5-4b79-8aee-c68b0f0a101d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:22:16 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:22:16 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=853487124
16/03/21 17:22:16 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 813.9 MB)
16/03/21 17:22:16 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:54848 (size: 166.0 B, free: 813.9 MB)
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: area
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: issue
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: planning
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: permission
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: economy
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: composition
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: agency
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): adding to parents: syn =  Synset('agency.n.02') ; keyword:  business  in syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= [u'agency']
reduceFunction_Parents(): returns= ['None', u'agency']
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'agency']
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'agency']
16/03/21 17:22:24 INFO PythonRunner: Times: total = 7956, boot = 506, init = 371, finish = 7079
16/03/21 17:22:24 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:22:24 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:22:24 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:22:24 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:22:24 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8042 ms on localhost (1/2)
16/03/21 17:22:24 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=853487124
16/03/21 17:22:24 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 813.9 MB)
16/03/21 17:22:24 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:54848 (size: 155.0 B, free: 813.9 MB)
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: set
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: bend
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: giant
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: astatine
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: present
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: area
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:22:25 INFO PythonRunner: Times: total = 270, boot = 172, init = 1, finish = 97
16/03/21 17:22:25 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:22:25 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.343 s
16/03/21 17:22:25 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:22:25 INFO DAGScheduler: running: Set()
16/03/21 17:22:25 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:22:25 INFO DAGScheduler: failed: Set()
16/03/21 17:22:25 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:22:25 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:22:25 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=853487124
16/03/21 17:22:25 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 813.9 MB)
16/03/21 17:22:25 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 306 ms on localhost (2/2)
16/03/21 17:22:25 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:22:25 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=853487124
16/03/21 17:22:25 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 813.9 MB)
16/03/21 17:22:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:54848 (size: 3.0 KB, free: 813.9 MB)
16/03/21 17:22:25 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:22:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:25 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:22:25 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:22:25 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:22:25 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:22:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:22:25 INFO PythonRunner: Times: total = 109, boot = 108, init = 0, finish = 1
16/03/21 17:22:25 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:22:25 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:22:25 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:22:25 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:22:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:22:25 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 133 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'agency', 'None']
16/03/21 17:22:25 INFO PythonRunner: Times: total = 153, boot = 152, init = 0, finish = 1
16/03/21 17:22:25 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1240 bytes result sent to driver
16/03/21 17:22:25 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.289 s
16/03/21 17:22:25 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.684236 s
16/03/21 17:22:25 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 175 ms on localhost (2/2)
16/03/21 17:22:25 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:22:25 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:22:25 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:22:25 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:25 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:22:25 INFO DAGScheduler: Missing parents: List()
16/03/21 17:22:25 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:22:25 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=853487124
16/03/21 17:22:25 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 813.9 MB)
16/03/21 17:22:25 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=853487124
16/03/21 17:22:25 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 813.9 MB)
16/03/21 17:22:25 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:54848 (size: 3.3 KB, free: 813.9 MB)
16/03/21 17:22:25 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:22:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:25 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:22:25 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:22:25 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:22:25 INFO PythonRunner: Times: total = 39, boot = 38, init = 1, finish = 0
16/03/21 17:22:25 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:22:25 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2270 bytes)
16/03/21 17:22:25 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:22:25 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 54 ms on localhost (1/2)
16/03/21 17:22:25 INFO PythonRunner: Times: total = 161, boot = 160, init = 0, finish = 1
16/03/21 17:22:25 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1309 bytes result sent to driver
16/03/21 17:22:25 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.221 s
16/03/21 17:22:25 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.263255 s
16/03/21 17:22:25 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 176 ms on localhost (2/2)
16/03/21 17:22:25 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:22:26 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:22:26 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:22:26 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:22:26 INFO MemoryStore: MemoryStore cleared
16/03/21 17:22:26 INFO BlockManager: BlockManager stopped
16/03/21 17:22:26 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:22:26 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:22:26 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:22:26 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:22:26 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:22:26 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:22:26 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:22:27 INFO SecurityManager: Changing view acls to: root
16/03/21 17:22:27 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:22:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:22:27 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:22:27 INFO Remoting: Starting remoting
16/03/21 17:22:27 INFO Utils: Successfully started service 'sparkDriver' on port 41991.
16/03/21 17:22:27 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:41991]
16/03/21 17:22:27 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:22:27 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:22:27 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1bb3f405-6c58-4050-90f4-a6475c8d9d3c
16/03/21 17:22:27 INFO MemoryStore: MemoryStore started with capacity 813.9 MB
16/03/21 17:22:27 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-05d00d9b-c48a-4b53-829e-c8e0a807dacd
16/03/21 17:22:27 INFO HttpServer: Starting HTTP Server
16/03/21 17:22:27 INFO Utils: Successfully started service 'HTTP file server' on port 57752.
16/03/21 17:22:27 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:22:27 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:22:27 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:22:27 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-6317782a-2234-42a1-b189-28f4be18578f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:22:27 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561147141
16/03/21 17:22:27 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:22:27 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:22:27 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51595.
16/03/21 17:22:27 INFO NettyBlockTransferService: Server created on 51595
16/03/21 17:22:27 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:22:27 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51595 with 813.9 MB RAM, BlockManagerId(driver, localhost, 51595)
16/03/21 17:22:27 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:22:27 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561147154
16/03/21 17:22:27 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:22:27 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:27 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:22:27 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:22:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:22:27 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:22:27 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=853487124
16/03/21 17:22:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 813.9 MB)
16/03/21 17:22:27 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=853487124
16/03/21 17:22:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 813.9 MB)
16/03/21 17:22:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51595 (size: 4.1 KB, free: 813.9 MB)
16/03/21 17:22:27 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:22:27 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:27 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:22:27 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:22:27 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:22:27 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:22:27 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561147141
16/03/21 17:22:27 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-6317782a-2234-42a1-b189-28f4be18578f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:22:27 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:22:27 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=853487124
16/03/21 17:22:27 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 813.9 MB)
16/03/21 17:22:27 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:51595 (size: 166.0 B, free: 813.9 MB)
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: area
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: issue
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: planning
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: permission
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: economy
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: composition
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: agency
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:22:35 INFO PythonRunner: Times: total = 7969, boot = 441, init = 358, finish = 7170
16/03/21 17:22:35 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:22:35 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:22:35 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:22:35 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:22:35 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=853487124
16/03/21 17:22:35 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 813.9 MB)
16/03/21 17:22:35 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8049 ms on localhost (1/2)
16/03/21 17:22:35 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:51595 (size: 155.0 B, free: 813.9 MB)
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: set
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: bend
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: giant
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): adding to parents: syn =  Synset('colossus.n.02') ; keyword:  importance  in syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= [u'giant']
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: astatine
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: present
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: area
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
16/03/21 17:22:35 INFO PythonRunner: Times: total = 254, boot = 158, init = 0, finish = 96
16/03/21 17:22:35 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:22:35 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.323 s
16/03/21 17:22:35 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:22:35 INFO DAGScheduler: running: Set()
16/03/21 17:22:35 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:22:35 INFO DAGScheduler: failed: Set()
16/03/21 17:22:35 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:22:35 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:22:35 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=853487124
16/03/21 17:22:35 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 813.9 MB)
16/03/21 17:22:35 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=853487124
16/03/21 17:22:35 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 813.9 MB)
16/03/21 17:22:35 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 286 ms on localhost (2/2)
16/03/21 17:22:35 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:22:35 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51595 (size: 3.0 KB, free: 813.9 MB)
16/03/21 17:22:35 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:22:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:35 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:22:35 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:22:35 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:22:35 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:22:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:22:35 INFO PythonRunner: Times: total = 154, boot = 153, init = 0, finish = 1
16/03/21 17:22:35 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:22:35 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:22:35 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:22:35 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:22:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
16/03/21 17:22:35 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 185 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'giant']
16/03/21 17:22:35 INFO PythonRunner: Times: total = 146, boot = 145, init = 1, finish = 0
16/03/21 17:22:35 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1239 bytes result sent to driver
16/03/21 17:22:35 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.332 s
16/03/21 17:22:35 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.698949 s
16/03/21 17:22:35 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 169 ms on localhost (2/2)
16/03/21 17:22:35 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:22:36 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:22:36 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:22:36 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:36 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:22:36 INFO DAGScheduler: Missing parents: List()
16/03/21 17:22:36 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:22:36 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=853487124
16/03/21 17:22:36 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 813.9 MB)
16/03/21 17:22:36 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=853487124
16/03/21 17:22:36 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 813.9 MB)
16/03/21 17:22:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:51595 (size: 3.3 KB, free: 813.9 MB)
16/03/21 17:22:36 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:22:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:36 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:22:36 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:22:36 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:22:36 INFO PythonRunner: Times: total = 85, boot = 84, init = 1, finish = 0
16/03/21 17:22:36 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:22:36 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2269 bytes)
16/03/21 17:22:36 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 102 ms on localhost (1/2)
16/03/21 17:22:36 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:22:36 INFO PythonRunner: Times: total = 159, boot = 159, init = 0, finish = 0
16/03/21 17:22:36 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1308 bytes result sent to driver
16/03/21 17:22:36 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.275 s
16/03/21 17:22:36 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.298600 s
16/03/21 17:22:36 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 184 ms on localhost (2/2)
16/03/21 17:22:36 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:22:36 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:22:36 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:22:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:22:36 INFO MemoryStore: MemoryStore cleared
16/03/21 17:22:36 INFO BlockManager: BlockManager stopped
16/03/21 17:22:36 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:22:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:22:36 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:22:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:22:36 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:22:36 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:22:37 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:22:37 INFO SecurityManager: Changing view acls to: root
16/03/21 17:22:37 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:22:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:22:37 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:22:37 INFO Remoting: Starting remoting
16/03/21 17:22:37 INFO Utils: Successfully started service 'sparkDriver' on port 39325.
16/03/21 17:22:37 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:39325]
16/03/21 17:22:37 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:22:37 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:22:37 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d9ae5ebc-03ab-4ce1-9314-6edb41f911ec
16/03/21 17:22:37 INFO MemoryStore: MemoryStore started with capacity 813.9 MB
16/03/21 17:22:37 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-3bd34574-a54d-4cd7-9642-7d06603bb589
16/03/21 17:22:37 INFO HttpServer: Starting HTTP Server
16/03/21 17:22:37 INFO Utils: Successfully started service 'HTTP file server' on port 57612.
16/03/21 17:22:37 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:22:37 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:22:37 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:22:37 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-5c6af447-d390-4c5c-a607-f6855c614f23/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:22:37 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561157718
16/03/21 17:22:37 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:22:37 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:22:37 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50652.
16/03/21 17:22:37 INFO NettyBlockTransferService: Server created on 50652
16/03/21 17:22:37 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:22:37 INFO BlockManagerMasterEndpoint: Registering block manager localhost:50652 with 813.9 MB RAM, BlockManagerId(driver, localhost, 50652)
16/03/21 17:22:37 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:22:37 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561157728
16/03/21 17:22:37 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:22:37 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:37 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:22:37 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:22:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:22:37 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:22:37 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=853487124
16/03/21 17:22:37 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 813.9 MB)
16/03/21 17:22:37 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6576, maxMem=853487124
16/03/21 17:22:37 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 813.9 MB)
16/03/21 17:22:37 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:50652 (size: 4.1 KB, free: 813.9 MB)
16/03/21 17:22:37 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:22:37 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:37 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:22:37 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:22:37 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:22:37 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:22:37 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561157718
16/03/21 17:22:37 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-5c6af447-d390-4c5c-a607-f6855c614f23/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:22:37 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:22:37 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10724, maxMem=853487124
16/03/21 17:22:37 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 813.9 MB)
16/03/21 17:22:37 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:50652 (size: 166.0 B, free: 813.9 MB)
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: area
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: issue
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: planning
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: permission
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: economy
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: composition
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: agency
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:22:45 INFO PythonRunner: Times: total = 7781, boot = 457, init = 350, finish = 6974
16/03/21 17:22:45 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:22:45 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:22:45 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:22:45 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:22:45 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7870 ms on localhost (1/2)
16/03/21 17:22:45 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10890, maxMem=853487124
16/03/21 17:22:45 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 813.9 MB)
16/03/21 17:22:45 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:50652 (size: 155.0 B, free: 813.9 MB)
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: set
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: bend
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: giant
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: astatine
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: present
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  equivalent  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: area
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
16/03/21 17:22:45 INFO PythonRunner: Times: total = 224, boot = 127, init = 0, finish = 97
16/03/21 17:22:45 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:22:45 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 290 ms on localhost (2/2)
16/03/21 17:22:45 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:22:45 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.142 s
16/03/21 17:22:45 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:22:45 INFO DAGScheduler: running: Set()
16/03/21 17:22:45 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:22:45 INFO DAGScheduler: failed: Set()
16/03/21 17:22:45 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:22:45 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:22:45 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11045, maxMem=853487124
16/03/21 17:22:45 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 813.9 MB)
16/03/21 17:22:46 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16029, maxMem=853487124
16/03/21 17:22:46 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 813.9 MB)
16/03/21 17:22:46 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:50652 (size: 3.0 KB, free: 813.9 MB)
16/03/21 17:22:46 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:22:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:46 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:22:46 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:22:46 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:22:46 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:22:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:22:46 INFO PythonRunner: Times: total = 135, boot = 134, init = 0, finish = 1
16/03/21 17:22:46 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:22:46 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:22:46 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:22:46 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:22:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:22:46 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 178 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'metropolitan']
16/03/21 17:22:46 INFO PythonRunner: Times: total = 136, boot = 135, init = 0, finish = 1
16/03/21 17:22:46 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1246 bytes result sent to driver
16/03/21 17:22:46 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.320 s
16/03/21 17:22:46 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.496138 s
16/03/21 17:22:46 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 173 ms on localhost (2/2)
16/03/21 17:22:46 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:22:46 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:22:46 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:22:46 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:46 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:22:46 INFO DAGScheduler: Missing parents: List()
16/03/21 17:22:46 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:22:46 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19076, maxMem=853487124
16/03/21 17:22:46 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 813.9 MB)
16/03/21 17:22:46 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24892, maxMem=853487124
16/03/21 17:22:46 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 813.9 MB)
16/03/21 17:22:46 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:50652 (size: 3.3 KB, free: 813.9 MB)
16/03/21 17:22:46 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:22:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:46 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:22:46 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:22:46 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:22:46 INFO PythonRunner: Times: total = 54, boot = 54, init = 0, finish = 0
16/03/21 17:22:46 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:22:46 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2276 bytes)
16/03/21 17:22:46 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:22:46 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 73 ms on localhost (1/2)
16/03/21 17:22:46 INFO PythonRunner: Times: total = 162, boot = 162, init = 0, finish = 0
16/03/21 17:22:46 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1315 bytes result sent to driver
16/03/21 17:22:46 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 185 ms on localhost (2/2)
16/03/21 17:22:46 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:22:46 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.242 s
16/03/21 17:22:46 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.273277 s
16/03/21 17:22:46 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:22:46 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:22:46 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:22:46 INFO MemoryStore: MemoryStore cleared
16/03/21 17:22:46 INFO BlockManager: BlockManager stopped
16/03/21 17:22:46 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:22:46 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:22:46 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:22:46 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:22:46 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:22:46 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:22:47 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:22:47 INFO SecurityManager: Changing view acls to: root
16/03/21 17:22:47 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:22:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:22:47 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:22:47 INFO Remoting: Starting remoting
16/03/21 17:22:47 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:58881]
16/03/21 17:22:47 INFO Utils: Successfully started service 'sparkDriver' on port 58881.
16/03/21 17:22:47 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:22:47 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:22:47 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9c49ae03-1d25-4d79-bec9-ab06737ae094
16/03/21 17:22:47 INFO MemoryStore: MemoryStore started with capacity 813.9 MB
16/03/21 17:22:47 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-59619599-0d30-4085-84dd-c7f0ace81bd8
16/03/21 17:22:47 INFO HttpServer: Starting HTTP Server
16/03/21 17:22:47 INFO Utils: Successfully started service 'HTTP file server' on port 33767.
16/03/21 17:22:47 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:22:47 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:22:47 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:22:47 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-2896fb4a-535b-457c-b8cf-d94251890f4f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:22:47 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561167917
16/03/21 17:22:47 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:22:47 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:22:47 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37739.
16/03/21 17:22:47 INFO NettyBlockTransferService: Server created on 37739
16/03/21 17:22:47 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:22:47 INFO BlockManagerMasterEndpoint: Registering block manager localhost:37739 with 813.9 MB RAM, BlockManagerId(driver, localhost, 37739)
16/03/21 17:22:47 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:22:47 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561167929
16/03/21 17:22:48 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:22:48 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:48 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:22:48 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:22:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:22:48 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:22:48 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=853487124
16/03/21 17:22:48 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 813.9 MB)
16/03/21 17:22:48 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=853487124
16/03/21 17:22:48 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 813.9 MB)
16/03/21 17:22:48 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:37739 (size: 4.1 KB, free: 813.9 MB)
16/03/21 17:22:48 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:22:48 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:48 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:22:48 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:22:48 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:22:48 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:22:48 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561167917
16/03/21 17:22:48 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-2896fb4a-535b-457c-b8cf-d94251890f4f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:22:48 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:22:48 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=853487124
16/03/21 17:22:48 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 813.9 MB)
16/03/21 17:22:48 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:37739 (size: 166.0 B, free: 813.9 MB)
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: area
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: issue
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: planning
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: permission
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: economy
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: composition
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: agency
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:22:56 INFO PythonRunner: Times: total = 7895, boot = 474, init = 350, finish = 7071
16/03/21 17:22:56 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:22:56 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:22:56 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:22:56 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7963 ms on localhost (1/2)
16/03/21 17:22:56 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:22:56 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=853487124
16/03/21 17:22:56 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 813.9 MB)
16/03/21 17:22:56 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:37739 (size: 155.0 B, free: 813.9 MB)
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: set
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: bend
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: giant
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: astatine
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  thorium  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: present
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: area
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/21 17:22:56 INFO PythonRunner: Times: total = 266, boot = 168, init = 1, finish = 97
16/03/21 17:22:56 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:22:56 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.259 s
16/03/21 17:22:56 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:22:56 INFO DAGScheduler: running: Set()
16/03/21 17:22:56 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:22:56 INFO DAGScheduler: failed: Set()
16/03/21 17:22:56 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:22:56 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:22:56 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 297 ms on localhost (2/2)
16/03/21 17:22:56 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=853487124
16/03/21 17:22:56 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:22:56 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 813.9 MB)
16/03/21 17:22:56 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=853487124
16/03/21 17:22:56 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 813.9 MB)
16/03/21 17:22:56 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:37739 (size: 3.0 KB, free: 813.9 MB)
16/03/21 17:22:56 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:22:56 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:56 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:22:56 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:22:56 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:22:56 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:22:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:22:56 INFO PythonRunner: Times: total = 127, boot = 126, init = 1, finish = 0
16/03/21 17:22:56 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:22:56 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:22:56 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:22:56 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:22:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:22:56 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 158 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/03/21 17:22:56 INFO PythonRunner: Times: total = 158, boot = 157, init = 1, finish = 0
16/03/21 17:22:56 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1242 bytes result sent to driver
16/03/21 17:22:56 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.312 s
16/03/21 17:22:56 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.645344 s
16/03/21 17:22:56 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 178 ms on localhost (2/2)
16/03/21 17:22:56 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:22:56 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:22:56 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:22:56 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:56 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:22:56 INFO DAGScheduler: Missing parents: List()
16/03/21 17:22:56 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:22:56 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=853487124
16/03/21 17:22:56 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 813.9 MB)
16/03/21 17:22:56 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=853487124
16/03/21 17:22:56 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 813.9 MB)
16/03/21 17:22:56 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:37739 (size: 3.3 KB, free: 813.9 MB)
16/03/21 17:22:56 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:22:56 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:56 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:22:56 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:22:56 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:22:56 INFO PythonRunner: Times: total = 5, boot = -12, init = 17, finish = 0
16/03/21 17:22:56 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:22:56 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2272 bytes)
16/03/21 17:22:56 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 97 ms on localhost (1/2)
16/03/21 17:22:56 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:22:57 INFO PythonRunner: Times: total = 96, boot = 95, init = 0, finish = 1
16/03/21 17:22:57 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1311 bytes result sent to driver
16/03/21 17:22:57 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 114 ms on localhost (2/2)
16/03/21 17:22:57 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:22:57 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.207 s
16/03/21 17:22:57 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.269082 s
16/03/21 17:22:57 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:22:57 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:22:57 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:22:57 INFO MemoryStore: MemoryStore cleared
16/03/21 17:22:57 INFO BlockManager: BlockManager stopped
16/03/21 17:22:57 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:22:57 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:22:57 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:22:57 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:22:57 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:22:57 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:22:58 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:22:58 INFO SecurityManager: Changing view acls to: root
16/03/21 17:22:58 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:22:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:22:58 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:22:58 INFO Remoting: Starting remoting
16/03/21 17:22:58 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:50010]
16/03/21 17:22:58 INFO Utils: Successfully started service 'sparkDriver' on port 50010.
16/03/21 17:22:58 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:22:58 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:22:58 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-bc01a609-459f-4f00-a81e-93c339d69d11
16/03/21 17:22:58 INFO MemoryStore: MemoryStore started with capacity 813.9 MB
16/03/21 17:22:58 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-1bbf4ee7-404c-4265-9868-0f31bc3a704d
16/03/21 17:22:58 INFO HttpServer: Starting HTTP Server
16/03/21 17:22:58 INFO Utils: Successfully started service 'HTTP file server' on port 60763.
16/03/21 17:22:58 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:22:58 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:22:58 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:22:58 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-641136c7-4abc-4986-83b1-e919c44e2726/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:22:58 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561178324
16/03/21 17:22:58 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:22:58 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:22:58 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58471.
16/03/21 17:22:58 INFO NettyBlockTransferService: Server created on 58471
16/03/21 17:22:58 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:22:58 INFO BlockManagerMasterEndpoint: Registering block manager localhost:58471 with 813.9 MB RAM, BlockManagerId(driver, localhost, 58471)
16/03/21 17:22:58 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:22:58 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561178344
16/03/21 17:22:58 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:22:58 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:58 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:22:58 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:22:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:22:58 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:22:58 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=853487124
16/03/21 17:22:58 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 813.9 MB)
16/03/21 17:22:58 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=853487124
16/03/21 17:22:58 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 813.9 MB)
16/03/21 17:22:58 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:58471 (size: 4.1 KB, free: 813.9 MB)
16/03/21 17:22:58 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:22:58 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:22:58 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:22:58 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:22:58 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:22:58 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:22:58 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561178324
16/03/21 17:22:58 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-641136c7-4abc-4986-83b1-e919c44e2726/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:22:58 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:22:58 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=853487124
16/03/21 17:22:58 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 813.9 MB)
16/03/21 17:22:58 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:58471 (size: 166.0 B, free: 813.9 MB)
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: area
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: issue
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: planning
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: permission
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): adding to parents: syn =  Synset('permission.n.01') ; keyword:  approval  in syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= [u'permission']
reduceFunction_Parents(): returns= ['None', u'permission']
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: economy
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'permission']
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: composition
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'permission']
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: agency
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'permission']
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'permission']
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'permission']
16/03/21 17:23:06 INFO PythonRunner: Times: total = 7945, boot = 627, init = 363, finish = 6955
16/03/21 17:23:06 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:23:06 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:23:06 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:23:06 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8019 ms on localhost (1/2)
16/03/21 17:23:06 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:23:06 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=853487124
16/03/21 17:23:06 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 813.9 MB)
16/03/21 17:23:06 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:58471 (size: 155.0 B, free: 813.9 MB)
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: set
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: bend
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: giant
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: astatine
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: present
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: area
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:23:06 INFO PythonRunner: Times: total = 251, boot = 153, init = 1, finish = 97
16/03/21 17:23:06 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:23:06 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 292 ms on localhost (2/2)
16/03/21 17:23:06 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:23:06 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.302 s
16/03/21 17:23:06 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:23:06 INFO DAGScheduler: running: Set()
16/03/21 17:23:06 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:23:06 INFO DAGScheduler: failed: Set()
16/03/21 17:23:06 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:23:06 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:23:06 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=853487124
16/03/21 17:23:06 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 813.9 MB)
16/03/21 17:23:06 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=853487124
16/03/21 17:23:06 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 813.9 MB)
16/03/21 17:23:06 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:58471 (size: 3.0 KB, free: 813.9 MB)
16/03/21 17:23:06 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:23:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:23:06 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:23:06 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:23:06 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:23:06 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:23:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:23:06 INFO PythonRunner: Times: total = 131, boot = 130, init = 0, finish = 1
16/03/21 17:23:06 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:23:06 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:23:06 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:23:06 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:23:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:23:06 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 153 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'permission', 'None']
16/03/21 17:23:07 INFO PythonRunner: Times: total = 157, boot = 157, init = 0, finish = 0
16/03/21 17:23:07 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1244 bytes result sent to driver
16/03/21 17:23:07 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 171 ms on localhost (2/2)
16/03/21 17:23:07 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.306 s
16/03/21 17:23:07 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.649136 s
16/03/21 17:23:07 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:23:07 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:23:07 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:23:07 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:23:07 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:23:07 INFO DAGScheduler: Missing parents: List()
16/03/21 17:23:07 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:23:07 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=853487124
16/03/21 17:23:07 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 813.9 MB)
16/03/21 17:23:07 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=853487124
16/03/21 17:23:07 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 813.9 MB)
16/03/21 17:23:07 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:58471 (size: 3.3 KB, free: 813.9 MB)
16/03/21 17:23:07 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:23:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:23:07 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:23:07 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:23:07 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:23:07 INFO PythonRunner: Times: total = 109, boot = 108, init = 0, finish = 1
16/03/21 17:23:07 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:23:07 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2274 bytes)
16/03/21 17:23:07 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:23:07 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 127 ms on localhost (1/2)
16/03/21 17:23:07 INFO PythonRunner: Times: total = 185, boot = 185, init = 0, finish = 0
16/03/21 17:23:07 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1313 bytes result sent to driver
16/03/21 17:23:07 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 208 ms on localhost (2/2)
16/03/21 17:23:07 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:23:07 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.327 s
16/03/21 17:23:07 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.343929 s
16/03/21 17:23:07 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:23:07 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:23:07 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:23:07 INFO MemoryStore: MemoryStore cleared
16/03/21 17:23:07 INFO BlockManager: BlockManager stopped
16/03/21 17:23:07 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:23:07 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:23:07 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:23:07 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:23:07 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:23:08 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:23:08 INFO SecurityManager: Changing view acls to: root
16/03/21 17:23:08 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:23:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:23:08 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:23:08 INFO Remoting: Starting remoting
16/03/21 17:23:08 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:59584]
16/03/21 17:23:08 INFO Utils: Successfully started service 'sparkDriver' on port 59584.
16/03/21 17:23:08 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:23:08 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:23:08 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-664dd81c-ebc1-4675-a731-c68214ce2f67
16/03/21 17:23:08 INFO MemoryStore: MemoryStore started with capacity 811.9 MB
16/03/21 17:23:08 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-7356b28c-8357-4838-a334-02aaedcdf118
16/03/21 17:23:08 INFO HttpServer: Starting HTTP Server
16/03/21 17:23:08 INFO Utils: Successfully started service 'HTTP file server' on port 38083.
16/03/21 17:23:08 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:23:08 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:23:08 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:23:08 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-0b3ffa9f-5b1a-4c08-bbdd-8f7dcac8dfd3/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:23:08 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561188776
16/03/21 17:23:08 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:23:08 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:23:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40603.
16/03/21 17:23:08 INFO NettyBlockTransferService: Server created on 40603
16/03/21 17:23:08 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:23:08 INFO BlockManagerMasterEndpoint: Registering block manager localhost:40603 with 811.9 MB RAM, BlockManagerId(driver, localhost, 40603)
16/03/21 17:23:08 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:23:08 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561188787
16/03/21 17:23:08 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:23:08 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:23:08 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:23:08 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:23:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:23:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:23:08 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:23:08 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=851363758
16/03/21 17:23:08 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 811.9 MB)
16/03/21 17:23:08 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=851363758
16/03/21 17:23:08 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 811.9 MB)
16/03/21 17:23:08 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:40603 (size: 4.1 KB, free: 811.9 MB)
16/03/21 17:23:08 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:23:08 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:23:08 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:23:08 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:23:08 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:23:08 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561188776
16/03/21 17:23:08 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:23:08 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-0b3ffa9f-5b1a-4c08-bbdd-8f7dcac8dfd3/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:23:08 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:23:08 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=851363758
16/03/21 17:23:08 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 811.9 MB)
16/03/21 17:23:08 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:40603 (size: 166.0 B, free: 811.9 MB)
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: area
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: issue
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: planning
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: permission
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: economy
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: composition
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: agency
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:23:16 INFO PythonRunner: Times: total = 7975, boot = 458, init = 416, finish = 7101
16/03/21 17:23:16 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:23:16 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:23:16 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:23:16 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8041 ms on localhost (1/2)
16/03/21 17:23:16 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:23:16 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=851363758
16/03/21 17:23:16 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 811.9 MB)
16/03/21 17:23:16 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:40603 (size: 155.0 B, free: 811.9 MB)
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: set
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: bend
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: giant
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: astatine
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: present
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: area
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:23:17 INFO PythonRunner: Times: total = 258, boot = 158, init = 0, finish = 100
16/03/21 17:23:17 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:23:17 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.336 s
16/03/21 17:23:17 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:23:17 INFO DAGScheduler: running: Set()
16/03/21 17:23:17 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:23:17 INFO DAGScheduler: failed: Set()
16/03/21 17:23:17 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:23:17 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:23:17 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=851363758
16/03/21 17:23:17 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 811.9 MB)
16/03/21 17:23:17 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 299 ms on localhost (2/2)
16/03/21 17:23:17 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:23:17 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=851363758
16/03/21 17:23:17 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 811.9 MB)
16/03/21 17:23:17 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:40603 (size: 3.0 KB, free: 811.9 MB)
16/03/21 17:23:17 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:23:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:23:17 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:23:17 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:23:17 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:23:17 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:23:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:23:17 INFO PythonRunner: Times: total = 160, boot = 159, init = 0, finish = 1
16/03/21 17:23:17 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:23:17 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:23:17 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:23:17 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:23:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:23:17 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 184 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None']
16/03/21 17:23:17 INFO PythonRunner: Times: total = 185, boot = 184, init = 0, finish = 1
16/03/21 17:23:17 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1227 bytes result sent to driver
16/03/21 17:23:17 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.370 s
16/03/21 17:23:17 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.732938 s
16/03/21 17:23:17 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 200 ms on localhost (2/2)
16/03/21 17:23:17 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:23:17 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:23:17 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:23:17 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:23:17 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:23:17 INFO DAGScheduler: Missing parents: List()
16/03/21 17:23:17 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:23:17 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=851363758
16/03/21 17:23:17 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 811.9 MB)
16/03/21 17:23:17 INFO MemoryStore: ensureFreeSpace(3371) called with curMem=24893, maxMem=851363758
16/03/21 17:23:17 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 811.9 MB)
16/03/21 17:23:17 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:40603 (size: 3.3 KB, free: 811.9 MB)
16/03/21 17:23:17 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:23:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:23:17 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:23:17 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:23:17 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:23:17 INFO PythonRunner: Times: total = 113, boot = 113, init = 0, finish = 0
16/03/21 17:23:17 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:23:17 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2257 bytes)
16/03/21 17:23:17 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 132 ms on localhost (1/2)
16/03/21 17:23:17 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:23:18 INFO PythonRunner: Times: total = 168, boot = 168, init = 0, finish = 0
16/03/21 17:23:18 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1296 bytes result sent to driver
16/03/21 17:23:18 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.321 s
16/03/21 17:23:18 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.351259 s
16/03/21 17:23:18 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 193 ms on localhost (2/2)
16/03/21 17:23:18 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:23:18 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:23:18 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:23:18 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:23:18 INFO MemoryStore: MemoryStore cleared
16/03/21 17:23:18 INFO BlockManager: BlockManager stopped
16/03/21 17:23:18 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:23:18 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:23:18 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:23:18 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:23:18 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:23:18 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:23:19 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:23:19 INFO SecurityManager: Changing view acls to: root
16/03/21 17:23:19 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:23:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:23:19 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:23:19 INFO Remoting: Starting remoting
16/03/21 17:23:19 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:34035]
16/03/21 17:23:19 INFO Utils: Successfully started service 'sparkDriver' on port 34035.
16/03/21 17:23:19 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:23:19 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:23:19 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3639f8e4-632d-45a1-b795-32b893f3be5b
16/03/21 17:23:19 INFO MemoryStore: MemoryStore started with capacity 811.9 MB
16/03/21 17:23:19 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-38495158-268d-4168-93a3-a46637f82f41
16/03/21 17:23:19 INFO HttpServer: Starting HTTP Server
16/03/21 17:23:19 INFO Utils: Successfully started service 'HTTP file server' on port 59529.
16/03/21 17:23:19 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:23:19 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:23:19 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:23:19 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-d4682450-a4ca-4718-9ecd-b3a3bea5d5c0/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:23:19 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561199321
16/03/21 17:23:19 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:23:19 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:23:19 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56124.
16/03/21 17:23:19 INFO NettyBlockTransferService: Server created on 56124
16/03/21 17:23:19 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:23:19 INFO BlockManagerMasterEndpoint: Registering block manager localhost:56124 with 811.9 MB RAM, BlockManagerId(driver, localhost, 56124)
16/03/21 17:23:19 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:23:19 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561199333
16/03/21 17:23:19 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:23:19 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:23:19 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:23:19 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:23:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:23:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:23:19 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:23:19 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=851363758
16/03/21 17:23:19 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 811.9 MB)
16/03/21 17:23:19 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=851363758
16/03/21 17:23:19 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 811.9 MB)
16/03/21 17:23:19 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:56124 (size: 4.1 KB, free: 811.9 MB)
16/03/21 17:23:19 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:23:19 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:23:19 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:23:19 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:23:19 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:23:19 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:23:19 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561199321
16/03/21 17:23:19 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-d4682450-a4ca-4718-9ecd-b3a3bea5d5c0/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:23:19 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:23:19 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=851363758
16/03/21 17:23:19 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 811.9 MB)
16/03/21 17:23:19 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:56124 (size: 166.0 B, free: 811.9 MB)
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: area
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  region  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: issue
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: planning
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: permission
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: economy
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: composition
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: agency
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/21 17:23:27 INFO PythonRunner: Times: total = 8283, boot = 559, init = 417, finish = 7307
16/03/21 17:23:27 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:23:27 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:23:27 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:23:27 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:23:27 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8385 ms on localhost (1/2)
16/03/21 17:23:27 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=851363758
16/03/21 17:23:27 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 811.9 MB)
16/03/21 17:23:27 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:56124 (size: 155.0 B, free: 811.9 MB)
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: set
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: bend
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: giant
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: astatine
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: present
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: area
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  region  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/21 17:23:28 INFO PythonRunner: Times: total = 265, boot = 168, init = 1, finish = 96
16/03/21 17:23:28 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:23:28 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 291 ms on localhost (2/2)
16/03/21 17:23:28 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:23:28 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.671 s
16/03/21 17:23:28 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:23:28 INFO DAGScheduler: running: Set()
16/03/21 17:23:28 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:23:28 INFO DAGScheduler: failed: Set()
16/03/21 17:23:28 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:23:28 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:23:28 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=851363758
16/03/21 17:23:28 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 811.9 MB)
16/03/21 17:23:28 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=851363758
16/03/21 17:23:28 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 811.9 MB)
16/03/21 17:23:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:56124 (size: 3.0 KB, free: 811.9 MB)
16/03/21 17:23:28 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:23:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:23:28 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:23:28 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:23:28 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:23:28 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:23:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:23:28 INFO PythonRunner: Times: total = 161, boot = 161, init = 0, finish = 0
16/03/21 17:23:28 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:23:28 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:23:28 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:23:28 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:23:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:23:28 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 184 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'area', 'None', u'area']
16/03/21 17:23:28 INFO PythonRunner: Times: total = 159, boot = 159, init = 0, finish = 0
16/03/21 17:23:28 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/21 17:23:28 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 177 ms on localhost (2/2)
16/03/21 17:23:28 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:23:28 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.343 s
16/03/21 17:23:28 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.049055 s
16/03/21 17:23:28 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:23:28 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:23:28 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:23:28 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:23:28 INFO DAGScheduler: Missing parents: List()
16/03/21 17:23:28 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:23:28 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=851363758
16/03/21 17:23:28 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 811.9 MB)
16/03/21 17:23:28 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=851363758
16/03/21 17:23:28 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 811.9 MB)
16/03/21 17:23:28 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:56124 (size: 3.3 KB, free: 811.9 MB)
16/03/21 17:23:28 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:23:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:23:28 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:23:28 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:23:28 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:23:28 INFO PythonRunner: Times: total = 99, boot = 99, init = 0, finish = 0
16/03/21 17:23:28 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:23:28 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/21 17:23:28 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 115 ms on localhost (1/2)
16/03/21 17:23:28 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:23:28 INFO PythonRunner: Times: total = 157, boot = 156, init = 0, finish = 1
16/03/21 17:23:28 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1307 bytes result sent to driver
16/03/21 17:23:28 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.288 s
16/03/21 17:23:28 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.298687 s
16/03/21 17:23:28 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 176 ms on localhost (2/2)
16/03/21 17:23:28 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:23:28 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:23:28 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:23:29 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:23:29 INFO MemoryStore: MemoryStore cleared
16/03/21 17:23:29 INFO BlockManager: BlockManager stopped
16/03/21 17:23:29 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:23:29 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:23:29 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:23:29 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:23:29 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:23:29 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:23:29 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:23:29 INFO SecurityManager: Changing view acls to: root
16/03/21 17:23:29 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:23:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:23:29 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:23:29 INFO Remoting: Starting remoting
16/03/21 17:23:30 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:50415]
16/03/21 17:23:30 INFO Utils: Successfully started service 'sparkDriver' on port 50415.
16/03/21 17:23:30 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:23:30 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:23:30 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-6dfe3b8a-2fe8-4380-8433-e822c95f38f2
16/03/21 17:23:30 INFO MemoryStore: MemoryStore started with capacity 811.9 MB
16/03/21 17:23:30 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-0dbac418-6b1d-4ade-ad82-4a38f7fc5831
16/03/21 17:23:30 INFO HttpServer: Starting HTTP Server
16/03/21 17:23:30 INFO Utils: Successfully started service 'HTTP file server' on port 56278.
16/03/21 17:23:30 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:23:30 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:23:30 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:23:30 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-efe18950-e9ce-45b9-b9d8-a432ef1dc11e/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:23:30 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561210171
16/03/21 17:23:30 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:23:30 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:23:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35767.
16/03/21 17:23:30 INFO NettyBlockTransferService: Server created on 35767
16/03/21 17:23:30 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:23:30 INFO BlockManagerMasterEndpoint: Registering block manager localhost:35767 with 811.9 MB RAM, BlockManagerId(driver, localhost, 35767)
16/03/21 17:23:30 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:23:30 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561210187
16/03/21 17:23:30 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:23:30 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:23:30 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:23:30 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:23:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:23:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:23:30 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:23:30 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=851363758
16/03/21 17:23:30 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 811.9 MB)
16/03/21 17:23:30 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=851363758
16/03/21 17:23:30 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 811.9 MB)
16/03/21 17:23:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:35767 (size: 4.1 KB, free: 811.9 MB)
16/03/21 17:23:30 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:23:30 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:23:30 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:23:30 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:23:30 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:23:30 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:23:30 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561210171
16/03/21 17:23:30 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-efe18950-e9ce-45b9-b9d8-a432ef1dc11e/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:23:30 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:23:30 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=851363758
16/03/21 17:23:30 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 811.9 MB)
16/03/21 17:23:30 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:35767 (size: 166.0 B, free: 811.9 MB)
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: area
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: issue
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: planning
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: permission
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: economy
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: composition
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: agency
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:23:38 INFO PythonRunner: Times: total = 7982, boot = 463, init = 383, finish = 7136
16/03/21 17:23:38 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:23:38 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:23:38 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:23:38 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:23:38 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=851363758
16/03/21 17:23:38 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 811.9 MB)
16/03/21 17:23:38 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8078 ms on localhost (1/2)
16/03/21 17:23:38 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:35767 (size: 155.0 B, free: 811.9 MB)
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: set
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: bend
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: giant
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: astatine
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: present
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  title  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: area
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
16/03/21 17:23:38 INFO PythonRunner: Times: total = 233, boot = 137, init = 0, finish = 96
16/03/21 17:23:38 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:23:38 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 277 ms on localhost (2/2)
16/03/21 17:23:38 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:23:38 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.333 s
16/03/21 17:23:38 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:23:38 INFO DAGScheduler: running: Set()
16/03/21 17:23:38 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:23:38 INFO DAGScheduler: failed: Set()
16/03/21 17:23:38 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:23:38 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:23:38 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=851363758
16/03/21 17:23:38 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 811.9 MB)
16/03/21 17:23:38 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=851363758
16/03/21 17:23:38 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 811.9 MB)
16/03/21 17:23:38 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:35767 (size: 3.0 KB, free: 811.9 MB)
16/03/21 17:23:38 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:23:38 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:23:38 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:23:38 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:23:38 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:23:38 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:23:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:23:38 INFO PythonRunner: Times: total = 121, boot = 120, init = 1, finish = 0
16/03/21 17:23:38 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:23:38 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:23:38 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:23:38 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:23:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:23:38 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 149 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'metropolitan']
16/03/21 17:23:38 INFO PythonRunner: Times: total = 152, boot = 151, init = 0, finish = 1
16/03/21 17:23:38 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1246 bytes result sent to driver
16/03/21 17:23:38 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.289 s
16/03/21 17:23:38 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.677516 s
16/03/21 17:23:38 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 167 ms on localhost (2/2)
16/03/21 17:23:38 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:23:39 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:23:39 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:23:39 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:23:39 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:23:39 INFO DAGScheduler: Missing parents: List()
16/03/21 17:23:39 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:23:39 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=851363758
16/03/21 17:23:39 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 811.9 MB)
16/03/21 17:23:39 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=851363758
16/03/21 17:23:39 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 811.9 MB)
16/03/21 17:23:39 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:35767 (size: 3.3 KB, free: 811.9 MB)
16/03/21 17:23:39 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:23:39 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:23:39 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:23:39 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:23:39 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:23:39 INFO PythonRunner: Times: total = 116, boot = 116, init = 0, finish = 0
16/03/21 17:23:39 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:23:39 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2276 bytes)
16/03/21 17:23:39 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 133 ms on localhost (1/2)
16/03/21 17:23:39 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:23:39 INFO PythonRunner: Times: total = 163, boot = 163, init = 0, finish = 0
16/03/21 17:23:39 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1315 bytes result sent to driver
16/03/21 17:23:39 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.307 s
16/03/21 17:23:39 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.341267 s
16/03/21 17:23:39 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 187 ms on localhost (2/2)
16/03/21 17:23:39 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:23:39 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:23:39 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:23:39 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:23:39 INFO MemoryStore: MemoryStore cleared
16/03/21 17:23:39 INFO BlockManager: BlockManager stopped
16/03/21 17:23:39 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:23:39 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:23:39 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:23:39 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:23:39 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:23:39 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:23:40 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:23:40 INFO SecurityManager: Changing view acls to: root
16/03/21 17:23:40 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:23:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:23:40 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:23:40 INFO Remoting: Starting remoting
16/03/21 17:23:40 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:51660]
16/03/21 17:23:40 INFO Utils: Successfully started service 'sparkDriver' on port 51660.
16/03/21 17:23:40 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:23:40 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:23:40 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b960dfd6-4fb6-4ed9-809c-47424cca2660
16/03/21 17:23:40 INFO MemoryStore: MemoryStore started with capacity 811.9 MB
16/03/21 17:23:40 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-481551c4-411d-44ef-9278-bc6cea907985
16/03/21 17:23:40 INFO HttpServer: Starting HTTP Server
16/03/21 17:23:40 INFO Utils: Successfully started service 'HTTP file server' on port 35685.
16/03/21 17:23:40 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:23:40 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:23:40 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:23:41 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-8874989a-0ef2-4431-ad20-ab80bf4cbb53/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:23:41 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561221016
16/03/21 17:23:41 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:23:41 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:23:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59635.
16/03/21 17:23:41 INFO NettyBlockTransferService: Server created on 59635
16/03/21 17:23:41 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:23:41 INFO BlockManagerMasterEndpoint: Registering block manager localhost:59635 with 811.9 MB RAM, BlockManagerId(driver, localhost, 59635)
16/03/21 17:23:41 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:23:41 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561221025
16/03/21 17:23:41 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:23:41 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:23:41 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:23:41 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:23:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:23:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:23:41 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:23:41 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=851363758
16/03/21 17:23:41 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 811.9 MB)
16/03/21 17:23:41 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=851363758
16/03/21 17:23:41 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 811.9 MB)
16/03/21 17:23:41 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:59635 (size: 4.1 KB, free: 811.9 MB)
16/03/21 17:23:41 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:23:41 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:23:41 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:23:41 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:23:41 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:23:41 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:23:41 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561221016
16/03/21 17:23:41 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-8874989a-0ef2-4431-ad20-ab80bf4cbb53/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:23:41 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:23:41 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=851363758
16/03/21 17:23:41 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 811.9 MB)
16/03/21 17:23:41 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:59635 (size: 166.0 B, free: 811.9 MB)
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: area
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: issue
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: planning
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: permission
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: economy
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: composition
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: agency
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): adding to parents: syn =  Synset('kilometer.n.01') ; keyword:  equal  in syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= [u'kilometer']
reduceFunction_Parents(): returns= ['None', u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'kilometer']
16/03/21 17:23:48 INFO PythonRunner: Times: total = 7750, boot = 441, init = 359, finish = 6950
16/03/21 17:23:48 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:23:48 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:23:48 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:23:48 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:23:48 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=851363758
16/03/21 17:23:48 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 811.9 MB)
16/03/21 17:23:48 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7825 ms on localhost (1/2)
16/03/21 17:23:48 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:59635 (size: 155.0 B, free: 811.9 MB)
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: set
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: bend
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: giant
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: astatine
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: present
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: area
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): adding to parents: syn =  Synset('kilometer.n.01') ; keyword:  equal  in syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= [u'kilometer']
reduceFunction_Parents(): returns= ['None', u'kilometer']
16/03/21 17:23:49 INFO PythonRunner: Times: total = 273, boot = 171, init = 1, finish = 101
16/03/21 17:23:49 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:23:49 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.133 s
16/03/21 17:23:49 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:23:49 INFO DAGScheduler: running: Set()
16/03/21 17:23:49 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:23:49 INFO DAGScheduler: failed: Set()
16/03/21 17:23:49 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:23:49 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:23:49 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=851363758
16/03/21 17:23:49 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 811.9 MB)
16/03/21 17:23:49 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 322 ms on localhost (2/2)
16/03/21 17:23:49 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:23:49 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=851363758
16/03/21 17:23:49 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 811.9 MB)
16/03/21 17:23:49 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:59635 (size: 3.0 KB, free: 811.9 MB)
16/03/21 17:23:49 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:23:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:23:49 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:23:49 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:23:49 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:23:49 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:23:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:23:49 INFO PythonRunner: Times: total = 109, boot = 108, init = 0, finish = 1
16/03/21 17:23:49 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:23:49 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:23:49 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:23:49 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:23:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:23:49 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 129 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'kilometer', 'None', u'kilometer']
16/03/21 17:23:49 INFO PythonRunner: Times: total = 160, boot = 159, init = 1, finish = 0
16/03/21 17:23:49 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1259 bytes result sent to driver
16/03/21 17:23:49 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.298 s
16/03/21 17:23:49 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.477183 s
16/03/21 17:23:49 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 173 ms on localhost (2/2)
16/03/21 17:23:49 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:23:49 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:23:49 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:23:49 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:23:49 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:23:49 INFO DAGScheduler: Missing parents: List()
16/03/21 17:23:49 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:23:49 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=851363758
16/03/21 17:23:49 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 811.9 MB)
16/03/21 17:23:49 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=851363758
16/03/21 17:23:49 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 811.9 MB)
16/03/21 17:23:49 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:59635 (size: 3.3 KB, free: 811.9 MB)
16/03/21 17:23:49 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:23:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:23:49 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:23:49 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:23:49 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:23:49 INFO PythonRunner: Times: total = 132, boot = 131, init = 1, finish = 0
16/03/21 17:23:49 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:23:49 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2289 bytes)
16/03/21 17:23:49 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:23:49 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 157 ms on localhost (1/2)
16/03/21 17:23:50 INFO PythonRunner: Times: total = 182, boot = 182, init = 0, finish = 0
16/03/21 17:23:50 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1328 bytes result sent to driver
16/03/21 17:23:50 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 208 ms on localhost (2/2)
16/03/21 17:23:50 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:23:50 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.340 s
16/03/21 17:23:50 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.379534 s
16/03/21 17:23:50 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:23:50 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:23:50 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:23:50 INFO MemoryStore: MemoryStore cleared
16/03/21 17:23:50 INFO BlockManager: BlockManager stopped
16/03/21 17:23:50 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:23:50 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:23:50 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:23:50 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:23:50 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:23:50 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:23:51 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:23:51 INFO SecurityManager: Changing view acls to: root
16/03/21 17:23:51 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:23:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:23:51 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:23:51 INFO Remoting: Starting remoting
16/03/21 17:23:51 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:38468]
16/03/21 17:23:51 INFO Utils: Successfully started service 'sparkDriver' on port 38468.
16/03/21 17:23:51 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:23:51 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:23:51 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e2e83659-5a72-43d9-ae43-5e2246a78c85
16/03/21 17:23:51 INFO MemoryStore: MemoryStore started with capacity 811.9 MB
16/03/21 17:23:51 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-de2872b3-93f8-41ef-ab53-92b40fbb9b57
16/03/21 17:23:51 INFO HttpServer: Starting HTTP Server
16/03/21 17:23:51 INFO Utils: Successfully started service 'HTTP file server' on port 57582.
16/03/21 17:23:51 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:23:51 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:23:51 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:23:51 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-eff1e430-58e8-469e-ab71-4f1c2e74e2dd/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:23:51 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561231273
16/03/21 17:23:51 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:23:51 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:23:51 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34869.
16/03/21 17:23:51 INFO NettyBlockTransferService: Server created on 34869
16/03/21 17:23:51 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:23:51 INFO BlockManagerMasterEndpoint: Registering block manager localhost:34869 with 811.9 MB RAM, BlockManagerId(driver, localhost, 34869)
16/03/21 17:23:51 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:23:51 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561231283
16/03/21 17:23:51 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:23:51 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:23:51 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:23:51 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:23:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:23:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:23:51 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:23:51 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=851363758
16/03/21 17:23:51 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 811.9 MB)
16/03/21 17:23:51 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=851363758
16/03/21 17:23:51 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 811.9 MB)
16/03/21 17:23:51 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:34869 (size: 4.1 KB, free: 811.9 MB)
16/03/21 17:23:51 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:23:51 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:23:51 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:23:51 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:23:51 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:23:51 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:23:51 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561231273
16/03/21 17:23:51 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-eff1e430-58e8-469e-ab71-4f1c2e74e2dd/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:23:51 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:23:51 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=851363758
16/03/21 17:23:51 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 811.9 MB)
16/03/21 17:23:51 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:34869 (size: 166.0 B, free: 811.9 MB)
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: area
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: issue
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: planning
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: permission
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: economy
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: composition
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: agency
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): adding to parents: syn =  Synset('kilometer.n.01') ; keyword:  length  in syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= [u'kilometer']
reduceFunction_Parents(): returns= ['None', u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'kilometer']
16/03/21 17:23:59 INFO PythonRunner: Times: total = 7882, boot = 453, init = 355, finish = 7074
16/03/21 17:23:59 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:23:59 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:23:59 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:23:59 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:23:59 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=851363758
16/03/21 17:23:59 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 811.9 MB)
16/03/21 17:23:59 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7977 ms on localhost (1/2)
16/03/21 17:23:59 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:34869 (size: 155.0 B, free: 811.9 MB)
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: set
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: bend
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: giant
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: astatine
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: present
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: area
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): adding to parents: syn =  Synset('kilometer.n.01') ; keyword:  length  in syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= [u'kilometer']
reduceFunction_Parents(): returns= ['None', u'kilometer']
16/03/21 17:23:59 INFO PythonRunner: Times: total = 231, boot = 136, init = 1, finish = 94
16/03/21 17:23:59 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:23:59 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.248 s
16/03/21 17:23:59 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:23:59 INFO DAGScheduler: running: Set()
16/03/21 17:23:59 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:23:59 INFO DAGScheduler: failed: Set()
16/03/21 17:23:59 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:23:59 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:23:59 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=851363758
16/03/21 17:23:59 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 811.9 MB)
16/03/21 17:23:59 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 279 ms on localhost (2/2)
16/03/21 17:23:59 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:23:59 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=851363758
16/03/21 17:23:59 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 811.9 MB)
16/03/21 17:23:59 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:34869 (size: 3.0 KB, free: 811.9 MB)
16/03/21 17:23:59 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:23:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:23:59 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:23:59 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:23:59 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:23:59 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:23:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:23:59 INFO PythonRunner: Times: total = 114, boot = 114, init = 0, finish = 0
16/03/21 17:23:59 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:23:59 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:23:59 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:23:59 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:23:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:23:59 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 149 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'kilometer', 'None', u'kilometer']
16/03/21 17:23:59 INFO PythonRunner: Times: total = 141, boot = 141, init = 0, finish = 0
16/03/21 17:23:59 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1259 bytes result sent to driver
16/03/21 17:23:59 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.291 s
16/03/21 17:23:59 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.582925 s
16/03/21 17:23:59 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 158 ms on localhost (2/2)
16/03/21 17:23:59 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:24:00 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:24:00 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:24:00 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:00 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:24:00 INFO DAGScheduler: Missing parents: List()
16/03/21 17:24:00 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:24:00 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=851363758
16/03/21 17:24:00 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 811.9 MB)
16/03/21 17:24:00 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=851363758
16/03/21 17:24:00 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 811.9 MB)
16/03/21 17:24:00 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:34869 (size: 3.3 KB, free: 811.9 MB)
16/03/21 17:24:00 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:24:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:00 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:24:00 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:24:00 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:24:00 INFO PythonRunner: Times: total = 51, boot = 50, init = 0, finish = 1
16/03/21 17:24:00 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:24:00 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2289 bytes)
16/03/21 17:24:00 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:24:00 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 70 ms on localhost (1/2)
16/03/21 17:24:00 INFO PythonRunner: Times: total = 160, boot = 160, init = 0, finish = 0
16/03/21 17:24:00 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1328 bytes result sent to driver
16/03/21 17:24:00 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 185 ms on localhost (2/2)
16/03/21 17:24:00 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:24:00 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.242 s
16/03/21 17:24:00 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.281925 s
16/03/21 17:24:00 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:24:00 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:24:00 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:24:00 INFO MemoryStore: MemoryStore cleared
16/03/21 17:24:00 INFO BlockManager: BlockManager stopped
16/03/21 17:24:00 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:24:00 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:24:00 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:24:00 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:24:01 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:24:01 INFO SecurityManager: Changing view acls to: root
16/03/21 17:24:01 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:24:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:24:01 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:24:01 INFO Remoting: Starting remoting
16/03/21 17:24:01 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:49258]
16/03/21 17:24:01 INFO Utils: Successfully started service 'sparkDriver' on port 49258.
16/03/21 17:24:01 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:24:01 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:24:01 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-aa4a7fdd-6db9-400e-b098-1eea057c1337
16/03/21 17:24:01 INFO MemoryStore: MemoryStore started with capacity 811.9 MB
16/03/21 17:24:01 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-459930cf-b317-4e91-96c6-39a2f0aea45b
16/03/21 17:24:01 INFO HttpServer: Starting HTTP Server
16/03/21 17:24:01 INFO Utils: Successfully started service 'HTTP file server' on port 43417.
16/03/21 17:24:01 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:24:01 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:24:01 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:24:01 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-722777ad-bd6f-4fc1-9df9-a9a4597c5bdc/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:24:01 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561241765
16/03/21 17:24:01 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:24:01 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:24:01 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60772.
16/03/21 17:24:01 INFO NettyBlockTransferService: Server created on 60772
16/03/21 17:24:01 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:24:01 INFO BlockManagerMasterEndpoint: Registering block manager localhost:60772 with 811.9 MB RAM, BlockManagerId(driver, localhost, 60772)
16/03/21 17:24:01 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:24:01 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561241778
16/03/21 17:24:01 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:24:01 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:01 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:24:01 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:24:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:24:01 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:24:01 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=851363758
16/03/21 17:24:01 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 811.9 MB)
16/03/21 17:24:01 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=851363758
16/03/21 17:24:01 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 811.9 MB)
16/03/21 17:24:01 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:60772 (size: 4.1 KB, free: 811.9 MB)
16/03/21 17:24:01 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:24:01 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:01 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:24:01 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:24:01 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:24:01 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:24:01 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561241765
16/03/21 17:24:01 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-722777ad-bd6f-4fc1-9df9-a9a4597c5bdc/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:24:01 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:24:01 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=851363758
16/03/21 17:24:01 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 811.9 MB)
16/03/21 17:24:01 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:60772 (size: 166.0 B, free: 811.9 MB)
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: area
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: issue
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: planning
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: permission
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: economy
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: composition
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  resulting  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: agency
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/21 17:24:09 INFO PythonRunner: Times: total = 7719, boot = 446, init = 357, finish = 6916
16/03/21 17:24:09 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:24:09 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:24:09 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:24:09 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:24:09 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=851363758
16/03/21 17:24:09 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 811.9 MB)
16/03/21 17:24:09 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:60772 (size: 155.0 B, free: 811.9 MB)
16/03/21 17:24:09 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7788 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: set
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: bend
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: giant
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: astatine
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: present
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: area
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:24:09 INFO PythonRunner: Times: total = 257, boot = 163, init = 1, finish = 93
16/03/21 17:24:09 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:24:10 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 306 ms on localhost (2/2)
16/03/21 17:24:10 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:24:10 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.084 s
16/03/21 17:24:10 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:24:10 INFO DAGScheduler: running: Set()
16/03/21 17:24:10 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:24:10 INFO DAGScheduler: failed: Set()
16/03/21 17:24:10 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:24:10 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:24:10 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=851363758
16/03/21 17:24:10 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 811.9 MB)
16/03/21 17:24:10 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=851363758
16/03/21 17:24:10 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 811.9 MB)
16/03/21 17:24:10 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:60772 (size: 3.0 KB, free: 811.9 MB)
16/03/21 17:24:10 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:24:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:10 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:24:10 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:24:10 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:24:10 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:24:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:24:10 INFO PythonRunner: Times: total = 116, boot = 115, init = 1, finish = 0
16/03/21 17:24:10 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:24:10 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:24:10 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:24:10 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:24:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:24:10 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 138 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'composition', 'None']
16/03/21 17:24:10 INFO PythonRunner: Times: total = 157, boot = 156, init = 1, finish = 0
16/03/21 17:24:10 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1245 bytes result sent to driver
16/03/21 17:24:10 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.293 s
16/03/21 17:24:10 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.427023 s
16/03/21 17:24:10 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 171 ms on localhost (2/2)
16/03/21 17:24:10 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:24:10 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:24:10 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:24:10 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:10 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:24:10 INFO DAGScheduler: Missing parents: List()
16/03/21 17:24:10 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:24:10 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=851363758
16/03/21 17:24:10 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 811.9 MB)
16/03/21 17:24:10 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=851363758
16/03/21 17:24:10 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 811.9 MB)
16/03/21 17:24:10 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:60772 (size: 3.3 KB, free: 811.9 MB)
16/03/21 17:24:10 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:24:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:10 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:24:10 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:24:10 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:24:10 INFO PythonRunner: Times: total = 75, boot = 75, init = 0, finish = 0
16/03/21 17:24:10 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:24:10 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2275 bytes)
16/03/21 17:24:10 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 93 ms on localhost (1/2)
16/03/21 17:24:10 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:24:10 INFO PythonRunner: Times: total = 147, boot = 147, init = 0, finish = 0
16/03/21 17:24:10 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1314 bytes result sent to driver
16/03/21 17:24:10 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 170 ms on localhost (2/2)
16/03/21 17:24:10 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:24:10 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.251 s
16/03/21 17:24:10 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.270361 s
16/03/21 17:24:10 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:24:10 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:24:10 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:24:10 INFO MemoryStore: MemoryStore cleared
16/03/21 17:24:10 INFO BlockManager: BlockManager stopped
16/03/21 17:24:10 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:24:10 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:24:10 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:24:10 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:24:10 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:24:10 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:24:11 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:24:11 INFO SecurityManager: Changing view acls to: root
16/03/21 17:24:11 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:24:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:24:11 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:24:11 INFO Remoting: Starting remoting
16/03/21 17:24:11 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:51079]
16/03/21 17:24:11 INFO Utils: Successfully started service 'sparkDriver' on port 51079.
16/03/21 17:24:11 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:24:11 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:24:11 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-791959a9-e35f-4910-897f-7dbee0c2a4cb
16/03/21 17:24:11 INFO MemoryStore: MemoryStore started with capacity 811.9 MB
16/03/21 17:24:11 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-34181e56-3b9b-4cd2-a601-fffa1ae4296a
16/03/21 17:24:11 INFO HttpServer: Starting HTTP Server
16/03/21 17:24:11 INFO Utils: Successfully started service 'HTTP file server' on port 53436.
16/03/21 17:24:11 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:24:11 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:24:11 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:24:11 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-f074abbd-ab75-4ab4-8b93-8d00b8377e06/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:24:11 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561251945
16/03/21 17:24:11 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:24:11 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:24:12 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46527.
16/03/21 17:24:12 INFO NettyBlockTransferService: Server created on 46527
16/03/21 17:24:12 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:24:12 INFO BlockManagerMasterEndpoint: Registering block manager localhost:46527 with 811.9 MB RAM, BlockManagerId(driver, localhost, 46527)
16/03/21 17:24:12 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:24:12 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561251965
16/03/21 17:24:12 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:24:12 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:12 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:24:12 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:24:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:24:12 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:24:12 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=851363758
16/03/21 17:24:12 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 811.9 MB)
16/03/21 17:24:12 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=851363758
16/03/21 17:24:12 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 811.9 MB)
16/03/21 17:24:12 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:46527 (size: 4.1 KB, free: 811.9 MB)
16/03/21 17:24:12 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:24:12 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:12 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:24:12 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:24:12 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:24:12 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:24:12 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561251945
16/03/21 17:24:12 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-f074abbd-ab75-4ab4-8b93-8d00b8377e06/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:24:12 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:24:12 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=851363758
16/03/21 17:24:12 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 811.9 MB)
16/03/21 17:24:12 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:46527 (size: 166.0 B, free: 811.9 MB)
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: area
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: issue
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: planning
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): adding to parents: syn =  Synset('planning.n.01') ; keyword:  act  in syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= [u'planning']
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: permission
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: economy
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: composition
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: agency
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
16/03/21 17:24:19 INFO PythonRunner: Times: total = 7696, boot = 455, init = 350, finish = 6891
16/03/21 17:24:19 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:24:19 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:24:19 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:24:19 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:24:19 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7772 ms on localhost (1/2)
16/03/21 17:24:19 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=851363758
16/03/21 17:24:19 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 811.9 MB)
16/03/21 17:24:19 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:46527 (size: 155.0 B, free: 811.9 MB)
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: set
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: bend
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: giant
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: astatine
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: present
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: area
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:24:20 INFO PythonRunner: Times: total = 246, boot = 151, init = 1, finish = 94
16/03/21 17:24:20 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:24:20 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 287 ms on localhost (2/2)
16/03/21 17:24:20 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:24:20 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.037 s
16/03/21 17:24:20 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:24:20 INFO DAGScheduler: running: Set()
16/03/21 17:24:20 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:24:20 INFO DAGScheduler: failed: Set()
16/03/21 17:24:20 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:24:20 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:24:20 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=851363758
16/03/21 17:24:20 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 811.9 MB)
16/03/21 17:24:20 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=851363758
16/03/21 17:24:20 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 811.9 MB)
16/03/21 17:24:20 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:46527 (size: 3.0 KB, free: 811.9 MB)
16/03/21 17:24:20 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:24:20 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:20 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:24:20 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:24:20 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:24:20 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:24:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:24:20 INFO PythonRunner: Times: total = 127, boot = 126, init = 0, finish = 1
16/03/21 17:24:20 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:24:20 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:24:20 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:24:20 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:24:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:24:20 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 158 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'planning', 'None']
16/03/21 17:24:20 INFO PythonRunner: Times: total = 156, boot = 156, init = 0, finish = 0
16/03/21 17:24:20 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1242 bytes result sent to driver
16/03/21 17:24:20 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.302 s
16/03/21 17:24:20 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.381510 s
16/03/21 17:24:20 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 170 ms on localhost (2/2)
16/03/21 17:24:20 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:24:20 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:24:20 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:24:20 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:20 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:24:20 INFO DAGScheduler: Missing parents: List()
16/03/21 17:24:20 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:24:20 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=851363758
16/03/21 17:24:20 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 811.9 MB)
16/03/21 17:24:20 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=851363758
16/03/21 17:24:20 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 811.9 MB)
16/03/21 17:24:20 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:46527 (size: 3.3 KB, free: 811.9 MB)
16/03/21 17:24:20 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:24:20 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:20 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:24:20 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:24:20 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:24:20 INFO PythonRunner: Times: total = 129, boot = 129, init = 0, finish = 0
16/03/21 17:24:20 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:24:20 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2272 bytes)
16/03/21 17:24:20 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:24:20 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 146 ms on localhost (1/2)
16/03/21 17:24:20 INFO PythonRunner: Times: total = 159, boot = 159, init = 0, finish = 0
16/03/21 17:24:20 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1311 bytes result sent to driver
16/03/21 17:24:20 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 172 ms on localhost (2/2)
16/03/21 17:24:20 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:24:20 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.308 s
16/03/21 17:24:20 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.344515 s
16/03/21 17:24:21 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:24:21 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:24:21 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:24:21 INFO MemoryStore: MemoryStore cleared
16/03/21 17:24:21 INFO BlockManager: BlockManager stopped
16/03/21 17:24:21 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:24:21 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:24:21 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:24:21 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:24:21 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:24:21 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:24:21 INFO SecurityManager: Changing view acls to: root
16/03/21 17:24:21 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:24:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:24:22 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:24:22 INFO Remoting: Starting remoting
16/03/21 17:24:22 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:42705]
16/03/21 17:24:22 INFO Utils: Successfully started service 'sparkDriver' on port 42705.
16/03/21 17:24:22 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:24:22 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:24:22 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-4c6eacd4-f511-48be-89a1-4df3a793900f
16/03/21 17:24:22 INFO MemoryStore: MemoryStore started with capacity 811.9 MB
16/03/21 17:24:22 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-9923bc5b-5431-4695-9877-e55afbc55e3f
16/03/21 17:24:22 INFO HttpServer: Starting HTTP Server
16/03/21 17:24:22 INFO Utils: Successfully started service 'HTTP file server' on port 58409.
16/03/21 17:24:22 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:24:22 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:24:22 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:24:22 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-28182eb7-f655-4cff-847e-b2e3a1dc21c8/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:24:22 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561262399
16/03/21 17:24:22 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:24:22 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:24:22 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34589.
16/03/21 17:24:22 INFO NettyBlockTransferService: Server created on 34589
16/03/21 17:24:22 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:24:22 INFO BlockManagerMasterEndpoint: Registering block manager localhost:34589 with 811.9 MB RAM, BlockManagerId(driver, localhost, 34589)
16/03/21 17:24:22 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:24:22 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561262418
16/03/21 17:24:22 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:24:22 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:22 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:24:22 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:24:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:24:22 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:24:22 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=851363758
16/03/21 17:24:22 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 811.9 MB)
16/03/21 17:24:22 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=851363758
16/03/21 17:24:22 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 811.9 MB)
16/03/21 17:24:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:34589 (size: 4.1 KB, free: 811.9 MB)
16/03/21 17:24:22 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:24:22 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:22 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:24:22 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:24:22 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:24:22 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:24:22 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561262399
16/03/21 17:24:22 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-28182eb7-f655-4cff-847e-b2e3a1dc21c8/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:24:22 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:24:22 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=851363758
16/03/21 17:24:22 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 811.9 MB)
16/03/21 17:24:22 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:34589 (size: 166.0 B, free: 811.9 MB)
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: area
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: issue
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: planning
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): adding to parents: syn =  Synset('planning.n.01') ; keyword:  action  in syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= [u'planning']
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: permission
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: economy
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: composition
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: agency
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
16/03/21 17:24:30 INFO PythonRunner: Times: total = 7885, boot = 463, init = 354, finish = 7068
16/03/21 17:24:30 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:24:30 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:24:30 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:24:30 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:24:30 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8187 ms on localhost (1/2)
16/03/21 17:24:30 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=851363758
16/03/21 17:24:30 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 811.9 MB)
16/03/21 17:24:30 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:34589 (size: 155.0 B, free: 811.9 MB)
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: set
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: bend
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: giant
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: astatine
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: present
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: area
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:24:30 INFO PythonRunner: Times: total = 239, boot = 143, init = 1, finish = 95
16/03/21 17:24:30 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:24:30 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.452 s
16/03/21 17:24:30 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:24:30 INFO DAGScheduler: running: Set()
16/03/21 17:24:30 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:24:30 INFO DAGScheduler: failed: Set()
16/03/21 17:24:30 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:24:30 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:24:31 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=851363758
16/03/21 17:24:31 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 811.9 MB)
16/03/21 17:24:31 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 292 ms on localhost (2/2)
16/03/21 17:24:31 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:24:31 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=851363758
16/03/21 17:24:31 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 811.9 MB)
16/03/21 17:24:31 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:34589 (size: 3.0 KB, free: 811.9 MB)
16/03/21 17:24:31 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:24:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:31 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:24:31 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:24:31 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:24:31 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:24:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:24:31 INFO PythonRunner: Times: total = 141, boot = 141, init = 0, finish = 0
16/03/21 17:24:31 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:24:31 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:24:31 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:24:31 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:24:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:24:31 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 184 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'planning', 'None']
16/03/21 17:24:31 INFO PythonRunner: Times: total = 157, boot = 156, init = 0, finish = 1
16/03/21 17:24:31 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1242 bytes result sent to driver
16/03/21 17:24:31 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.331 s
16/03/21 17:24:31 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.815295 s
16/03/21 17:24:31 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 177 ms on localhost (2/2)
16/03/21 17:24:31 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:24:31 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:24:31 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:24:31 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:31 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:24:31 INFO DAGScheduler: Missing parents: List()
16/03/21 17:24:31 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:24:31 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=851363758
16/03/21 17:24:31 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 811.9 MB)
16/03/21 17:24:31 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=851363758
16/03/21 17:24:31 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 811.9 MB)
16/03/21 17:24:31 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:34589 (size: 3.3 KB, free: 811.9 MB)
16/03/21 17:24:31 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:24:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:31 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:24:31 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:24:31 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:24:31 INFO PythonRunner: Times: total = 110, boot = 110, init = 0, finish = 0
16/03/21 17:24:31 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:24:31 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2272 bytes)
16/03/21 17:24:31 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 133 ms on localhost (1/2)
16/03/21 17:24:31 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:24:31 INFO PythonRunner: Times: total = 140, boot = 139, init = 0, finish = 1
16/03/21 17:24:31 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1311 bytes result sent to driver
16/03/21 17:24:31 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.284 s
16/03/21 17:24:31 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.314680 s
16/03/21 17:24:31 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 165 ms on localhost (2/2)
16/03/21 17:24:31 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:24:31 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:24:31 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:24:31 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:24:31 INFO MemoryStore: MemoryStore cleared
16/03/21 17:24:31 INFO BlockManager: BlockManager stopped
16/03/21 17:24:31 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:24:31 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:24:31 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:24:31 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:24:31 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:24:31 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:24:32 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:24:32 INFO SecurityManager: Changing view acls to: root
16/03/21 17:24:32 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:24:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:24:32 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:24:32 INFO Remoting: Starting remoting
16/03/21 17:24:32 INFO Utils: Successfully started service 'sparkDriver' on port 41902.
16/03/21 17:24:32 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:24:32 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:24:32 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8b8b5299-38af-46a7-a9c0-4f76a07f8b20
16/03/21 17:24:32 INFO MemoryStore: MemoryStore started with capacity 805.6 MB
16/03/21 17:24:32 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:41902]
16/03/21 17:24:32 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-4947c24d-4707-4ee3-93c7-a8bab47ae522
16/03/21 17:24:32 INFO HttpServer: Starting HTTP Server
16/03/21 17:24:32 INFO Utils: Successfully started service 'HTTP file server' on port 38802.
16/03/21 17:24:32 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:24:33 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:24:33 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:24:33 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-d6fcde3e-878a-4ed3-a89d-c32d9b9e2f8f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:24:33 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561273347
16/03/21 17:24:33 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:24:33 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:24:33 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58634.
16/03/21 17:24:33 INFO NettyBlockTransferService: Server created on 58634
16/03/21 17:24:33 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:24:33 INFO BlockManagerMasterEndpoint: Registering block manager localhost:58634 with 805.6 MB RAM, BlockManagerId(driver, localhost, 58634)
16/03/21 17:24:33 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:24:33 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561273357
16/03/21 17:24:33 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:24:33 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:33 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:24:33 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:24:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:24:33 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:24:33 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=844781322
16/03/21 17:24:33 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 805.6 MB)
16/03/21 17:24:33 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=844781322
16/03/21 17:24:33 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 805.6 MB)
16/03/21 17:24:33 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:58634 (size: 4.1 KB, free: 805.6 MB)
16/03/21 17:24:33 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:24:33 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:33 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:24:33 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:24:33 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:24:33 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561273347
16/03/21 17:24:33 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:24:33 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-d6fcde3e-878a-4ed3-a89d-c32d9b9e2f8f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:24:33 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:24:33 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=844781322
16/03/21 17:24:33 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 805.6 MB)
16/03/21 17:24:33 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:58634 (size: 166.0 B, free: 805.6 MB)
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: area
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: issue
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: planning
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: permission
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: economy
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: composition
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  whole  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: agency
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/21 17:24:41 INFO PythonRunner: Times: total = 7853, boot = 487, init = 355, finish = 7011
16/03/21 17:24:41 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:24:41 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:24:41 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:24:41 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:24:41 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=844781322
16/03/21 17:24:41 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 805.6 MB)
16/03/21 17:24:41 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7920 ms on localhost (1/2)
16/03/21 17:24:41 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:58634 (size: 155.0 B, free: 805.6 MB)
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: set
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: bend
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: giant
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: astatine
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: present
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: area
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:24:41 INFO PythonRunner: Times: total = 248, boot = 152, init = 1, finish = 95
16/03/21 17:24:41 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:24:41 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 303 ms on localhost (2/2)
16/03/21 17:24:41 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:24:41 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.210 s
16/03/21 17:24:41 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:24:41 INFO DAGScheduler: running: Set()
16/03/21 17:24:41 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:24:41 INFO DAGScheduler: failed: Set()
16/03/21 17:24:41 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:24:41 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:24:41 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=844781322
16/03/21 17:24:41 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 805.6 MB)
16/03/21 17:24:41 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=844781322
16/03/21 17:24:41 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 805.6 MB)
16/03/21 17:24:41 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:58634 (size: 3.0 KB, free: 805.6 MB)
16/03/21 17:24:41 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:24:41 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:41 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:24:41 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:24:41 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:24:41 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:24:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:24:41 INFO PythonRunner: Times: total = 110, boot = 109, init = 0, finish = 1
16/03/21 17:24:41 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:24:41 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:24:41 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:24:41 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:24:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:24:41 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 154 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'composition', 'None']
16/03/21 17:24:42 INFO PythonRunner: Times: total = 152, boot = 151, init = 0, finish = 1
16/03/21 17:24:42 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1245 bytes result sent to driver
16/03/21 17:24:42 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 177 ms on localhost (2/2)
16/03/21 17:24:42 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:24:42 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.305 s
16/03/21 17:24:42 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.556790 s
16/03/21 17:24:42 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:24:42 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:24:42 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:42 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:24:42 INFO DAGScheduler: Missing parents: List()
16/03/21 17:24:42 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:24:42 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=844781322
16/03/21 17:24:42 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 805.6 MB)
16/03/21 17:24:42 INFO MemoryStore: ensureFreeSpace(3372) called with curMem=24893, maxMem=844781322
16/03/21 17:24:42 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 805.6 MB)
16/03/21 17:24:42 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:58634 (size: 3.3 KB, free: 805.6 MB)
16/03/21 17:24:42 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:24:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:42 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:24:42 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:24:42 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:24:42 INFO PythonRunner: Times: total = 17, boot = 17, init = 0, finish = 0
16/03/21 17:24:42 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:24:42 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2275 bytes)
16/03/21 17:24:42 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 38 ms on localhost (1/2)
16/03/21 17:24:42 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:24:42 INFO PythonRunner: Times: total = 147, boot = 146, init = 1, finish = 0
16/03/21 17:24:42 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1314 bytes result sent to driver
16/03/21 17:24:42 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 179 ms on localhost (2/2)
16/03/21 17:24:42 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:24:42 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.200 s
16/03/21 17:24:42 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.241174 s
16/03/21 17:24:42 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:24:42 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:24:42 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:24:42 INFO MemoryStore: MemoryStore cleared
16/03/21 17:24:42 INFO BlockManager: BlockManager stopped
16/03/21 17:24:42 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:24:42 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:24:42 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:24:42 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:24:42 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:24:42 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:24:43 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:24:43 INFO SecurityManager: Changing view acls to: root
16/03/21 17:24:43 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:24:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:24:43 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:24:43 INFO Remoting: Starting remoting
16/03/21 17:24:43 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:52164]
16/03/21 17:24:43 INFO Utils: Successfully started service 'sparkDriver' on port 52164.
16/03/21 17:24:43 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:24:43 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:24:43 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b3ecebc8-6276-4e30-83ff-18ea04713439
16/03/21 17:24:43 INFO MemoryStore: MemoryStore started with capacity 805.6 MB
16/03/21 17:24:43 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-250609c9-bc47-47f7-a05d-c3aea0390eb2
16/03/21 17:24:43 INFO HttpServer: Starting HTTP Server
16/03/21 17:24:43 INFO Utils: Successfully started service 'HTTP file server' on port 55531.
16/03/21 17:24:43 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:24:43 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:24:43 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:24:43 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-fe2b671c-8bc4-4bbc-bd1d-b0938d8f118d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:24:43 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561283729
16/03/21 17:24:43 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:24:43 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:24:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41763.
16/03/21 17:24:43 INFO NettyBlockTransferService: Server created on 41763
16/03/21 17:24:43 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:24:43 INFO BlockManagerMasterEndpoint: Registering block manager localhost:41763 with 805.6 MB RAM, BlockManagerId(driver, localhost, 41763)
16/03/21 17:24:43 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:24:43 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561283749
16/03/21 17:24:43 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:24:43 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:43 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:24:43 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:24:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:24:43 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:24:43 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=844781322
16/03/21 17:24:43 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 805.6 MB)
16/03/21 17:24:43 INFO MemoryStore: ensureFreeSpace(4150) called with curMem=6576, maxMem=844781322
16/03/21 17:24:43 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 805.6 MB)
16/03/21 17:24:43 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:41763 (size: 4.1 KB, free: 805.6 MB)
16/03/21 17:24:43 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:24:43 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:43 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:24:43 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:24:43 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:24:43 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:24:43 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561283729
16/03/21 17:24:43 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-fe2b671c-8bc4-4bbc-bd1d-b0938d8f118d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:24:43 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:24:43 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10726, maxMem=844781322
16/03/21 17:24:43 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 805.6 MB)
16/03/21 17:24:43 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:41763 (size: 166.0 B, free: 805.6 MB)
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: area
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: issue
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: planning
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: permission
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: economy
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: composition
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: agency
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): adding to parents: syn =  Synset('agency.n.02') ; keyword:  businesses  in syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= [u'agency']
reduceFunction_Parents(): returns= ['None', u'agency']
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'agency']
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'agency']
16/03/21 17:24:51 INFO PythonRunner: Times: total = 7930, boot = 457, init = 360, finish = 7113
16/03/21 17:24:51 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:24:51 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:24:51 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:24:51 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:24:51 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7992 ms on localhost (1/2)
16/03/21 17:24:51 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10892, maxMem=844781322
16/03/21 17:24:51 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 805.6 MB)
16/03/21 17:24:51 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:41763 (size: 155.0 B, free: 805.6 MB)
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: set
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: bend
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: giant
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: astatine
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: present
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: area
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:24:52 INFO PythonRunner: Times: total = 271, boot = 177, init = 0, finish = 94
16/03/21 17:24:52 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:24:52 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 306 ms on localhost (2/2)
16/03/21 17:24:52 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:24:52 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.290 s
16/03/21 17:24:52 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:24:52 INFO DAGScheduler: running: Set()
16/03/21 17:24:52 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:24:52 INFO DAGScheduler: failed: Set()
16/03/21 17:24:52 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:24:52 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:24:52 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11047, maxMem=844781322
16/03/21 17:24:52 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 805.6 MB)
16/03/21 17:24:52 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16031, maxMem=844781322
16/03/21 17:24:52 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 805.6 MB)
16/03/21 17:24:52 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:41763 (size: 3.0 KB, free: 805.6 MB)
16/03/21 17:24:52 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:24:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:52 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:24:52 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:24:52 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:24:52 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:24:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:24:52 INFO PythonRunner: Times: total = 138, boot = 137, init = 0, finish = 1
16/03/21 17:24:52 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:24:52 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:24:52 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:24:52 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:24:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:24:52 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 158 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'agency', 'None']
16/03/21 17:24:52 INFO PythonRunner: Times: total = 164, boot = 163, init = 1, finish = 0
16/03/21 17:24:52 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1240 bytes result sent to driver
16/03/21 17:24:52 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.320 s
16/03/21 17:24:52 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.654186 s
16/03/21 17:24:52 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 178 ms on localhost (2/2)
16/03/21 17:24:52 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:24:52 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:24:52 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:24:52 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:52 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:24:52 INFO DAGScheduler: Missing parents: List()
16/03/21 17:24:52 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:24:52 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19079, maxMem=844781322
16/03/21 17:24:52 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 805.6 MB)
16/03/21 17:24:52 INFO MemoryStore: ensureFreeSpace(3374) called with curMem=24895, maxMem=844781322
16/03/21 17:24:52 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 805.6 MB)
16/03/21 17:24:52 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:41763 (size: 3.3 KB, free: 805.6 MB)
16/03/21 17:24:52 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:24:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:52 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:24:52 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:24:52 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:24:52 INFO PythonRunner: Times: total = 130, boot = 129, init = 1, finish = 0
16/03/21 17:24:52 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:24:52 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2270 bytes)
16/03/21 17:24:52 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:24:52 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 145 ms on localhost (1/2)
16/03/21 17:24:52 INFO PythonRunner: Times: total = 159, boot = 158, init = 1, finish = 0
16/03/21 17:24:52 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1309 bytes result sent to driver
16/03/21 17:24:52 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.309 s
16/03/21 17:24:52 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.330414 s
16/03/21 17:24:52 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 175 ms on localhost (2/2)
16/03/21 17:24:52 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:24:53 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:24:53 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:24:53 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:24:53 INFO MemoryStore: MemoryStore cleared
16/03/21 17:24:53 INFO BlockManager: BlockManager stopped
16/03/21 17:24:53 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:24:53 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:24:53 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:24:53 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:24:53 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:24:53 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:24:53 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:24:53 INFO SecurityManager: Changing view acls to: root
16/03/21 17:24:53 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:24:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:24:53 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:24:53 INFO Remoting: Starting remoting
16/03/21 17:24:54 INFO Utils: Successfully started service 'sparkDriver' on port 54821.
16/03/21 17:24:54 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:54821]
16/03/21 17:24:54 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:24:54 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:24:54 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ff0fe055-53ec-45c6-9f1c-39e274348934
16/03/21 17:24:54 INFO MemoryStore: MemoryStore started with capacity 805.6 MB
16/03/21 17:24:54 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-0eebd4ac-8151-419b-bbf6-7c7ed67cd69a
16/03/21 17:24:54 INFO HttpServer: Starting HTTP Server
16/03/21 17:24:54 INFO Utils: Successfully started service 'HTTP file server' on port 45009.
16/03/21 17:24:54 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:24:54 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:24:54 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:24:54 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-769ed5a9-c71d-4894-9417-fb65be1d311e/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:24:54 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561294142
16/03/21 17:24:54 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:24:54 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:24:54 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42650.
16/03/21 17:24:54 INFO NettyBlockTransferService: Server created on 42650
16/03/21 17:24:54 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:24:54 INFO BlockManagerMasterEndpoint: Registering block manager localhost:42650 with 805.6 MB RAM, BlockManagerId(driver, localhost, 42650)
16/03/21 17:24:54 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:24:54 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561294152
16/03/21 17:24:54 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:24:54 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:54 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:24:54 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:24:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:24:54 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:24:54 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=844781322
16/03/21 17:24:54 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 805.6 MB)
16/03/21 17:24:54 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=844781322
16/03/21 17:24:54 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 805.6 MB)
16/03/21 17:24:54 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:42650 (size: 4.1 KB, free: 805.6 MB)
16/03/21 17:24:54 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:24:54 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:24:54 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:24:54 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:24:54 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:24:54 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:24:54 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561294142
16/03/21 17:24:54 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-769ed5a9-c71d-4894-9417-fb65be1d311e/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:24:54 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:24:54 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=844781322
16/03/21 17:24:54 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 805.6 MB)
16/03/21 17:24:54 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:42650 (size: 166.0 B, free: 805.6 MB)
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: area
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: issue
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: planning
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: permission
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: economy
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: composition
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: agency
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): adding to parents: syn =  Synset('kilometer.n.01') ; keyword:  1000  in syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= [u'kilometer']
reduceFunction_Parents(): returns= ['None', u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'kilometer']
16/03/21 17:25:02 INFO PythonRunner: Times: total = 7820, boot = 483, init = 350, finish = 6987
16/03/21 17:25:02 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:25:02 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:25:02 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:25:02 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:25:02 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=844781322
16/03/21 17:25:02 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 805.6 MB)
16/03/21 17:25:02 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7896 ms on localhost (1/2)
16/03/21 17:25:02 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:42650 (size: 155.0 B, free: 805.6 MB)
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: set
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: bend
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: giant
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: astatine
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: present
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: area
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): adding to parents: syn =  Synset('kilometer.n.01') ; keyword:  1000  in syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= [u'kilometer']
reduceFunction_Parents(): returns= ['None', u'kilometer']
16/03/21 17:25:02 INFO PythonRunner: Times: total = 244, boot = 147, init = 1, finish = 96
16/03/21 17:25:02 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:25:02 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.179 s
16/03/21 17:25:02 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:25:02 INFO DAGScheduler: running: Set()
16/03/21 17:25:02 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:25:02 INFO DAGScheduler: failed: Set()
16/03/21 17:25:02 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:25:02 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:25:02 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=844781322
16/03/21 17:25:02 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 805.6 MB)
16/03/21 17:25:02 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=844781322
16/03/21 17:25:02 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 805.6 MB)
16/03/21 17:25:02 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 292 ms on localhost (2/2)
16/03/21 17:25:02 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:25:02 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:42650 (size: 3.0 KB, free: 805.6 MB)
16/03/21 17:25:02 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:25:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:02 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:25:02 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:25:02 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:25:02 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:25:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:25:02 INFO PythonRunner: Times: total = 139, boot = 138, init = 0, finish = 1
16/03/21 17:25:02 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:25:02 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:25:02 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:25:02 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:25:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:25:02 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 175 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'kilometer', 'None', u'kilometer']
16/03/21 17:25:02 INFO PythonRunner: Times: total = 154, boot = 153, init = 1, finish = 0
16/03/21 17:25:02 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1259 bytes result sent to driver
16/03/21 17:25:02 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.317 s
16/03/21 17:25:02 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.524717 s
16/03/21 17:25:02 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 169 ms on localhost (2/2)
16/03/21 17:25:02 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:25:02 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:25:02 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:25:02 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:02 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:25:02 INFO DAGScheduler: Missing parents: List()
16/03/21 17:25:02 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:25:02 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=844781322
16/03/21 17:25:02 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 805.6 MB)
16/03/21 17:25:02 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=844781322
16/03/21 17:25:02 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 805.6 MB)
16/03/21 17:25:02 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:42650 (size: 3.3 KB, free: 805.6 MB)
16/03/21 17:25:02 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:25:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:02 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:25:02 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:25:02 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:25:02 INFO PythonRunner: Times: total = 52, boot = 51, init = 1, finish = 0
16/03/21 17:25:02 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:25:02 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2289 bytes)
16/03/21 17:25:02 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:25:02 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 66 ms on localhost (1/2)
16/03/21 17:25:03 INFO PythonRunner: Times: total = 158, boot = 158, init = 0, finish = 0
16/03/21 17:25:03 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1328 bytes result sent to driver
16/03/21 17:25:03 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.246 s
16/03/21 17:25:03 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.264248 s
16/03/21 17:25:03 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 183 ms on localhost (2/2)
16/03/21 17:25:03 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:25:03 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:25:03 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:25:03 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:25:03 INFO MemoryStore: MemoryStore cleared
16/03/21 17:25:03 INFO BlockManager: BlockManager stopped
16/03/21 17:25:03 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:25:03 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:25:03 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:25:03 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:25:03 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:25:03 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:25:04 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:25:04 INFO SecurityManager: Changing view acls to: root
16/03/21 17:25:04 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:25:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:25:04 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:25:04 INFO Remoting: Starting remoting
16/03/21 17:25:04 INFO Utils: Successfully started service 'sparkDriver' on port 56321.
16/03/21 17:25:04 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:56321]
16/03/21 17:25:04 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:25:04 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:25:04 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2aec2bda-4c4a-44c9-962b-18e8cbd2b164
16/03/21 17:25:04 INFO MemoryStore: MemoryStore started with capacity 805.6 MB
16/03/21 17:25:04 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-9a5fbfcb-ec1e-4068-afe4-c53bdded4add
16/03/21 17:25:04 INFO HttpServer: Starting HTTP Server
16/03/21 17:25:04 INFO Utils: Successfully started service 'HTTP file server' on port 40001.
16/03/21 17:25:04 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:25:04 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:25:04 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:25:04 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-4ffc6f3e-c642-41fa-96b8-2e4d7299ab9c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:25:04 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561304394
16/03/21 17:25:04 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:25:04 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:25:04 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40907.
16/03/21 17:25:04 INFO NettyBlockTransferService: Server created on 40907
16/03/21 17:25:04 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:25:04 INFO BlockManagerMasterEndpoint: Registering block manager localhost:40907 with 805.6 MB RAM, BlockManagerId(driver, localhost, 40907)
16/03/21 17:25:04 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:25:04 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561304405
16/03/21 17:25:04 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:25:04 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:04 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:25:04 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:25:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:25:04 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:25:04 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=844781322
16/03/21 17:25:04 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 805.6 MB)
16/03/21 17:25:04 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=844781322
16/03/21 17:25:04 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 805.6 MB)
16/03/21 17:25:04 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:40907 (size: 4.1 KB, free: 805.6 MB)
16/03/21 17:25:04 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:25:04 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:04 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:25:04 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:25:04 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:25:04 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:25:04 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561304394
16/03/21 17:25:04 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-4ffc6f3e-c642-41fa-96b8-2e4d7299ab9c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:25:04 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:25:04 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=844781322
16/03/21 17:25:04 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 805.6 MB)
16/03/21 17:25:04 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:40907 (size: 166.0 B, free: 805.6 MB)
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: area
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: issue
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: planning
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: permission
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: economy
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: composition
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: agency
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  formerly  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/21 17:25:12 INFO PythonRunner: Times: total = 7819, boot = 448, init = 359, finish = 7012
16/03/21 17:25:12 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:25:12 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:25:12 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:25:12 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:25:12 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=844781322
16/03/21 17:25:12 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 805.6 MB)
16/03/21 17:25:12 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:40907 (size: 155.0 B, free: 805.6 MB)
16/03/21 17:25:12 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7888 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: set
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: bend
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: giant
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: astatine
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: present
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  formerly  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: area
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/21 17:25:12 INFO PythonRunner: Times: total = 264, boot = 171, init = 1, finish = 92
16/03/21 17:25:12 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:25:12 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 300 ms on localhost (2/2)
16/03/21 17:25:12 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:25:12 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.168 s
16/03/21 17:25:12 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:25:12 INFO DAGScheduler: running: Set()
16/03/21 17:25:12 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:25:12 INFO DAGScheduler: failed: Set()
16/03/21 17:25:12 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:25:12 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:25:12 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=844781322
16/03/21 17:25:12 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 805.6 MB)
16/03/21 17:25:12 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=844781322
16/03/21 17:25:12 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 805.6 MB)
16/03/21 17:25:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:40907 (size: 3.0 KB, free: 805.6 MB)
16/03/21 17:25:12 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:25:12 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:12 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:25:12 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:25:12 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:25:12 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:25:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:25:12 INFO PythonRunner: Times: total = 139, boot = 139, init = 0, finish = 0
16/03/21 17:25:12 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:25:12 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:25:12 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:25:12 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:25:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:25:12 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 161 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'Chennai', 'None', u'Chennai']
16/03/21 17:25:13 INFO PythonRunner: Times: total = 166, boot = 165, init = 0, finish = 1
16/03/21 17:25:13 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1255 bytes result sent to driver
16/03/21 17:25:13 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.331 s
16/03/21 17:25:13 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.534645 s
16/03/21 17:25:13 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 179 ms on localhost (2/2)
16/03/21 17:25:13 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:25:13 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:25:13 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:25:13 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:13 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:25:13 INFO DAGScheduler: Missing parents: List()
16/03/21 17:25:13 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:25:13 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=844781322
16/03/21 17:25:13 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 805.6 MB)
16/03/21 17:25:13 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=844781322
16/03/21 17:25:13 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 805.6 MB)
16/03/21 17:25:13 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:40907 (size: 3.3 KB, free: 805.6 MB)
16/03/21 17:25:13 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:25:13 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:13 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:25:13 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:25:13 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:25:13 INFO PythonRunner: Times: total = 107, boot = 107, init = 0, finish = 0
16/03/21 17:25:13 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:25:13 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2285 bytes)
16/03/21 17:25:13 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 124 ms on localhost (1/2)
16/03/21 17:25:13 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:25:13 INFO PythonRunner: Times: total = 169, boot = 169, init = 0, finish = 0
16/03/21 17:25:13 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1324 bytes result sent to driver
16/03/21 17:25:13 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 186 ms on localhost (2/2)
16/03/21 17:25:13 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:25:13 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.295 s
16/03/21 17:25:13 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.324279 s
16/03/21 17:25:13 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:25:13 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:25:13 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:25:13 INFO MemoryStore: MemoryStore cleared
16/03/21 17:25:13 INFO BlockManager: BlockManager stopped
16/03/21 17:25:13 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:25:13 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:25:13 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:25:13 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:25:13 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:25:13 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:25:14 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:25:14 INFO SecurityManager: Changing view acls to: root
16/03/21 17:25:14 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:25:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:25:14 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:25:14 INFO Remoting: Starting remoting
16/03/21 17:25:14 INFO Utils: Successfully started service 'sparkDriver' on port 33426.
16/03/21 17:25:14 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:33426]
16/03/21 17:25:14 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:25:14 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:25:14 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0544db04-339f-403b-9250-381cd02dfe9c
16/03/21 17:25:14 INFO MemoryStore: MemoryStore started with capacity 805.6 MB
16/03/21 17:25:14 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-c0632a31-cd7e-43c8-a7aa-393c499c9325
16/03/21 17:25:14 INFO HttpServer: Starting HTTP Server
16/03/21 17:25:14 INFO Utils: Successfully started service 'HTTP file server' on port 35031.
16/03/21 17:25:14 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:25:14 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:25:14 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:25:14 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-f069cb5c-7a51-4bd9-a475-7cba5a915cfc/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:25:14 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561314665
16/03/21 17:25:14 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:25:14 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:25:14 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44571.
16/03/21 17:25:14 INFO NettyBlockTransferService: Server created on 44571
16/03/21 17:25:14 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:25:14 INFO BlockManagerMasterEndpoint: Registering block manager localhost:44571 with 805.6 MB RAM, BlockManagerId(driver, localhost, 44571)
16/03/21 17:25:14 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:25:14 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561314677
16/03/21 17:25:14 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:25:14 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:14 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:25:14 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:25:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:25:14 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:25:14 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=844781322
16/03/21 17:25:14 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 805.6 MB)
16/03/21 17:25:14 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=844781322
16/03/21 17:25:14 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 805.6 MB)
16/03/21 17:25:14 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:44571 (size: 4.1 KB, free: 805.6 MB)
16/03/21 17:25:14 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:25:14 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:14 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:25:14 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:25:14 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:25:14 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:25:14 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561314665
16/03/21 17:25:14 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-f069cb5c-7a51-4bd9-a475-7cba5a915cfc/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:25:14 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:25:14 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=844781322
16/03/21 17:25:14 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 805.6 MB)
16/03/21 17:25:14 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:44571 (size: 166.0 B, free: 805.6 MB)
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: area
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: issue
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: planning
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: permission
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: economy
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: composition
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: agency
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:25:22 INFO PythonRunner: Times: total = 7779, boot = 459, init = 358, finish = 6962
16/03/21 17:25:22 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:25:22 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:25:22 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:25:22 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:25:22 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=844781322
16/03/21 17:25:22 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 805.6 MB)
16/03/21 17:25:22 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:44571 (size: 155.0 B, free: 805.6 MB)
16/03/21 17:25:22 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7871 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: set
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: bend
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: giant
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: astatine
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: present
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  period  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: area
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/21 17:25:22 INFO PythonRunner: Times: total = 269, boot = 172, init = 1, finish = 96
16/03/21 17:25:22 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:25:22 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 297 ms on localhost (2/2)
16/03/21 17:25:22 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:25:22 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.152 s
16/03/21 17:25:22 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:25:22 INFO DAGScheduler: running: Set()
16/03/21 17:25:22 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:25:22 INFO DAGScheduler: failed: Set()
16/03/21 17:25:22 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:25:22 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:25:22 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=844781322
16/03/21 17:25:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 805.6 MB)
16/03/21 17:25:22 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=844781322
16/03/21 17:25:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 805.6 MB)
16/03/21 17:25:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:44571 (size: 3.0 KB, free: 805.6 MB)
16/03/21 17:25:22 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:25:22 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:22 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:25:22 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:25:22 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:25:22 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:25:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:25:23 INFO PythonRunner: Times: total = 145, boot = 145, init = 0, finish = 0
16/03/21 17:25:23 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:25:23 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:25:23 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:25:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:25:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:25:23 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 167 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'present']
16/03/21 17:25:23 INFO PythonRunner: Times: total = 165, boot = 164, init = 0, finish = 1
16/03/21 17:25:23 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/21 17:25:23 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 181 ms on localhost (2/2)
16/03/21 17:25:23 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:25:23 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.332 s
16/03/21 17:25:23 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.526016 s
16/03/21 17:25:23 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:25:23 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:25:23 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:23 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:25:23 INFO DAGScheduler: Missing parents: List()
16/03/21 17:25:23 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:25:23 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=844781322
16/03/21 17:25:23 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 805.6 MB)
16/03/21 17:25:23 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=844781322
16/03/21 17:25:23 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 805.6 MB)
16/03/21 17:25:23 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:44571 (size: 3.3 KB, free: 805.6 MB)
16/03/21 17:25:23 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:25:23 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:23 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:25:23 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:25:23 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:25:23 INFO PythonRunner: Times: total = 64, boot = 64, init = 0, finish = 0
16/03/21 17:25:23 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:25:23 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/21 17:25:23 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 81 ms on localhost (1/2)
16/03/21 17:25:23 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:25:23 INFO PythonRunner: Times: total = 156, boot = 155, init = 1, finish = 0
16/03/21 17:25:23 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1310 bytes result sent to driver
16/03/21 17:25:23 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 172 ms on localhost (2/2)
16/03/21 17:25:23 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:25:23 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.250 s
16/03/21 17:25:23 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.272475 s
16/03/21 17:25:23 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:25:23 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:25:23 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:25:23 INFO MemoryStore: MemoryStore cleared
16/03/21 17:25:23 INFO BlockManager: BlockManager stopped
16/03/21 17:25:23 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:25:23 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:25:23 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:25:23 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:25:23 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:25:23 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:25:24 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:25:24 INFO SecurityManager: Changing view acls to: root
16/03/21 17:25:24 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:25:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:25:24 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:25:24 INFO Remoting: Starting remoting
16/03/21 17:25:24 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:38886]
16/03/21 17:25:24 INFO Utils: Successfully started service 'sparkDriver' on port 38886.
16/03/21 17:25:24 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:25:24 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:25:24 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d1c9900f-d94d-4742-9da3-bd9ce75cee7c
16/03/21 17:25:24 INFO MemoryStore: MemoryStore started with capacity 805.6 MB
16/03/21 17:25:24 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-31323b97-5639-41a3-9fb8-58c15916e2e7
16/03/21 17:25:24 INFO HttpServer: Starting HTTP Server
16/03/21 17:25:24 INFO Utils: Successfully started service 'HTTP file server' on port 60717.
16/03/21 17:25:24 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:25:24 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:25:24 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:25:24 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-ef901bce-7fec-4ca0-a2fb-e3da0aefd52c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:25:24 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561324873
16/03/21 17:25:24 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:25:24 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:25:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50619.
16/03/21 17:25:24 INFO NettyBlockTransferService: Server created on 50619
16/03/21 17:25:24 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:25:24 INFO BlockManagerMasterEndpoint: Registering block manager localhost:50619 with 805.6 MB RAM, BlockManagerId(driver, localhost, 50619)
16/03/21 17:25:24 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:25:24 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561324882
16/03/21 17:25:25 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:25:25 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:25 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:25:25 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:25:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:25:25 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:25:25 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=844781322
16/03/21 17:25:25 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 805.6 MB)
16/03/21 17:25:25 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=844781322
16/03/21 17:25:25 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 805.6 MB)
16/03/21 17:25:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:50619 (size: 4.1 KB, free: 805.6 MB)
16/03/21 17:25:25 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:25:25 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:25 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:25:25 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:25:25 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:25:25 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561324873
16/03/21 17:25:25 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:25:25 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-ef901bce-7fec-4ca0-a2fb-e3da0aefd52c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:25:25 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:25:25 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=844781322
16/03/21 17:25:25 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 805.6 MB)
16/03/21 17:25:25 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:50619 (size: 166.0 B, free: 805.6 MB)
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: area
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: issue
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: planning
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: permission
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: economy
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: composition
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: agency
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:25:32 INFO PythonRunner: Times: total = 7883, boot = 466, init = 348, finish = 7069
16/03/21 17:25:32 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:25:32 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:25:32 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:25:32 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:25:32 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=844781322
16/03/21 17:25:32 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 805.6 MB)
16/03/21 17:25:32 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7947 ms on localhost (1/2)
16/03/21 17:25:32 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:50619 (size: 155.0 B, free: 805.6 MB)
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: set
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: bend
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: giant
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: astatine
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  highly  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: present
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: area
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/21 17:25:33 INFO PythonRunner: Times: total = 266, boot = 165, init = 1, finish = 100
16/03/21 17:25:33 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:25:33 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.233 s
16/03/21 17:25:33 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:25:33 INFO DAGScheduler: running: Set()
16/03/21 17:25:33 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:25:33 INFO DAGScheduler: failed: Set()
16/03/21 17:25:33 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:25:33 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:25:33 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=844781322
16/03/21 17:25:33 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 805.6 MB)
16/03/21 17:25:33 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 296 ms on localhost (2/2)
16/03/21 17:25:33 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:25:33 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=844781322
16/03/21 17:25:33 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 805.6 MB)
16/03/21 17:25:33 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:50619 (size: 3.0 KB, free: 805.6 MB)
16/03/21 17:25:33 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:25:33 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:33 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:25:33 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:25:33 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:25:33 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:25:33 INFO PythonRunner: Times: total = 150, boot = 150, init = 0, finish = 0
16/03/21 17:25:33 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:25:33 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:25:33 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:25:33 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:25:33 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 176 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/03/21 17:25:33 INFO PythonRunner: Times: total = 159, boot = 159, init = 0, finish = 0
16/03/21 17:25:33 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1242 bytes result sent to driver
16/03/21 17:25:33 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 175 ms on localhost (2/2)
16/03/21 17:25:33 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:25:33 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.330 s
16/03/21 17:25:33 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.600999 s
16/03/21 17:25:33 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:25:33 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:25:33 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:33 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:25:33 INFO DAGScheduler: Missing parents: List()
16/03/21 17:25:33 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:25:33 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=844781322
16/03/21 17:25:33 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 805.6 MB)
16/03/21 17:25:33 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=844781322
16/03/21 17:25:33 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 805.6 MB)
16/03/21 17:25:33 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:50619 (size: 3.3 KB, free: 805.6 MB)
16/03/21 17:25:33 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:25:33 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:33 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:25:33 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:25:33 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:25:33 INFO PythonRunner: Times: total = 133, boot = 132, init = 1, finish = 0
16/03/21 17:25:33 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:25:33 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2272 bytes)
16/03/21 17:25:33 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 149 ms on localhost (1/2)
16/03/21 17:25:33 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:25:34 INFO PythonRunner: Times: total = 151, boot = 151, init = 0, finish = 0
16/03/21 17:25:34 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1311 bytes result sent to driver
16/03/21 17:25:34 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 176 ms on localhost (2/2)
16/03/21 17:25:34 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:25:34 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.311 s
16/03/21 17:25:34 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.339802 s
16/03/21 17:25:34 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:25:34 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:25:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:25:34 INFO MemoryStore: MemoryStore cleared
16/03/21 17:25:34 INFO BlockManager: BlockManager stopped
16/03/21 17:25:34 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:25:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:25:34 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:25:34 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:25:34 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:25:34 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:25:35 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:25:35 INFO SecurityManager: Changing view acls to: root
16/03/21 17:25:35 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:25:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:25:35 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:25:35 INFO Remoting: Starting remoting
16/03/21 17:25:35 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:44408]
16/03/21 17:25:35 INFO Utils: Successfully started service 'sparkDriver' on port 44408.
16/03/21 17:25:35 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:25:35 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:25:35 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2927a438-bcc5-4a12-bee7-342775b045e3
16/03/21 17:25:35 INFO MemoryStore: MemoryStore started with capacity 805.6 MB
16/03/21 17:25:35 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-9bc7748f-6323-4d30-b386-caac6831b3ea
16/03/21 17:25:35 INFO HttpServer: Starting HTTP Server
16/03/21 17:25:35 INFO Utils: Successfully started service 'HTTP file server' on port 50920.
16/03/21 17:25:35 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:25:35 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:25:35 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:25:35 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-fc41060e-16eb-4343-a44a-a6c99e08c382/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:25:35 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561335261
16/03/21 17:25:35 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:25:35 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:25:35 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38848.
16/03/21 17:25:35 INFO NettyBlockTransferService: Server created on 38848
16/03/21 17:25:35 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:25:35 INFO BlockManagerMasterEndpoint: Registering block manager localhost:38848 with 805.6 MB RAM, BlockManagerId(driver, localhost, 38848)
16/03/21 17:25:35 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:25:35 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561335275
16/03/21 17:25:35 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:25:35 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:35 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:25:35 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:25:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:25:35 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:25:35 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=844781322
16/03/21 17:25:35 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 805.6 MB)
16/03/21 17:25:35 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=844781322
16/03/21 17:25:35 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 805.6 MB)
16/03/21 17:25:35 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:38848 (size: 4.1 KB, free: 805.6 MB)
16/03/21 17:25:35 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:25:35 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:35 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:25:35 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:25:35 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:25:35 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:25:35 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561335261
16/03/21 17:25:35 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-fc41060e-16eb-4343-a44a-a6c99e08c382/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:25:35 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:25:35 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=844781322
16/03/21 17:25:35 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 805.6 MB)
16/03/21 17:25:35 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:38848 (size: 166.0 B, free: 805.6 MB)
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: area
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: issue
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: planning
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: permission
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: economy
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): adding to parents: syn =  Synset('economy.n.01') ; keyword:  production  in syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= [u'economy']
reduceFunction_Parents(): returns= ['None', u'economy']
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: composition
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'economy']
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: agency
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'economy']
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'economy']
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'economy']
16/03/21 17:25:43 INFO PythonRunner: Times: total = 7925, boot = 455, init = 369, finish = 7101
16/03/21 17:25:43 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:25:43 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:25:43 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:25:43 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:25:43 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=844781322
16/03/21 17:25:43 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 805.6 MB)
16/03/21 17:25:43 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7990 ms on localhost (1/2)
16/03/21 17:25:43 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:38848 (size: 155.0 B, free: 805.6 MB)
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: set
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: bend
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: giant
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: astatine
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: present
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: area
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:25:43 INFO PythonRunner: Times: total = 250, boot = 151, init = 0, finish = 99
16/03/21 17:25:43 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:25:43 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 285 ms on localhost (2/2)
16/03/21 17:25:43 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.265 s
16/03/21 17:25:43 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:25:43 INFO DAGScheduler: running: Set()
16/03/21 17:25:43 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:25:43 INFO DAGScheduler: failed: Set()
16/03/21 17:25:43 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:25:43 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:25:43 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=844781322
16/03/21 17:25:43 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 805.6 MB)
16/03/21 17:25:43 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:25:43 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=844781322
16/03/21 17:25:43 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 805.6 MB)
16/03/21 17:25:43 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:38848 (size: 3.0 KB, free: 805.6 MB)
16/03/21 17:25:43 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:25:43 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:43 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:25:43 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:25:43 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:25:43 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:25:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:25:43 INFO PythonRunner: Times: total = 141, boot = 140, init = 0, finish = 1
16/03/21 17:25:43 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:25:43 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:25:43 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:25:43 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:25:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:25:43 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 170 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'economy', 'None']
16/03/21 17:25:44 INFO PythonRunner: Times: total = 163, boot = 162, init = 1, finish = 0
16/03/21 17:25:44 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/21 17:25:44 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.328 s
16/03/21 17:25:44 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.635717 s
16/03/21 17:25:44 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 177 ms on localhost (2/2)
16/03/21 17:25:44 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:25:44 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:25:44 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:25:44 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:44 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:25:44 INFO DAGScheduler: Missing parents: List()
16/03/21 17:25:44 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:25:44 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=844781322
16/03/21 17:25:44 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 805.6 MB)
16/03/21 17:25:44 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=844781322
16/03/21 17:25:44 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 805.6 MB)
16/03/21 17:25:44 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:38848 (size: 3.3 KB, free: 805.6 MB)
16/03/21 17:25:44 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:25:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:44 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:25:44 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:25:44 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:25:44 INFO PythonRunner: Times: total = 100, boot = 100, init = 0, finish = 0
16/03/21 17:25:44 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:25:44 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/21 17:25:44 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:25:44 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 117 ms on localhost (1/2)
16/03/21 17:25:44 INFO PythonRunner: Times: total = 161, boot = 161, init = 0, finish = 0
16/03/21 17:25:44 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1310 bytes result sent to driver
16/03/21 17:25:44 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 173 ms on localhost (2/2)
16/03/21 17:25:44 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.276 s
16/03/21 17:25:44 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:25:44 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.299225 s
16/03/21 17:25:44 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:25:44 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:25:44 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:25:44 INFO MemoryStore: MemoryStore cleared
16/03/21 17:25:44 INFO BlockManager: BlockManager stopped
16/03/21 17:25:44 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:25:44 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:25:44 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:25:44 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:25:44 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:25:44 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:25:45 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:25:45 INFO SecurityManager: Changing view acls to: root
16/03/21 17:25:45 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:25:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:25:45 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:25:45 INFO Remoting: Starting remoting
16/03/21 17:25:45 INFO Utils: Successfully started service 'sparkDriver' on port 49267.
16/03/21 17:25:45 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:49267]
16/03/21 17:25:45 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:25:45 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:25:45 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-35168cd2-0bf7-49d9-b362-d87907344946
16/03/21 17:25:45 INFO MemoryStore: MemoryStore started with capacity 810.7 MB
16/03/21 17:25:45 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-a604f3f4-83ff-4fca-aef4-76abfede2f5f
16/03/21 17:25:45 INFO HttpServer: Starting HTTP Server
16/03/21 17:25:45 INFO Utils: Successfully started service 'HTTP file server' on port 52113.
16/03/21 17:25:45 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:25:45 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:25:45 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:25:45 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-5d87c262-d813-4df5-9697-5f9d55b49140/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:25:45 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561345862
16/03/21 17:25:45 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:25:45 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:25:45 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43148.
16/03/21 17:25:45 INFO NettyBlockTransferService: Server created on 43148
16/03/21 17:25:45 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:25:45 INFO BlockManagerMasterEndpoint: Registering block manager localhost:43148 with 810.7 MB RAM, BlockManagerId(driver, localhost, 43148)
16/03/21 17:25:45 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:25:45 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561345877
16/03/21 17:25:46 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:25:46 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:46 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:25:46 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:25:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:25:46 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:25:46 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=850089738
16/03/21 17:25:46 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 810.7 MB)
16/03/21 17:25:46 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=850089738
16/03/21 17:25:46 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 810.7 MB)
16/03/21 17:25:46 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:43148 (size: 4.1 KB, free: 810.7 MB)
16/03/21 17:25:46 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:25:46 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:46 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:25:46 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:25:46 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:25:46 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:25:46 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561345862
16/03/21 17:25:46 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-5d87c262-d813-4df5-9697-5f9d55b49140/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:25:46 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:25:46 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=850089738
16/03/21 17:25:46 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 810.7 MB)
16/03/21 17:25:46 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:43148 (size: 166.0 B, free: 810.7 MB)
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: area
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  indefinite  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: issue
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: planning
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: permission
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: economy
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: composition
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: agency
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/21 17:25:54 INFO PythonRunner: Times: total = 7912, boot = 476, init = 358, finish = 7078
16/03/21 17:25:54 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:25:54 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:25:54 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:25:54 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:25:54 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=850089738
16/03/21 17:25:54 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 810.7 MB)
16/03/21 17:25:54 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8002 ms on localhost (1/2)
16/03/21 17:25:54 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:43148 (size: 155.0 B, free: 810.7 MB)
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: set
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: bend
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: giant
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: astatine
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: present
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: area
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  indefinite  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/21 17:25:54 INFO PythonRunner: Times: total = 245, boot = 149, init = 0, finish = 96
16/03/21 17:25:54 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:25:54 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.271 s
16/03/21 17:25:54 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:25:54 INFO DAGScheduler: running: Set()
16/03/21 17:25:54 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:25:54 INFO DAGScheduler: failed: Set()
16/03/21 17:25:54 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:25:54 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 302 ms on localhost (2/2)
16/03/21 17:25:54 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:25:54 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:25:54 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=850089738
16/03/21 17:25:54 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 810.7 MB)
16/03/21 17:25:54 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=850089738
16/03/21 17:25:54 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 810.7 MB)
16/03/21 17:25:54 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:43148 (size: 3.0 KB, free: 810.7 MB)
16/03/21 17:25:54 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:25:54 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:54 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:25:54 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:25:54 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:25:54 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:25:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:25:54 INFO PythonRunner: Times: total = 113, boot = 112, init = 0, finish = 1
16/03/21 17:25:54 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:25:54 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:25:54 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:25:54 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:25:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:25:54 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 140 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'area', 'None', u'area']
16/03/21 17:25:54 INFO PythonRunner: Times: total = 156, boot = 154, init = 1, finish = 1
16/03/21 17:25:54 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/21 17:25:54 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.296 s
16/03/21 17:25:54 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 177 ms on localhost (2/2)
16/03/21 17:25:54 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:25:54 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.621018 s
16/03/21 17:25:54 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:25:54 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:25:54 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:54 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:25:54 INFO DAGScheduler: Missing parents: List()
16/03/21 17:25:54 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:25:54 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=850089738
16/03/21 17:25:54 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 810.7 MB)
16/03/21 17:25:54 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=850089738
16/03/21 17:25:54 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 810.7 MB)
16/03/21 17:25:54 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:43148 (size: 3.3 KB, free: 810.7 MB)
16/03/21 17:25:54 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:25:54 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:54 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:25:54 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:25:54 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:25:54 INFO PythonRunner: Times: total = 53, boot = 53, init = 0, finish = 0
16/03/21 17:25:54 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:25:54 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/21 17:25:54 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 68 ms on localhost (1/2)
16/03/21 17:25:54 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:25:54 INFO PythonRunner: Times: total = 152, boot = 152, init = 0, finish = 0
16/03/21 17:25:55 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1307 bytes result sent to driver
16/03/21 17:25:55 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 174 ms on localhost (2/2)
16/03/21 17:25:55 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:25:55 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.229 s
16/03/21 17:25:55 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.249753 s
16/03/21 17:25:55 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:25:55 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:25:55 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:25:55 INFO MemoryStore: MemoryStore cleared
16/03/21 17:25:55 INFO BlockManager: BlockManager stopped
16/03/21 17:25:55 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:25:55 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:25:55 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:25:55 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:25:55 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:25:56 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:25:56 INFO SecurityManager: Changing view acls to: root
16/03/21 17:25:56 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:25:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:25:56 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:25:56 INFO Remoting: Starting remoting
16/03/21 17:25:56 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:41384]
16/03/21 17:25:56 INFO Utils: Successfully started service 'sparkDriver' on port 41384.
16/03/21 17:25:56 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:25:56 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:25:56 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-13c9984c-34b6-4502-b224-7b325073e870
16/03/21 17:25:56 INFO MemoryStore: MemoryStore started with capacity 810.7 MB
16/03/21 17:25:56 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-7ca77b49-caa9-45e1-8ed7-5e3333aabf85
16/03/21 17:25:56 INFO HttpServer: Starting HTTP Server
16/03/21 17:25:56 INFO Utils: Successfully started service 'HTTP file server' on port 36282.
16/03/21 17:25:56 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:25:56 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:25:56 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:25:56 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-038fe1e3-be87-480a-a4a1-9c540bab0cfb/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:25:56 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561356262
16/03/21 17:25:56 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:25:56 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:25:56 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46430.
16/03/21 17:25:56 INFO NettyBlockTransferService: Server created on 46430
16/03/21 17:25:56 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:25:56 INFO BlockManagerMasterEndpoint: Registering block manager localhost:46430 with 810.7 MB RAM, BlockManagerId(driver, localhost, 46430)
16/03/21 17:25:56 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:25:56 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561356273
16/03/21 17:25:56 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:25:56 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:56 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:25:56 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:25:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:25:56 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:25:56 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=850089738
16/03/21 17:25:56 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 810.7 MB)
16/03/21 17:25:56 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=850089738
16/03/21 17:25:56 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 810.7 MB)
16/03/21 17:25:56 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:46430 (size: 4.1 KB, free: 810.7 MB)
16/03/21 17:25:56 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:25:56 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:25:56 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:25:56 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:25:56 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:25:56 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:25:56 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561356262
16/03/21 17:25:56 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-038fe1e3-be87-480a-a4a1-9c540bab0cfb/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:25:56 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:25:56 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=850089738
16/03/21 17:25:56 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 810.7 MB)
16/03/21 17:25:56 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:46430 (size: 166.0 B, free: 810.7 MB)
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: area
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: issue
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: planning
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: permission
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: economy
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: composition
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: agency
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): adding to parents: syn =  Synset('kilometer.n.01') ; keyword:  unit  in syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= [u'kilometer']
reduceFunction_Parents(): returns= ['None', u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'kilometer']
16/03/21 17:26:04 INFO PythonRunner: Times: total = 7747, boot = 447, init = 359, finish = 6941
16/03/21 17:26:04 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:26:04 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:26:04 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:26:04 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:26:04 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=850089738
16/03/21 17:26:04 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 810.7 MB)
16/03/21 17:26:04 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7813 ms on localhost (1/2)
16/03/21 17:26:04 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:46430 (size: 155.0 B, free: 810.7 MB)
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: set
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: bend
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: giant
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: astatine
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: present
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: area
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): adding to parents: syn =  Synset('kilometer.n.01') ; keyword:  unit  in syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= [u'kilometer']
reduceFunction_Parents(): returns= ['None', u'kilometer']
16/03/21 17:26:04 INFO PythonRunner: Times: total = 272, boot = 174, init = 1, finish = 97
16/03/21 17:26:04 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:26:04 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.100 s
16/03/21 17:26:04 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:26:04 INFO DAGScheduler: running: Set()
16/03/21 17:26:04 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:26:04 INFO DAGScheduler: failed: Set()
16/03/21 17:26:04 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:26:04 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:26:04 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=850089738
16/03/21 17:26:04 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 810.7 MB)
16/03/21 17:26:04 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 300 ms on localhost (2/2)
16/03/21 17:26:04 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:26:04 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=850089738
16/03/21 17:26:04 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 810.7 MB)
16/03/21 17:26:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:46430 (size: 3.0 KB, free: 810.7 MB)
16/03/21 17:26:04 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:26:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:04 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:26:04 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:26:04 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:26:04 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:26:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:26:04 INFO PythonRunner: Times: total = 141, boot = 140, init = 1, finish = 0
16/03/21 17:26:04 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:26:04 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:26:04 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:26:04 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:26:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:26:04 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 165 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'kilometer', 'None', u'kilometer']
16/03/21 17:26:04 INFO PythonRunner: Times: total = 147, boot = 146, init = 0, finish = 1
16/03/21 17:26:04 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1259 bytes result sent to driver
16/03/21 17:26:04 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.316 s
16/03/21 17:26:04 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.460146 s
16/03/21 17:26:04 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 162 ms on localhost (2/2)
16/03/21 17:26:04 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:26:04 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:26:04 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:26:04 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:04 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:26:04 INFO DAGScheduler: Missing parents: List()
16/03/21 17:26:04 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:26:04 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=850089738
16/03/21 17:26:04 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 810.7 MB)
16/03/21 17:26:04 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=850089738
16/03/21 17:26:04 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 810.7 MB)
16/03/21 17:26:04 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:46430 (size: 3.3 KB, free: 810.7 MB)
16/03/21 17:26:04 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:26:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:04 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:26:04 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:26:04 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:26:05 INFO PythonRunner: Times: total = 74, boot = 74, init = 0, finish = 0
16/03/21 17:26:05 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:26:05 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2289 bytes)
16/03/21 17:26:05 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 90 ms on localhost (1/2)
16/03/21 17:26:05 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:26:05 INFO PythonRunner: Times: total = 149, boot = 149, init = 0, finish = 0
16/03/21 17:26:05 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1328 bytes result sent to driver
16/03/21 17:26:05 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.252 s
16/03/21 17:26:05 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 167 ms on localhost (2/2)
16/03/21 17:26:05 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:26:05 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.264972 s
16/03/21 17:26:05 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:26:05 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:26:05 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:26:05 INFO MemoryStore: MemoryStore cleared
16/03/21 17:26:05 INFO BlockManager: BlockManager stopped
16/03/21 17:26:05 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:26:05 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:26:05 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:26:05 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:26:05 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:26:05 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:26:06 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:26:06 INFO SecurityManager: Changing view acls to: root
16/03/21 17:26:06 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:26:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:26:06 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:26:06 INFO Remoting: Starting remoting
16/03/21 17:26:06 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:45665]
16/03/21 17:26:06 INFO Utils: Successfully started service 'sparkDriver' on port 45665.
16/03/21 17:26:06 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:26:06 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:26:06 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-919ef89c-8e45-490b-85e2-5b3ecf44f8de
16/03/21 17:26:06 INFO MemoryStore: MemoryStore started with capacity 810.7 MB
16/03/21 17:26:06 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-0f1f6b75-9b7f-40ba-8417-8160d4428926
16/03/21 17:26:06 INFO HttpServer: Starting HTTP Server
16/03/21 17:26:06 INFO Utils: Successfully started service 'HTTP file server' on port 46223.
16/03/21 17:26:06 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:26:06 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:26:06 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:26:06 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-273f106c-def6-41df-9631-ff9ec3573047/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:26:06 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561366700
16/03/21 17:26:06 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:26:06 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:26:06 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55047.
16/03/21 17:26:06 INFO NettyBlockTransferService: Server created on 55047
16/03/21 17:26:06 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:26:06 INFO BlockManagerMasterEndpoint: Registering block manager localhost:55047 with 810.7 MB RAM, BlockManagerId(driver, localhost, 55047)
16/03/21 17:26:06 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:26:06 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561366720
16/03/21 17:26:06 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:26:06 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:06 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:26:06 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:26:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:26:06 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:26:06 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=850089738
16/03/21 17:26:06 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 810.7 MB)
16/03/21 17:26:06 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=850089738
16/03/21 17:26:06 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 810.7 MB)
16/03/21 17:26:06 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:55047 (size: 4.1 KB, free: 810.7 MB)
16/03/21 17:26:06 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:26:06 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:06 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:26:06 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:26:06 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:26:06 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:26:06 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561366700
16/03/21 17:26:06 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-273f106c-def6-41df-9631-ff9ec3573047/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:26:06 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:26:06 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=850089738
16/03/21 17:26:06 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 810.7 MB)
16/03/21 17:26:06 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:55047 (size: 166.0 B, free: 810.7 MB)
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: area
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: issue
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: planning
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: permission
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: economy
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: composition
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: agency
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  city  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/21 17:26:14 INFO PythonRunner: Times: total = 7812, boot = 457, init = 364, finish = 6991
16/03/21 17:26:14 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:26:14 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:26:14 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:26:14 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:26:14 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=850089738
16/03/21 17:26:14 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 810.7 MB)
16/03/21 17:26:14 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:55047 (size: 155.0 B, free: 810.7 MB)
16/03/21 17:26:14 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7881 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: set
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: bend
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: giant
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: astatine
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: present
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  city  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: area
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/21 17:26:14 INFO PythonRunner: Times: total = 250, boot = 155, init = 1, finish = 94
16/03/21 17:26:15 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:26:15 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 281 ms on localhost (2/2)
16/03/21 17:26:15 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:26:15 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.154 s
16/03/21 17:26:15 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:26:15 INFO DAGScheduler: running: Set()
16/03/21 17:26:15 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:26:15 INFO DAGScheduler: failed: Set()
16/03/21 17:26:15 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:26:15 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:26:15 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=850089738
16/03/21 17:26:15 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 810.7 MB)
16/03/21 17:26:15 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=850089738
16/03/21 17:26:15 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 810.7 MB)
16/03/21 17:26:15 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:55047 (size: 3.0 KB, free: 810.7 MB)
16/03/21 17:26:15 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:26:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:15 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:26:15 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:26:15 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:26:15 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:26:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:26:15 INFO PythonRunner: Times: total = 127, boot = 126, init = 0, finish = 1
16/03/21 17:26:15 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:26:15 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:26:15 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:26:15 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:26:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:26:15 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 180 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'Chennai', 'None', u'Chennai']
16/03/21 17:26:15 INFO PythonRunner: Times: total = 125, boot = 124, init = 1, finish = 0
16/03/21 17:26:15 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1255 bytes result sent to driver
16/03/21 17:26:15 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.302 s
16/03/21 17:26:15 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.504847 s
16/03/21 17:26:15 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 140 ms on localhost (2/2)
16/03/21 17:26:15 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:26:15 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:26:15 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:26:15 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:15 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:26:15 INFO DAGScheduler: Missing parents: List()
16/03/21 17:26:15 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:26:15 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=850089738
16/03/21 17:26:15 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 810.7 MB)
16/03/21 17:26:15 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=850089738
16/03/21 17:26:15 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 810.7 MB)
16/03/21 17:26:15 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:55047 (size: 3.3 KB, free: 810.7 MB)
16/03/21 17:26:15 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:26:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:15 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:26:15 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:26:15 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:26:15 INFO PythonRunner: Times: total = 4, boot = -15, init = 19, finish = 0
16/03/21 17:26:15 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:26:15 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2285 bytes)
16/03/21 17:26:15 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 25 ms on localhost (1/2)
16/03/21 17:26:15 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:26:15 INFO PythonRunner: Times: total = 149, boot = 149, init = 0, finish = 0
16/03/21 17:26:15 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1324 bytes result sent to driver
16/03/21 17:26:15 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 167 ms on localhost (2/2)
16/03/21 17:26:15 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:26:15 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.184 s
16/03/21 17:26:15 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.205365 s
16/03/21 17:26:15 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:26:15 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:26:15 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:26:15 INFO MemoryStore: MemoryStore cleared
16/03/21 17:26:15 INFO BlockManager: BlockManager stopped
16/03/21 17:26:15 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:26:15 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:26:15 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:26:15 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:26:15 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:26:15 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:26:16 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:26:16 INFO SecurityManager: Changing view acls to: root
16/03/21 17:26:16 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:26:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:26:16 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:26:16 INFO Remoting: Starting remoting
16/03/21 17:26:16 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:53483]
16/03/21 17:26:16 INFO Utils: Successfully started service 'sparkDriver' on port 53483.
16/03/21 17:26:16 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:26:16 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:26:16 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a2e1061e-812c-4a31-b782-da281fb9e4aa
16/03/21 17:26:16 INFO MemoryStore: MemoryStore started with capacity 810.7 MB
16/03/21 17:26:16 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-ff30fab6-e286-4b88-83d9-3d674fe5803c
16/03/21 17:26:16 INFO HttpServer: Starting HTTP Server
16/03/21 17:26:16 INFO Utils: Successfully started service 'HTTP file server' on port 35922.
16/03/21 17:26:16 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:26:16 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:26:16 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:26:16 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-e850778c-4491-4160-8081-edc2574e0bf1/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:26:16 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561376895
16/03/21 17:26:16 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:26:16 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:26:16 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50030.
16/03/21 17:26:16 INFO NettyBlockTransferService: Server created on 50030
16/03/21 17:26:16 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:26:16 INFO BlockManagerMasterEndpoint: Registering block manager localhost:50030 with 810.7 MB RAM, BlockManagerId(driver, localhost, 50030)
16/03/21 17:26:16 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:26:16 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561376904
16/03/21 17:26:17 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:26:17 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:17 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:26:17 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:26:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:26:17 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:26:17 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=850089738
16/03/21 17:26:17 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 810.7 MB)
16/03/21 17:26:17 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=850089738
16/03/21 17:26:17 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 810.7 MB)
16/03/21 17:26:17 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:50030 (size: 4.1 KB, free: 810.7 MB)
16/03/21 17:26:17 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:26:17 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:17 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:26:17 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:26:17 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:26:17 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:26:17 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561376895
16/03/21 17:26:17 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-e850778c-4491-4160-8081-edc2574e0bf1/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:26:17 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:26:17 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=850089738
16/03/21 17:26:17 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 810.7 MB)
16/03/21 17:26:17 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:50030 (size: 166.0 B, free: 810.7 MB)
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: area
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: issue
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: planning
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: permission
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: economy
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: composition
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: agency
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:26:24 INFO PythonRunner: Times: total = 7898, boot = 461, init = 344, finish = 7093
16/03/21 17:26:25 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:26:25 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:26:25 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:26:25 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:26:25 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=850089738
16/03/21 17:26:25 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 810.7 MB)
16/03/21 17:26:25 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:50030 (size: 155.0 B, free: 810.7 MB)
16/03/21 17:26:25 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7978 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: set
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: bend
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: giant
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: astatine
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: present
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: area
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:26:25 INFO PythonRunner: Times: total = 275, boot = 178, init = 1, finish = 96
16/03/21 17:26:25 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:26:25 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.284 s
16/03/21 17:26:25 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:26:25 INFO DAGScheduler: running: Set()
16/03/21 17:26:25 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:26:25 INFO DAGScheduler: failed: Set()
16/03/21 17:26:25 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:26:25 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:26:25 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=850089738
16/03/21 17:26:25 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 810.7 MB)
16/03/21 17:26:25 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 319 ms on localhost (2/2)
16/03/21 17:26:25 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:26:25 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=850089738
16/03/21 17:26:25 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 810.7 MB)
16/03/21 17:26:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:50030 (size: 3.0 KB, free: 810.7 MB)
16/03/21 17:26:25 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:26:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:25 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:26:25 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:26:25 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:26:25 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:26:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:26:25 INFO PythonRunner: Times: total = 136, boot = 135, init = 1, finish = 0
16/03/21 17:26:25 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:26:25 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:26:25 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:26:25 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:26:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:26:25 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 167 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None']
16/03/21 17:26:25 INFO PythonRunner: Times: total = 158, boot = 158, init = 0, finish = 0
16/03/21 17:26:25 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1227 bytes result sent to driver
16/03/21 17:26:25 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 172 ms on localhost (2/2)
16/03/21 17:26:25 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:26:25 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.312 s
16/03/21 17:26:25 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.647313 s
16/03/21 17:26:25 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:26:25 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:26:25 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:25 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:26:25 INFO DAGScheduler: Missing parents: List()
16/03/21 17:26:25 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:26:25 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=850089738
16/03/21 17:26:25 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 810.7 MB)
16/03/21 17:26:25 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=850089738
16/03/21 17:26:25 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 810.7 MB)
16/03/21 17:26:25 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:50030 (size: 3.3 KB, free: 810.7 MB)
16/03/21 17:26:25 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:26:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:25 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:26:25 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:26:25 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:26:25 INFO PythonRunner: Times: total = 82, boot = 82, init = 0, finish = 0
16/03/21 17:26:25 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:26:25 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2257 bytes)
16/03/21 17:26:25 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 100 ms on localhost (1/2)
16/03/21 17:26:25 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:26:26 INFO PythonRunner: Times: total = 151, boot = 150, init = 0, finish = 1
16/03/21 17:26:26 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1296 bytes result sent to driver
16/03/21 17:26:26 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 169 ms on localhost (2/2)
16/03/21 17:26:26 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:26:26 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.265 s
16/03/21 17:26:26 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.277574 s
16/03/21 17:26:26 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:26:26 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:26:26 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:26:26 INFO MemoryStore: MemoryStore cleared
16/03/21 17:26:26 INFO BlockManager: BlockManager stopped
16/03/21 17:26:26 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:26:26 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:26:26 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:26:26 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:26:26 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:26:26 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:26:27 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:26:27 INFO SecurityManager: Changing view acls to: root
16/03/21 17:26:27 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:26:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:26:27 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:26:27 INFO Remoting: Starting remoting
16/03/21 17:26:27 INFO Utils: Successfully started service 'sparkDriver' on port 47494.
16/03/21 17:26:27 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:47494]
16/03/21 17:26:27 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:26:27 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:26:27 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-94ddaba1-8dae-4cea-b29e-512712754903
16/03/21 17:26:27 INFO MemoryStore: MemoryStore started with capacity 810.7 MB
16/03/21 17:26:27 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-5f5185c7-104c-4b84-94e8-d02fc58361df
16/03/21 17:26:27 INFO HttpServer: Starting HTTP Server
16/03/21 17:26:27 INFO Utils: Successfully started service 'HTTP file server' on port 57658.
16/03/21 17:26:27 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:26:27 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:26:27 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:26:27 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-9fad4738-dbeb-4cf9-ba51-3b9a4e836ba6/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:26:27 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561387252
16/03/21 17:26:27 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:26:27 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:26:27 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54665.
16/03/21 17:26:27 INFO NettyBlockTransferService: Server created on 54665
16/03/21 17:26:27 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:26:27 INFO BlockManagerMasterEndpoint: Registering block manager localhost:54665 with 810.7 MB RAM, BlockManagerId(driver, localhost, 54665)
16/03/21 17:26:27 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:26:27 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561387262
16/03/21 17:26:27 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:26:27 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:27 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:26:27 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:26:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:26:27 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:26:27 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=850089738
16/03/21 17:26:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 810.7 MB)
16/03/21 17:26:27 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=850089738
16/03/21 17:26:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 810.7 MB)
16/03/21 17:26:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:54665 (size: 4.1 KB, free: 810.7 MB)
16/03/21 17:26:27 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:26:27 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:27 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:26:27 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:26:27 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:26:27 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:26:27 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561387252
16/03/21 17:26:27 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-9fad4738-dbeb-4cf9-ba51-3b9a4e836ba6/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:26:27 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:26:27 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=850089738
16/03/21 17:26:27 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 810.7 MB)
16/03/21 17:26:27 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:54665 (size: 166.0 B, free: 810.7 MB)
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: area
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: issue
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: planning
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: permission
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: economy
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): adding to parents: syn =  Synset('economy.n.01') ; keyword:  consumption  in syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= [u'economy']
reduceFunction_Parents(): returns= ['None', u'economy']
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: composition
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'economy']
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: agency
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'economy']
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'economy']
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'economy']
16/03/21 17:26:35 INFO PythonRunner: Times: total = 7813, boot = 453, init = 350, finish = 7010
16/03/21 17:26:35 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:26:35 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:26:35 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:26:35 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:26:35 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=850089738
16/03/21 17:26:35 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 810.7 MB)
16/03/21 17:26:35 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:54665 (size: 155.0 B, free: 810.7 MB)
16/03/21 17:26:35 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7890 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: set
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: bend
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: giant
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: astatine
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: present
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: area
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: kilometer
16/03/21 17:26:35 INFO PythonRunner: Times: total = 262, boot = 159, init = 1, finish = 102
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:26:35 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:26:35 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.190 s
16/03/21 17:26:35 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:26:35 INFO DAGScheduler: running: Set()
16/03/21 17:26:35 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:26:35 INFO DAGScheduler: failed: Set()
16/03/21 17:26:35 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:26:35 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:26:35 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=850089738
16/03/21 17:26:35 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 810.7 MB)
16/03/21 17:26:35 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 311 ms on localhost (2/2)
16/03/21 17:26:35 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:26:35 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=850089738
16/03/21 17:26:35 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 810.7 MB)
16/03/21 17:26:35 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:54665 (size: 3.0 KB, free: 810.7 MB)
16/03/21 17:26:35 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:26:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:35 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:26:35 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:26:35 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:26:35 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:26:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:26:35 INFO PythonRunner: Times: total = 121, boot = 120, init = 1, finish = 0
16/03/21 17:26:35 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:26:35 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:26:35 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:26:35 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:26:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:26:35 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 141 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'economy', 'None']
16/03/21 17:26:35 INFO PythonRunner: Times: total = 160, boot = 159, init = 0, finish = 1
16/03/21 17:26:35 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/21 17:26:35 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 182 ms on localhost (2/2)
16/03/21 17:26:35 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:26:35 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.312 s
16/03/21 17:26:35 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.539408 s
16/03/21 17:26:35 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:26:35 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:26:35 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:35 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:26:35 INFO DAGScheduler: Missing parents: List()
16/03/21 17:26:35 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:26:35 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=850089738
16/03/21 17:26:35 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 810.7 MB)
16/03/21 17:26:35 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=850089738
16/03/21 17:26:35 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 810.7 MB)
16/03/21 17:26:35 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:54665 (size: 3.3 KB, free: 810.7 MB)
16/03/21 17:26:35 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:26:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:35 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:26:35 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:26:35 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:26:36 INFO PythonRunner: Times: total = 93, boot = 93, init = 0, finish = 0
16/03/21 17:26:36 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:26:36 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/21 17:26:36 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:26:36 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 113 ms on localhost (1/2)
16/03/21 17:26:36 INFO PythonRunner: Times: total = 173, boot = 173, init = 0, finish = 0
16/03/21 17:26:36 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1310 bytes result sent to driver
16/03/21 17:26:36 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 186 ms on localhost (2/2)
16/03/21 17:26:36 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:26:36 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.267 s
16/03/21 17:26:36 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.306382 s
16/03/21 17:26:36 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:26:36 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:26:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:26:36 INFO MemoryStore: MemoryStore cleared
16/03/21 17:26:36 INFO BlockManager: BlockManager stopped
16/03/21 17:26:36 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:26:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:26:36 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:26:37 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:26:37 INFO SecurityManager: Changing view acls to: root
16/03/21 17:26:37 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:26:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:26:37 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:26:37 INFO Remoting: Starting remoting
16/03/21 17:26:37 INFO Utils: Successfully started service 'sparkDriver' on port 55876.
16/03/21 17:26:37 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:55876]
16/03/21 17:26:37 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:26:37 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:26:37 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e4b8a11e-12a6-4367-862d-299a7d9dd7d6
16/03/21 17:26:37 INFO MemoryStore: MemoryStore started with capacity 810.7 MB
16/03/21 17:26:37 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-74e92538-f337-41f2-a4ef-717d6d09be52
16/03/21 17:26:37 INFO HttpServer: Starting HTTP Server
16/03/21 17:26:37 INFO Utils: Successfully started service 'HTTP file server' on port 53389.
16/03/21 17:26:37 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:26:37 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:26:37 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:26:37 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-3429f8c2-549e-4425-9f52-a2c24bd1baf3/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:26:37 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561397569
16/03/21 17:26:37 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:26:37 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:26:37 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58162.
16/03/21 17:26:37 INFO NettyBlockTransferService: Server created on 58162
16/03/21 17:26:37 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:26:37 INFO BlockManagerMasterEndpoint: Registering block manager localhost:58162 with 810.7 MB RAM, BlockManagerId(driver, localhost, 58162)
16/03/21 17:26:37 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:26:37 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561397591
16/03/21 17:26:37 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:26:37 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:37 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:26:37 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:26:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:26:37 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:26:37 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=850089738
16/03/21 17:26:37 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 810.7 MB)
16/03/21 17:26:37 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=850089738
16/03/21 17:26:37 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 810.7 MB)
16/03/21 17:26:37 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:58162 (size: 4.1 KB, free: 810.7 MB)
16/03/21 17:26:37 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:26:37 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:37 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:26:37 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:26:37 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:26:37 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:26:37 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561397569
16/03/21 17:26:37 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-3429f8c2-549e-4425-9f52-a2c24bd1baf3/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:26:37 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:26:37 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=850089738
16/03/21 17:26:37 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 810.7 MB)
16/03/21 17:26:37 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:58162 (size: 166.0 B, free: 810.7 MB)
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: area
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: issue
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: planning
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: permission
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: economy
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: composition
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: agency
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:26:45 INFO PythonRunner: Times: total = 7903, boot = 465, init = 352, finish = 7086
16/03/21 17:26:45 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:26:45 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:26:45 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:26:45 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7980 ms on localhost (1/2)
16/03/21 17:26:45 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:26:45 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=850089738
16/03/21 17:26:45 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 810.7 MB)
16/03/21 17:26:45 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:58162 (size: 155.0 B, free: 810.7 MB)
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: set
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: bend
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: giant
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: astatine
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: present
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  Eastern  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: area
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
16/03/21 17:26:45 INFO PythonRunner: Times: total = 269, boot = 172, init = 1, finish = 96
16/03/21 17:26:46 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:26:46 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.272 s
16/03/21 17:26:46 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:26:46 INFO DAGScheduler: running: Set()
16/03/21 17:26:46 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:26:46 INFO DAGScheduler: failed: Set()
16/03/21 17:26:46 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:26:46 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:26:46 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 296 ms on localhost (2/2)
16/03/21 17:26:46 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:26:46 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=850089738
16/03/21 17:26:46 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 810.7 MB)
16/03/21 17:26:46 INFO MemoryStore: ensureFreeSpace(3046) called with curMem=16030, maxMem=850089738
16/03/21 17:26:46 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 810.7 MB)
16/03/21 17:26:46 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:58162 (size: 3.0 KB, free: 810.7 MB)
16/03/21 17:26:46 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:26:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:46 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:26:46 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:26:46 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:26:46 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:26:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:26:46 INFO PythonRunner: Times: total = 142, boot = 142, init = 0, finish = 0
16/03/21 17:26:46 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:26:46 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:26:46 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:26:46 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:26:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:26:46 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 169 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'metropolitan']
16/03/21 17:26:46 INFO PythonRunner: Times: total = 168, boot = 167, init = 0, finish = 1
16/03/21 17:26:46 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1246 bytes result sent to driver
16/03/21 17:26:46 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.353 s
16/03/21 17:26:46 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 186 ms on localhost (2/2)
16/03/21 17:26:46 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.649483 s
16/03/21 17:26:46 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:26:46 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:26:46 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:26:46 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:46 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:26:46 INFO DAGScheduler: Missing parents: List()
16/03/21 17:26:46 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:26:46 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19076, maxMem=850089738
16/03/21 17:26:46 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 810.7 MB)
16/03/21 17:26:46 INFO MemoryStore: ensureFreeSpace(3372) called with curMem=24892, maxMem=850089738
16/03/21 17:26:46 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 810.7 MB)
16/03/21 17:26:46 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:58162 (size: 3.3 KB, free: 810.7 MB)
16/03/21 17:26:46 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:26:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:46 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:26:46 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:26:46 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:26:46 INFO PythonRunner: Times: total = 104, boot = 104, init = 0, finish = 0
16/03/21 17:26:46 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:26:46 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2276 bytes)
16/03/21 17:26:46 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 122 ms on localhost (1/2)
16/03/21 17:26:46 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:26:46 INFO PythonRunner: Times: total = 153, boot = 153, init = 0, finish = 0
16/03/21 17:26:46 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1315 bytes result sent to driver
16/03/21 17:26:46 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.291 s
16/03/21 17:26:46 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.304684 s
16/03/21 17:26:46 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 174 ms on localhost (2/2)
16/03/21 17:26:46 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:26:46 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:26:46 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:26:46 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:26:46 INFO MemoryStore: MemoryStore cleared
16/03/21 17:26:46 INFO BlockManager: BlockManager stopped
16/03/21 17:26:46 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:26:46 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:26:46 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:26:46 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:26:46 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:26:46 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:26:47 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:26:47 INFO SecurityManager: Changing view acls to: root
16/03/21 17:26:47 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:26:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:26:47 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:26:47 INFO Remoting: Starting remoting
16/03/21 17:26:47 INFO Utils: Successfully started service 'sparkDriver' on port 33226.
16/03/21 17:26:47 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:33226]
16/03/21 17:26:47 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:26:47 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:26:47 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-59a420da-260e-4629-85aa-b9292e2af7cd
16/03/21 17:26:47 INFO MemoryStore: MemoryStore started with capacity 810.7 MB
16/03/21 17:26:47 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-668643fd-195c-4eeb-b0af-1d3fb1dd8b3e
16/03/21 17:26:47 INFO HttpServer: Starting HTTP Server
16/03/21 17:26:47 INFO Utils: Successfully started service 'HTTP file server' on port 53339.
16/03/21 17:26:47 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:26:47 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:26:47 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:26:47 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-e8f33587-0b6e-42c7-81ce-00cc5a58cff5/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:26:47 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561407976
16/03/21 17:26:47 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:26:47 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:26:48 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39477.
16/03/21 17:26:48 INFO NettyBlockTransferService: Server created on 39477
16/03/21 17:26:48 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:26:48 INFO BlockManagerMasterEndpoint: Registering block manager localhost:39477 with 810.7 MB RAM, BlockManagerId(driver, localhost, 39477)
16/03/21 17:26:48 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:26:48 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561407992
16/03/21 17:26:48 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:26:48 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:48 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:26:48 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:26:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:26:48 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:26:48 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=850089738
16/03/21 17:26:48 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 810.7 MB)
16/03/21 17:26:48 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=850089738
16/03/21 17:26:48 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 810.7 MB)
16/03/21 17:26:48 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:39477 (size: 4.1 KB, free: 810.7 MB)
16/03/21 17:26:48 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:26:48 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:48 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:26:48 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:26:48 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:26:48 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:26:48 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561407976
16/03/21 17:26:48 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-e8f33587-0b6e-42c7-81ce-00cc5a58cff5/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:26:48 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:26:48 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=850089738
16/03/21 17:26:48 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 810.7 MB)
16/03/21 17:26:48 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:39477 (size: 166.0 B, free: 810.7 MB)
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: area
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: issue
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: planning
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: permission
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: economy
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: composition
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: agency
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:26:56 INFO PythonRunner: Times: total = 7942, boot = 449, init = 353, finish = 7140
16/03/21 17:26:56 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:26:56 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:26:56 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:26:56 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:26:56 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8027 ms on localhost (1/2)
16/03/21 17:26:56 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=850089738
16/03/21 17:26:56 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 810.7 MB)
16/03/21 17:26:56 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:39477 (size: 155.0 B, free: 810.7 MB)
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: set
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: bend
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: giant
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: astatine
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: present
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  stretch  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: area
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/21 17:26:56 INFO PythonRunner: Times: total = 290, boot = 193, init = 1, finish = 96
16/03/21 17:26:56 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:26:56 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.340 s
16/03/21 17:26:56 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:26:56 INFO DAGScheduler: running: Set()
16/03/21 17:26:56 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:26:56 INFO DAGScheduler: failed: Set()
16/03/21 17:26:56 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:26:56 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:26:56 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=850089738
16/03/21 17:26:56 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 810.7 MB)
16/03/21 17:26:56 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 325 ms on localhost (2/2)
16/03/21 17:26:56 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:26:56 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=850089738
16/03/21 17:26:56 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 810.7 MB)
16/03/21 17:26:56 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:39477 (size: 3.0 KB, free: 810.7 MB)
16/03/21 17:26:56 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:26:56 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:56 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:26:56 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:26:56 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:26:56 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:26:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:26:56 INFO PythonRunner: Times: total = 172, boot = 172, init = 0, finish = 0
16/03/21 17:26:56 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:26:56 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:26:56 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:26:56 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:26:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:26:56 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 210 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'present']
16/03/21 17:26:56 INFO PythonRunner: Times: total = 153, boot = 152, init = 1, finish = 0
16/03/21 17:26:56 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/21 17:26:56 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 168 ms on localhost (2/2)
16/03/21 17:26:56 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:26:56 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.357 s
16/03/21 17:26:56 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.728193 s
16/03/21 17:26:57 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:39477 in memory (size: 3.0 KB, free: 810.7 MB)
16/03/21 17:26:57 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:26:57 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:26:57 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:57 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:26:57 INFO DAGScheduler: Missing parents: List()
16/03/21 17:26:57 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:26:57 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=11046, maxMem=850089738
16/03/21 17:26:57 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 810.7 MB)
16/03/21 17:26:57 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=16862, maxMem=850089738
16/03/21 17:26:57 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 810.7 MB)
16/03/21 17:26:57 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:39477 (size: 3.3 KB, free: 810.7 MB)
16/03/21 17:26:57 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:26:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:57 INFO ContextCleaner: Cleaned accumulator 223
16/03/21 17:26:57 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:39477 in memory (size: 4.1 KB, free: 810.7 MB)
16/03/21 17:26:57 INFO ContextCleaner: Cleaned accumulator 222
16/03/21 17:26:57 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:26:57 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:26:57 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:26:57 INFO PythonRunner: Times: total = 17, boot = -137, init = 154, finish = 0
16/03/21 17:26:57 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:26:57 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/21 17:26:57 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 50 ms on localhost (1/2)
16/03/21 17:26:57 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:26:57 INFO PythonRunner: Times: total = 153, boot = 152, init = 1, finish = 0
16/03/21 17:26:57 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1310 bytes result sent to driver
16/03/21 17:26:57 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.214 s
16/03/21 17:26:57 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.238905 s
16/03/21 17:26:57 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 173 ms on localhost (2/2)
16/03/21 17:26:57 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:26:57 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:26:57 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:26:57 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:26:57 INFO MemoryStore: MemoryStore cleared
16/03/21 17:26:57 INFO BlockManager: BlockManager stopped
16/03/21 17:26:57 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:26:57 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:26:57 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:26:57 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:26:57 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:26:57 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:26:58 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:26:58 INFO SecurityManager: Changing view acls to: root
16/03/21 17:26:58 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:26:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:26:58 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:26:58 INFO Remoting: Starting remoting
16/03/21 17:26:58 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:57905]
16/03/21 17:26:58 INFO Utils: Successfully started service 'sparkDriver' on port 57905.
16/03/21 17:26:58 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:26:58 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:26:58 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-bd998ce5-0bc7-4df8-b56f-0380b5ec3311
16/03/21 17:26:58 INFO MemoryStore: MemoryStore started with capacity 811.4 MB
16/03/21 17:26:58 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-0c18ccf3-517f-44be-821f-ac8fa0994465
16/03/21 17:26:58 INFO HttpServer: Starting HTTP Server
16/03/21 17:26:58 INFO Utils: Successfully started service 'HTTP file server' on port 56046.
16/03/21 17:26:58 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:26:58 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:26:58 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:26:58 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-46fcb893-c3c7-400d-9d74-1297fa88732f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:26:58 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561418692
16/03/21 17:26:58 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:26:58 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:26:58 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35726.
16/03/21 17:26:58 INFO NettyBlockTransferService: Server created on 35726
16/03/21 17:26:58 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:26:58 INFO BlockManagerMasterEndpoint: Registering block manager localhost:35726 with 811.4 MB RAM, BlockManagerId(driver, localhost, 35726)
16/03/21 17:26:58 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:26:58 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561418708
16/03/21 17:26:58 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:26:58 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:58 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:26:58 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:26:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:26:58 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:26:58 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=850832916
16/03/21 17:26:58 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 811.4 MB)
16/03/21 17:26:58 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6576, maxMem=850832916
16/03/21 17:26:58 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 811.4 MB)
16/03/21 17:26:58 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:35726 (size: 4.1 KB, free: 811.4 MB)
16/03/21 17:26:58 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:26:58 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:26:58 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:26:58 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:26:58 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:26:58 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:26:58 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561418692
16/03/21 17:26:58 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-46fcb893-c3c7-400d-9d74-1297fa88732f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:26:58 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:26:58 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10724, maxMem=850832916
16/03/21 17:26:58 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 811.4 MB)
16/03/21 17:26:58 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:35726 (size: 166.0 B, free: 811.4 MB)
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: area
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: issue
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: planning
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: permission
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: economy
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: composition
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: agency
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:27:06 INFO PythonRunner: Times: total = 7817, boot = 478, init = 354, finish = 6985
16/03/21 17:27:06 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:27:06 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:27:06 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:27:06 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:27:06 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10890, maxMem=850832916
16/03/21 17:27:06 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 811.4 MB)
16/03/21 17:27:06 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7879 ms on localhost (1/2)
16/03/21 17:27:06 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:35726 (size: 155.0 B, free: 811.4 MB)
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: set
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: bend
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: giant
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: astatine
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: present
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  archbishop  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: area
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
16/03/21 17:27:06 INFO PythonRunner: Times: total = 251, boot = 158, init = 0, finish = 93
16/03/21 17:27:06 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:27:06 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.154 s
16/03/21 17:27:06 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:27:06 INFO DAGScheduler: running: Set()
16/03/21 17:27:06 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:27:06 INFO DAGScheduler: failed: Set()
16/03/21 17:27:06 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:27:06 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:27:06 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11045, maxMem=850832916
16/03/21 17:27:06 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 811.4 MB)
16/03/21 17:27:07 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 282 ms on localhost (2/2)
16/03/21 17:27:07 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:27:07 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16029, maxMem=850832916
16/03/21 17:27:07 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 811.4 MB)
16/03/21 17:27:07 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:35726 (size: 3.0 KB, free: 811.4 MB)
16/03/21 17:27:07 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:27:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:27:07 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:27:07 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:27:07 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:27:07 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:27:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:27:07 INFO PythonRunner: Times: total = 123, boot = 123, init = 0, finish = 0
16/03/21 17:27:07 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:27:07 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:27:07 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:27:07 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:27:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:27:07 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 150 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'metropolitan']
16/03/21 17:27:07 INFO PythonRunner: Times: total = 152, boot = 151, init = 0, finish = 1
16/03/21 17:27:07 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1246 bytes result sent to driver
16/03/21 17:27:07 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.296 s
16/03/21 17:27:07 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.493995 s
16/03/21 17:27:07 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 166 ms on localhost (2/2)
16/03/21 17:27:07 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:27:07 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:27:07 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:27:07 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:27:07 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:27:07 INFO DAGScheduler: Missing parents: List()
16/03/21 17:27:07 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:27:07 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19076, maxMem=850832916
16/03/21 17:27:07 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 811.4 MB)
16/03/21 17:27:07 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24892, maxMem=850832916
16/03/21 17:27:07 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 811.4 MB)
16/03/21 17:27:07 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:35726 (size: 3.3 KB, free: 811.4 MB)
16/03/21 17:27:07 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:27:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:27:07 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:27:07 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:27:07 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:27:07 INFO PythonRunner: Times: total = 88, boot = 87, init = 1, finish = 0
16/03/21 17:27:07 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:27:07 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2276 bytes)
16/03/21 17:27:07 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 107 ms on localhost (1/2)
16/03/21 17:27:07 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:27:07 INFO PythonRunner: Times: total = 152, boot = 152, init = 0, finish = 0
16/03/21 17:27:07 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1315 bytes result sent to driver
16/03/21 17:27:07 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 173 ms on localhost (2/2)
16/03/21 17:27:07 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:27:07 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.274 s
16/03/21 17:27:07 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.301353 s
16/03/21 17:27:07 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:27:07 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:27:07 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:27:07 INFO MemoryStore: MemoryStore cleared
16/03/21 17:27:07 INFO BlockManager: BlockManager stopped
16/03/21 17:27:07 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:27:07 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:27:07 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:27:07 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:27:07 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:27:07 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:27:08 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:27:08 INFO SecurityManager: Changing view acls to: root
16/03/21 17:27:08 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:27:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:27:08 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:27:08 INFO Remoting: Starting remoting
16/03/21 17:27:08 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:41843]
16/03/21 17:27:08 INFO Utils: Successfully started service 'sparkDriver' on port 41843.
16/03/21 17:27:08 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:27:08 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:27:08 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-032a4302-cbe7-4636-b295-9afeafea5bff
16/03/21 17:27:08 INFO MemoryStore: MemoryStore started with capacity 811.4 MB
16/03/21 17:27:08 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-65ba09d1-7b38-45ce-b7cb-ddcc92fcd34d
16/03/21 17:27:08 INFO HttpServer: Starting HTTP Server
16/03/21 17:27:08 INFO Utils: Successfully started service 'HTTP file server' on port 59624.
16/03/21 17:27:08 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:27:08 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:27:08 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:27:08 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-7d70e56a-692c-43df-891e-54460d029b87/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:27:08 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561428930
16/03/21 17:27:08 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:27:08 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:27:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 47806.
16/03/21 17:27:08 INFO NettyBlockTransferService: Server created on 47806
16/03/21 17:27:08 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:27:08 INFO BlockManagerMasterEndpoint: Registering block manager localhost:47806 with 811.4 MB RAM, BlockManagerId(driver, localhost, 47806)
16/03/21 17:27:08 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:27:08 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561428941
16/03/21 17:27:09 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:27:09 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:27:09 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:27:09 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:27:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:27:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:27:09 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:27:09 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=850832916
16/03/21 17:27:09 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 811.4 MB)
16/03/21 17:27:09 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=850832916
16/03/21 17:27:09 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 811.4 MB)
16/03/21 17:27:09 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:47806 (size: 4.1 KB, free: 811.4 MB)
16/03/21 17:27:09 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:27:09 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:27:09 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:27:09 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:27:09 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:27:09 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:27:09 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561428930
16/03/21 17:27:09 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-7d70e56a-692c-43df-891e-54460d029b87/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:27:09 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:27:09 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=850832916
16/03/21 17:27:09 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 811.4 MB)
16/03/21 17:27:09 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:47806 (size: 166.0 B, free: 811.4 MB)
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: area
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: issue
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: planning
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: permission
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: economy
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): adding to parents: syn =  Synset('economy.n.01') ; keyword:  system  in syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= [u'economy']
reduceFunction_Parents(): returns= ['None', u'economy']
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: composition
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'economy']
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: agency
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'economy']
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'economy']
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'economy']
16/03/21 17:27:16 INFO PythonRunner: Times: total = 7727, boot = 455, init = 356, finish = 6916
16/03/21 17:27:16 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:27:16 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:27:16 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:27:16 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:27:16 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=850832916
16/03/21 17:27:16 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 811.4 MB)
16/03/21 17:27:16 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7801 ms on localhost (1/2)
16/03/21 17:27:16 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:47806 (size: 155.0 B, free: 811.4 MB)
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: set
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: bend
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: giant
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: astatine
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: present
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: area
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:27:17 INFO PythonRunner: Times: total = 232, boot = 133, init = 0, finish = 99
16/03/21 17:27:17 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:27:17 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 279 ms on localhost (2/2)
16/03/21 17:27:17 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:27:17 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.069 s
16/03/21 17:27:17 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:27:17 INFO DAGScheduler: running: Set()
16/03/21 17:27:17 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:27:17 INFO DAGScheduler: failed: Set()
16/03/21 17:27:17 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:27:17 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:27:17 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=850832916
16/03/21 17:27:17 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 811.4 MB)
16/03/21 17:27:17 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=850832916
16/03/21 17:27:17 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 811.4 MB)
16/03/21 17:27:17 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:47806 (size: 3.0 KB, free: 811.4 MB)
16/03/21 17:27:17 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:27:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:27:17 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:27:17 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:27:17 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:27:17 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:27:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:27:17 INFO PythonRunner: Times: total = 139, boot = 139, init = 0, finish = 0
16/03/21 17:27:17 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:27:17 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:27:17 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:27:17 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:27:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:27:17 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 160 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'economy', 'None']
16/03/21 17:27:17 INFO PythonRunner: Times: total = 153, boot = 152, init = 1, finish = 0
16/03/21 17:27:17 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/21 17:27:17 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 167 ms on localhost (2/2)
16/03/21 17:27:17 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.310 s
16/03/21 17:27:17 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:27:17 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.412075 s
16/03/21 17:27:17 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:27:17 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:27:17 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:27:17 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:27:17 INFO DAGScheduler: Missing parents: List()
16/03/21 17:27:17 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:27:17 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=850832916
16/03/21 17:27:17 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 811.4 MB)
16/03/21 17:27:17 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=850832916
16/03/21 17:27:17 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 811.4 MB)
16/03/21 17:27:17 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:47806 (size: 3.3 KB, free: 811.4 MB)
16/03/21 17:27:17 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:27:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:27:17 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:27:17 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:27:17 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:27:17 INFO PythonRunner: Times: total = 96, boot = 96, init = 0, finish = 0
16/03/21 17:27:17 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:27:17 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/21 17:27:17 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:27:17 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 112 ms on localhost (1/2)
16/03/21 17:27:17 INFO PythonRunner: Times: total = 159, boot = 159, init = 0, finish = 0
16/03/21 17:27:17 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1310 bytes result sent to driver
16/03/21 17:27:17 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.270 s
16/03/21 17:27:17 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.292548 s
16/03/21 17:27:17 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 173 ms on localhost (2/2)
16/03/21 17:27:17 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:27:17 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:27:17 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:27:17 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:27:17 INFO MemoryStore: MemoryStore cleared
16/03/21 17:27:17 INFO BlockManager: BlockManager stopped
16/03/21 17:27:17 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:27:17 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:27:17 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:27:18 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:27:18 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:27:18 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:27:18 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:27:18 INFO SecurityManager: Changing view acls to: root
16/03/21 17:27:18 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:27:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:27:18 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:27:18 INFO Remoting: Starting remoting
16/03/21 17:27:18 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:43165]
16/03/21 17:27:18 INFO Utils: Successfully started service 'sparkDriver' on port 43165.
16/03/21 17:27:18 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:27:18 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:27:18 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a9b78b3c-b932-47cf-a3a1-e486fd42a2ec
16/03/21 17:27:18 INFO MemoryStore: MemoryStore started with capacity 811.4 MB
16/03/21 17:27:18 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-76b411c1-12b7-46bf-9cc4-ae3ab73502fa
16/03/21 17:27:18 INFO HttpServer: Starting HTTP Server
16/03/21 17:27:18 INFO Utils: Successfully started service 'HTTP file server' on port 36638.
16/03/21 17:27:18 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:27:19 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:27:19 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:27:19 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-f12804d4-76a0-4717-828e-50eea13897b4/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:27:19 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561439026
16/03/21 17:27:19 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:27:19 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:27:19 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57972.
16/03/21 17:27:19 INFO NettyBlockTransferService: Server created on 57972
16/03/21 17:27:19 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:27:19 INFO BlockManagerMasterEndpoint: Registering block manager localhost:57972 with 811.4 MB RAM, BlockManagerId(driver, localhost, 57972)
16/03/21 17:27:19 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:27:19 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561439036
16/03/21 17:27:19 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:27:19 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:27:19 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:27:19 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:27:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:27:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:27:19 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:27:19 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=850832916
16/03/21 17:27:19 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 811.4 MB)
16/03/21 17:27:19 INFO MemoryStore: ensureFreeSpace(4152) called with curMem=6576, maxMem=850832916
16/03/21 17:27:19 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 811.4 MB)
16/03/21 17:27:19 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:57972 (size: 4.1 KB, free: 811.4 MB)
16/03/21 17:27:19 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:27:19 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:27:19 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:27:19 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:27:19 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:27:19 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:27:19 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561439026
16/03/21 17:27:19 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-f12804d4-76a0-4717-828e-50eea13897b4/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:27:19 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:27:19 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10728, maxMem=850832916
16/03/21 17:27:19 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 811.4 MB)
16/03/21 17:27:19 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:57972 (size: 166.0 B, free: 811.4 MB)
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: area
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: issue
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: planning
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: permission
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: economy
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: composition
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: agency
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:27:27 INFO PythonRunner: Times: total = 7846, boot = 449, init = 355, finish = 7042
16/03/21 17:27:27 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:27:27 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:27:27 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:27:27 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:27:27 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10894, maxMem=850832916
16/03/21 17:27:27 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 811.4 MB)
16/03/21 17:27:27 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7920 ms on localhost (1/2)
16/03/21 17:27:27 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:57972 (size: 155.0 B, free: 811.4 MB)
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: set
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: bend
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: giant
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: astatine
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  halogen  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: present
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: area
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/21 17:27:27 INFO PythonRunner: Times: total = 268, boot = 170, init = 1, finish = 97
16/03/21 17:27:27 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:27:27 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.208 s
16/03/21 17:27:27 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:27:27 INFO DAGScheduler: running: Set()
16/03/21 17:27:27 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:27:27 INFO DAGScheduler: failed: Set()
16/03/21 17:27:27 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:27:27 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:27:27 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11049, maxMem=850832916
16/03/21 17:27:27 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 811.4 MB)
16/03/21 17:27:27 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16033, maxMem=850832916
16/03/21 17:27:27 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 295 ms on localhost (2/2)
16/03/21 17:27:27 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:27:27 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 811.4 MB)
16/03/21 17:27:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:57972 (size: 3.0 KB, free: 811.4 MB)
16/03/21 17:27:27 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:27:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:27:27 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:27:27 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:27:27 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:27:27 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:27:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:27:27 INFO PythonRunner: Times: total = 142, boot = 142, init = 0, finish = 0
16/03/21 17:27:27 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:27:27 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:27:27 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:27:27 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:27:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:27:27 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 176 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/03/21 17:27:27 INFO PythonRunner: Times: total = 159, boot = 158, init = 0, finish = 1
16/03/21 17:27:27 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1242 bytes result sent to driver
16/03/21 17:27:27 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.347 s
16/03/21 17:27:27 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 185 ms on localhost (2/2)
16/03/21 17:27:27 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.582761 s
16/03/21 17:27:27 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:27:27 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:27:27 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:27:27 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:27:27 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:27:27 INFO DAGScheduler: Missing parents: List()
16/03/21 17:27:27 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:27:27 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19080, maxMem=850832916
16/03/21 17:27:27 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 811.4 MB)
16/03/21 17:27:27 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24896, maxMem=850832916
16/03/21 17:27:27 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 811.4 MB)
16/03/21 17:27:27 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:57972 (size: 3.3 KB, free: 811.4 MB)
16/03/21 17:27:27 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:27:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:27:27 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:27:27 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:27:27 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:27:27 INFO PythonRunner: Times: total = 69, boot = 69, init = 0, finish = 0
16/03/21 17:27:27 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:27:27 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2272 bytes)
16/03/21 17:27:27 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:27:27 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 84 ms on localhost (1/2)
16/03/21 17:27:28 INFO PythonRunner: Times: total = 161, boot = 161, init = 0, finish = 0
16/03/21 17:27:28 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1311 bytes result sent to driver
16/03/21 17:27:28 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.261 s
16/03/21 17:27:28 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.273227 s
16/03/21 17:27:28 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 178 ms on localhost (2/2)
16/03/21 17:27:28 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:27:28 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:27:28 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:27:28 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:27:28 INFO MemoryStore: MemoryStore cleared
16/03/21 17:27:28 INFO BlockManager: BlockManager stopped
16/03/21 17:27:28 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:27:28 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:27:28 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:27:28 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:27:28 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:27:28 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:27:29 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:27:29 INFO SecurityManager: Changing view acls to: root
16/03/21 17:27:29 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:27:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:27:29 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:27:29 INFO Remoting: Starting remoting
16/03/21 17:27:29 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:33440]
16/03/21 17:27:29 INFO Utils: Successfully started service 'sparkDriver' on port 33440.
16/03/21 17:27:29 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:27:29 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:27:29 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-79e85572-6c9a-4d78-ab60-defac156a0d1
16/03/21 17:27:29 INFO MemoryStore: MemoryStore started with capacity 811.4 MB
16/03/21 17:27:29 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-380486ad-e59f-4b2c-a046-cf92cab7d39b
16/03/21 17:27:29 INFO HttpServer: Starting HTTP Server
16/03/21 17:27:29 INFO Utils: Successfully started service 'HTTP file server' on port 53464.
16/03/21 17:27:29 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:27:29 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:27:29 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:27:29 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-b583e15f-9c66-46fb-9744-00b85be45f1c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:27:29 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561449316
16/03/21 17:27:29 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:27:29 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:27:29 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38838.
16/03/21 17:27:29 INFO NettyBlockTransferService: Server created on 38838
16/03/21 17:27:29 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:27:29 INFO BlockManagerMasterEndpoint: Registering block manager localhost:38838 with 811.4 MB RAM, BlockManagerId(driver, localhost, 38838)
16/03/21 17:27:29 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:27:29 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561449331
16/03/21 17:27:29 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:27:29 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:27:29 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:27:29 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:27:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:27:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:27:29 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:27:29 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=850832916
16/03/21 17:27:29 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 811.4 MB)
16/03/21 17:27:29 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=850832916
16/03/21 17:27:29 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 811.4 MB)
16/03/21 17:27:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:38838 (size: 4.1 KB, free: 811.4 MB)
16/03/21 17:27:29 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:27:29 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:27:29 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:27:29 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:27:29 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:27:29 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:27:29 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561449316
16/03/21 17:27:29 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-b583e15f-9c66-46fb-9744-00b85be45f1c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:27:29 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:27:29 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=850832916
16/03/21 17:27:29 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 811.4 MB)
16/03/21 17:27:29 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:38838 (size: 166.0 B, free: 811.4 MB)
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: area
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: issue
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: planning
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: permission
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: economy
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: composition
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: agency
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:27:37 INFO PythonRunner: Times: total = 7748, boot = 462, init = 351, finish = 6935
16/03/21 17:27:37 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:27:37 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:27:37 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:27:37 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:27:37 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=850832916
16/03/21 17:27:37 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 811.4 MB)
16/03/21 17:27:37 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7819 ms on localhost (1/2)
16/03/21 17:27:37 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:38838 (size: 155.0 B, free: 811.4 MB)
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: set
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: bend
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: giant
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: astatine
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: present
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  continuous  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: area
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/21 17:27:37 INFO PythonRunner: Times: total = 254, boot = 153, init = 0, finish = 101
16/03/21 17:27:37 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:27:37 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.092 s
16/03/21 17:27:37 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:27:37 INFO DAGScheduler: running: Set()
16/03/21 17:27:37 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:27:37 INFO DAGScheduler: failed: Set()
16/03/21 17:27:37 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:27:37 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:27:37 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=850832916
16/03/21 17:27:37 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 811.4 MB)
16/03/21 17:27:37 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 280 ms on localhost (2/2)
16/03/21 17:27:37 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:27:37 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=850832916
16/03/21 17:27:37 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 811.4 MB)
16/03/21 17:27:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:38838 (size: 3.0 KB, free: 811.4 MB)
16/03/21 17:27:37 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:27:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:27:37 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:27:37 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:27:37 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:27:37 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:27:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:27:37 INFO PythonRunner: Times: total = 161, boot = 160, init = 1, finish = 0
16/03/21 17:27:37 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:27:37 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:27:37 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:27:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:27:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:27:37 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 182 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'present']
16/03/21 17:27:37 INFO PythonRunner: Times: total = 165, boot = 164, init = 0, finish = 1
16/03/21 17:27:37 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/21 17:27:37 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.362 s
16/03/21 17:27:37 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.495164 s
16/03/21 17:27:37 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 188 ms on localhost (2/2)
16/03/21 17:27:37 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:27:38 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:27:38 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:27:38 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:27:38 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:27:38 INFO DAGScheduler: Missing parents: List()
16/03/21 17:27:38 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:27:38 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=850832916
16/03/21 17:27:38 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 811.4 MB)
16/03/21 17:27:38 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=850832916
16/03/21 17:27:38 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 811.4 MB)
16/03/21 17:27:38 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:38838 (size: 3.3 KB, free: 811.4 MB)
16/03/21 17:27:38 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:27:38 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:27:38 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:27:38 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:27:38 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:27:38 INFO PythonRunner: Times: total = 73, boot = 72, init = 1, finish = 0
16/03/21 17:27:38 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:27:38 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/21 17:27:38 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 88 ms on localhost (1/2)
16/03/21 17:27:38 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:27:38 INFO PythonRunner: Times: total = 154, boot = 153, init = 1, finish = 0
16/03/21 17:27:38 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1310 bytes result sent to driver
16/03/21 17:27:38 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 174 ms on localhost (2/2)
16/03/21 17:27:38 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:27:38 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.248 s
16/03/21 17:27:38 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.269897 s
16/03/21 17:27:38 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:27:38 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:27:38 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:27:38 INFO MemoryStore: MemoryStore cleared
16/03/21 17:27:38 INFO BlockManager: BlockManager stopped
16/03/21 17:27:38 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:27:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:27:38 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:27:38 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:27:38 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:27:39 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:27:39 INFO SecurityManager: Changing view acls to: root
16/03/21 17:27:39 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:27:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:27:39 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:27:39 INFO Remoting: Starting remoting
16/03/21 17:27:39 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:38544]
16/03/21 17:27:39 INFO Utils: Successfully started service 'sparkDriver' on port 38544.
16/03/21 17:27:39 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:27:39 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:27:39 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9bc67fc3-1ebe-446d-8f52-93227f82dd10
16/03/21 17:27:39 INFO MemoryStore: MemoryStore started with capacity 811.4 MB
16/03/21 17:27:39 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-3540bdb2-ed73-4873-9dab-bc29f7bbd53c
16/03/21 17:27:39 INFO HttpServer: Starting HTTP Server
16/03/21 17:27:39 INFO Utils: Successfully started service 'HTTP file server' on port 44090.
16/03/21 17:27:39 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:27:39 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:27:39 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:27:39 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-2c44666f-fbd6-4e5d-87c4-98eb7984a5e4/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:27:39 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561459530
16/03/21 17:27:39 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:27:39 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:27:39 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55399.
16/03/21 17:27:39 INFO NettyBlockTransferService: Server created on 55399
16/03/21 17:27:39 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:27:39 INFO BlockManagerMasterEndpoint: Registering block manager localhost:55399 with 811.4 MB RAM, BlockManagerId(driver, localhost, 55399)
16/03/21 17:27:39 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:27:39 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561459543
16/03/21 17:27:39 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:27:39 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:27:39 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:27:39 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:27:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:27:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:27:39 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:27:39 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=850832916
16/03/21 17:27:39 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 811.4 MB)
16/03/21 17:27:39 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=850832916
16/03/21 17:27:39 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 811.4 MB)
16/03/21 17:27:39 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:55399 (size: 4.1 KB, free: 811.4 MB)
16/03/21 17:27:39 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:27:39 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:27:39 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:27:39 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:27:39 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:27:39 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:27:39 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561459530
16/03/21 17:27:39 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-2c44666f-fbd6-4e5d-87c4-98eb7984a5e4/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:27:39 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:27:39 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=850832916
16/03/21 17:27:39 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 811.4 MB)
16/03/21 17:27:39 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:55399 (size: 166.0 B, free: 811.4 MB)
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: area
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: issue
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: planning
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: permission
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: economy
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: composition
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: agency
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:27:47 INFO PythonRunner: Times: total = 7906, boot = 476, init = 355, finish = 7075
16/03/21 17:27:47 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:27:47 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:27:47 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:27:47 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:27:47 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=850832916
16/03/21 17:27:47 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 811.4 MB)
16/03/21 17:27:47 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7977 ms on localhost (1/2)
16/03/21 17:27:47 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:55399 (size: 155.0 B, free: 811.4 MB)
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: set
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: bend
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: giant
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: astatine
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: present
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  western  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: area
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
16/03/21 17:27:47 INFO PythonRunner: Times: total = 247, boot = 147, init = 1, finish = 99
16/03/21 17:27:47 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:27:47 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 284 ms on localhost (2/2)
16/03/21 17:27:47 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:27:47 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.241 s
16/03/21 17:27:47 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:27:47 INFO DAGScheduler: running: Set()
16/03/21 17:27:47 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:27:47 INFO DAGScheduler: failed: Set()
16/03/21 17:27:47 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:27:47 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:27:47 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=850832916
16/03/21 17:27:47 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 811.4 MB)
16/03/21 17:27:47 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=850832916
16/03/21 17:27:47 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 811.4 MB)
16/03/21 17:27:47 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:55399 (size: 3.0 KB, free: 811.4 MB)
16/03/21 17:27:47 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:27:47 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:27:47 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:27:47 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:27:47 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:27:47 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:27:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:27:48 INFO PythonRunner: Times: total = 138, boot = 137, init = 1, finish = 0
16/03/21 17:27:48 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:27:48 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:27:48 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:27:48 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:27:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:27:48 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 164 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'metropolitan']
16/03/21 17:27:48 INFO PythonRunner: Times: total = 150, boot = 150, init = 0, finish = 0
16/03/21 17:27:48 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1246 bytes result sent to driver
16/03/21 17:27:48 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.314 s
16/03/21 17:27:48 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.594109 s
16/03/21 17:27:48 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 170 ms on localhost (2/2)
16/03/21 17:27:48 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:27:48 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:27:48 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:27:48 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:27:48 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:27:48 INFO DAGScheduler: Missing parents: List()
16/03/21 17:27:48 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:27:48 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=850832916
16/03/21 17:27:48 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 811.4 MB)
16/03/21 17:27:48 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=850832916
16/03/21 17:27:48 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 811.4 MB)
16/03/21 17:27:48 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:55399 (size: 3.3 KB, free: 811.4 MB)
16/03/21 17:27:48 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:27:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:27:48 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:27:48 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:27:48 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:27:48 INFO PythonRunner: Times: total = 78, boot = 78, init = 0, finish = 0
16/03/21 17:27:48 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:27:48 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2276 bytes)
16/03/21 17:27:48 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 97 ms on localhost (1/2)
16/03/21 17:27:48 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:27:48 INFO PythonRunner: Times: total = 147, boot = 147, init = 0, finish = 0
16/03/21 17:27:48 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1315 bytes result sent to driver
16/03/21 17:27:48 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 167 ms on localhost (2/2)
16/03/21 17:27:48 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:27:48 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.247 s
16/03/21 17:27:48 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.272849 s
16/03/21 17:27:48 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:27:48 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:27:48 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:27:48 INFO MemoryStore: MemoryStore cleared
16/03/21 17:27:48 INFO BlockManager: BlockManager stopped
16/03/21 17:27:48 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:27:48 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:27:48 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:27:48 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:27:48 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:27:49 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:27:49 INFO SecurityManager: Changing view acls to: root
16/03/21 17:27:49 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:27:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:27:49 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:27:49 INFO Remoting: Starting remoting
16/03/21 17:27:49 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:53411]
16/03/21 17:27:49 INFO Utils: Successfully started service 'sparkDriver' on port 53411.
16/03/21 17:27:49 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:27:49 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:27:49 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e768b1fa-aa4e-42ae-b351-ecfb1d3b0bac
16/03/21 17:27:49 INFO MemoryStore: MemoryStore started with capacity 811.4 MB
16/03/21 17:27:49 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-225a3782-f53c-4ac3-b3ef-d4b49328ca34
16/03/21 17:27:49 INFO HttpServer: Starting HTTP Server
16/03/21 17:27:49 INFO Utils: Successfully started service 'HTTP file server' on port 45669.
16/03/21 17:27:49 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:27:50 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:27:50 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:27:50 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-42a536fb-6cc6-4e3c-a368-ffdf2baf81d6/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:27:50 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561470026
16/03/21 17:27:50 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:27:50 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:27:50 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52387.
16/03/21 17:27:50 INFO NettyBlockTransferService: Server created on 52387
16/03/21 17:27:50 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:27:50 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52387 with 811.4 MB RAM, BlockManagerId(driver, localhost, 52387)
16/03/21 17:27:50 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:27:50 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561470037
16/03/21 17:27:50 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:27:50 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:27:50 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:27:50 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:27:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:27:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:27:50 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:27:50 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=850832916
16/03/21 17:27:50 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 811.4 MB)
16/03/21 17:27:50 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=850832916
16/03/21 17:27:50 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 811.4 MB)
16/03/21 17:27:50 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52387 (size: 4.1 KB, free: 811.4 MB)
16/03/21 17:27:50 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:27:50 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:27:50 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:27:50 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:27:50 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:27:50 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:27:50 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561470026
16/03/21 17:27:50 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-42a536fb-6cc6-4e3c-a368-ffdf2baf81d6/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:27:50 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:27:50 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=850832916
16/03/21 17:27:50 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 811.4 MB)
16/03/21 17:27:50 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:52387 (size: 166.0 B, free: 811.4 MB)
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: area
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  particular  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: issue
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: planning
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: permission
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: economy
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: composition
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: agency
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/21 17:27:58 INFO PythonRunner: Times: total = 7892, boot = 450, init = 363, finish = 7079
16/03/21 17:27:58 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:27:58 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:27:58 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:27:58 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:27:58 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=850832916
16/03/21 17:27:58 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 811.4 MB)
16/03/21 17:27:58 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7960 ms on localhost (1/2)
16/03/21 17:27:58 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:52387 (size: 155.0 B, free: 811.4 MB)
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: set
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: bend
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: giant
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: astatine
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: present
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: area
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  particular  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/21 17:27:58 INFO PythonRunner: Times: total = 263, boot = 166, init = 1, finish = 96
16/03/21 17:27:58 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:27:58 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.243 s
16/03/21 17:27:58 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:27:58 INFO DAGScheduler: running: Set()
16/03/21 17:27:58 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:27:58 INFO DAGScheduler: failed: Set()
16/03/21 17:27:58 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:27:58 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:27:58 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=850832916
16/03/21 17:27:58 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 811.4 MB)
16/03/21 17:27:58 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 292 ms on localhost (2/2)
16/03/21 17:27:58 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:27:58 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=850832916
16/03/21 17:27:58 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 811.4 MB)
16/03/21 17:27:58 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52387 (size: 3.0 KB, free: 811.4 MB)
16/03/21 17:27:58 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:27:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:27:58 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:27:58 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:27:58 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:27:58 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:27:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:27:58 INFO PythonRunner: Times: total = 146, boot = 145, init = 0, finish = 1
16/03/21 17:27:58 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:27:58 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:27:58 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:27:58 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:27:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:27:58 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 160 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'area', 'None', u'area']
16/03/21 17:27:58 INFO PythonRunner: Times: total = 158, boot = 157, init = 0, finish = 1
16/03/21 17:27:58 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/21 17:27:58 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.321 s
16/03/21 17:27:58 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.595194 s
16/03/21 17:27:58 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 170 ms on localhost (2/2)
16/03/21 17:27:58 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:27:58 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:27:58 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:27:58 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:27:58 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:27:58 INFO DAGScheduler: Missing parents: List()
16/03/21 17:27:58 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:27:58 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=850832916
16/03/21 17:27:58 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 811.4 MB)
16/03/21 17:27:58 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=850832916
16/03/21 17:27:58 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 811.4 MB)
16/03/21 17:27:58 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:52387 (size: 3.3 KB, free: 811.4 MB)
16/03/21 17:27:58 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:27:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:27:58 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:27:58 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:27:58 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:27:58 INFO PythonRunner: Times: total = 99, boot = 98, init = 1, finish = 0
16/03/21 17:27:58 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:27:58 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/21 17:27:58 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 116 ms on localhost (1/2)
16/03/21 17:27:58 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:27:59 INFO PythonRunner: Times: total = 139, boot = 138, init = 0, finish = 1
16/03/21 17:27:59 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1307 bytes result sent to driver
16/03/21 17:27:59 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 176 ms on localhost (2/2)
16/03/21 17:27:59 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:27:59 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.285 s
16/03/21 17:27:59 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.308628 s
16/03/21 17:27:59 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:27:59 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:27:59 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:27:59 INFO MemoryStore: MemoryStore cleared
16/03/21 17:27:59 INFO BlockManager: BlockManager stopped
16/03/21 17:27:59 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:27:59 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:27:59 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:27:59 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:27:59 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:27:59 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:28:00 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:28:00 INFO SecurityManager: Changing view acls to: root
16/03/21 17:28:00 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:28:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:28:00 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:28:00 INFO Remoting: Starting remoting
16/03/21 17:28:00 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:42977]
16/03/21 17:28:00 INFO Utils: Successfully started service 'sparkDriver' on port 42977.
16/03/21 17:28:00 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:28:00 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:28:00 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3ddefdc0-e941-464f-9164-0df618dad11e
16/03/21 17:28:00 INFO MemoryStore: MemoryStore started with capacity 811.4 MB
16/03/21 17:28:00 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-1bae3935-d652-4207-ac54-be9f2543bac1
16/03/21 17:28:00 INFO HttpServer: Starting HTTP Server
16/03/21 17:28:00 INFO Utils: Successfully started service 'HTTP file server' on port 42261.
16/03/21 17:28:00 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:28:00 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:28:00 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:28:00 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-04448779-5a52-4c16-a65b-1fc17bf939e7/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:28:00 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561480380
16/03/21 17:28:00 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:28:00 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:28:00 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59840.
16/03/21 17:28:00 INFO NettyBlockTransferService: Server created on 59840
16/03/21 17:28:00 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:28:00 INFO BlockManagerMasterEndpoint: Registering block manager localhost:59840 with 811.4 MB RAM, BlockManagerId(driver, localhost, 59840)
16/03/21 17:28:00 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:28:00 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561480392
16/03/21 17:28:00 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:28:00 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:28:00 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:28:00 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:28:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:28:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:28:00 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:28:00 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=850832916
16/03/21 17:28:00 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 811.4 MB)
16/03/21 17:28:00 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=850832916
16/03/21 17:28:00 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 811.4 MB)
16/03/21 17:28:00 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:59840 (size: 4.1 KB, free: 811.4 MB)
16/03/21 17:28:00 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:28:00 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:28:00 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:28:00 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:28:00 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:28:00 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:28:00 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561480380
16/03/21 17:28:00 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-04448779-5a52-4c16-a65b-1fc17bf939e7/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:28:00 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:28:00 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=850832916
16/03/21 17:28:00 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 811.4 MB)
16/03/21 17:28:00 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:59840 (size: 166.0 B, free: 811.4 MB)
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: area
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: issue
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: planning
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: permission
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: economy
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: composition
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: agency
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:28:08 INFO PythonRunner: Times: total = 7934, boot = 454, init = 349, finish = 7131
16/03/21 17:28:08 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:28:08 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:28:08 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:28:08 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:28:08 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=850832916
16/03/21 17:28:08 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 811.4 MB)
16/03/21 17:28:08 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:59840 (size: 155.0 B, free: 811.4 MB)
16/03/21 17:28:08 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8007 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: set
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: bend
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: giant
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: astatine
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: present
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  given  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: area
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
16/03/21 17:28:08 INFO PythonRunner: Times: total = 259, boot = 162, init = 1, finish = 96
16/03/21 17:28:08 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:28:08 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 292 ms on localhost (2/2)
16/03/21 17:28:08 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:28:08 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.287 s
16/03/21 17:28:08 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:28:08 INFO DAGScheduler: running: Set()
16/03/21 17:28:08 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:28:08 INFO DAGScheduler: failed: Set()
16/03/21 17:28:08 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:28:08 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:28:08 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=850832916
16/03/21 17:28:08 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 811.4 MB)
16/03/21 17:28:08 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=850832916
16/03/21 17:28:08 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 811.4 MB)
16/03/21 17:28:08 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:59840 (size: 3.0 KB, free: 811.4 MB)
16/03/21 17:28:08 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:28:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:28:08 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:28:08 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:28:08 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:28:08 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:28:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:28:09 INFO PythonRunner: Times: total = 130, boot = 129, init = 1, finish = 0
16/03/21 17:28:09 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:28:09 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:28:09 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:28:09 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:28:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:28:09 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 153 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'metropolitan']
16/03/21 17:28:09 INFO PythonRunner: Times: total = 155, boot = 154, init = 0, finish = 1
16/03/21 17:28:09 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1246 bytes result sent to driver
16/03/21 17:28:09 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.307 s
16/03/21 17:28:09 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.771575 s
16/03/21 17:28:09 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 170 ms on localhost (2/2)
16/03/21 17:28:09 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:28:09 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:28:09 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:28:09 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:28:09 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:28:09 INFO DAGScheduler: Missing parents: List()
16/03/21 17:28:09 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:28:09 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=850832916
16/03/21 17:28:09 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 811.4 MB)
16/03/21 17:28:09 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=850832916
16/03/21 17:28:09 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 811.4 MB)
16/03/21 17:28:09 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:59840 (size: 3.3 KB, free: 811.4 MB)
16/03/21 17:28:09 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:28:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:28:09 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:28:09 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:28:09 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:28:09 INFO PythonRunner: Times: total = 83, boot = 83, init = 0, finish = 0
16/03/21 17:28:09 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:28:09 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2276 bytes)
16/03/21 17:28:09 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:28:09 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 99 ms on localhost (1/2)
16/03/21 17:28:09 INFO PythonRunner: Times: total = 160, boot = 160, init = 0, finish = 0
16/03/21 17:28:09 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1315 bytes result sent to driver
16/03/21 17:28:09 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 176 ms on localhost (2/2)
16/03/21 17:28:09 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:28:09 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.271 s
16/03/21 17:28:09 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.290422 s
16/03/21 17:28:09 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:28:09 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:28:09 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:28:09 INFO MemoryStore: MemoryStore cleared
16/03/21 17:28:09 INFO BlockManager: BlockManager stopped
16/03/21 17:28:09 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:28:09 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:28:09 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:28:09 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:28:09 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:28:09 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:28:10 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:28:10 INFO SecurityManager: Changing view acls to: root
16/03/21 17:28:10 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:28:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:28:10 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:28:10 INFO Remoting: Starting remoting
16/03/21 17:28:10 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:50917]
16/03/21 17:28:10 INFO Utils: Successfully started service 'sparkDriver' on port 50917.
16/03/21 17:28:10 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:28:10 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:28:10 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e4cf3b4f-b3e1-4061-8b64-a617ebc0be98
16/03/21 17:28:10 INFO MemoryStore: MemoryStore started with capacity 808.4 MB
16/03/21 17:28:10 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-25e62e13-5671-456c-b19f-742a764a9d36
16/03/21 17:28:10 INFO HttpServer: Starting HTTP Server
16/03/21 17:28:10 INFO Utils: Successfully started service 'HTTP file server' on port 55360.
16/03/21 17:28:10 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:28:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:28:10 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:28:10 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-9360c9cb-5d77-467f-af0a-ad9263b1e06b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:28:10 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561490937
16/03/21 17:28:10 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:28:10 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:28:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 47387.
16/03/21 17:28:10 INFO NettyBlockTransferService: Server created on 47387
16/03/21 17:28:10 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:28:10 INFO BlockManagerMasterEndpoint: Registering block manager localhost:47387 with 808.4 MB RAM, BlockManagerId(driver, localhost, 47387)
16/03/21 17:28:10 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:28:11 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561490953
16/03/21 17:28:11 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:28:11 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:28:11 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:28:11 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:28:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:28:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:28:11 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:28:11 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=847647866
16/03/21 17:28:11 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 808.4 MB)
16/03/21 17:28:11 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=847647866
16/03/21 17:28:11 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 808.4 MB)
16/03/21 17:28:11 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:47387 (size: 4.1 KB, free: 808.4 MB)
16/03/21 17:28:11 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:28:11 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:28:11 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:28:11 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:28:11 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:28:11 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:28:11 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561490937
16/03/21 17:28:11 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-9360c9cb-5d77-467f-af0a-ad9263b1e06b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:28:11 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:28:11 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=847647866
16/03/21 17:28:11 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 808.4 MB)
16/03/21 17:28:11 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:47387 (size: 166.0 B, free: 808.4 MB)
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: area
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: issue
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: planning
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: permission
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: economy
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: composition
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: agency
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:28:19 INFO PythonRunner: Times: total = 7871, boot = 464, init = 355, finish = 7052
16/03/21 17:28:19 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:28:19 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:28:19 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:28:19 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:28:19 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=847647866
16/03/21 17:28:19 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 808.4 MB)
16/03/21 17:28:19 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:47387 (size: 155.0 B, free: 808.4 MB)
16/03/21 17:28:19 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7948 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: set
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  Synset('set.n.01') ; keyword:  kind  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: bend
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: giant
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: astatine
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: present
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: area
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
16/03/21 17:28:19 INFO PythonRunner: Times: total = 303, boot = 209, init = 0, finish = 94
16/03/21 17:28:19 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:28:19 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 353 ms on localhost (2/2)
16/03/21 17:28:19 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:28:19 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.296 s
16/03/21 17:28:19 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:28:19 INFO DAGScheduler: running: Set()
16/03/21 17:28:19 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:28:19 INFO DAGScheduler: failed: Set()
16/03/21 17:28:19 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:28:19 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:28:19 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=847647866
16/03/21 17:28:19 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 808.4 MB)
16/03/21 17:28:19 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16030, maxMem=847647866
16/03/21 17:28:19 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 808.4 MB)
16/03/21 17:28:19 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:47387 (size: 3.0 KB, free: 808.4 MB)
16/03/21 17:28:19 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:28:19 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:28:19 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:28:19 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:28:19 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:28:19 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:28:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:28:19 INFO PythonRunner: Times: total = 113, boot = 113, init = 0, finish = 0
16/03/21 17:28:19 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:28:19 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:28:19 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:28:19 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:28:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:28:19 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 143 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'set']
16/03/21 17:28:19 INFO PythonRunner: Times: total = 151, boot = 150, init = 0, finish = 1
16/03/21 17:28:19 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1229 bytes result sent to driver
16/03/21 17:28:19 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.293 s
16/03/21 17:28:19 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.635484 s
16/03/21 17:28:19 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 175 ms on localhost (2/2)
16/03/21 17:28:19 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:28:19 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:28:19 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:28:19 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:28:19 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:28:19 INFO DAGScheduler: Missing parents: List()
16/03/21 17:28:19 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:28:19 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19077, maxMem=847647866
16/03/21 17:28:19 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 808.4 MB)
16/03/21 17:28:19 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24893, maxMem=847647866
16/03/21 17:28:19 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 808.4 MB)
16/03/21 17:28:19 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:47387 (size: 3.3 KB, free: 808.4 MB)
16/03/21 17:28:19 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:28:19 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:28:19 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:28:19 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:28:19 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:28:19 INFO PythonRunner: Times: total = 87, boot = 87, init = 0, finish = 0
16/03/21 17:28:19 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:28:19 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2259 bytes)
16/03/21 17:28:19 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 108 ms on localhost (1/2)
16/03/21 17:28:20 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:28:20 INFO PythonRunner: Times: total = 196, boot = 196, init = 0, finish = 0
16/03/21 17:28:20 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1295 bytes result sent to driver
16/03/21 17:28:20 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 244 ms on localhost (2/2)
16/03/21 17:28:20 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:28:20 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.338 s
16/03/21 17:28:20 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.364252 s
16/03/21 17:28:20 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:28:20 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:28:20 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:28:20 INFO MemoryStore: MemoryStore cleared
16/03/21 17:28:20 INFO BlockManager: BlockManager stopped
16/03/21 17:28:20 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:28:20 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:28:20 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:28:20 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:28:20 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:28:20 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:28:21 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:28:21 INFO SecurityManager: Changing view acls to: root
16/03/21 17:28:21 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:28:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:28:21 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:28:21 INFO Remoting: Starting remoting
16/03/21 17:28:21 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:56661]
16/03/21 17:28:21 INFO Utils: Successfully started service 'sparkDriver' on port 56661.
16/03/21 17:28:21 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:28:21 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:28:21 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-6f798213-15e8-4ce3-bb67-df396993327d
16/03/21 17:28:21 INFO MemoryStore: MemoryStore started with capacity 808.4 MB
16/03/21 17:28:21 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-4bad825c-e14b-4394-8ca0-136fe4dc0ec7
16/03/21 17:28:21 INFO HttpServer: Starting HTTP Server
16/03/21 17:28:21 INFO Utils: Successfully started service 'HTTP file server' on port 51502.
16/03/21 17:28:21 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:28:21 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:28:21 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:28:21 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-73818eea-541d-4df9-8f1a-44556219e073/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:28:21 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561501474
16/03/21 17:28:21 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:28:21 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:28:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35067.
16/03/21 17:28:21 INFO NettyBlockTransferService: Server created on 35067
16/03/21 17:28:21 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:28:21 INFO BlockManagerMasterEndpoint: Registering block manager localhost:35067 with 808.4 MB RAM, BlockManagerId(driver, localhost, 35067)
16/03/21 17:28:21 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:28:21 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561501486
16/03/21 17:28:21 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:28:21 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:28:21 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:28:21 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:28:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:28:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:28:21 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:28:21 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=847647866
16/03/21 17:28:21 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 808.4 MB)
16/03/21 17:28:21 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=847647866
16/03/21 17:28:21 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 808.4 MB)
16/03/21 17:28:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:35067 (size: 4.1 KB, free: 808.4 MB)
16/03/21 17:28:21 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:28:21 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:28:21 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:28:21 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:28:21 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:28:21 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:28:21 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561501474
16/03/21 17:28:21 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-73818eea-541d-4df9-8f1a-44556219e073/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:28:21 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:28:21 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=847647866
16/03/21 17:28:21 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 808.4 MB)
16/03/21 17:28:21 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:35067 (size: 166.0 B, free: 808.4 MB)
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: area
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: issue
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: planning
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: permission
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: economy
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: composition
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: agency
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:28:29 INFO PythonRunner: Times: total = 7972, boot = 458, init = 429, finish = 7085
16/03/21 17:28:29 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:28:29 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:28:29 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:28:29 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:28:29 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8052 ms on localhost (1/2)
16/03/21 17:28:29 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=847647866
16/03/21 17:28:29 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 808.4 MB)
16/03/21 17:28:29 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:35067 (size: 155.0 B, free: 808.4 MB)
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: set
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: bend
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: giant
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: astatine
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: present
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: area
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:28:29 INFO PythonRunner: Times: total = 237, boot = 141, init = 0, finish = 96
16/03/21 17:28:29 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:28:29 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.325 s
16/03/21 17:28:29 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:28:29 INFO DAGScheduler: running: Set()
16/03/21 17:28:29 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:28:29 INFO DAGScheduler: failed: Set()
16/03/21 17:28:29 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:28:29 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:28:29 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=847647866
16/03/21 17:28:29 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 808.4 MB)
16/03/21 17:28:29 INFO MemoryStore: ensureFreeSpace(3050) called with curMem=16030, maxMem=847647866
16/03/21 17:28:29 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 808.4 MB)
16/03/21 17:28:29 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 280 ms on localhost (2/2)
16/03/21 17:28:29 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:28:29 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:35067 (size: 3.0 KB, free: 808.4 MB)
16/03/21 17:28:29 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:28:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:28:29 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:28:29 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:28:29 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:28:29 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:28:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:28:30 INFO PythonRunner: Times: total = 132, boot = 131, init = 1, finish = 0
16/03/21 17:28:30 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:28:30 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:28:30 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:28:30 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:28:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:28:30 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 163 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None']
16/03/21 17:28:30 INFO PythonRunner: Times: total = 153, boot = 152, init = 0, finish = 1
16/03/21 17:28:30 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1227 bytes result sent to driver
16/03/21 17:28:30 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.310 s
16/03/21 17:28:30 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.672478 s
16/03/21 17:28:30 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 173 ms on localhost (2/2)
16/03/21 17:28:30 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:28:30 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:28:30 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:28:30 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:28:30 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:28:30 INFO DAGScheduler: Missing parents: List()
16/03/21 17:28:30 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:28:30 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19080, maxMem=847647866
16/03/21 17:28:30 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 808.4 MB)
16/03/21 17:28:30 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24896, maxMem=847647866
16/03/21 17:28:30 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 808.4 MB)
16/03/21 17:28:30 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:35067 (size: 3.3 KB, free: 808.4 MB)
16/03/21 17:28:30 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:28:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:28:30 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:28:30 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:28:30 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:28:30 INFO PythonRunner: Times: total = 124, boot = 123, init = 0, finish = 1
16/03/21 17:28:30 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:28:30 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2257 bytes)
16/03/21 17:28:30 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:28:30 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 139 ms on localhost (1/2)
16/03/21 17:28:30 INFO PythonRunner: Times: total = 158, boot = 157, init = 0, finish = 1
16/03/21 17:28:30 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1296 bytes result sent to driver
16/03/21 17:28:30 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 173 ms on localhost (2/2)
16/03/21 17:28:30 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:28:30 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.296 s
16/03/21 17:28:30 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.319850 s
16/03/21 17:28:30 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:28:30 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:28:30 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:28:30 INFO MemoryStore: MemoryStore cleared
16/03/21 17:28:30 INFO BlockManager: BlockManager stopped
16/03/21 17:28:30 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:28:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:28:30 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:28:30 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:28:30 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:28:30 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:28:31 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:28:31 INFO SecurityManager: Changing view acls to: root
16/03/21 17:28:31 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:28:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:28:31 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:28:31 INFO Remoting: Starting remoting
16/03/21 17:28:31 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:33948]
16/03/21 17:28:31 INFO Utils: Successfully started service 'sparkDriver' on port 33948.
16/03/21 17:28:31 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:28:31 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:28:31 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-76f41c82-a51f-4ffe-98f6-d547170aef30
16/03/21 17:28:31 INFO MemoryStore: MemoryStore started with capacity 808.4 MB
16/03/21 17:28:31 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-68776a31-8ae9-4dc8-ba3d-68f9d84b22f0
16/03/21 17:28:31 INFO HttpServer: Starting HTTP Server
16/03/21 17:28:31 INFO Utils: Successfully started service 'HTTP file server' on port 58509.
16/03/21 17:28:31 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:28:31 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:28:31 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:28:31 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-027c41ed-a0a5-4b22-a497-88945a01202a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:28:31 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561511906
16/03/21 17:28:31 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:28:31 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:28:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 47462.
16/03/21 17:28:31 INFO NettyBlockTransferService: Server created on 47462
16/03/21 17:28:31 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:28:31 INFO BlockManagerMasterEndpoint: Registering block manager localhost:47462 with 808.4 MB RAM, BlockManagerId(driver, localhost, 47462)
16/03/21 17:28:31 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:28:31 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561511923
16/03/21 17:28:32 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:28:32 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:28:32 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:28:32 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:28:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:28:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:28:32 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:28:32 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=847647866
16/03/21 17:28:32 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 808.4 MB)
16/03/21 17:28:32 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=847647866
16/03/21 17:28:32 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 808.4 MB)
16/03/21 17:28:32 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:47462 (size: 4.1 KB, free: 808.4 MB)
16/03/21 17:28:32 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:28:32 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:28:32 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:28:32 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:28:32 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:28:32 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:28:32 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561511906
16/03/21 17:28:32 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-027c41ed-a0a5-4b22-a497-88945a01202a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:28:32 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:28:32 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=847647866
16/03/21 17:28:32 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 808.4 MB)
16/03/21 17:28:32 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:47462 (size: 166.0 B, free: 808.4 MB)
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: area
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: issue
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: planning
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: permission
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: economy
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: composition
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: agency
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:28:40 INFO PythonRunner: Times: total = 7943, boot = 466, init = 348, finish = 7129
16/03/21 17:28:40 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:28:40 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:28:40 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:28:40 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:28:40 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8020 ms on localhost (1/2)
16/03/21 17:28:40 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=847647866
16/03/21 17:28:40 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 808.4 MB)
16/03/21 17:28:40 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:47462 (size: 155.0 B, free: 808.4 MB)
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: set
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: bend
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: giant
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: astatine
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: present
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  patriarch  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: area
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
16/03/21 17:28:40 INFO PythonRunner: Times: total = 266, boot = 164, init = 0, finish = 102
16/03/21 17:28:40 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:28:40 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 297 ms on localhost (2/2)
16/03/21 17:28:40 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:28:40 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.307 s
16/03/21 17:28:40 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:28:40 INFO DAGScheduler: running: Set()
16/03/21 17:28:40 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:28:40 INFO DAGScheduler: failed: Set()
16/03/21 17:28:40 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:28:40 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:28:40 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=847647866
16/03/21 17:28:40 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 808.4 MB)
16/03/21 17:28:40 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16030, maxMem=847647866
16/03/21 17:28:40 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 808.4 MB)
16/03/21 17:28:40 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:47462 (size: 3.0 KB, free: 808.4 MB)
16/03/21 17:28:40 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:28:40 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:28:40 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:28:40 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:28:40 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:28:40 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:28:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:28:40 INFO PythonRunner: Times: total = 144, boot = 143, init = 0, finish = 1
16/03/21 17:28:40 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:28:40 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:28:40 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:28:40 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:28:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:28:40 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 168 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'metropolitan']
16/03/21 17:28:40 INFO PythonRunner: Times: total = 154, boot = 153, init = 1, finish = 0
16/03/21 17:28:40 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1246 bytes result sent to driver
16/03/21 17:28:40 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.319 s
16/03/21 17:28:40 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.657902 s
16/03/21 17:28:40 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 170 ms on localhost (2/2)
16/03/21 17:28:40 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:28:40 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:28:40 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:28:40 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:28:40 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:28:40 INFO DAGScheduler: Missing parents: List()
16/03/21 17:28:40 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:28:40 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19078, maxMem=847647866
16/03/21 17:28:40 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 808.4 MB)
16/03/21 17:28:40 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24894, maxMem=847647866
16/03/21 17:28:40 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 808.4 MB)
16/03/21 17:28:40 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:47462 (size: 3.3 KB, free: 808.4 MB)
16/03/21 17:28:40 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:28:40 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:28:40 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:28:40 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:28:40 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:28:40 INFO PythonRunner: Times: total = 73, boot = 73, init = 0, finish = 0
16/03/21 17:28:40 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:28:40 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2276 bytes)
16/03/21 17:28:40 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:28:40 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 89 ms on localhost (1/2)
16/03/21 17:28:41 INFO PythonRunner: Times: total = 154, boot = 153, init = 1, finish = 0
16/03/21 17:28:41 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1315 bytes result sent to driver
16/03/21 17:28:41 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 168 ms on localhost (2/2)
16/03/21 17:28:41 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:28:41 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.255 s
16/03/21 17:28:41 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.264171 s
16/03/21 17:28:41 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:28:41 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:28:41 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:28:41 INFO MemoryStore: MemoryStore cleared
16/03/21 17:28:41 INFO BlockManager: BlockManager stopped
16/03/21 17:28:41 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:28:41 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:28:41 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:28:41 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:28:41 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:28:41 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:28:42 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:28:42 INFO SecurityManager: Changing view acls to: root
16/03/21 17:28:42 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:28:42 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:28:42 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:28:42 INFO Remoting: Starting remoting
16/03/21 17:28:42 INFO Utils: Successfully started service 'sparkDriver' on port 47357.
16/03/21 17:28:42 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:47357]
16/03/21 17:28:42 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:28:42 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:28:42 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b7b1cd0b-4b97-446a-9682-b6b1a91d123c
16/03/21 17:28:42 INFO MemoryStore: MemoryStore started with capacity 808.4 MB
16/03/21 17:28:42 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-643d1503-3786-4498-8420-1ef923836c12
16/03/21 17:28:42 INFO HttpServer: Starting HTTP Server
16/03/21 17:28:42 INFO Utils: Successfully started service 'HTTP file server' on port 50773.
16/03/21 17:28:42 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:28:42 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:28:42 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:28:42 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-340ed7c3-39f1-4b1f-9a74-ec2b358493b6/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:28:42 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561522299
16/03/21 17:28:42 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:28:42 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:28:42 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50218.
16/03/21 17:28:42 INFO NettyBlockTransferService: Server created on 50218
16/03/21 17:28:42 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:28:42 INFO BlockManagerMasterEndpoint: Registering block manager localhost:50218 with 808.4 MB RAM, BlockManagerId(driver, localhost, 50218)
16/03/21 17:28:42 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:28:42 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561522313
16/03/21 17:28:42 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:28:42 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:28:42 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:28:42 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:28:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:28:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:28:42 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:28:42 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=847647866
16/03/21 17:28:42 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 808.4 MB)
16/03/21 17:28:42 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=847647866
16/03/21 17:28:42 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 808.4 MB)
16/03/21 17:28:42 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:50218 (size: 4.1 KB, free: 808.4 MB)
16/03/21 17:28:42 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:28:42 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:28:42 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:28:42 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:28:42 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:28:42 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561522299
16/03/21 17:28:42 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:28:42 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-340ed7c3-39f1-4b1f-9a74-ec2b358493b6/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:28:42 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:28:42 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=847647866
16/03/21 17:28:42 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 808.4 MB)
16/03/21 17:28:42 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:50218 (size: 166.0 B, free: 808.4 MB)
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: area
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: issue
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: planning
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: permission
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: economy
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: composition
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: agency
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:28:50 INFO PythonRunner: Times: total = 7740, boot = 455, init = 355, finish = 6930
16/03/21 17:28:50 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:28:50 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:28:50 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:28:50 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7839 ms on localhost (1/2)
16/03/21 17:28:50 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:28:50 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=847647866
16/03/21 17:28:50 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 808.4 MB)
16/03/21 17:28:50 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:50218 (size: 155.0 B, free: 808.4 MB)
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: set
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: bend
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: giant
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: astatine
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: present
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  Church  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: area
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
16/03/21 17:28:50 INFO PythonRunner: Times: total = 250, boot = 153, init = 0, finish = 97
16/03/21 17:28:50 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:28:50 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.115 s
16/03/21 17:28:50 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:28:50 INFO DAGScheduler: running: Set()
16/03/21 17:28:50 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:28:50 INFO DAGScheduler: failed: Set()
16/03/21 17:28:50 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:28:50 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:28:50 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 288 ms on localhost (2/2)
16/03/21 17:28:50 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:28:50 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=847647866
16/03/21 17:28:50 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 808.4 MB)
16/03/21 17:28:50 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16030, maxMem=847647866
16/03/21 17:28:50 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 808.4 MB)
16/03/21 17:28:50 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:50218 (size: 3.0 KB, free: 808.4 MB)
16/03/21 17:28:50 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:28:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:28:50 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:28:50 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:28:50 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:28:50 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:28:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:28:50 INFO PythonRunner: Times: total = 160, boot = 159, init = 1, finish = 0
16/03/21 17:28:50 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:28:50 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:28:50 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:28:50 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:28:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:28:50 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 191 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'metropolitan']
16/03/21 17:28:50 INFO PythonRunner: Times: total = 185, boot = 184, init = 0, finish = 1
16/03/21 17:28:50 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1246 bytes result sent to driver
16/03/21 17:28:50 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 205 ms on localhost (2/2)
16/03/21 17:28:50 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:28:50 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.369 s
16/03/21 17:28:50 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.540754 s
16/03/21 17:28:51 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:28:51 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:28:51 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:28:51 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:28:51 INFO DAGScheduler: Missing parents: List()
16/03/21 17:28:51 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:28:51 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19078, maxMem=847647866
16/03/21 17:28:51 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 808.4 MB)
16/03/21 17:28:51 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24894, maxMem=847647866
16/03/21 17:28:51 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 808.4 MB)
16/03/21 17:28:51 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:50218 (size: 3.3 KB, free: 808.4 MB)
16/03/21 17:28:51 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:28:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:28:51 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:28:51 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:28:51 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:28:51 INFO PythonRunner: Times: total = 89, boot = 89, init = 0, finish = 0
16/03/21 17:28:51 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:28:51 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2276 bytes)
16/03/21 17:28:51 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 105 ms on localhost (1/2)
16/03/21 17:28:51 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:28:51 INFO PythonRunner: Times: total = 191, boot = 190, init = 1, finish = 0
16/03/21 17:28:51 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1315 bytes result sent to driver
16/03/21 17:28:51 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 205 ms on localhost (2/2)
16/03/21 17:28:51 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:28:51 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.303 s
16/03/21 17:28:51 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.325405 s
16/03/21 17:28:51 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:28:51 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:28:51 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:28:51 INFO MemoryStore: MemoryStore cleared
16/03/21 17:28:51 INFO BlockManager: BlockManager stopped
16/03/21 17:28:51 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:28:51 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:28:51 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:28:51 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:28:51 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:28:51 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:28:52 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:28:52 INFO SecurityManager: Changing view acls to: root
16/03/21 17:28:52 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:28:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:28:52 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:28:52 INFO Remoting: Starting remoting
16/03/21 17:28:52 INFO Utils: Successfully started service 'sparkDriver' on port 60679.
16/03/21 17:28:52 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:60679]
16/03/21 17:28:52 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:28:52 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:28:52 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c2618d0b-38d5-488a-9f9f-9017e66814e1
16/03/21 17:28:52 INFO MemoryStore: MemoryStore started with capacity 808.4 MB
16/03/21 17:28:52 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-0cf7b70a-90c6-4a56-9e21-d373b8622d87
16/03/21 17:28:52 INFO HttpServer: Starting HTTP Server
16/03/21 17:28:52 INFO Utils: Successfully started service 'HTTP file server' on port 35414.
16/03/21 17:28:52 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:28:53 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:28:53 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:28:53 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-1fe9a42f-fb95-4563-897e-33b6088998f9/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:28:53 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561533169
16/03/21 17:28:53 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:28:53 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:28:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41562.
16/03/21 17:28:53 INFO NettyBlockTransferService: Server created on 41562
16/03/21 17:28:53 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:28:53 INFO BlockManagerMasterEndpoint: Registering block manager localhost:41562 with 808.4 MB RAM, BlockManagerId(driver, localhost, 41562)
16/03/21 17:28:53 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:28:53 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561533194
16/03/21 17:28:53 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:28:53 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:28:53 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:28:53 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:28:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:28:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:28:53 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:28:53 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=847647866
16/03/21 17:28:53 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 808.4 MB)
16/03/21 17:28:53 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=847647866
16/03/21 17:28:53 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 808.4 MB)
16/03/21 17:28:53 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:41562 (size: 4.1 KB, free: 808.4 MB)
16/03/21 17:28:53 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:28:53 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:28:53 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:28:53 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:28:53 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:28:53 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:28:53 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561533169
16/03/21 17:28:53 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-1fe9a42f-fb95-4563-897e-33b6088998f9/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:28:53 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:28:53 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=847647866
16/03/21 17:28:53 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 808.4 MB)
16/03/21 17:28:53 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:41562 (size: 166.0 B, free: 808.4 MB)
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: area
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: issue
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: planning
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: permission
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: economy
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): adding to parents: syn =  Synset('economy.n.01') ; keyword:  distribution  in syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= [u'economy']
reduceFunction_Parents(): returns= ['None', u'economy']
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: composition
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'economy']
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: agency
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'economy']
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'economy']
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'economy']
16/03/21 17:29:01 INFO PythonRunner: Times: total = 8235, boot = 496, init = 365, finish = 7374
16/03/21 17:29:01 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:29:01 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:29:01 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:29:01 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:29:01 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=847647866
16/03/21 17:29:01 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8300 ms on localhost (1/2)
16/03/21 17:29:01 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 808.4 MB)
16/03/21 17:29:01 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:41562 (size: 155.0 B, free: 808.4 MB)
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: set
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: bend
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: giant
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: astatine
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: present
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: area
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:29:01 INFO PythonRunner: Times: total = 267, boot = 169, init = 1, finish = 97
16/03/21 17:29:01 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:29:01 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 298 ms on localhost (2/2)
16/03/21 17:29:01 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:29:01 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.597 s
16/03/21 17:29:01 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:29:01 INFO DAGScheduler: running: Set()
16/03/21 17:29:01 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:29:01 INFO DAGScheduler: failed: Set()
16/03/21 17:29:01 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:29:01 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:29:01 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=847647866
16/03/21 17:29:01 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 808.4 MB)
16/03/21 17:29:01 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16030, maxMem=847647866
16/03/21 17:29:01 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 808.4 MB)
16/03/21 17:29:01 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:41562 (size: 3.0 KB, free: 808.4 MB)
16/03/21 17:29:01 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:29:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:29:01 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:29:01 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:29:01 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:29:01 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:29:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:29:02 INFO PythonRunner: Times: total = 153, boot = 152, init = 0, finish = 1
16/03/21 17:29:02 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:29:02 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:29:02 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:29:02 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:29:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:29:02 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 177 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'economy', 'None']
16/03/21 17:29:02 INFO PythonRunner: Times: total = 154, boot = 153, init = 0, finish = 1
16/03/21 17:29:02 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/21 17:29:02 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.342 s
16/03/21 17:29:02 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.976336 s
16/03/21 17:29:02 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 174 ms on localhost (2/2)
16/03/21 17:29:02 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:29:02 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:29:02 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:29:02 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:29:02 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:29:02 INFO DAGScheduler: Missing parents: List()
16/03/21 17:29:02 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:29:02 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19078, maxMem=847647866
16/03/21 17:29:02 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 808.4 MB)
16/03/21 17:29:02 INFO MemoryStore: ensureFreeSpace(3374) called with curMem=24894, maxMem=847647866
16/03/21 17:29:02 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 808.4 MB)
16/03/21 17:29:02 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:41562 (size: 3.3 KB, free: 808.4 MB)
16/03/21 17:29:02 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:29:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:29:02 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:29:02 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:29:02 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:29:02 INFO PythonRunner: Times: total = 158, boot = 157, init = 1, finish = 0
16/03/21 17:29:02 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:29:02 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/21 17:29:02 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:29:02 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 174 ms on localhost (1/2)
16/03/21 17:29:02 INFO PythonRunner: Times: total = 232, boot = 232, init = 0, finish = 0
16/03/21 17:29:02 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1310 bytes result sent to driver
16/03/21 17:29:02 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 248 ms on localhost (2/2)
16/03/21 17:29:02 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:29:02 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.405 s
16/03/21 17:29:02 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.443050 s
16/03/21 17:29:03 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:29:03 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:29:03 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:29:03 INFO MemoryStore: MemoryStore cleared
16/03/21 17:29:03 INFO BlockManager: BlockManager stopped
16/03/21 17:29:03 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:29:03 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:29:03 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:29:03 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:29:03 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:29:03 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:29:03 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:29:03 INFO SecurityManager: Changing view acls to: root
16/03/21 17:29:03 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:29:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:29:03 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:29:03 INFO Remoting: Starting remoting
16/03/21 17:29:04 INFO Utils: Successfully started service 'sparkDriver' on port 45982.
16/03/21 17:29:04 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:45982]
16/03/21 17:29:04 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:29:04 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:29:04 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1e4b2a93-c57c-4a2e-be88-0a24313599b1
16/03/21 17:29:04 INFO MemoryStore: MemoryStore started with capacity 808.4 MB
16/03/21 17:29:04 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-246d0d11-95d9-4d94-9456-ab766994a1c8
16/03/21 17:29:04 INFO HttpServer: Starting HTTP Server
16/03/21 17:29:04 INFO Utils: Successfully started service 'HTTP file server' on port 44178.
16/03/21 17:29:04 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:29:04 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:29:04 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:29:04 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-388e5111-09c7-43ac-bc42-9969a42cfe5b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:29:04 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561544747
16/03/21 17:29:04 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:29:04 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:29:04 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39643.
16/03/21 17:29:04 INFO NettyBlockTransferService: Server created on 39643
16/03/21 17:29:04 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:29:04 INFO BlockManagerMasterEndpoint: Registering block manager localhost:39643 with 808.4 MB RAM, BlockManagerId(driver, localhost, 39643)
16/03/21 17:29:04 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:29:04 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561544766
16/03/21 17:29:04 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:29:04 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:29:04 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:29:04 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:29:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:29:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:29:04 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:29:04 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=847647866
16/03/21 17:29:04 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 808.4 MB)
16/03/21 17:29:04 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=847647866
16/03/21 17:29:04 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 808.4 MB)
16/03/21 17:29:04 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:39643 (size: 4.1 KB, free: 808.4 MB)
16/03/21 17:29:04 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:29:04 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:29:04 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:29:04 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:29:04 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:29:04 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:29:04 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561544747
16/03/21 17:29:04 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-388e5111-09c7-43ac-bc42-9969a42cfe5b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:29:04 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:29:04 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=847647866
16/03/21 17:29:04 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 808.4 MB)
16/03/21 17:29:04 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:39643 (size: 166.0 B, free: 808.4 MB)
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: area
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: issue
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: planning
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: permission
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: economy
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: composition
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  property  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: agency
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/21 17:29:15 INFO PythonRunner: Times: total = 10307, boot = 501, init = 508, finish = 9298
16/03/21 17:29:15 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:29:15 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:29:15 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 10371 ms on localhost (1/2)
16/03/21 17:29:15 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:29:15 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:29:15 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=847647866
16/03/21 17:29:15 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 808.4 MB)
16/03/21 17:29:15 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:39643 (size: 155.0 B, free: 808.4 MB)
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: set
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: bend
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: giant
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: astatine
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: present
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: area
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:29:15 INFO PythonRunner: Times: total = 295, boot = 171, init = 0, finish = 124
16/03/21 17:29:15 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:29:15 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 10.699 s
16/03/21 17:29:15 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:29:15 INFO DAGScheduler: running: Set()
16/03/21 17:29:15 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:29:15 INFO DAGScheduler: failed: Set()
16/03/21 17:29:15 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 330 ms on localhost (2/2)
16/03/21 17:29:15 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:29:15 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:29:15 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:29:15 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=847647866
16/03/21 17:29:15 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 808.4 MB)
16/03/21 17:29:15 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16030, maxMem=847647866
16/03/21 17:29:15 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 808.4 MB)
16/03/21 17:29:15 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:39643 (size: 3.0 KB, free: 808.4 MB)
16/03/21 17:29:15 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:29:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:29:15 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:29:15 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:29:15 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:29:15 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:29:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:29:15 INFO PythonRunner: Times: total = 233, boot = 232, init = 1, finish = 0
16/03/21 17:29:15 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:29:15 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:29:15 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:29:15 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:29:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:29:15 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 275 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'composition', 'None']
16/03/21 17:29:16 INFO PythonRunner: Times: total = 193, boot = 193, init = 0, finish = 0
16/03/21 17:29:16 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1245 bytes result sent to driver
16/03/21 17:29:16 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.462 s
16/03/21 17:29:16 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 11.212046 s
16/03/21 17:29:16 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 209 ms on localhost (2/2)
16/03/21 17:29:16 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:29:16 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:29:16 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:29:16 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:29:16 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:29:16 INFO DAGScheduler: Missing parents: List()
16/03/21 17:29:16 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:29:16 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19078, maxMem=847647866
16/03/21 17:29:16 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 808.4 MB)
16/03/21 17:29:16 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24894, maxMem=847647866
16/03/21 17:29:16 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 808.4 MB)
16/03/21 17:29:16 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:39643 (size: 3.3 KB, free: 808.4 MB)
16/03/21 17:29:16 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:29:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:29:16 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:29:16 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:29:16 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:29:16 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:39643 in memory (size: 3.0 KB, free: 808.4 MB)
16/03/21 17:29:16 INFO PythonRunner: Times: total = 224, boot = 71, init = 153, finish = 0
16/03/21 17:29:16 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:29:16 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2275 bytes)
16/03/21 17:29:16 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 277 ms on localhost (1/2)
16/03/21 17:29:16 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:29:16 INFO ContextCleaner: Cleaned accumulator 275
16/03/21 17:29:16 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:39643 in memory (size: 4.1 KB, free: 808.4 MB)
16/03/21 17:29:16 INFO ContextCleaner: Cleaned accumulator 274
16/03/21 17:29:16 INFO PythonRunner: Times: total = 140, boot = 140, init = 0, finish = 0
16/03/21 17:29:16 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1314 bytes result sent to driver
16/03/21 17:29:16 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.432 s
16/03/21 17:29:16 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.443918 s
16/03/21 17:29:16 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 157 ms on localhost (2/2)
16/03/21 17:29:16 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:29:16 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:29:16 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:29:16 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:29:16 INFO MemoryStore: MemoryStore cleared
16/03/21 17:29:16 INFO BlockManager: BlockManager stopped
16/03/21 17:29:16 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:29:16 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:29:16 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:29:16 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:29:16 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:29:16 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:29:17 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:29:17 INFO SecurityManager: Changing view acls to: root
16/03/21 17:29:17 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:29:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:29:17 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:29:17 INFO Remoting: Starting remoting
16/03/21 17:29:17 INFO Utils: Successfully started service 'sparkDriver' on port 58586.
16/03/21 17:29:17 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:58586]
16/03/21 17:29:17 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:29:17 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:29:17 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b5fd65f2-e086-43c2-b09f-09dab8f7ec16
16/03/21 17:29:17 INFO MemoryStore: MemoryStore started with capacity 808.0 MB
16/03/21 17:29:17 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-87450ddf-a349-4d99-be1b-f5d7c0e3330a
16/03/21 17:29:17 INFO HttpServer: Starting HTTP Server
16/03/21 17:29:17 INFO Utils: Successfully started service 'HTTP file server' on port 34897.
16/03/21 17:29:17 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:29:18 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:29:18 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:29:18 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-2499c4b0-f7fe-4ce5-84f3-5504df8ceb20/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:29:18 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561558318
16/03/21 17:29:18 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:29:18 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:29:18 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39517.
16/03/21 17:29:18 INFO NettyBlockTransferService: Server created on 39517
16/03/21 17:29:18 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:29:18 INFO BlockManagerMasterEndpoint: Registering block manager localhost:39517 with 808.0 MB RAM, BlockManagerId(driver, localhost, 39517)
16/03/21 17:29:18 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:29:18 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561558355
16/03/21 17:29:18 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:29:18 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:29:18 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:29:18 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:29:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:29:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:29:18 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:29:18 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=847223193
16/03/21 17:29:18 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 808.0 MB)
16/03/21 17:29:18 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=847223193
16/03/21 17:29:18 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 808.0 MB)
16/03/21 17:29:18 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:39517 (size: 4.1 KB, free: 808.0 MB)
16/03/21 17:29:18 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:29:18 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:29:18 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:29:18 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:29:18 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:29:18 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:29:18 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561558318
16/03/21 17:29:18 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-2499c4b0-f7fe-4ce5-84f3-5504df8ceb20/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:29:18 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:29:18 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=847223193
16/03/21 17:29:18 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 808.0 MB)
16/03/21 17:29:18 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:39517 (size: 166.0 B, free: 808.0 MB)
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: area
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  distinguished  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: issue
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: planning
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: permission
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: economy
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: composition
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: agency
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/21 17:29:27 INFO PythonRunner: Times: total = 9285, boot = 658, init = 451, finish = 8176
16/03/21 17:29:27 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:29:27 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:29:27 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:29:27 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:29:27 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9378 ms on localhost (1/2)
16/03/21 17:29:27 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=847223193
16/03/21 17:29:27 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 808.0 MB)
16/03/21 17:29:27 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:39517 (size: 155.0 B, free: 808.0 MB)
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: set
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: bend
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: giant
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: astatine
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: present
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: area
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  distinguished  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/21 17:29:28 INFO PythonRunner: Times: total = 372, boot = 187, init = 1, finish = 184
16/03/21 17:29:28 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:29:28 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 432 ms on localhost (2/2)
16/03/21 17:29:28 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:29:28 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.800 s
16/03/21 17:29:28 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:29:28 INFO DAGScheduler: running: Set()
16/03/21 17:29:28 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:29:28 INFO DAGScheduler: failed: Set()
16/03/21 17:29:28 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:29:28 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:29:28 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=847223193
16/03/21 17:29:28 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 808.0 MB)
16/03/21 17:29:28 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16030, maxMem=847223193
16/03/21 17:29:28 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 808.0 MB)
16/03/21 17:29:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:39517 (size: 3.0 KB, free: 808.0 MB)
16/03/21 17:29:28 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:29:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:29:28 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:29:28 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:29:28 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:29:28 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:29:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:29:28 INFO PythonRunner: Times: total = 226, boot = 226, init = 0, finish = 0
16/03/21 17:29:28 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:29:28 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:29:28 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:29:28 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:29:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:29:28 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 256 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'area', 'None', u'area']
16/03/21 17:29:28 INFO PythonRunner: Times: total = 156, boot = 155, init = 0, finish = 1
16/03/21 17:29:28 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/21 17:29:28 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.416 s
16/03/21 17:29:28 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 10.250945 s
16/03/21 17:29:28 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 177 ms on localhost (2/2)
16/03/21 17:29:28 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:29:28 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:29:28 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:29:28 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:29:28 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:29:28 INFO DAGScheduler: Missing parents: List()
16/03/21 17:29:28 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:29:28 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19078, maxMem=847223193
16/03/21 17:29:28 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 808.0 MB)
16/03/21 17:29:28 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24894, maxMem=847223193
16/03/21 17:29:28 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 807.9 MB)
16/03/21 17:29:28 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:39517 (size: 3.3 KB, free: 808.0 MB)
16/03/21 17:29:28 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:29:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:29:28 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:29:28 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:29:28 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:29:28 INFO PythonRunner: Times: total = 97, boot = 96, init = 1, finish = 0
16/03/21 17:29:28 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:29:28 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/21 17:29:28 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 114 ms on localhost (1/2)
16/03/21 17:29:28 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:29:29 INFO PythonRunner: Times: total = 155, boot = 154, init = 0, finish = 1
16/03/21 17:29:29 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1307 bytes result sent to driver
16/03/21 17:29:29 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.276 s
16/03/21 17:29:29 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.298117 s
16/03/21 17:29:29 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 178 ms on localhost (2/2)
16/03/21 17:29:29 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:29:29 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:29:29 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:29:29 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:29:29 INFO MemoryStore: MemoryStore cleared
16/03/21 17:29:29 INFO BlockManager: BlockManager stopped
16/03/21 17:29:29 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:29:29 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:29:29 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:29:29 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:29:29 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:29:30 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:29:30 INFO SecurityManager: Changing view acls to: root
16/03/21 17:29:30 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:29:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:29:30 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:29:30 INFO Remoting: Starting remoting
16/03/21 17:29:30 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:53464]
16/03/21 17:29:30 INFO Utils: Successfully started service 'sparkDriver' on port 53464.
16/03/21 17:29:30 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:29:30 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:29:30 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-33fdd56a-81b9-474f-b5c6-457ad44e825a
16/03/21 17:29:30 INFO MemoryStore: MemoryStore started with capacity 808.0 MB
16/03/21 17:29:30 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-2376f9d5-330d-46bf-8302-d54389487bc7
16/03/21 17:29:30 INFO HttpServer: Starting HTTP Server
16/03/21 17:29:30 INFO Utils: Successfully started service 'HTTP file server' on port 55995.
16/03/21 17:29:30 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:29:30 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:29:30 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:29:30 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-020f83c0-92e8-4bdb-a722-5d9988fb0c14/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:29:30 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561570434
16/03/21 17:29:30 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:29:30 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:29:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38062.
16/03/21 17:29:30 INFO NettyBlockTransferService: Server created on 38062
16/03/21 17:29:30 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:29:30 INFO BlockManagerMasterEndpoint: Registering block manager localhost:38062 with 808.0 MB RAM, BlockManagerId(driver, localhost, 38062)
16/03/21 17:29:30 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:29:30 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561570457
16/03/21 17:29:30 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:29:30 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:29:30 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:29:30 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:29:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:29:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:29:30 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:29:30 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=847223193
16/03/21 17:29:30 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 808.0 MB)
16/03/21 17:29:30 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6576, maxMem=847223193
16/03/21 17:29:30 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 808.0 MB)
16/03/21 17:29:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:38062 (size: 4.1 KB, free: 808.0 MB)
16/03/21 17:29:30 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:29:30 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:29:30 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:29:30 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:29:30 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:29:30 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:29:30 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561570434
16/03/21 17:29:30 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-020f83c0-92e8-4bdb-a722-5d9988fb0c14/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:29:30 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:29:30 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10724, maxMem=847223193
16/03/21 17:29:30 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 808.0 MB)
16/03/21 17:29:30 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:38062 (size: 166.0 B, free: 808.0 MB)
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: area
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: issue
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: planning
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: permission
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: economy
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: composition
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: agency
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): adding to parents: syn =  Synset('kilometer.n.01') ; keyword:  metric  in syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= [u'kilometer']
reduceFunction_Parents(): returns= ['None', u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'kilometer']
16/03/21 17:29:38 INFO PythonRunner: Times: total = 8219, boot = 461, init = 376, finish = 7382
16/03/21 17:29:38 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:29:38 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:29:38 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:29:38 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:29:38 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10890, maxMem=847223193
16/03/21 17:29:38 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 808.0 MB)
16/03/21 17:29:38 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8289 ms on localhost (1/2)
16/03/21 17:29:38 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:38062 (size: 155.0 B, free: 808.0 MB)
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: set
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: bend
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: giant
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: astatine
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: present
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: area
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): adding to parents: syn =  Synset('kilometer.n.01') ; keyword:  metric  in syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= [u'kilometer']
reduceFunction_Parents(): returns= ['None', u'kilometer']
16/03/21 17:29:39 INFO PythonRunner: Times: total = 256, boot = 158, init = 1, finish = 97
16/03/21 17:29:39 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:29:39 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.587 s
16/03/21 17:29:39 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:29:39 INFO DAGScheduler: running: Set()
16/03/21 17:29:39 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:29:39 INFO DAGScheduler: failed: Set()
16/03/21 17:29:39 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:29:39 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:29:39 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 308 ms on localhost (2/2)
16/03/21 17:29:39 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:29:39 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11045, maxMem=847223193
16/03/21 17:29:39 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 808.0 MB)
16/03/21 17:29:39 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16029, maxMem=847223193
16/03/21 17:29:39 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 808.0 MB)
16/03/21 17:29:39 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:38062 (size: 3.0 KB, free: 808.0 MB)
16/03/21 17:29:39 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:29:39 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:29:39 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:29:39 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:29:39 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:29:39 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:29:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:29:39 INFO PythonRunner: Times: total = 127, boot = 127, init = 0, finish = 0
16/03/21 17:29:39 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:29:39 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:29:39 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:29:39 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:29:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:29:39 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 155 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'kilometer', 'None', u'kilometer']
16/03/21 17:29:39 INFO PythonRunner: Times: total = 167, boot = 167, init = 0, finish = 0
16/03/21 17:29:39 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1259 bytes result sent to driver
16/03/21 17:29:39 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.333 s
16/03/21 17:29:39 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.951251 s
16/03/21 17:29:39 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 182 ms on localhost (2/2)
16/03/21 17:29:39 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:29:39 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:29:39 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:29:39 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:29:39 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:29:39 INFO DAGScheduler: Missing parents: List()
16/03/21 17:29:39 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:29:39 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19076, maxMem=847223193
16/03/21 17:29:39 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 808.0 MB)
16/03/21 17:29:39 INFO MemoryStore: ensureFreeSpace(3374) called with curMem=24892, maxMem=847223193
16/03/21 17:29:39 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 807.9 MB)
16/03/21 17:29:39 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:38062 (size: 3.3 KB, free: 808.0 MB)
16/03/21 17:29:39 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:29:39 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:29:39 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:29:39 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:29:39 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:29:39 INFO PythonRunner: Times: total = 82, boot = 81, init = 0, finish = 1
16/03/21 17:29:39 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:29:39 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2289 bytes)
16/03/21 17:29:39 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 97 ms on localhost (1/2)
16/03/21 17:29:39 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:29:39 INFO PythonRunner: Times: total = 166, boot = 165, init = 1, finish = 0
16/03/21 17:29:39 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1328 bytes result sent to driver
16/03/21 17:29:39 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 179 ms on localhost (2/2)
16/03/21 17:29:39 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:29:39 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.270 s
16/03/21 17:29:39 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.289076 s
16/03/21 17:29:39 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:29:39 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:29:40 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:29:40 INFO MemoryStore: MemoryStore cleared
16/03/21 17:29:40 INFO BlockManager: BlockManager stopped
16/03/21 17:29:40 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:29:40 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:29:40 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:29:40 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:29:40 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:29:40 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:29:40 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:29:40 INFO SecurityManager: Changing view acls to: root
16/03/21 17:29:40 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:29:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:29:41 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:29:41 INFO Remoting: Starting remoting
16/03/21 17:29:41 INFO Utils: Successfully started service 'sparkDriver' on port 48164.
16/03/21 17:29:41 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:48164]
16/03/21 17:29:41 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:29:41 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:29:41 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3f10e290-55c2-48dd-b065-597a7b98601a
16/03/21 17:29:41 INFO MemoryStore: MemoryStore started with capacity 808.0 MB
16/03/21 17:29:41 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-d37f81c3-0bec-445e-9b28-a935b930d929
16/03/21 17:29:41 INFO HttpServer: Starting HTTP Server
16/03/21 17:29:41 INFO Utils: Successfully started service 'HTTP file server' on port 48799.
16/03/21 17:29:41 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:29:41 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:29:41 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:29:41 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-69193312-c68d-479f-bd28-bc17ad5a3acf/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:29:41 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561581255
16/03/21 17:29:41 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:29:41 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:29:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54635.
16/03/21 17:29:41 INFO NettyBlockTransferService: Server created on 54635
16/03/21 17:29:41 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:29:41 INFO BlockManagerMasterEndpoint: Registering block manager localhost:54635 with 808.0 MB RAM, BlockManagerId(driver, localhost, 54635)
16/03/21 17:29:41 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:29:41 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561581271
16/03/21 17:29:41 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:29:41 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:29:41 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:29:41 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:29:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:29:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:29:41 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:29:41 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=847223193
16/03/21 17:29:41 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 808.0 MB)
16/03/21 17:29:41 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=847223193
16/03/21 17:29:41 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 808.0 MB)
16/03/21 17:29:41 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:54635 (size: 4.1 KB, free: 808.0 MB)
16/03/21 17:29:41 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:29:41 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:29:41 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:29:41 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:29:41 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:29:41 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561581255
16/03/21 17:29:41 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:29:41 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-69193312-c68d-479f-bd28-bc17ad5a3acf/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:29:41 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:29:41 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=847223193
16/03/21 17:29:41 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 808.0 MB)
16/03/21 17:29:41 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:54635 (size: 166.0 B, free: 808.0 MB)
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: area
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: issue
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: planning
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: permission
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: economy
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: composition
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: agency
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:29:49 INFO PythonRunner: Times: total = 8163, boot = 461, init = 365, finish = 7337
16/03/21 17:29:49 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:29:49 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:29:49 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:29:49 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8252 ms on localhost (1/2)
16/03/21 17:29:49 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:29:49 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=847223193
16/03/21 17:29:49 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 808.0 MB)
16/03/21 17:29:49 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:54635 (size: 155.0 B, free: 808.0 MB)
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: set
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: bend
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: giant
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: astatine
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  heaviest  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: present
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: area
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/21 17:29:50 INFO PythonRunner: Times: total = 395, boot = 272, init = 1, finish = 122
16/03/21 17:29:50 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:29:50 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 439 ms on localhost (2/2)
16/03/21 17:29:50 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:29:50 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.690 s
16/03/21 17:29:50 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:29:50 INFO DAGScheduler: running: Set()
16/03/21 17:29:50 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:29:50 INFO DAGScheduler: failed: Set()
16/03/21 17:29:50 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:29:50 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:29:50 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=847223193
16/03/21 17:29:50 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 808.0 MB)
16/03/21 17:29:50 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16030, maxMem=847223193
16/03/21 17:29:50 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 808.0 MB)
16/03/21 17:29:50 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:54635 (size: 3.0 KB, free: 808.0 MB)
16/03/21 17:29:50 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:29:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:29:50 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:29:50 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:29:50 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:29:50 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:29:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:29:50 INFO PythonRunner: Times: total = 173, boot = 172, init = 1, finish = 0
16/03/21 17:29:50 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:29:50 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:29:50 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:29:50 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:29:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:29:50 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 203 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/03/21 17:29:50 INFO PythonRunner: Times: total = 210, boot = 209, init = 0, finish = 1
16/03/21 17:29:50 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1242 bytes result sent to driver
16/03/21 17:29:50 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 244 ms on localhost (2/2)
16/03/21 17:29:50 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:29:50 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.435 s
16/03/21 17:29:50 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.156119 s
16/03/21 17:29:50 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:29:50 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:29:50 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:29:50 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:29:50 INFO DAGScheduler: Missing parents: List()
16/03/21 17:29:50 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:29:50 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19078, maxMem=847223193
16/03/21 17:29:50 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 808.0 MB)
16/03/21 17:29:50 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24894, maxMem=847223193
16/03/21 17:29:50 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 807.9 MB)
16/03/21 17:29:50 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:54635 (size: 3.3 KB, free: 808.0 MB)
16/03/21 17:29:50 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:29:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:29:50 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:29:50 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:29:50 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:29:50 INFO PythonRunner: Times: total = 286, boot = 285, init = 1, finish = 0
16/03/21 17:29:50 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:29:50 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2272 bytes)
16/03/21 17:29:50 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 303 ms on localhost (1/2)
16/03/21 17:29:50 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:29:51 INFO PythonRunner: Times: total = 260, boot = 260, init = 0, finish = 0
16/03/21 17:29:51 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1311 bytes result sent to driver
16/03/21 17:29:51 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 279 ms on localhost (2/2)
16/03/21 17:29:51 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:29:51 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.584 s
16/03/21 17:29:51 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.613327 s
16/03/21 17:29:51 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:29:51 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:29:51 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:29:51 INFO MemoryStore: MemoryStore cleared
16/03/21 17:29:51 INFO BlockManager: BlockManager stopped
16/03/21 17:29:51 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:29:51 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:29:51 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:29:51 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:29:51 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:29:51 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:29:52 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:29:52 INFO SecurityManager: Changing view acls to: root
16/03/21 17:29:52 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:29:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:29:52 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:29:52 INFO Remoting: Starting remoting
16/03/21 17:29:52 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:50327]
16/03/21 17:29:52 INFO Utils: Successfully started service 'sparkDriver' on port 50327.
16/03/21 17:29:52 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:29:52 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:29:52 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3e811ff9-f783-4b98-b2b7-d5002df44a0d
16/03/21 17:29:52 INFO MemoryStore: MemoryStore started with capacity 808.0 MB
16/03/21 17:29:52 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-cab0297e-df58-4e0b-b044-a57f5086c5d9
16/03/21 17:29:52 INFO HttpServer: Starting HTTP Server
16/03/21 17:29:52 INFO Utils: Successfully started service 'HTTP file server' on port 56988.
16/03/21 17:29:52 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:29:52 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:29:52 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:29:52 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-71794e1a-0fbc-4ee5-aa30-be28426613a7/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:29:52 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561592587
16/03/21 17:29:52 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:29:52 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:29:52 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56056.
16/03/21 17:29:52 INFO NettyBlockTransferService: Server created on 56056
16/03/21 17:29:52 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:29:52 INFO BlockManagerMasterEndpoint: Registering block manager localhost:56056 with 808.0 MB RAM, BlockManagerId(driver, localhost, 56056)
16/03/21 17:29:52 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:29:52 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561592614
16/03/21 17:29:52 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:29:52 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:29:52 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:29:52 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:29:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:29:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:29:52 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:29:52 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=847223193
16/03/21 17:29:52 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 808.0 MB)
16/03/21 17:29:52 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=847223193
16/03/21 17:29:52 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 808.0 MB)
16/03/21 17:29:52 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:56056 (size: 4.1 KB, free: 808.0 MB)
16/03/21 17:29:52 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:29:52 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:29:52 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:29:52 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:29:52 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:29:52 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:29:52 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561592587
16/03/21 17:29:52 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-71794e1a-0fbc-4ee5-aa30-be28426613a7/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:29:52 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:29:52 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=847223193
16/03/21 17:29:52 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 808.0 MB)
16/03/21 17:29:52 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:56056 (size: 166.0 B, free: 808.0 MB)
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: area
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: issue
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: planning
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: permission
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: economy
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: composition
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: agency
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:30:00 INFO PythonRunner: Times: total = 8040, boot = 464, init = 367, finish = 7209
16/03/21 17:30:00 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:30:00 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:30:00 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:30:00 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:30:00 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=847223193
16/03/21 17:30:00 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 808.0 MB)
16/03/21 17:30:00 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8107 ms on localhost (1/2)
16/03/21 17:30:00 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:56056 (size: 155.0 B, free: 808.0 MB)
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: set
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: bend
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: giant
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: astatine
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: present
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: area
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:30:01 INFO PythonRunner: Times: total = 252, boot = 158, init = 0, finish = 94
16/03/21 17:30:01 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:30:01 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.381 s
16/03/21 17:30:01 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:30:01 INFO DAGScheduler: running: Set()
16/03/21 17:30:01 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:30:01 INFO DAGScheduler: failed: Set()
16/03/21 17:30:01 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:30:01 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:30:01 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=847223193
16/03/21 17:30:01 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 808.0 MB)
16/03/21 17:30:01 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16030, maxMem=847223193
16/03/21 17:30:01 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 285 ms on localhost (2/2)
16/03/21 17:30:01 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:30:01 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 808.0 MB)
16/03/21 17:30:01 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:56056 (size: 3.0 KB, free: 808.0 MB)
16/03/21 17:30:01 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:30:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:30:01 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:30:01 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:30:01 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:30:01 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:30:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:30:01 INFO PythonRunner: Times: total = 139, boot = 138, init = 0, finish = 1
16/03/21 17:30:01 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:30:01 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:30:01 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:30:01 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:30:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:30:01 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 165 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None']
16/03/21 17:30:01 INFO PythonRunner: Times: total = 152, boot = 151, init = 1, finish = 0
16/03/21 17:30:01 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1227 bytes result sent to driver
16/03/21 17:30:01 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.313 s
16/03/21 17:30:01 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.725309 s
16/03/21 17:30:01 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 169 ms on localhost (2/2)
16/03/21 17:30:01 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:30:01 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:30:01 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:30:01 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:30:01 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:30:01 INFO DAGScheduler: Missing parents: List()
16/03/21 17:30:01 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:30:01 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19078, maxMem=847223193
16/03/21 17:30:01 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 808.0 MB)
16/03/21 17:30:01 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24894, maxMem=847223193
16/03/21 17:30:01 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 807.9 MB)
16/03/21 17:30:01 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:56056 (size: 3.3 KB, free: 808.0 MB)
16/03/21 17:30:01 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:30:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:30:01 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:30:01 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:30:01 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:30:01 INFO PythonRunner: Times: total = 124, boot = 124, init = 0, finish = 0
16/03/21 17:30:01 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:30:01 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2257 bytes)
16/03/21 17:30:01 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 142 ms on localhost (1/2)
16/03/21 17:30:01 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:30:01 INFO PythonRunner: Times: total = 152, boot = 152, init = 0, finish = 0
16/03/21 17:30:01 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1296 bytes result sent to driver
16/03/21 17:30:01 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.297 s
16/03/21 17:30:01 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.317956 s
16/03/21 17:30:01 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 171 ms on localhost (2/2)
16/03/21 17:30:01 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:30:02 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:30:02 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:30:02 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:30:02 INFO MemoryStore: MemoryStore cleared
16/03/21 17:30:02 INFO BlockManager: BlockManager stopped
16/03/21 17:30:02 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:30:02 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:30:02 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:30:02 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:30:02 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:30:02 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:30:02 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:30:02 INFO SecurityManager: Changing view acls to: root
16/03/21 17:30:02 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:30:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:30:02 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:30:02 INFO Remoting: Starting remoting
16/03/21 17:30:03 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:46399]
16/03/21 17:30:03 INFO Utils: Successfully started service 'sparkDriver' on port 46399.
16/03/21 17:30:03 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:30:03 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:30:03 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-42b440e4-4384-4ba7-af12-da78f9f3cdba
16/03/21 17:30:03 INFO MemoryStore: MemoryStore started with capacity 808.0 MB
16/03/21 17:30:03 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-f4387190-18f0-4383-b269-ad105303248b
16/03/21 17:30:03 INFO HttpServer: Starting HTTP Server
16/03/21 17:30:03 INFO Utils: Successfully started service 'HTTP file server' on port 40012.
16/03/21 17:30:03 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:30:03 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:30:03 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:30:03 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-20a53db5-5570-4e81-8227-87cb5997c2e4/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:30:03 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561603162
16/03/21 17:30:03 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:30:03 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:30:03 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35112.
16/03/21 17:30:03 INFO NettyBlockTransferService: Server created on 35112
16/03/21 17:30:03 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:30:03 INFO BlockManagerMasterEndpoint: Registering block manager localhost:35112 with 808.0 MB RAM, BlockManagerId(driver, localhost, 35112)
16/03/21 17:30:03 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:30:03 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561603183
16/03/21 17:30:03 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:30:03 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:30:03 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:30:03 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:30:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:30:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:30:03 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:30:03 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=847223193
16/03/21 17:30:03 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 808.0 MB)
16/03/21 17:30:03 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=847223193
16/03/21 17:30:03 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 808.0 MB)
16/03/21 17:30:03 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:35112 (size: 4.1 KB, free: 808.0 MB)
16/03/21 17:30:03 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:30:03 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:30:03 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:30:03 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:30:03 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:30:03 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:30:03 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561603162
16/03/21 17:30:03 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-20a53db5-5570-4e81-8227-87cb5997c2e4/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:30:03 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:30:03 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=847223193
16/03/21 17:30:03 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 808.0 MB)
16/03/21 17:30:03 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:35112 (size: 166.0 B, free: 808.0 MB)
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: area
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: issue
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: planning
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: permission
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: economy
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: composition
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: agency
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:30:11 INFO PythonRunner: Times: total = 8262, boot = 460, init = 356, finish = 7446
16/03/21 17:30:11 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:30:11 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:30:11 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:30:11 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:30:11 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=847223193
16/03/21 17:30:11 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 808.0 MB)
16/03/21 17:30:11 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:35112 (size: 155.0 B, free: 808.0 MB)
16/03/21 17:30:11 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8355 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: set
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: bend
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: giant
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: astatine
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: present
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: area
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:30:11 INFO PythonRunner: Times: total = 296, boot = 197, init = 0, finish = 99
16/03/21 17:30:11 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:30:11 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.670 s
16/03/21 17:30:11 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:30:11 INFO DAGScheduler: running: Set()
16/03/21 17:30:11 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:30:11 INFO DAGScheduler: failed: Set()
16/03/21 17:30:11 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:30:11 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:30:11 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=847223193
16/03/21 17:30:11 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 808.0 MB)
16/03/21 17:30:11 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 328 ms on localhost (2/2)
16/03/21 17:30:11 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:30:11 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16030, maxMem=847223193
16/03/21 17:30:11 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 808.0 MB)
16/03/21 17:30:11 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:35112 (size: 3.0 KB, free: 808.0 MB)
16/03/21 17:30:11 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:30:11 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:30:11 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:30:12 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:30:12 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:30:12 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:30:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:30:12 INFO PythonRunner: Times: total = 167, boot = 166, init = 0, finish = 1
16/03/21 17:30:12 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:30:12 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:30:12 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:30:12 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:30:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:30:12 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 180 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None']
16/03/21 17:30:12 INFO PythonRunner: Times: total = 177, boot = 176, init = 0, finish = 1
16/03/21 17:30:12 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1227 bytes result sent to driver
16/03/21 17:30:12 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.364 s
16/03/21 17:30:12 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.066739 s
16/03/21 17:30:12 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 191 ms on localhost (2/2)
16/03/21 17:30:12 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:30:12 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:30:12 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:30:12 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:30:12 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:30:12 INFO DAGScheduler: Missing parents: List()
16/03/21 17:30:12 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:30:12 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19078, maxMem=847223193
16/03/21 17:30:12 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 808.0 MB)
16/03/21 17:30:12 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24894, maxMem=847223193
16/03/21 17:30:12 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 807.9 MB)
16/03/21 17:30:12 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:35112 (size: 3.3 KB, free: 808.0 MB)
16/03/21 17:30:12 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:30:12 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:30:12 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:30:12 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:30:12 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:30:12 INFO PythonRunner: Times: total = 121, boot = 121, init = 0, finish = 0
16/03/21 17:30:12 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:30:12 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2257 bytes)
16/03/21 17:30:12 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:30:12 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 136 ms on localhost (1/2)
16/03/21 17:30:12 INFO PythonRunner: Times: total = 205, boot = 204, init = 0, finish = 1
16/03/21 17:30:12 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1296 bytes result sent to driver
16/03/21 17:30:12 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 227 ms on localhost (2/2)
16/03/21 17:30:12 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:30:12 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.356 s
16/03/21 17:30:12 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.377005 s
16/03/21 17:30:12 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:30:12 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:30:13 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:30:13 INFO MemoryStore: MemoryStore cleared
16/03/21 17:30:13 INFO BlockManager: BlockManager stopped
16/03/21 17:30:13 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:30:13 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:30:13 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:30:13 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:30:13 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:30:13 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:30:13 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:30:13 INFO SecurityManager: Changing view acls to: root
16/03/21 17:30:13 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:30:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:30:13 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:30:13 INFO Remoting: Starting remoting
16/03/21 17:30:14 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:59406]
16/03/21 17:30:14 INFO Utils: Successfully started service 'sparkDriver' on port 59406.
16/03/21 17:30:14 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:30:14 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:30:14 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-59feeb81-c509-4063-8aab-6da7797efc81
16/03/21 17:30:14 INFO MemoryStore: MemoryStore started with capacity 808.0 MB
16/03/21 17:30:14 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-321fa1c7-31a7-4990-919a-1a06fefbfbb1
16/03/21 17:30:14 INFO HttpServer: Starting HTTP Server
16/03/21 17:30:14 INFO Utils: Successfully started service 'HTTP file server' on port 34206.
16/03/21 17:30:14 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:30:14 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:30:14 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:30:14 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-e07702e3-aae3-464d-8313-376ceabaa7ff/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:30:14 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561614234
16/03/21 17:30:14 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:30:14 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:30:14 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37846.
16/03/21 17:30:14 INFO NettyBlockTransferService: Server created on 37846
16/03/21 17:30:14 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:30:14 INFO BlockManagerMasterEndpoint: Registering block manager localhost:37846 with 808.0 MB RAM, BlockManagerId(driver, localhost, 37846)
16/03/21 17:30:14 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:30:14 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561614249
16/03/21 17:30:14 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:30:14 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:30:14 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:30:14 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:30:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:30:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:30:14 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:30:14 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=847223193
16/03/21 17:30:14 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 808.0 MB)
16/03/21 17:30:14 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=847223193
16/03/21 17:30:14 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 808.0 MB)
16/03/21 17:30:14 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:37846 (size: 4.1 KB, free: 808.0 MB)
16/03/21 17:30:14 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:30:14 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:30:14 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:30:14 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:30:14 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:30:14 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:30:14 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561614234
16/03/21 17:30:14 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-e07702e3-aae3-464d-8313-376ceabaa7ff/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:30:14 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:30:14 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=847223193
16/03/21 17:30:14 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 808.0 MB)
16/03/21 17:30:14 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:37846 (size: 166.0 B, free: 808.0 MB)
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: area
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: issue
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: planning
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: permission
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): adding to parents: syn =  Synset('permission.n.01') ; keyword:  something  in syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= [u'permission']
reduceFunction_Parents(): returns= ['None', u'permission']
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: economy
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'permission']
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: composition
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'permission']
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: agency
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'permission']
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'permission']
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'permission']
16/03/21 17:30:29 INFO PythonRunner: Times: total = 15483, boot = 629, init = 569, finish = 14285
16/03/21 17:30:29 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:30:29 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:30:29 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:30:29 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 15565 ms on localhost (1/2)
16/03/21 17:30:29 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:30:29 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=847223193
16/03/21 17:30:29 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 808.0 MB)
16/03/21 17:30:29 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:37846 (size: 155.0 B, free: 808.0 MB)
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: set
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: bend
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: giant
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: astatine
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: present
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: area
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:30:30 INFO PythonRunner: Times: total = 635, boot = 407, init = 0, finish = 228
16/03/21 17:30:30 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:30:30 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 16.233 s
16/03/21 17:30:30 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:30:30 INFO DAGScheduler: running: Set()
16/03/21 17:30:30 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:30:30 INFO DAGScheduler: failed: Set()
16/03/21 17:30:30 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:30:30 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:30:30 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=847223193
16/03/21 17:30:30 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 808.0 MB)
16/03/21 17:30:30 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 677 ms on localhost (2/2)
16/03/21 17:30:30 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:30:30 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16030, maxMem=847223193
16/03/21 17:30:30 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 808.0 MB)
16/03/21 17:30:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:37846 (size: 3.0 KB, free: 808.0 MB)
16/03/21 17:30:30 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:30:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:30:30 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:30:30 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:30:30 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:30:30 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:30:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:30:31 INFO PythonRunner: Times: total = 355, boot = 354, init = 0, finish = 1
16/03/21 17:30:31 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:30:31 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:30:31 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:30:31 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:30:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:30:31 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 398 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'permission', 'None']
16/03/21 17:30:31 INFO PythonRunner: Times: total = 202, boot = 202, init = 0, finish = 0
16/03/21 17:30:31 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1244 bytes result sent to driver
16/03/21 17:30:31 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 235 ms on localhost (2/2)
16/03/21 17:30:31 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:30:31 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.614 s
16/03/21 17:30:31 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 16.904144 s
16/03/21 17:30:31 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:30:31 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:30:31 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:30:31 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:30:31 INFO DAGScheduler: Missing parents: List()
16/03/21 17:30:31 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:30:31 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19078, maxMem=847223193
16/03/21 17:30:31 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 808.0 MB)
16/03/21 17:30:31 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24894, maxMem=847223193
16/03/21 17:30:31 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 807.9 MB)
16/03/21 17:30:31 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:37846 (size: 3.3 KB, free: 808.0 MB)
16/03/21 17:30:31 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:30:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:30:31 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:30:31 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:30:31 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:30:31 INFO PythonRunner: Times: total = 167, boot = 165, init = 2, finish = 0
16/03/21 17:30:31 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:30:31 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2274 bytes)
16/03/21 17:30:31 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 185 ms on localhost (1/2)
16/03/21 17:30:31 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:30:32 INFO PythonRunner: Times: total = 25, boot = -196, init = 221, finish = 0
16/03/21 17:30:32 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1313 bytes result sent to driver
16/03/21 17:30:32 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 586 ms on localhost (2/2)
16/03/21 17:30:32 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:30:32 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.754 s
16/03/21 17:30:32 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.788099 s
16/03/21 17:30:32 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:37846 in memory (size: 3.0 KB, free: 808.0 MB)
16/03/21 17:30:32 INFO ContextCleaner: Cleaned accumulator 299
16/03/21 17:30:32 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:37846 in memory (size: 4.1 KB, free: 808.0 MB)
16/03/21 17:30:32 INFO ContextCleaner: Cleaned accumulator 298
16/03/21 17:30:32 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:30:32 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:30:32 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:30:32 INFO MemoryStore: MemoryStore cleared
16/03/21 17:30:32 INFO BlockManager: BlockManager stopped
16/03/21 17:30:32 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:30:32 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:30:32 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:30:32 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:30:32 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:30:32 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:30:33 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:30:33 INFO SecurityManager: Changing view acls to: root
16/03/21 17:30:33 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:30:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:30:33 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:30:33 INFO Remoting: Starting remoting
16/03/21 17:30:33 INFO Utils: Successfully started service 'sparkDriver' on port 54153.
16/03/21 17:30:33 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:54153]
16/03/21 17:30:33 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:30:33 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:30:33 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-eaa868e0-3f29-4359-a229-d29d3b033bea
16/03/21 17:30:33 INFO MemoryStore: MemoryStore started with capacity 808.5 MB
16/03/21 17:30:33 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-f2d958db-4272-421c-bc57-1e87fea6f4e7
16/03/21 17:30:33 INFO HttpServer: Starting HTTP Server
16/03/21 17:30:33 INFO Utils: Successfully started service 'HTTP file server' on port 54936.
16/03/21 17:30:33 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:30:34 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:30:34 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:30:34 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-cd5ca2c2-9e2f-4e87-a997-0925fe3b867c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:30:34 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561634626
16/03/21 17:30:34 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:30:34 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:30:34 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33289.
16/03/21 17:30:34 INFO NettyBlockTransferService: Server created on 33289
16/03/21 17:30:34 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:30:34 INFO BlockManagerMasterEndpoint: Registering block manager localhost:33289 with 808.5 MB RAM, BlockManagerId(driver, localhost, 33289)
16/03/21 17:30:34 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:30:34 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561634672
16/03/21 17:30:34 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:30:34 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:30:34 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:30:34 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:30:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:30:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:30:34 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:30:35 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=847754035
16/03/21 17:30:35 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 808.5 MB)
16/03/21 17:30:35 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=847754035
16/03/21 17:30:35 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 808.5 MB)
16/03/21 17:30:35 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:33289 (size: 4.1 KB, free: 808.5 MB)
16/03/21 17:30:35 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:30:35 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:30:35 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:30:35 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:30:35 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:30:35 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:30:35 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561634626
16/03/21 17:30:35 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-cd5ca2c2-9e2f-4e87-a997-0925fe3b867c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:30:35 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:30:35 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=847754035
16/03/21 17:30:35 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 808.5 MB)
16/03/21 17:30:35 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:33289 (size: 166.0 B, free: 808.5 MB)
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: area
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: issue
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: planning
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: permission
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: economy
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: composition
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: agency
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:30:52 INFO PythonRunner: Times: total = 17020, boot = 1673, init = 1113, finish = 14234
16/03/21 17:30:52 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:30:52 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:30:52 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:30:52 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 17152 ms on localhost (1/2)
16/03/21 17:30:52 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:30:52 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=847754035
16/03/21 17:30:52 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 808.5 MB)
16/03/21 17:30:52 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:33289 (size: 155.0 B, free: 808.5 MB)
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: set
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: bend
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: giant
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: astatine
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: present
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  bishop  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: area
16/03/21 17:30:52 INFO PythonRunner: Times: total = 530, boot = 344, init = 2, finish = 184
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
16/03/21 17:30:52 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:30:52 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 590 ms on localhost (2/2)
16/03/21 17:30:52 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:30:52 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 17.737 s
16/03/21 17:30:52 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:30:52 INFO DAGScheduler: running: Set()
16/03/21 17:30:52 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:30:52 INFO DAGScheduler: failed: Set()
16/03/21 17:30:52 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:30:52 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:30:52 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=847754035
16/03/21 17:30:52 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 808.5 MB)
16/03/21 17:30:52 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16030, maxMem=847754035
16/03/21 17:30:52 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 808.5 MB)
16/03/21 17:30:52 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:33289 (size: 3.0 KB, free: 808.5 MB)
16/03/21 17:30:52 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:30:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:30:52 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:30:52 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:30:52 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:30:52 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:30:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:30:53 INFO PythonRunner: Times: total = 281, boot = 280, init = 0, finish = 1
16/03/21 17:30:53 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:30:53 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:30:53 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:30:53 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:30:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:30:53 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 307 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'metropolitan']
16/03/21 17:30:53 INFO PythonRunner: Times: total = 322, boot = 320, init = 1, finish = 1
16/03/21 17:30:53 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1246 bytes result sent to driver
16/03/21 17:30:53 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 354 ms on localhost (2/2)
16/03/21 17:30:53 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:30:53 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.654 s
16/03/21 17:30:53 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 18.437445 s
16/03/21 17:30:53 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:30:53 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:30:53 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:30:53 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:30:53 INFO DAGScheduler: Missing parents: List()
16/03/21 17:30:53 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:30:53 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19078, maxMem=847754035
16/03/21 17:30:53 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 808.5 MB)
16/03/21 17:30:53 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24894, maxMem=847754035
16/03/21 17:30:53 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 808.5 MB)
16/03/21 17:30:53 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:33289 (size: 3.3 KB, free: 808.5 MB)
16/03/21 17:30:53 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:30:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:30:53 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:30:53 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:30:53 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:30:53 INFO PythonRunner: Times: total = 292, boot = 292, init = 0, finish = 0
16/03/21 17:30:53 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:30:53 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2276 bytes)
16/03/21 17:30:53 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:30:53 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 313 ms on localhost (1/2)
16/03/21 17:30:54 INFO PythonRunner: Times: total = 395, boot = 394, init = 1, finish = 0
16/03/21 17:30:54 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1315 bytes result sent to driver
16/03/21 17:30:54 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 413 ms on localhost (2/2)
16/03/21 17:30:54 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:30:54 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.723 s
16/03/21 17:30:54 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.744347 s
16/03/21 17:30:54 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:30:54 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:30:54 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:30:54 INFO MemoryStore: MemoryStore cleared
16/03/21 17:30:54 INFO BlockManager: BlockManager stopped
16/03/21 17:30:54 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:30:54 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:30:54 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:30:54 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:30:54 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:30:54 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:30:55 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:30:55 INFO SecurityManager: Changing view acls to: root
16/03/21 17:30:55 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:30:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:30:55 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:30:55 INFO Remoting: Starting remoting
16/03/21 17:30:55 INFO Utils: Successfully started service 'sparkDriver' on port 35648.
16/03/21 17:30:55 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:35648]
16/03/21 17:30:55 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:30:55 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:30:55 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-cd2b0c15-38b4-42a7-ab83-783f3d82538f
16/03/21 17:30:55 INFO MemoryStore: MemoryStore started with capacity 808.5 MB
16/03/21 17:30:55 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-376c0ae8-6858-453b-b8e7-72cd4c9fdaf0
16/03/21 17:30:55 INFO HttpServer: Starting HTTP Server
16/03/21 17:30:55 INFO Utils: Successfully started service 'HTTP file server' on port 43609.
16/03/21 17:30:55 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:30:56 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:30:56 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:30:56 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-ab5b42a5-76c1-46a7-b7b0-e92073a5618e/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:30:56 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561656185
16/03/21 17:30:56 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:30:56 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:30:56 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46538.
16/03/21 17:30:56 INFO NettyBlockTransferService: Server created on 46538
16/03/21 17:30:56 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:30:56 INFO BlockManagerMasterEndpoint: Registering block manager localhost:46538 with 808.5 MB RAM, BlockManagerId(driver, localhost, 46538)
16/03/21 17:30:56 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:30:56 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561656229
16/03/21 17:30:56 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:30:56 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:30:56 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:30:56 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:30:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:30:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:30:56 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:30:56 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=847754035
16/03/21 17:30:56 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 808.5 MB)
16/03/21 17:30:56 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=847754035
16/03/21 17:30:56 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 808.5 MB)
16/03/21 17:30:56 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:46538 (size: 4.1 KB, free: 808.5 MB)
16/03/21 17:30:56 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:30:56 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:30:56 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:30:56 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:30:56 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:30:56 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:30:56 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561656185
16/03/21 17:30:56 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-ab5b42a5-76c1-46a7-b7b0-e92073a5618e/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:30:56 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:30:56 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=847754035
16/03/21 17:30:56 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 808.5 MB)
16/03/21 17:30:56 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:46538 (size: 166.0 B, free: 808.5 MB)
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: area
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: issue
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: planning
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: permission
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: economy
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: composition
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: agency
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:31:08 INFO PythonRunner: Times: total = 12102, boot = 1094, init = 769, finish = 10239
16/03/21 17:31:08 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:31:08 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:31:08 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:31:08 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:31:08 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=847754035
16/03/21 17:31:08 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 808.5 MB)
16/03/21 17:31:08 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 12253 ms on localhost (1/2)
16/03/21 17:31:08 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:46538 (size: 155.0 B, free: 808.5 MB)
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: set
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  Synset('set.n.01') ; keyword:  things  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: bend
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: giant
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: astatine
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: present
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: area
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
16/03/21 17:31:09 INFO PythonRunner: Times: total = 286, boot = 186, init = 0, finish = 100
16/03/21 17:31:09 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:31:09 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 12.573 s
16/03/21 17:31:09 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:31:09 INFO DAGScheduler: running: Set()
16/03/21 17:31:09 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:31:09 INFO DAGScheduler: failed: Set()
16/03/21 17:31:09 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:31:09 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:31:09 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=847754035
16/03/21 17:31:09 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 808.5 MB)
16/03/21 17:31:09 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16030, maxMem=847754035
16/03/21 17:31:09 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 808.5 MB)
16/03/21 17:31:09 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 320 ms on localhost (2/2)
16/03/21 17:31:09 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:31:09 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:46538 (size: 3.0 KB, free: 808.5 MB)
16/03/21 17:31:09 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:31:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:31:09 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:31:09 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:31:09 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:31:09 INFO PythonRunner: Times: total = 168, boot = 168, init = 0, finish = 0
16/03/21 17:31:09 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:31:09 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:31:09 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:31:09 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:31:09 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 189 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'set']
16/03/21 17:31:09 INFO PythonRunner: Times: total = 173, boot = 172, init = 0, finish = 1
16/03/21 17:31:09 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1229 bytes result sent to driver
16/03/21 17:31:09 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.372 s
16/03/21 17:31:09 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 13.002809 s
16/03/21 17:31:09 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 189 ms on localhost (2/2)
16/03/21 17:31:09 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:31:09 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:31:09 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:31:09 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:31:09 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:31:09 INFO DAGScheduler: Missing parents: List()
16/03/21 17:31:09 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:31:09 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19078, maxMem=847754035
16/03/21 17:31:09 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 808.5 MB)
16/03/21 17:31:09 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24894, maxMem=847754035
16/03/21 17:31:09 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 808.5 MB)
16/03/21 17:31:09 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:46538 (size: 3.3 KB, free: 808.5 MB)
16/03/21 17:31:09 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:31:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:31:09 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:31:09 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:31:09 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:31:09 INFO PythonRunner: Times: total = 89, boot = 89, init = 0, finish = 0
16/03/21 17:31:09 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:31:09 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2259 bytes)
16/03/21 17:31:09 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:31:09 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 105 ms on localhost (1/2)
16/03/21 17:31:09 INFO PythonRunner: Times: total = 167, boot = 167, init = 0, finish = 0
16/03/21 17:31:09 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1295 bytes result sent to driver
16/03/21 17:31:09 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 180 ms on localhost (2/2)
16/03/21 17:31:09 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:31:09 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.279 s
16/03/21 17:31:09 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.298913 s
16/03/21 17:31:10 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:31:10 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:31:10 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:31:10 INFO MemoryStore: MemoryStore cleared
16/03/21 17:31:10 INFO BlockManager: BlockManager stopped
16/03/21 17:31:10 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:31:10 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:31:10 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:31:10 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:31:10 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:31:10 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:31:10 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:31:10 INFO SecurityManager: Changing view acls to: root
16/03/21 17:31:10 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:31:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:31:10 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:31:11 INFO Remoting: Starting remoting
16/03/21 17:31:11 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:55134]
16/03/21 17:31:11 INFO Utils: Successfully started service 'sparkDriver' on port 55134.
16/03/21 17:31:11 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:31:11 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:31:11 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d6dc222d-7470-49ba-aa5c-d14f25585827
16/03/21 17:31:11 INFO MemoryStore: MemoryStore started with capacity 808.5 MB
16/03/21 17:31:11 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-f5234a51-bd06-4ad4-9b5a-1172da496d40
16/03/21 17:31:11 INFO HttpServer: Starting HTTP Server
16/03/21 17:31:11 INFO Utils: Successfully started service 'HTTP file server' on port 34863.
16/03/21 17:31:11 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:31:11 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:31:11 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:31:11 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-5237e2a1-76d5-4113-af3b-eff8c58ae09a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:31:11 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561671264
16/03/21 17:31:11 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:31:11 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:31:11 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60811.
16/03/21 17:31:11 INFO NettyBlockTransferService: Server created on 60811
16/03/21 17:31:11 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:31:11 INFO BlockManagerMasterEndpoint: Registering block manager localhost:60811 with 808.5 MB RAM, BlockManagerId(driver, localhost, 60811)
16/03/21 17:31:11 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:31:11 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561671282
16/03/21 17:31:11 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:31:11 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:31:11 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:31:11 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:31:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:31:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:31:11 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:31:11 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=847754035
16/03/21 17:31:11 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 808.5 MB)
16/03/21 17:31:11 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=847754035
16/03/21 17:31:11 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 808.5 MB)
16/03/21 17:31:11 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:60811 (size: 4.1 KB, free: 808.5 MB)
16/03/21 17:31:11 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:31:11 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:31:11 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:31:11 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:31:11 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:31:11 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:31:11 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561671264
16/03/21 17:31:11 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-5237e2a1-76d5-4113-af3b-eff8c58ae09a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:31:11 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:31:11 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=847754035
16/03/21 17:31:11 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 808.5 MB)
16/03/21 17:31:11 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:60811 (size: 166.0 B, free: 808.5 MB)
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: area
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: issue
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: planning
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: permission
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: economy
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: composition
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: agency
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:31:19 INFO PythonRunner: Times: total = 8024, boot = 518, init = 410, finish = 7096
16/03/21 17:31:19 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:31:19 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:31:19 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:31:19 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8109 ms on localhost (1/2)
16/03/21 17:31:19 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:31:19 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=847754035
16/03/21 17:31:19 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 808.5 MB)
16/03/21 17:31:19 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:60811 (size: 155.0 B, free: 808.5 MB)
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: set
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  Synset('set.n.01') ; keyword:  belong  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: bend
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: giant
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: astatine
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: present
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: area
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
16/03/21 17:31:19 INFO PythonRunner: Times: total = 266, boot = 164, init = 1, finish = 101
16/03/21 17:31:19 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:31:19 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 293 ms on localhost (2/2)
16/03/21 17:31:19 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:31:19 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.399 s
16/03/21 17:31:19 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:31:19 INFO DAGScheduler: running: Set()
16/03/21 17:31:19 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:31:19 INFO DAGScheduler: failed: Set()
16/03/21 17:31:19 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:31:19 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:31:19 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=847754035
16/03/21 17:31:19 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 808.5 MB)
16/03/21 17:31:19 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16030, maxMem=847754035
16/03/21 17:31:19 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 808.5 MB)
16/03/21 17:31:19 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:60811 (size: 3.0 KB, free: 808.5 MB)
16/03/21 17:31:19 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:31:19 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:31:19 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:31:19 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:31:19 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:31:19 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:31:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:31:20 INFO PythonRunner: Times: total = 152, boot = 151, init = 1, finish = 0
16/03/21 17:31:20 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:31:20 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:31:20 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:31:20 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:31:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:31:20 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 167 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'set']
16/03/21 17:31:20 INFO PythonRunner: Times: total = 167, boot = 166, init = 0, finish = 1
16/03/21 17:31:20 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1229 bytes result sent to driver
16/03/21 17:31:20 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 185 ms on localhost (2/2)
16/03/21 17:31:20 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:31:20 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.349 s
16/03/21 17:31:20 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.776253 s
16/03/21 17:31:20 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:31:20 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:31:20 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:31:20 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:31:20 INFO DAGScheduler: Missing parents: List()
16/03/21 17:31:20 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:31:20 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19078, maxMem=847754035
16/03/21 17:31:20 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 808.5 MB)
16/03/21 17:31:20 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24894, maxMem=847754035
16/03/21 17:31:20 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 808.5 MB)
16/03/21 17:31:20 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:60811 (size: 3.3 KB, free: 808.5 MB)
16/03/21 17:31:20 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:31:20 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:31:20 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:31:20 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:31:20 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:31:20 INFO PythonRunner: Times: total = 69, boot = 68, init = 1, finish = 0
16/03/21 17:31:20 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:31:20 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2259 bytes)
16/03/21 17:31:20 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 83 ms on localhost (1/2)
16/03/21 17:31:20 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:31:20 INFO PythonRunner: Times: total = 190, boot = 190, init = 0, finish = 0
16/03/21 17:31:20 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1295 bytes result sent to driver
16/03/21 17:31:20 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.274 s
16/03/21 17:31:20 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.308382 s
16/03/21 17:31:20 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 206 ms on localhost (2/2)
16/03/21 17:31:20 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:31:20 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:31:20 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:31:20 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:31:20 INFO MemoryStore: MemoryStore cleared
16/03/21 17:31:20 INFO BlockManager: BlockManager stopped
16/03/21 17:31:20 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:31:20 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:31:20 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:31:20 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:31:20 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:31:20 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:31:21 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:31:21 INFO SecurityManager: Changing view acls to: root
16/03/21 17:31:21 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:31:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:31:21 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:31:21 INFO Remoting: Starting remoting
16/03/21 17:31:21 INFO Utils: Successfully started service 'sparkDriver' on port 35953.
16/03/21 17:31:21 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:35953]
16/03/21 17:31:21 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:31:21 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:31:21 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3370b0c5-c27e-48b5-9374-c38aebbda3eb
16/03/21 17:31:21 INFO MemoryStore: MemoryStore started with capacity 808.5 MB
16/03/21 17:31:21 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-cd94bbd3-2835-45c3-8109-4334db9fd896
16/03/21 17:31:21 INFO HttpServer: Starting HTTP Server
16/03/21 17:31:21 INFO Utils: Successfully started service 'HTTP file server' on port 34958.
16/03/21 17:31:21 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:31:21 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:31:21 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:31:21 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-5ecfad38-00e1-42a4-85f4-e5c1a6ab6b8d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:31:22 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561681988
16/03/21 17:31:22 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:31:22 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:31:22 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33954.
16/03/21 17:31:22 INFO NettyBlockTransferService: Server created on 33954
16/03/21 17:31:22 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:31:22 INFO BlockManagerMasterEndpoint: Registering block manager localhost:33954 with 808.5 MB RAM, BlockManagerId(driver, localhost, 33954)
16/03/21 17:31:22 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:31:22 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561682041
16/03/21 17:31:22 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:31:22 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:31:22 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:31:22 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:31:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:31:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:31:22 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:31:22 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=847754035
16/03/21 17:31:22 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 808.5 MB)
16/03/21 17:31:22 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=847754035
16/03/21 17:31:22 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 808.5 MB)
16/03/21 17:31:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:33954 (size: 4.1 KB, free: 808.5 MB)
16/03/21 17:31:22 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:31:22 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:31:22 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:31:22 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:31:22 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:31:22 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:31:22 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561681988
16/03/21 17:31:22 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-5ecfad38-00e1-42a4-85f4-e5c1a6ab6b8d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:31:22 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:31:22 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=847754035
16/03/21 17:31:22 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 808.5 MB)
16/03/21 17:31:22 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:33954 (size: 166.0 B, free: 808.5 MB)
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: area
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: issue
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: planning
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: permission
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: economy
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: composition
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: agency
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:31:30 INFO PythonRunner: Times: total = 8220, boot = 535, init = 435, finish = 7250
16/03/21 17:31:30 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:31:30 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:31:30 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:31:30 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:31:30 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=847754035
16/03/21 17:31:30 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 808.5 MB)
16/03/21 17:31:30 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8315 ms on localhost (1/2)
16/03/21 17:31:30 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:33954 (size: 155.0 B, free: 808.5 MB)
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: set
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: bend
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: giant
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: astatine
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  uranium  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: present
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: area
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/21 17:31:30 INFO PythonRunner: Times: total = 243, boot = 146, init = 1, finish = 96
16/03/21 17:31:30 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:31:30 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.596 s
16/03/21 17:31:30 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:31:30 INFO DAGScheduler: running: Set()
16/03/21 17:31:30 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:31:30 INFO DAGScheduler: failed: Set()
16/03/21 17:31:30 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:31:30 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:31:30 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=847754035
16/03/21 17:31:30 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 808.5 MB)
16/03/21 17:31:30 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16030, maxMem=847754035
16/03/21 17:31:30 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 808.5 MB)
16/03/21 17:31:30 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 278 ms on localhost (2/2)
16/03/21 17:31:30 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:31:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:33954 (size: 3.0 KB, free: 808.5 MB)
16/03/21 17:31:30 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:31:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:31:30 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:31:30 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:31:30 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:31:30 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:31:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:31:30 INFO PythonRunner: Times: total = 147, boot = 146, init = 0, finish = 1
16/03/21 17:31:30 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:31:30 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:31:30 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:31:30 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:31:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:31:30 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 169 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/03/21 17:31:31 INFO PythonRunner: Times: total = 172, boot = 171, init = 0, finish = 1
16/03/21 17:31:31 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1242 bytes result sent to driver
16/03/21 17:31:31 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.359 s
16/03/21 17:31:31 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.981328 s
16/03/21 17:31:31 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 191 ms on localhost (2/2)
16/03/21 17:31:31 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:31:31 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:31:31 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:31:31 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:31:31 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:31:31 INFO DAGScheduler: Missing parents: List()
16/03/21 17:31:31 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:31:31 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19078, maxMem=847754035
16/03/21 17:31:31 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 808.5 MB)
16/03/21 17:31:31 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24894, maxMem=847754035
16/03/21 17:31:31 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 808.5 MB)
16/03/21 17:31:31 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:33954 (size: 3.3 KB, free: 808.5 MB)
16/03/21 17:31:31 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:31:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:31:31 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:31:31 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:31:31 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:31:31 INFO PythonRunner: Times: total = 103, boot = 102, init = 1, finish = 0
16/03/21 17:31:31 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:31:31 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2272 bytes)
16/03/21 17:31:31 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 118 ms on localhost (1/2)
16/03/21 17:31:31 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:31:31 INFO PythonRunner: Times: total = 163, boot = 162, init = 1, finish = 0
16/03/21 17:31:31 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1311 bytes result sent to driver
16/03/21 17:31:31 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 178 ms on localhost (2/2)
16/03/21 17:31:31 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:31:31 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.282 s
16/03/21 17:31:31 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.318379 s
16/03/21 17:31:31 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:31:31 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:31:31 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:31:31 INFO MemoryStore: MemoryStore cleared
16/03/21 17:31:31 INFO BlockManager: BlockManager stopped
16/03/21 17:31:31 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:31:31 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:31:31 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:31:31 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:31:31 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:31:31 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:31:32 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:31:32 INFO SecurityManager: Changing view acls to: root
16/03/21 17:31:32 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:31:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:31:32 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:31:32 INFO Remoting: Starting remoting
16/03/21 17:31:32 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:51873]
16/03/21 17:31:32 INFO Utils: Successfully started service 'sparkDriver' on port 51873.
16/03/21 17:31:32 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:31:32 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:31:32 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9148ceba-c439-4d10-abb8-b572e20fd60d
16/03/21 17:31:32 INFO MemoryStore: MemoryStore started with capacity 808.5 MB
16/03/21 17:31:32 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-b3b0128c-f569-42af-a63c-b965df844f94
16/03/21 17:31:32 INFO HttpServer: Starting HTTP Server
16/03/21 17:31:32 INFO Utils: Successfully started service 'HTTP file server' on port 60592.
16/03/21 17:31:32 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:31:32 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:31:32 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:31:32 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-02a5b991-eaef-45bd-be6c-236e91125de1/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:31:32 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561692909
16/03/21 17:31:32 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:31:32 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:31:32 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52283.
16/03/21 17:31:32 INFO NettyBlockTransferService: Server created on 52283
16/03/21 17:31:32 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:31:32 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52283 with 808.5 MB RAM, BlockManagerId(driver, localhost, 52283)
16/03/21 17:31:32 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:31:32 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561692924
16/03/21 17:31:33 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:31:33 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:31:33 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:31:33 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:31:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:31:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:31:33 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:31:33 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=847754035
16/03/21 17:31:33 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 808.5 MB)
16/03/21 17:31:33 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=847754035
16/03/21 17:31:33 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 808.5 MB)
16/03/21 17:31:33 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52283 (size: 4.1 KB, free: 808.5 MB)
16/03/21 17:31:33 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:31:33 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:31:33 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:31:33 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:31:33 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:31:33 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:31:33 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561692909
16/03/21 17:31:33 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-02a5b991-eaef-45bd-be6c-236e91125de1/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:31:33 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:31:33 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=847754035
16/03/21 17:31:33 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 808.5 MB)
16/03/21 17:31:33 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:52283 (size: 166.0 B, free: 808.5 MB)
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: area
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: issue
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: planning
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: permission
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: economy
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: composition
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  arrangement  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: agency
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/21 17:31:41 INFO PythonRunner: Times: total = 7940, boot = 457, init = 354, finish = 7129
16/03/21 17:31:41 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:31:41 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:31:41 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:31:41 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:31:41 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=847754035
16/03/21 17:31:41 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 808.5 MB)
16/03/21 17:31:41 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8011 ms on localhost (1/2)
16/03/21 17:31:41 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:52283 (size: 155.0 B, free: 808.5 MB)
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: set
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: bend
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: giant
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: astatine
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: present
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: area
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:31:41 INFO PythonRunner: Times: total = 253, boot = 157, init = 0, finish = 96
16/03/21 17:31:41 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:31:41 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 291 ms on localhost (2/2)
16/03/21 17:31:41 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:31:41 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.284 s
16/03/21 17:31:41 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:31:41 INFO DAGScheduler: running: Set()
16/03/21 17:31:41 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:31:41 INFO DAGScheduler: failed: Set()
16/03/21 17:31:41 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:31:41 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:31:41 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=847754035
16/03/21 17:31:41 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 808.5 MB)
16/03/21 17:31:41 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16030, maxMem=847754035
16/03/21 17:31:41 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 808.5 MB)
16/03/21 17:31:41 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52283 (size: 3.0 KB, free: 808.5 MB)
16/03/21 17:31:41 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:31:41 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:31:41 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:31:41 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:31:41 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:31:41 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:31:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:31:41 INFO PythonRunner: Times: total = 150, boot = 149, init = 1, finish = 0
16/03/21 17:31:41 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:31:41 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:31:41 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:31:41 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:31:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:31:41 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 175 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'composition', 'None']
16/03/21 17:31:41 INFO PythonRunner: Times: total = 155, boot = 154, init = 0, finish = 1
16/03/21 17:31:41 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1245 bytes result sent to driver
16/03/21 17:31:41 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.335 s
16/03/21 17:31:41 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.648460 s
16/03/21 17:31:41 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 171 ms on localhost (2/2)
16/03/21 17:31:41 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:31:41 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:31:41 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:31:41 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:31:41 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:31:41 INFO DAGScheduler: Missing parents: List()
16/03/21 17:31:41 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:31:41 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19078, maxMem=847754035
16/03/21 17:31:41 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 808.5 MB)
16/03/21 17:31:41 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24894, maxMem=847754035
16/03/21 17:31:41 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 808.5 MB)
16/03/21 17:31:41 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:52283 (size: 3.3 KB, free: 808.5 MB)
16/03/21 17:31:41 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:31:41 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:31:41 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:31:41 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:31:41 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:31:41 INFO PythonRunner: Times: total = 138, boot = 137, init = 1, finish = 0
16/03/21 17:31:41 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:31:41 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2275 bytes)
16/03/21 17:31:41 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:31:41 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 155 ms on localhost (1/2)
16/03/21 17:31:42 INFO PythonRunner: Times: total = 172, boot = 172, init = 0, finish = 0
16/03/21 17:31:42 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1314 bytes result sent to driver
16/03/21 17:31:42 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.334 s
16/03/21 17:31:42 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.364681 s
16/03/21 17:31:42 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 189 ms on localhost (2/2)
16/03/21 17:31:42 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:31:42 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:31:42 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:31:42 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:31:42 INFO MemoryStore: MemoryStore cleared
16/03/21 17:31:42 INFO BlockManager: BlockManager stopped
16/03/21 17:31:42 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:31:42 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:31:42 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:31:42 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:31:42 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:31:43 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:31:43 INFO SecurityManager: Changing view acls to: root
16/03/21 17:31:43 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:31:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:31:43 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:31:43 INFO Remoting: Starting remoting
16/03/21 17:31:43 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:32963]
16/03/21 17:31:43 INFO Utils: Successfully started service 'sparkDriver' on port 32963.
16/03/21 17:31:43 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:31:43 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:31:43 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2f74c6cb-8756-49d7-9d3a-2861c299c816
16/03/21 17:31:43 INFO MemoryStore: MemoryStore started with capacity 808.5 MB
16/03/21 17:31:43 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-f2568aac-9ca9-4df5-9363-b2414731f657
16/03/21 17:31:43 INFO HttpServer: Starting HTTP Server
16/03/21 17:31:43 INFO Utils: Successfully started service 'HTTP file server' on port 59260.
16/03/21 17:31:43 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:31:43 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:31:43 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:31:43 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-72ee937d-8d56-4a9e-8582-ce2ae53a3820/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:31:43 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561703383
16/03/21 17:31:43 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:31:43 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:31:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57499.
16/03/21 17:31:43 INFO NettyBlockTransferService: Server created on 57499
16/03/21 17:31:43 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:31:43 INFO BlockManagerMasterEndpoint: Registering block manager localhost:57499 with 808.5 MB RAM, BlockManagerId(driver, localhost, 57499)
16/03/21 17:31:43 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:31:43 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561703395
16/03/21 17:31:43 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:31:43 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:31:43 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:31:43 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:31:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:31:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:31:43 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:31:43 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=847754035
16/03/21 17:31:43 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 808.5 MB)
16/03/21 17:31:43 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=847754035
16/03/21 17:31:43 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 808.5 MB)
16/03/21 17:31:43 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:57499 (size: 4.1 KB, free: 808.5 MB)
16/03/21 17:31:43 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:31:43 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:31:43 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:31:43 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:31:43 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:31:43 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:31:43 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561703383
16/03/21 17:31:43 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-72ee937d-8d56-4a9e-8582-ce2ae53a3820/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:31:43 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:31:43 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=847754035
16/03/21 17:31:43 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 808.5 MB)
16/03/21 17:31:43 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:57499 (size: 166.0 B, free: 808.5 MB)
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: area
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: issue
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: planning
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: permission
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: economy
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: composition
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  parts  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: agency
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/21 17:31:51 INFO PythonRunner: Times: total = 7808, boot = 454, init = 353, finish = 7001
16/03/21 17:31:51 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:31:51 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:31:51 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:31:51 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:31:51 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=847754035
16/03/21 17:31:51 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 808.5 MB)
16/03/21 17:31:51 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7877 ms on localhost (1/2)
16/03/21 17:31:51 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:57499 (size: 155.0 B, free: 808.5 MB)
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: set
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: bend
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: giant
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: astatine
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: present
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: area
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:31:51 INFO PythonRunner: Times: total = 284, boot = 189, init = 0, finish = 95
16/03/21 17:31:51 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:31:51 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.182 s
16/03/21 17:31:51 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:31:51 INFO DAGScheduler: running: Set()
16/03/21 17:31:51 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:31:51 INFO DAGScheduler: failed: Set()
16/03/21 17:31:51 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:31:51 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:31:51 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=847754035
16/03/21 17:31:51 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 808.5 MB)
16/03/21 17:31:51 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 313 ms on localhost (2/2)
16/03/21 17:31:51 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:31:51 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16030, maxMem=847754035
16/03/21 17:31:51 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 808.5 MB)
16/03/21 17:31:51 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:57499 (size: 3.0 KB, free: 808.5 MB)
16/03/21 17:31:51 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:31:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:31:51 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:31:51 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:31:51 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:31:51 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:31:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:31:51 INFO PythonRunner: Times: total = 143, boot = 142, init = 1, finish = 0
16/03/21 17:31:51 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:31:51 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:31:51 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:31:51 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:31:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:31:51 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 165 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'composition', 'None']
16/03/21 17:31:52 INFO PythonRunner: Times: total = 163, boot = 163, init = 0, finish = 0
16/03/21 17:31:52 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1245 bytes result sent to driver
16/03/21 17:31:52 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.334 s
16/03/21 17:31:52 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.539633 s
16/03/21 17:31:52 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 179 ms on localhost (2/2)
16/03/21 17:31:52 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:31:52 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:57499 in memory (size: 3.0 KB, free: 808.5 MB)
16/03/21 17:31:52 INFO ContextCleaner: Cleaned accumulator 323
16/03/21 17:31:52 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:57499 in memory (size: 4.1 KB, free: 808.5 MB)
16/03/21 17:31:52 INFO ContextCleaner: Cleaned accumulator 322
16/03/21 17:31:52 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:31:52 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:31:52 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:31:52 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:31:52 INFO DAGScheduler: Missing parents: List()
16/03/21 17:31:52 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:31:52 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=321, maxMem=847754035
16/03/21 17:31:52 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 808.5 MB)
16/03/21 17:31:52 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=6137, maxMem=847754035
16/03/21 17:31:52 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 808.5 MB)
16/03/21 17:31:52 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:57499 (size: 3.3 KB, free: 808.5 MB)
16/03/21 17:31:52 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:31:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:31:52 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:31:52 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:31:52 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:31:52 INFO PythonRunner: Times: total = 5, boot = -125, init = 130, finish = 0
16/03/21 17:31:52 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:31:52 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2275 bytes)
16/03/21 17:31:52 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:31:52 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 26 ms on localhost (1/2)
16/03/21 17:31:52 INFO PythonRunner: Times: total = 163, boot = 162, init = 0, finish = 1
16/03/21 17:31:52 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1314 bytes result sent to driver
16/03/21 17:31:52 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.200 s
16/03/21 17:31:52 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.209394 s
16/03/21 17:31:52 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 181 ms on localhost (2/2)
16/03/21 17:31:52 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:31:52 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:31:52 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:31:52 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:31:52 INFO MemoryStore: MemoryStore cleared
16/03/21 17:31:52 INFO BlockManager: BlockManager stopped
16/03/21 17:31:52 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:31:52 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:31:52 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:31:52 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:31:52 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:31:52 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:31:53 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:31:53 INFO SecurityManager: Changing view acls to: root
16/03/21 17:31:53 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:31:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:31:53 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:31:53 INFO Remoting: Starting remoting
16/03/21 17:31:53 INFO Utils: Successfully started service 'sparkDriver' on port 54966.
16/03/21 17:31:53 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:54966]
16/03/21 17:31:53 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:31:53 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:31:53 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-05a924f4-b8b5-4854-a5f6-6071d9c0c62d
16/03/21 17:31:53 INFO MemoryStore: MemoryStore started with capacity 802.8 MB
16/03/21 17:31:53 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-63a28d39-dcb2-4acb-8520-1ad9125cef64
16/03/21 17:31:53 INFO HttpServer: Starting HTTP Server
16/03/21 17:31:53 INFO Utils: Successfully started service 'HTTP file server' on port 50237.
16/03/21 17:31:53 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:31:53 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:31:53 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:31:53 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-7b4b154b-7ef1-41ab-8eaa-857d0a6bbaaf/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:31:53 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561713907
16/03/21 17:31:53 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:31:53 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:31:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 47457.
16/03/21 17:31:53 INFO NettyBlockTransferService: Server created on 47457
16/03/21 17:31:53 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:31:53 INFO BlockManagerMasterEndpoint: Registering block manager localhost:47457 with 802.8 MB RAM, BlockManagerId(driver, localhost, 47457)
16/03/21 17:31:53 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:31:53 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561713923
16/03/21 17:31:54 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:31:54 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:31:54 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:31:54 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:31:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:31:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:31:54 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:31:54 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=841808609
16/03/21 17:31:54 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 802.8 MB)
16/03/21 17:31:54 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=841808609
16/03/21 17:31:54 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 802.8 MB)
16/03/21 17:31:54 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:47457 (size: 4.1 KB, free: 802.8 MB)
16/03/21 17:31:54 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:31:54 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:31:54 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:31:54 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:31:54 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:31:54 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:31:54 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561713907
16/03/21 17:31:54 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-7b4b154b-7ef1-41ab-8eaa-857d0a6bbaaf/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:31:54 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:31:54 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=841808609
16/03/21 17:31:54 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 802.8 MB)
16/03/21 17:31:54 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:47457 (size: 166.0 B, free: 802.8 MB)
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: area
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: issue
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: planning
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: permission
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: economy
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: composition
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: agency
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:32:01 INFO PythonRunner: Times: total = 7772, boot = 470, init = 362, finish = 6940
16/03/21 17:32:01 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:32:01 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:32:01 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:32:01 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:32:01 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=841808609
16/03/21 17:32:01 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 802.8 MB)
16/03/21 17:32:01 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:47457 (size: 155.0 B, free: 802.8 MB)
16/03/21 17:32:01 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7838 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: set
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: bend
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: giant
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: astatine
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: present
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  speech  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: area
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/21 17:32:02 INFO PythonRunner: Times: total = 267, boot = 165, init = 0, finish = 102
16/03/21 17:32:02 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:32:02 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.127 s
16/03/21 17:32:02 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:32:02 INFO DAGScheduler: running: Set()
16/03/21 17:32:02 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:32:02 INFO DAGScheduler: failed: Set()
16/03/21 17:32:02 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:32:02 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:32:02 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=841808609
16/03/21 17:32:02 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 297 ms on localhost (2/2)
16/03/21 17:32:02 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 802.8 MB)
16/03/21 17:32:02 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:32:02 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16030, maxMem=841808609
16/03/21 17:32:02 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 802.8 MB)
16/03/21 17:32:02 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:47457 (size: 3.0 KB, free: 802.8 MB)
16/03/21 17:32:02 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:32:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:32:02 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:32:02 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:32:02 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:32:02 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:32:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:32:02 INFO PythonRunner: Times: total = 172, boot = 171, init = 1, finish = 0
16/03/21 17:32:02 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:32:02 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:32:02 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:32:02 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:32:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:32:02 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 195 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'present']
16/03/21 17:32:02 INFO PythonRunner: Times: total = 164, boot = 163, init = 0, finish = 1
16/03/21 17:32:02 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/21 17:32:02 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.355 s
16/03/21 17:32:02 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.512826 s
16/03/21 17:32:02 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 179 ms on localhost (2/2)
16/03/21 17:32:02 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:32:02 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:32:02 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:32:02 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:32:02 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:32:02 INFO DAGScheduler: Missing parents: List()
16/03/21 17:32:02 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:32:02 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19078, maxMem=841808609
16/03/21 17:32:02 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 802.8 MB)
16/03/21 17:32:02 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24894, maxMem=841808609
16/03/21 17:32:02 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 802.8 MB)
16/03/21 17:32:02 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:47457 (size: 3.3 KB, free: 802.8 MB)
16/03/21 17:32:02 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:32:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:32:02 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:32:02 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:32:02 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:32:02 INFO PythonRunner: Times: total = 105, boot = 105, init = 0, finish = 0
16/03/21 17:32:02 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:32:02 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/21 17:32:02 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 121 ms on localhost (1/2)
16/03/21 17:32:02 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:32:02 INFO PythonRunner: Times: total = 150, boot = 149, init = 1, finish = 0
16/03/21 17:32:02 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1310 bytes result sent to driver
16/03/21 17:32:02 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 171 ms on localhost (2/2)
16/03/21 17:32:02 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:32:02 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.275 s
16/03/21 17:32:02 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.299093 s
16/03/21 17:32:03 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:32:03 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:32:03 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:32:03 INFO MemoryStore: MemoryStore cleared
16/03/21 17:32:03 INFO BlockManager: BlockManager stopped
16/03/21 17:32:03 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:32:03 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:32:03 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:32:03 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:32:03 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:32:03 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:32:03 INFO SecurityManager: Changing view acls to: root
16/03/21 17:32:03 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:32:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:32:04 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:32:04 INFO Remoting: Starting remoting
16/03/21 17:32:04 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:56176]
16/03/21 17:32:04 INFO Utils: Successfully started service 'sparkDriver' on port 56176.
16/03/21 17:32:04 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:32:04 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:32:04 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e1ac8469-b38e-49da-89c0-ee9eba9c91e8
16/03/21 17:32:04 INFO MemoryStore: MemoryStore started with capacity 802.8 MB
16/03/21 17:32:04 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-3ac05970-3d06-497d-b9b3-f508ec59be57
16/03/21 17:32:04 INFO HttpServer: Starting HTTP Server
16/03/21 17:32:04 INFO Utils: Successfully started service 'HTTP file server' on port 44682.
16/03/21 17:32:04 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:32:04 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:32:04 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:32:04 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-5acd1ca8-b271-46b2-b91d-4043f47a3f59/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:32:04 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561724239
16/03/21 17:32:04 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:32:04 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:32:04 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46799.
16/03/21 17:32:04 INFO NettyBlockTransferService: Server created on 46799
16/03/21 17:32:04 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:32:04 INFO BlockManagerMasterEndpoint: Registering block manager localhost:46799 with 802.8 MB RAM, BlockManagerId(driver, localhost, 46799)
16/03/21 17:32:04 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:32:04 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561724259
16/03/21 17:32:04 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:32:04 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:32:04 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:32:04 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:32:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:32:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:32:04 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:32:04 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=841808609
16/03/21 17:32:04 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 802.8 MB)
16/03/21 17:32:04 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=841808609
16/03/21 17:32:04 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 802.8 MB)
16/03/21 17:32:04 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:46799 (size: 4.1 KB, free: 802.8 MB)
16/03/21 17:32:04 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:32:04 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:32:04 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:32:04 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:32:04 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:32:04 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:32:04 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561724239
16/03/21 17:32:04 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-5acd1ca8-b271-46b2-b91d-4043f47a3f59/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:32:04 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:32:04 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=841808609
16/03/21 17:32:04 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 802.8 MB)
16/03/21 17:32:04 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:46799 (size: 166.0 B, free: 802.8 MB)
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: area
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  geographical  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: issue
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: planning
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: permission
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: economy
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: composition
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: agency
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/21 17:32:12 INFO PythonRunner: Times: total = 7811, boot = 463, init = 359, finish = 6989
16/03/21 17:32:12 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:32:12 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:32:12 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:32:12 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:32:12 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=841808609
16/03/21 17:32:12 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 802.8 MB)
16/03/21 17:32:12 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7897 ms on localhost (1/2)
16/03/21 17:32:12 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:46799 (size: 155.0 B, free: 802.8 MB)
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: set
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: bend
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: giant
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: astatine
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: present
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: area
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  geographical  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/21 17:32:12 INFO PythonRunner: Times: total = 252, boot = 158, init = 1, finish = 93
16/03/21 17:32:12 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:32:12 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 291 ms on localhost (2/2)
16/03/21 17:32:12 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:32:12 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.168 s
16/03/21 17:32:12 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:32:12 INFO DAGScheduler: running: Set()
16/03/21 17:32:12 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:32:12 INFO DAGScheduler: failed: Set()
16/03/21 17:32:12 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:32:12 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:32:12 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=841808609
16/03/21 17:32:12 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 802.8 MB)
16/03/21 17:32:12 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16030, maxMem=841808609
16/03/21 17:32:12 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 802.8 MB)
16/03/21 17:32:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:46799 (size: 3.0 KB, free: 802.8 MB)
16/03/21 17:32:12 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:32:12 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:32:12 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:32:12 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:32:12 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:32:12 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:32:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:32:12 INFO PythonRunner: Times: total = 143, boot = 142, init = 0, finish = 1
16/03/21 17:32:12 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:32:12 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:32:12 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:32:12 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:32:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:32:12 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 169 ms on localhost (1/2)
reduceFunction_Parents(): returns=16/03/21 17:32:12 INFO PythonRunner: Times: total = 174, boot = 173, init = 0, finish = 1
 [u'area', 'None', u'area']
16/03/21 17:32:12 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/21 17:32:12 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.338 s
16/03/21 17:32:12 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.564412 s
16/03/21 17:32:12 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 187 ms on localhost (2/2)
16/03/21 17:32:12 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:32:13 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:32:13 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:32:13 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:32:13 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:32:13 INFO DAGScheduler: Missing parents: List()
16/03/21 17:32:13 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:32:13 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19078, maxMem=841808609
16/03/21 17:32:13 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 802.8 MB)
16/03/21 17:32:13 INFO MemoryStore: ensureFreeSpace(3372) called with curMem=24894, maxMem=841808609
16/03/21 17:32:13 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 802.8 MB)
16/03/21 17:32:13 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:46799 (size: 3.3 KB, free: 802.8 MB)
16/03/21 17:32:13 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:32:13 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:32:13 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:32:13 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:32:13 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:32:13 INFO PythonRunner: Times: total = 104, boot = 104, init = 0, finish = 0
16/03/21 17:32:13 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:32:13 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/21 17:32:13 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 122 ms on localhost (1/2)
16/03/21 17:32:13 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:32:13 INFO PythonRunner: Times: total = 156, boot = 155, init = 1, finish = 0
16/03/21 17:32:13 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1307 bytes result sent to driver
16/03/21 17:32:13 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 179 ms on localhost (2/2)
16/03/21 17:32:13 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:32:13 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.297 s
16/03/21 17:32:13 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.317054 s
16/03/21 17:32:13 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:32:13 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:32:13 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:32:13 INFO MemoryStore: MemoryStore cleared
16/03/21 17:32:13 INFO BlockManager: BlockManager stopped
16/03/21 17:32:13 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:32:13 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:32:13 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:32:13 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:32:13 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:32:13 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:32:14 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:32:14 INFO SecurityManager: Changing view acls to: root
16/03/21 17:32:14 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:32:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:32:14 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:32:14 INFO Remoting: Starting remoting
16/03/21 17:32:14 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:35829]
16/03/21 17:32:14 INFO Utils: Successfully started service 'sparkDriver' on port 35829.
16/03/21 17:32:14 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:32:14 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:32:14 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-4f143cad-d52e-4e27-8ca1-d93fd76ffc98
16/03/21 17:32:14 INFO MemoryStore: MemoryStore started with capacity 802.8 MB
16/03/21 17:32:14 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-2866a185-24e7-42b9-b5a0-5216f10ddea2
16/03/21 17:32:14 INFO HttpServer: Starting HTTP Server
16/03/21 17:32:14 INFO Utils: Successfully started service 'HTTP file server' on port 57120.
16/03/21 17:32:14 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:32:14 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:32:14 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:32:14 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-be581479-1298-496f-8c17-a29b730d85dc/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:32:14 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561734620
16/03/21 17:32:14 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:32:14 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:32:14 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39605.
16/03/21 17:32:14 INFO NettyBlockTransferService: Server created on 39605
16/03/21 17:32:14 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:32:14 INFO BlockManagerMasterEndpoint: Registering block manager localhost:39605 with 802.8 MB RAM, BlockManagerId(driver, localhost, 39605)
16/03/21 17:32:14 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:32:14 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561734636
16/03/21 17:32:14 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:32:14 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:32:14 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:32:14 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:32:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:32:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:32:14 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:32:14 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=841808609
16/03/21 17:32:14 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 802.8 MB)
16/03/21 17:32:14 INFO MemoryStore: ensureFreeSpace(4150) called with curMem=6576, maxMem=841808609
16/03/21 17:32:14 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 802.8 MB)
16/03/21 17:32:14 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:39605 (size: 4.1 KB, free: 802.8 MB)
16/03/21 17:32:14 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:32:14 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:32:14 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:32:14 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:32:14 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:32:14 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:32:14 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561734620
16/03/21 17:32:14 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-be581479-1298-496f-8c17-a29b730d85dc/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:32:14 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:32:14 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10726, maxMem=841808609
16/03/21 17:32:14 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 802.8 MB)
16/03/21 17:32:14 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:39605 (size: 166.0 B, free: 802.8 MB)
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: area
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: issue
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: planning
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: permission
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: economy
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: composition
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  spatial  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: agency
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/21 17:32:24 INFO PythonRunner: Times: total = 9686, boot = 468, init = 361, finish = 8857
16/03/21 17:32:24 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:32:24 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:32:24 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:32:24 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:32:24 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9763 ms on localhost (1/2)
16/03/21 17:32:24 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10892, maxMem=841808609
16/03/21 17:32:24 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 802.8 MB)
16/03/21 17:32:24 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:39605 (size: 155.0 B, free: 802.8 MB)
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: set
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: bend
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: giant
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: astatine
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: present
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: area
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:32:24 INFO PythonRunner: Times: total = 374, boot = 199, init = 0, finish = 175
16/03/21 17:32:24 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:32:24 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 412 ms on localhost (2/2)
16/03/21 17:32:24 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:32:24 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 10.169 s
16/03/21 17:32:24 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:32:24 INFO DAGScheduler: running: Set()
16/03/21 17:32:24 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:32:24 INFO DAGScheduler: failed: Set()
16/03/21 17:32:24 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:32:24 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:32:24 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11047, maxMem=841808609
16/03/21 17:32:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 802.8 MB)
16/03/21 17:32:24 INFO MemoryStore: ensureFreeSpace(3049) called with curMem=16031, maxMem=841808609
16/03/21 17:32:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 802.8 MB)
16/03/21 17:32:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:39605 (size: 3.0 KB, free: 802.8 MB)
16/03/21 17:32:24 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:32:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:32:24 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:32:24 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:32:24 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:32:24 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:32:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:32:25 INFO PythonRunner: Times: total = 350, boot = 349, init = 1, finish = 0
16/03/21 17:32:25 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:32:25 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:32:25 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:32:25 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:32:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:32:25 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 383 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'composition', 'None']
16/03/21 17:32:25 INFO PythonRunner: Times: total = 369, boot = 368, init = 0, finish = 1
16/03/21 17:32:25 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1245 bytes result sent to driver
16/03/21 17:32:25 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.757 s
16/03/21 17:32:25 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 10.957492 s
16/03/21 17:32:25 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 386 ms on localhost (2/2)
16/03/21 17:32:25 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:32:25 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:32:25 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:32:25 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:32:25 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:32:25 INFO DAGScheduler: Missing parents: List()
16/03/21 17:32:25 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:32:25 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19080, maxMem=841808609
16/03/21 17:32:25 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 802.8 MB)
16/03/21 17:32:25 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24896, maxMem=841808609
16/03/21 17:32:25 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 802.8 MB)
16/03/21 17:32:25 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:39605 (size: 3.3 KB, free: 802.8 MB)
16/03/21 17:32:25 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:32:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:32:25 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:32:25 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:32:25 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:32:26 INFO PythonRunner: Times: total = 136, boot = 135, init = 1, finish = 0
16/03/21 17:32:26 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:32:26 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2275 bytes)
16/03/21 17:32:26 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 152 ms on localhost (1/2)
16/03/21 17:32:26 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:32:26 INFO PythonRunner: Times: total = 346, boot = 346, init = 0, finish = 0
16/03/21 17:32:26 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1314 bytes result sent to driver
16/03/21 17:32:26 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 362 ms on localhost (2/2)
16/03/21 17:32:26 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:32:26 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.499 s
16/03/21 17:32:26 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.532890 s
16/03/21 17:32:26 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:32:26 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:32:26 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:32:26 INFO MemoryStore: MemoryStore cleared
16/03/21 17:32:26 INFO BlockManager: BlockManager stopped
16/03/21 17:32:26 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:32:26 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:32:26 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:32:26 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:32:26 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:32:26 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:32:27 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:32:27 INFO SecurityManager: Changing view acls to: root
16/03/21 17:32:27 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:32:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:32:27 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:32:27 INFO Remoting: Starting remoting
16/03/21 17:32:27 INFO Utils: Successfully started service 'sparkDriver' on port 44511.
16/03/21 17:32:27 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:44511]
16/03/21 17:32:27 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:32:27 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:32:27 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8f0d5ffc-d291-483d-8cc5-e4d01ed36ac1
16/03/21 17:32:27 INFO MemoryStore: MemoryStore started with capacity 802.8 MB
16/03/21 17:32:27 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-f7a9c592-12d0-4553-ac62-753c95805759
16/03/21 17:32:27 INFO HttpServer: Starting HTTP Server
16/03/21 17:32:27 INFO Utils: Successfully started service 'HTTP file server' on port 39911.
16/03/21 17:32:27 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:32:27 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:32:27 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:32:28 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-29366ab1-14d7-4774-b493-f2f42c187644/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:32:28 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561748060
16/03/21 17:32:28 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:32:28 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:32:28 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38666.
16/03/21 17:32:28 INFO NettyBlockTransferService: Server created on 38666
16/03/21 17:32:28 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:32:28 INFO BlockManagerMasterEndpoint: Registering block manager localhost:38666 with 802.8 MB RAM, BlockManagerId(driver, localhost, 38666)
16/03/21 17:32:28 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:32:28 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561748109
16/03/21 17:32:28 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:32:28 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:32:28 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:32:28 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:32:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:32:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:32:28 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:32:28 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=841808609
16/03/21 17:32:28 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 802.8 MB)
16/03/21 17:32:28 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=841808609
16/03/21 17:32:28 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 802.8 MB)
16/03/21 17:32:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:38666 (size: 4.1 KB, free: 802.8 MB)
16/03/21 17:32:28 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:32:28 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:32:28 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:32:28 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:32:28 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:32:28 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:32:28 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561748060
16/03/21 17:32:28 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-29366ab1-14d7-4774-b493-f2f42c187644/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:32:28 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:32:28 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=841808609
16/03/21 17:32:28 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 802.8 MB)
16/03/21 17:32:28 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:38666 (size: 166.0 B, free: 802.8 MB)
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: area
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: issue
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: planning
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: permission
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: economy
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: composition
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: agency
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Nadu  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/21 17:32:37 INFO PythonRunner: Times: total = 9310, boot = 598, init = 399, finish = 8313
16/03/21 17:32:37 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:32:37 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:32:37 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:32:37 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9397 ms on localhost (1/2)
16/03/21 17:32:37 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:32:37 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=841808609
16/03/21 17:32:37 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 802.8 MB)
16/03/21 17:32:37 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:38666 (size: 155.0 B, free: 802.8 MB)
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: set
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: bend
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: giant
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: astatine
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: present
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Nadu  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: area
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/21 17:32:38 INFO PythonRunner: Times: total = 318, boot = 211, init = 0, finish = 107
16/03/21 17:32:38 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:32:38 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 362 ms on localhost (2/2)
16/03/21 17:32:38 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:32:38 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.744 s
16/03/21 17:32:38 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:32:38 INFO DAGScheduler: running: Set()
16/03/21 17:32:38 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:32:38 INFO DAGScheduler: failed: Set()
16/03/21 17:32:38 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:32:38 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:32:38 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=841808609
16/03/21 17:32:38 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 802.8 MB)
16/03/21 17:32:38 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16030, maxMem=841808609
16/03/21 17:32:38 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 802.8 MB)
16/03/21 17:32:38 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:38666 (size: 3.0 KB, free: 802.8 MB)
16/03/21 17:32:38 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:32:38 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:32:38 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:32:38 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:32:38 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:32:38 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:32:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:32:38 INFO PythonRunner: Times: total = 144, boot = 143, init = 1, finish = 0
16/03/21 17:32:38 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:32:38 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:32:38 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:32:38 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:32:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:32:38 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 170 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'Chennai', 'None', u'Chennai']
16/03/21 17:32:38 INFO PythonRunner: Times: total = 229, boot = 228, init = 1, finish = 0
16/03/21 17:32:38 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1255 bytes result sent to driver
16/03/21 17:32:38 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 258 ms on localhost (2/2)
16/03/21 17:32:38 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:32:38 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.419 s
16/03/21 17:32:38 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 10.205411 s
16/03/21 17:32:38 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:32:38 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:32:38 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:32:38 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:32:38 INFO DAGScheduler: Missing parents: List()
16/03/21 17:32:38 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:32:38 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19078, maxMem=841808609
16/03/21 17:32:38 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 802.8 MB)
16/03/21 17:32:38 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24894, maxMem=841808609
16/03/21 17:32:38 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 802.8 MB)
16/03/21 17:32:38 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:38666 (size: 3.3 KB, free: 802.8 MB)
16/03/21 17:32:38 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:32:38 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:32:38 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:32:38 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:32:38 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:32:38 INFO PythonRunner: Times: total = 168, boot = 168, init = 0, finish = 0
16/03/21 17:32:38 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:32:38 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2285 bytes)
16/03/21 17:32:38 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:32:38 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 186 ms on localhost (1/2)
16/03/21 17:32:39 INFO PythonRunner: Times: total = 243, boot = 242, init = 1, finish = 0
16/03/21 17:32:39 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1324 bytes result sent to driver
16/03/21 17:32:39 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 260 ms on localhost (2/2)
16/03/21 17:32:39 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:32:39 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.431 s
16/03/21 17:32:39 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.457379 s
16/03/21 17:32:39 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:32:39 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:32:39 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:32:39 INFO MemoryStore: MemoryStore cleared
16/03/21 17:32:39 INFO BlockManager: BlockManager stopped
16/03/21 17:32:39 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:32:39 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:32:39 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:32:39 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:32:39 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:32:39 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:32:40 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:32:40 INFO SecurityManager: Changing view acls to: root
16/03/21 17:32:40 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:32:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:32:40 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:32:40 INFO Remoting: Starting remoting
16/03/21 17:32:40 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:44539]
16/03/21 17:32:40 INFO Utils: Successfully started service 'sparkDriver' on port 44539.
16/03/21 17:32:40 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:32:40 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:32:40 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-eb4b7d9e-8b6c-4ccf-b902-e55cc89f11ba
16/03/21 17:32:40 INFO MemoryStore: MemoryStore started with capacity 802.8 MB
16/03/21 17:32:40 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-2d8fa440-10fd-4346-8779-8b719e7676e9
16/03/21 17:32:40 INFO HttpServer: Starting HTTP Server
16/03/21 17:32:40 INFO Utils: Successfully started service 'HTTP file server' on port 48591.
16/03/21 17:32:40 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:32:40 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:32:40 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:32:40 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-1ed66eba-24d7-4a39-bdd9-f9d899c01436/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:32:40 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561760484
16/03/21 17:32:40 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:32:40 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:32:40 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53345.
16/03/21 17:32:40 INFO NettyBlockTransferService: Server created on 53345
16/03/21 17:32:40 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:32:40 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53345 with 802.8 MB RAM, BlockManagerId(driver, localhost, 53345)
16/03/21 17:32:40 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:32:40 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561760502
16/03/21 17:32:40 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:32:40 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:32:40 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:32:40 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:32:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:32:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:32:40 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:32:40 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=841808609
16/03/21 17:32:40 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 802.8 MB)
16/03/21 17:32:40 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=841808609
16/03/21 17:32:40 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 802.8 MB)
16/03/21 17:32:40 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53345 (size: 4.1 KB, free: 802.8 MB)
16/03/21 17:32:40 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:32:40 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:32:40 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:32:40 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:32:40 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:32:40 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:32:40 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561760484
16/03/21 17:32:40 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-1ed66eba-24d7-4a39-bdd9-f9d899c01436/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:32:40 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:32:40 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=841808609
16/03/21 17:32:40 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 802.8 MB)
16/03/21 17:32:40 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:53345 (size: 166.0 B, free: 802.8 MB)
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: area
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: issue
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: planning
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: permission
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: economy
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: composition
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: agency
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:32:48 INFO PythonRunner: Times: total = 8225, boot = 538, init = 363, finish = 7324
16/03/21 17:32:48 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:32:48 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:32:48 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:32:49 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:32:49 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8325 ms on localhost (1/2)
16/03/21 17:32:49 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=841808609
16/03/21 17:32:49 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 802.8 MB)
16/03/21 17:32:49 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:53345 (size: 155.0 B, free: 802.8 MB)
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: set
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: bend
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): adding to parents: syn =  Synset('bend.n.01') ; keyword:  circular  in syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= [u'bend']
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: giant
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: astatine
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: present
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: area
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
16/03/21 17:32:49 INFO PythonRunner: Times: total = 278, boot = 181, init = 1, finish = 96
16/03/21 17:32:49 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:32:49 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.633 s
16/03/21 17:32:49 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:32:49 INFO DAGScheduler: running: Set()
16/03/21 17:32:49 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:32:49 INFO DAGScheduler: failed: Set()
16/03/21 17:32:49 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:32:49 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:32:49 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 322 ms on localhost (2/2)
16/03/21 17:32:49 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:32:49 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=841808609
16/03/21 17:32:49 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 802.8 MB)
16/03/21 17:32:49 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16030, maxMem=841808609
16/03/21 17:32:49 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 802.8 MB)
16/03/21 17:32:49 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53345 (size: 3.0 KB, free: 802.8 MB)
16/03/21 17:32:49 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:32:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:32:49 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:32:49 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:32:49 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:32:49 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:32:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:32:49 INFO PythonRunner: Times: total = 148, boot = 148, init = 0, finish = 0
16/03/21 17:32:49 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:32:49 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:32:49 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:32:49 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:32:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:32:49 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 209 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'bend']
16/03/21 17:32:49 INFO PythonRunner: Times: total = 130, boot = 129, init = 1, finish = 0
16/03/21 17:32:49 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1230 bytes result sent to driver
16/03/21 17:32:49 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.336 s
16/03/21 17:32:49 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.021919 s
16/03/21 17:32:49 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 149 ms on localhost (2/2)
16/03/21 17:32:49 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:32:49 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:32:49 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:32:49 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:32:49 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:32:49 INFO DAGScheduler: Missing parents: List()
16/03/21 17:32:49 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:32:49 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19078, maxMem=841808609
16/03/21 17:32:49 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 802.8 MB)
16/03/21 17:32:49 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24894, maxMem=841808609
16/03/21 17:32:49 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 802.8 MB)
16/03/21 17:32:49 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53345 (size: 3.3 KB, free: 802.8 MB)
16/03/21 17:32:49 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:32:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:32:49 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:32:49 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:32:49 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:32:49 INFO PythonRunner: Times: total = 130, boot = 130, init = 0, finish = 0
16/03/21 17:32:49 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:32:49 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2260 bytes)
16/03/21 17:32:49 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:32:49 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 145 ms on localhost (1/2)
16/03/21 17:32:50 INFO PythonRunner: Times: total = 164, boot = 164, init = 0, finish = 0
16/03/21 17:32:50 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1296 bytes result sent to driver
16/03/21 17:32:50 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 177 ms on localhost (2/2)
16/03/21 17:32:50 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:32:50 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.306 s
16/03/21 17:32:50 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.332015 s
16/03/21 17:32:50 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:32:50 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:32:50 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:32:50 INFO MemoryStore: MemoryStore cleared
16/03/21 17:32:50 INFO BlockManager: BlockManager stopped
16/03/21 17:32:50 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:32:50 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:32:50 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:32:50 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:32:50 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:32:50 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:32:51 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:32:51 INFO SecurityManager: Changing view acls to: root
16/03/21 17:32:51 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:32:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:32:51 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:32:51 INFO Remoting: Starting remoting
16/03/21 17:32:51 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:51442]
16/03/21 17:32:51 INFO Utils: Successfully started service 'sparkDriver' on port 51442.
16/03/21 17:32:51 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:32:51 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:32:51 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-45c9bb82-3686-456e-afb1-7c615b30a51c
16/03/21 17:32:51 INFO MemoryStore: MemoryStore started with capacity 802.8 MB
16/03/21 17:32:51 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-f9ea7def-57f6-4688-bbed-949a850dd8de
16/03/21 17:32:51 INFO HttpServer: Starting HTTP Server
16/03/21 17:32:51 INFO Utils: Successfully started service 'HTTP file server' on port 41410.
16/03/21 17:32:51 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:32:51 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:32:51 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:32:51 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-775969ee-9589-406b-9630-726e20d90d32/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:32:51 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561771554
16/03/21 17:32:51 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:32:51 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:32:52 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37232.
16/03/21 17:32:52 INFO NettyBlockTransferService: Server created on 37232
16/03/21 17:32:52 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:32:52 INFO BlockManagerMasterEndpoint: Registering block manager localhost:37232 with 802.8 MB RAM, BlockManagerId(driver, localhost, 37232)
16/03/21 17:32:52 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:32:52 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561771968
16/03/21 17:32:52 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:32:52 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:32:52 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:32:52 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:32:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:32:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:32:52 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:32:52 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=841808609
16/03/21 17:32:52 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 802.8 MB)
16/03/21 17:32:52 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=841808609
16/03/21 17:32:52 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 802.8 MB)
16/03/21 17:32:52 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:37232 (size: 4.1 KB, free: 802.8 MB)
16/03/21 17:32:52 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:32:52 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:32:52 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:32:52 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:32:52 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:32:52 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:32:52 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561771554
16/03/21 17:32:52 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-775969ee-9589-406b-9630-726e20d90d32/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:32:52 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:32:52 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=841808609
16/03/21 17:32:52 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 802.8 MB)
16/03/21 17:32:52 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:37232 (size: 166.0 B, free: 802.8 MB)
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: area
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: issue
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: planning
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: permission
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: economy
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: composition
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: agency
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:33:00 INFO PythonRunner: Times: total = 8697, boot = 494, init = 366, finish = 7837
16/03/21 17:33:00 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:33:00 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:33:00 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:33:00 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:33:00 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=841808609
16/03/21 17:33:00 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 802.8 MB)
16/03/21 17:33:00 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:37232 (size: 155.0 B, free: 802.8 MB)
16/03/21 17:33:00 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8806 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: set
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: bend
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: giant
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: astatine
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  product  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: present
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: area
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/21 17:33:01 INFO PythonRunner: Times: total = 273, boot = 164, init = 1, finish = 108
16/03/21 17:33:01 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:33:01 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.100 s
16/03/21 17:33:01 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:33:01 INFO DAGScheduler: running: Set()
16/03/21 17:33:01 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:33:01 INFO DAGScheduler: failed: Set()
16/03/21 17:33:01 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:33:01 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:33:01 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=841808609
16/03/21 17:33:01 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 802.8 MB)
16/03/21 17:33:01 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16030, maxMem=841808609
16/03/21 17:33:01 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 802.8 MB)
16/03/21 17:33:01 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 303 ms on localhost (2/2)
16/03/21 17:33:01 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:33:01 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:37232 (size: 3.0 KB, free: 802.8 MB)
16/03/21 17:33:01 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:33:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:01 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:33:01 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:33:01 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:33:01 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:33:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:33:01 INFO PythonRunner: Times: total = 141, boot = 141, init = 0, finish = 0
16/03/21 17:33:01 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:33:01 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:33:01 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:33:01 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:33:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:33:01 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 167 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/03/21 17:33:01 INFO PythonRunner: Times: total = 153, boot = 152, init = 0, finish = 1
16/03/21 17:33:01 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1242 bytes result sent to driver
16/03/21 17:33:01 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.326 s
16/03/21 17:33:01 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.463289 s
16/03/21 17:33:01 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 177 ms on localhost (2/2)
16/03/21 17:33:01 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:33:01 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:33:01 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:33:01 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:01 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:33:01 INFO DAGScheduler: Missing parents: List()
16/03/21 17:33:01 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:33:01 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19078, maxMem=841808609
16/03/21 17:33:01 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 802.8 MB)
16/03/21 17:33:01 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24894, maxMem=841808609
16/03/21 17:33:01 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 802.8 MB)
16/03/21 17:33:01 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:37232 (size: 3.3 KB, free: 802.8 MB)
16/03/21 17:33:01 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:33:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:01 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:33:01 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:33:01 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:33:01 INFO PythonRunner: Times: total = 62, boot = 62, init = 0, finish = 0
16/03/21 17:33:01 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:33:01 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2272 bytes)
16/03/21 17:33:01 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 81 ms on localhost (1/2)
16/03/21 17:33:01 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:33:02 INFO PythonRunner: Times: total = 185, boot = 185, init = 0, finish = 0
16/03/21 17:33:02 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1311 bytes result sent to driver
16/03/21 17:33:02 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 230 ms on localhost (2/2)
16/03/21 17:33:02 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:33:02 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.306 s
16/03/21 17:33:02 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.332800 s
16/03/21 17:33:02 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:33:02 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:33:02 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:33:02 INFO MemoryStore: MemoryStore cleared
16/03/21 17:33:02 INFO BlockManager: BlockManager stopped
16/03/21 17:33:02 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:33:02 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:33:02 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:33:02 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:33:02 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:33:02 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:33:03 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:33:03 INFO SecurityManager: Changing view acls to: root
16/03/21 17:33:03 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:33:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:33:03 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:33:03 INFO Remoting: Starting remoting
16/03/21 17:33:03 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:37230]
16/03/21 17:33:03 INFO Utils: Successfully started service 'sparkDriver' on port 37230.
16/03/21 17:33:03 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:33:03 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:33:03 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-07ccce14-f515-4a59-9a63-13571ed69c26
16/03/21 17:33:03 INFO MemoryStore: MemoryStore started with capacity 800.9 MB
16/03/21 17:33:03 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-4ed82d5a-95de-4573-8dd2-e702107f6ae9
16/03/21 17:33:03 INFO HttpServer: Starting HTTP Server
16/03/21 17:33:03 INFO Utils: Successfully started service 'HTTP file server' on port 57763.
16/03/21 17:33:03 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:33:03 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:33:03 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:33:03 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-94868a71-fa8f-4db0-99c2-65eaf86d96cf/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:33:03 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561783331
16/03/21 17:33:03 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:33:03 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:33:03 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56394.
16/03/21 17:33:03 INFO NettyBlockTransferService: Server created on 56394
16/03/21 17:33:03 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:33:03 INFO BlockManagerMasterEndpoint: Registering block manager localhost:56394 with 800.9 MB RAM, BlockManagerId(driver, localhost, 56394)
16/03/21 17:33:03 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:33:03 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561783351
16/03/21 17:33:03 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:33:03 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:03 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:33:03 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:33:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:33:03 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:33:03 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=839791411
16/03/21 17:33:03 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 800.9 MB)
16/03/21 17:33:03 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=839791411
16/03/21 17:33:03 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 800.9 MB)
16/03/21 17:33:03 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:56394 (size: 4.1 KB, free: 800.9 MB)
16/03/21 17:33:03 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:33:03 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:03 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:33:03 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:33:03 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:33:03 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:33:03 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561783331
16/03/21 17:33:03 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-94868a71-fa8f-4db0-99c2-65eaf86d96cf/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:33:03 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:33:03 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=839791411
16/03/21 17:33:03 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 800.9 MB)
16/03/21 17:33:03 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:56394 (size: 166.0 B, free: 800.9 MB)
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: area
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: issue
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: planning
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: permission
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: economy
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: composition
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: agency
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:33:12 INFO PythonRunner: Times: total = 9048, boot = 542, init = 446, finish = 8060
16/03/21 17:33:12 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:33:12 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:33:12 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:33:12 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:33:12 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=839791411
16/03/21 17:33:12 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 800.9 MB)
16/03/21 17:33:12 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9141 ms on localhost (1/2)
16/03/21 17:33:12 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:56394 (size: 155.0 B, free: 800.9 MB)
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: set
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  Synset('set.n.01') ; keyword:  used  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: bend
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: giant
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: astatine
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: present
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: area
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
16/03/21 17:33:12 INFO PythonRunner: Times: total = 278, boot = 180, init = 0, finish = 98
16/03/21 17:33:12 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:33:12 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.433 s
16/03/21 17:33:12 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:33:12 INFO DAGScheduler: running: Set()
16/03/21 17:33:12 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:33:12 INFO DAGScheduler: failed: Set()
16/03/21 17:33:12 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:33:12 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:33:12 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=839791411
16/03/21 17:33:12 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 800.9 MB)
16/03/21 17:33:12 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 307 ms on localhost (2/2)
16/03/21 17:33:12 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:33:12 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16030, maxMem=839791411
16/03/21 17:33:12 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 800.9 MB)
16/03/21 17:33:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:56394 (size: 3.0 KB, free: 800.9 MB)
16/03/21 17:33:12 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:33:12 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:12 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:33:12 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:33:12 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:33:12 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:33:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:33:13 INFO PythonRunner: Times: total = 153, boot = 152, init = 1, finish = 0
16/03/21 17:33:13 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:33:13 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:33:13 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:33:13 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:33:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:33:13 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 179 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'set']
16/03/21 17:33:13 INFO PythonRunner: Times: total = 180, boot = 179, init = 0, finish = 1
16/03/21 17:33:13 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1229 bytes result sent to driver
16/03/21 17:33:13 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 200 ms on localhost (2/2)
16/03/21 17:33:13 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:33:13 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.368 s
16/03/21 17:33:13 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.836516 s
16/03/21 17:33:13 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:33:13 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:33:13 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:13 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:33:13 INFO DAGScheduler: Missing parents: List()
16/03/21 17:33:13 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:33:13 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19078, maxMem=839791411
16/03/21 17:33:13 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 800.9 MB)
16/03/21 17:33:13 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24894, maxMem=839791411
16/03/21 17:33:13 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 800.9 MB)
16/03/21 17:33:13 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:56394 (size: 3.3 KB, free: 800.9 MB)
16/03/21 17:33:13 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:33:13 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:13 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:33:13 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:33:13 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:33:13 INFO PythonRunner: Times: total = 128, boot = 128, init = 0, finish = 0
16/03/21 17:33:13 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:33:13 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2259 bytes)
16/03/21 17:33:13 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 144 ms on localhost (1/2)
16/03/21 17:33:13 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:33:13 INFO PythonRunner: Times: total = 155, boot = 155, init = 0, finish = 0
16/03/21 17:33:13 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1295 bytes result sent to driver
16/03/21 17:33:13 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.305 s
16/03/21 17:33:13 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.328984 s
16/03/21 17:33:13 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 174 ms on localhost (2/2)
16/03/21 17:33:13 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:33:13 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:33:13 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:33:13 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:33:13 INFO MemoryStore: MemoryStore cleared
16/03/21 17:33:13 INFO BlockManager: BlockManager stopped
16/03/21 17:33:13 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:33:13 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:33:13 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:33:13 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:33:13 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:33:13 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:33:14 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:33:14 INFO SecurityManager: Changing view acls to: root
16/03/21 17:33:14 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:33:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:33:14 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:33:14 INFO Remoting: Starting remoting
16/03/21 17:33:14 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:45137]
16/03/21 17:33:14 INFO Utils: Successfully started service 'sparkDriver' on port 45137.
16/03/21 17:33:14 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:33:14 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:33:14 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-20ae9aaf-cd40-4801-8c7d-6997729cf35a
16/03/21 17:33:14 INFO MemoryStore: MemoryStore started with capacity 800.9 MB
16/03/21 17:33:15 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-8524f709-7ab4-4e74-bb9f-b6e2dffcd34a
16/03/21 17:33:15 INFO HttpServer: Starting HTTP Server
16/03/21 17:33:15 INFO Utils: Successfully started service 'HTTP file server' on port 42758.
16/03/21 17:33:15 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:33:15 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:33:15 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:33:15 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-d2700ae7-b60e-440e-84ad-e5b4498ce596/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:33:15 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561795132
16/03/21 17:33:15 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:33:15 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:33:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38060.
16/03/21 17:33:15 INFO NettyBlockTransferService: Server created on 38060
16/03/21 17:33:15 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:33:15 INFO BlockManagerMasterEndpoint: Registering block manager localhost:38060 with 800.9 MB RAM, BlockManagerId(driver, localhost, 38060)
16/03/21 17:33:15 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:33:15 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561795153
16/03/21 17:33:15 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:33:15 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:15 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:33:15 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:33:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:33:15 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:33:15 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=839791411
16/03/21 17:33:15 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 800.9 MB)
16/03/21 17:33:15 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=839791411
16/03/21 17:33:15 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 800.9 MB)
16/03/21 17:33:15 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:38060 (size: 4.1 KB, free: 800.9 MB)
16/03/21 17:33:15 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:33:15 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:15 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:33:15 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:33:15 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:33:15 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:33:15 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561795132
16/03/21 17:33:15 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-d2700ae7-b60e-440e-84ad-e5b4498ce596/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:33:15 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:33:15 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=839791411
16/03/21 17:33:15 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 800.9 MB)
16/03/21 17:33:15 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:38060 (size: 166.0 B, free: 800.9 MB)
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: area
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  usually  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: issue
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: planning
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: permission
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: economy
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: composition
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: agency
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/21 17:33:23 INFO PythonRunner: Times: total = 7883, boot = 466, init = 357, finish = 7060
16/03/21 17:33:23 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:33:23 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:33:23 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:33:23 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:33:23 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=839791411
16/03/21 17:33:23 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 800.9 MB)
16/03/21 17:33:23 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:38060 (size: 155.0 B, free: 800.9 MB)
16/03/21 17:33:23 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7957 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: set
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: bend
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: giant
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: astatine
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: present
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: area
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  usually  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/21 17:33:23 INFO PythonRunner: Times: total = 269, boot = 161, init = 1, finish = 107
16/03/21 17:33:23 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:33:23 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.239 s
16/03/21 17:33:23 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:33:23 INFO DAGScheduler: running: Set()
16/03/21 17:33:23 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:33:23 INFO DAGScheduler: failed: Set()
16/03/21 17:33:23 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:33:23 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:33:23 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=839791411
16/03/21 17:33:23 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 800.9 MB)
16/03/21 17:33:23 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16030, maxMem=839791411
16/03/21 17:33:23 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 800.9 MB)
16/03/21 17:33:23 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 296 ms on localhost (2/2)
16/03/21 17:33:23 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:33:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:38060 (size: 3.0 KB, free: 800.9 MB)
16/03/21 17:33:23 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:33:23 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:23 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:33:23 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:33:23 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:33:23 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:33:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:33:23 INFO PythonRunner: Times: total = 141, boot = 140, init = 1, finish = 0
16/03/21 17:33:23 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:33:23 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:33:23 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:33:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:33:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:33:23 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 157 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'area', 'None', u'area']
16/03/21 17:33:23 INFO PythonRunner: Times: total = 159, boot = 158, init = 0, finish = 1
16/03/21 17:33:23 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/21 17:33:23 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.328 s
16/03/21 17:33:23 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.588579 s
16/03/21 17:33:23 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 173 ms on localhost (2/2)
16/03/21 17:33:23 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:33:23 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:33:23 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:33:23 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:23 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:33:23 INFO DAGScheduler: Missing parents: List()
16/03/21 17:33:23 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:33:24 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19078, maxMem=839791411
16/03/21 17:33:24 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 800.9 MB)
16/03/21 17:33:24 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24894, maxMem=839791411
16/03/21 17:33:24 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 800.9 MB)
16/03/21 17:33:24 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:38060 (size: 3.3 KB, free: 800.9 MB)
16/03/21 17:33:24 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:33:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:24 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:33:24 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:33:24 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:33:24 INFO PythonRunner: Times: total = 62, boot = 61, init = 0, finish = 1
16/03/21 17:33:24 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:33:24 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/21 17:33:24 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 78 ms on localhost (1/2)
16/03/21 17:33:24 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:33:24 INFO PythonRunner: Times: total = 164, boot = 164, init = 0, finish = 0
16/03/21 17:33:24 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1307 bytes result sent to driver
16/03/21 17:33:24 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.246 s
16/03/21 17:33:24 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.275621 s
16/03/21 17:33:24 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 182 ms on localhost (2/2)
16/03/21 17:33:24 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:33:24 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:33:24 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:33:24 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:33:24 INFO MemoryStore: MemoryStore cleared
16/03/21 17:33:24 INFO BlockManager: BlockManager stopped
16/03/21 17:33:24 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:33:24 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:33:24 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:33:24 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:33:24 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:33:24 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:33:25 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:33:25 INFO SecurityManager: Changing view acls to: root
16/03/21 17:33:25 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:33:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:33:25 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:33:25 INFO Remoting: Starting remoting
16/03/21 17:33:25 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:58785]
16/03/21 17:33:25 INFO Utils: Successfully started service 'sparkDriver' on port 58785.
16/03/21 17:33:25 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:33:25 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:33:25 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ce8419eb-84ec-4dc8-8c99-995060eeb078
16/03/21 17:33:25 INFO MemoryStore: MemoryStore started with capacity 800.9 MB
16/03/21 17:33:25 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-efb90f7e-4986-4891-bc13-caa10d756407
16/03/21 17:33:25 INFO HttpServer: Starting HTTP Server
16/03/21 17:33:25 INFO Utils: Successfully started service 'HTTP file server' on port 33687.
16/03/21 17:33:25 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:33:25 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:33:25 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:33:25 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-16230f9b-5fd0-4a87-82dd-f0b44ad49083/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:33:25 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561805544
16/03/21 17:33:25 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:33:25 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:33:25 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36727.
16/03/21 17:33:25 INFO NettyBlockTransferService: Server created on 36727
16/03/21 17:33:25 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:33:25 INFO BlockManagerMasterEndpoint: Registering block manager localhost:36727 with 800.9 MB RAM, BlockManagerId(driver, localhost, 36727)
16/03/21 17:33:25 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:33:25 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561805557
16/03/21 17:33:25 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:33:25 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:25 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:33:25 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:33:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:33:25 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:33:25 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=839791411
16/03/21 17:33:25 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 800.9 MB)
16/03/21 17:33:25 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=839791411
16/03/21 17:33:25 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 800.9 MB)
16/03/21 17:33:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:36727 (size: 4.1 KB, free: 800.9 MB)
16/03/21 17:33:25 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:33:25 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:25 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:33:25 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:33:25 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:33:25 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:33:25 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561805544
16/03/21 17:33:25 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-16230f9b-5fd0-4a87-82dd-f0b44ad49083/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:33:25 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:33:25 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=839791411
16/03/21 17:33:25 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 800.9 MB)
16/03/21 17:33:25 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:36727 (size: 166.0 B, free: 800.9 MB)
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: area
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: issue
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: planning
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: permission
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: economy
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: composition
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: agency
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:33:33 INFO PythonRunner: Times: total = 7772, boot = 455, init = 349, finish = 6968
16/03/21 17:33:33 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:33:33 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:33:33 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:33:33 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:33:33 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7853 ms on localhost (1/2)
16/03/21 17:33:33 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=839791411
16/03/21 17:33:33 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 800.9 MB)
16/03/21 17:33:33 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:36727 (size: 155.0 B, free: 800.9 MB)
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: set
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: bend
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: giant
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: astatine
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: present
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  moment  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: area
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/21 17:33:33 INFO PythonRunner: Times: total = 241, boot = 147, init = 1, finish = 93
16/03/21 17:33:33 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:33:33 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 281 ms on localhost (2/2)
16/03/21 17:33:33 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:33:33 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.119 s
16/03/21 17:33:33 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:33:33 INFO DAGScheduler: running: Set()
16/03/21 17:33:33 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:33:33 INFO DAGScheduler: failed: Set()
16/03/21 17:33:33 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:33:33 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:33:33 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=839791411
16/03/21 17:33:33 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 800.9 MB)
16/03/21 17:33:33 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16030, maxMem=839791411
16/03/21 17:33:33 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 800.9 MB)
16/03/21 17:33:33 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:36727 (size: 3.0 KB, free: 800.9 MB)
16/03/21 17:33:33 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:33:33 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:33 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:33:33 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:33:33 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:33:33 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:33:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:33:33 INFO PythonRunner: Times: total = 130, boot = 129, init = 0, finish = 1
16/03/21 17:33:33 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:33:33 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:33:33 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:33:33 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:33:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:33:34 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 166 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'present']
16/03/21 17:33:34 INFO PythonRunner: Times: total = 154, boot = 154, init = 0, finish = 0
16/03/21 17:33:34 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/21 17:33:34 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 170 ms on localhost (2/2)
16/03/21 17:33:34 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:33:34 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.316 s
16/03/21 17:33:34 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.473632 s
16/03/21 17:33:34 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:33:34 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:33:34 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:34 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:33:34 INFO DAGScheduler: Missing parents: List()
16/03/21 17:33:34 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:33:34 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19078, maxMem=839791411
16/03/21 17:33:34 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 800.9 MB)
16/03/21 17:33:34 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24894, maxMem=839791411
16/03/21 17:33:34 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 800.9 MB)
16/03/21 17:33:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:36727 (size: 3.3 KB, free: 800.9 MB)
16/03/21 17:33:34 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:33:34 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:34 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:33:34 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:33:34 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:33:34 INFO PythonRunner: Times: total = 57, boot = 56, init = 1, finish = 0
16/03/21 17:33:34 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:33:34 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/21 17:33:34 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:33:34 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 73 ms on localhost (1/2)
16/03/21 17:33:34 INFO PythonRunner: Times: total = 165, boot = 164, init = 0, finish = 1
16/03/21 17:33:34 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1310 bytes result sent to driver
16/03/21 17:33:34 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.237 s
16/03/21 17:33:34 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.259842 s
16/03/21 17:33:34 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 177 ms on localhost (2/2)
16/03/21 17:33:34 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:33:34 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:33:34 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:33:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:33:34 INFO MemoryStore: MemoryStore cleared
16/03/21 17:33:34 INFO BlockManager: BlockManager stopped
16/03/21 17:33:34 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:33:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:33:34 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:33:34 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:33:34 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:33:34 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:33:35 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:33:35 INFO SecurityManager: Changing view acls to: root
16/03/21 17:33:35 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:33:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:33:35 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:33:35 INFO Remoting: Starting remoting
16/03/21 17:33:35 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:46710]
16/03/21 17:33:35 INFO Utils: Successfully started service 'sparkDriver' on port 46710.
16/03/21 17:33:35 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:33:35 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:33:35 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d5a6f00f-02db-47f9-8712-73cc5975c7e5
16/03/21 17:33:35 INFO MemoryStore: MemoryStore started with capacity 800.9 MB
16/03/21 17:33:35 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-eacd9099-f9bb-430f-9e27-98c880c6388b
16/03/21 17:33:35 INFO HttpServer: Starting HTTP Server
16/03/21 17:33:35 INFO Utils: Successfully started service 'HTTP file server' on port 53392.
16/03/21 17:33:35 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:33:35 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:33:35 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:33:35 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-1c2c7454-df24-4955-9e6d-559ec838b2b5/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:33:35 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561815806
16/03/21 17:33:35 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:33:35 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:33:35 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45615.
16/03/21 17:33:35 INFO NettyBlockTransferService: Server created on 45615
16/03/21 17:33:35 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:33:35 INFO BlockManagerMasterEndpoint: Registering block manager localhost:45615 with 800.9 MB RAM, BlockManagerId(driver, localhost, 45615)
16/03/21 17:33:35 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:33:35 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561815820
16/03/21 17:33:35 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:33:35 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:35 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:33:35 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:33:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:33:35 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:33:35 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=839791411
16/03/21 17:33:35 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 800.9 MB)
16/03/21 17:33:35 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=839791411
16/03/21 17:33:35 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 800.9 MB)
16/03/21 17:33:35 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:45615 (size: 4.1 KB, free: 800.9 MB)
16/03/21 17:33:35 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:33:35 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:35 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:33:35 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:33:35 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:33:35 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:33:35 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561815806
16/03/21 17:33:36 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-1c2c7454-df24-4955-9e6d-559ec838b2b5/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:33:36 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:33:36 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=839791411
16/03/21 17:33:36 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 800.9 MB)
16/03/21 17:33:36 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:45615 (size: 166.0 B, free: 800.9 MB)
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: area
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  purpose  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: issue
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: planning
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: permission
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: economy
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: composition
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: agency
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/21 17:33:43 INFO PythonRunner: Times: total = 7851, boot = 452, init = 355, finish = 7044
16/03/21 17:33:43 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:33:43 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:33:43 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:33:43 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:33:43 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=839791411
16/03/21 17:33:43 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 800.9 MB)
16/03/21 17:33:43 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7926 ms on localhost (1/2)
16/03/21 17:33:43 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:45615 (size: 155.0 B, free: 800.9 MB)
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: set
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: bend
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: giant
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: astatine
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: present
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: area
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  purpose  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/21 17:33:44 INFO PythonRunner: Times: total = 262, boot = 168, init = 0, finish = 94
16/03/21 17:33:44 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:33:44 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 291 ms on localhost (2/2)
16/03/21 17:33:44 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:33:44 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.206 s
16/03/21 17:33:44 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:33:44 INFO DAGScheduler: running: Set()
16/03/21 17:33:44 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:33:44 INFO DAGScheduler: failed: Set()
16/03/21 17:33:44 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:33:44 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:33:44 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=839791411
16/03/21 17:33:44 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 800.9 MB)
16/03/21 17:33:44 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16030, maxMem=839791411
16/03/21 17:33:44 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 800.9 MB)
16/03/21 17:33:44 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:45615 (size: 3.0 KB, free: 800.9 MB)
16/03/21 17:33:44 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:33:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:44 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:33:44 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:33:44 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:33:44 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:33:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:33:44 INFO PythonRunner: Times: total = 134, boot = 133, init = 1, finish = 0
16/03/21 17:33:44 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:33:44 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:33:44 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:33:44 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:33:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:33:44 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 166 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'area', 'None', u'area']
16/03/21 17:33:44 INFO PythonRunner: Times: total = 181, boot = 180, init = 0, finish = 1
16/03/21 17:33:44 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/21 17:33:44 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 195 ms on localhost (2/2)
16/03/21 17:33:44 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:33:44 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.340 s
16/03/21 17:33:44 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.587432 s
16/03/21 17:33:44 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:33:44 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:33:44 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:44 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:33:44 INFO DAGScheduler: Missing parents: List()
16/03/21 17:33:44 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:33:44 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19078, maxMem=839791411
16/03/21 17:33:44 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 800.9 MB)
16/03/21 17:33:44 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24894, maxMem=839791411
16/03/21 17:33:44 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 800.9 MB)
16/03/21 17:33:44 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:45615 (size: 3.3 KB, free: 800.9 MB)
16/03/21 17:33:44 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:33:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:44 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:33:44 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:33:44 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:33:44 INFO PythonRunner: Times: total = 69, boot = 68, init = 1, finish = 0
16/03/21 17:33:44 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:33:44 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/21 17:33:44 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 88 ms on localhost (1/2)
16/03/21 17:33:44 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:33:44 INFO PythonRunner: Times: total = 161, boot = 160, init = 1, finish = 0
16/03/21 17:33:44 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1307 bytes result sent to driver
16/03/21 17:33:44 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.264 s
16/03/21 17:33:44 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.285558 s
16/03/21 17:33:44 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 182 ms on localhost (2/2)
16/03/21 17:33:44 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:33:45 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:33:45 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:33:45 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:33:45 INFO MemoryStore: MemoryStore cleared
16/03/21 17:33:45 INFO BlockManager: BlockManager stopped
16/03/21 17:33:45 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:33:45 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:33:45 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:33:45 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:33:45 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:33:45 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:33:45 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:33:45 INFO SecurityManager: Changing view acls to: root
16/03/21 17:33:45 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:33:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:33:46 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:33:46 INFO Remoting: Starting remoting
16/03/21 17:33:46 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:40609]
16/03/21 17:33:46 INFO Utils: Successfully started service 'sparkDriver' on port 40609.
16/03/21 17:33:46 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:33:46 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:33:46 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-dd8d7d76-825b-420d-a817-e6e3bc1fd77d
16/03/21 17:33:46 INFO MemoryStore: MemoryStore started with capacity 800.9 MB
16/03/21 17:33:46 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-289327a3-7371-452e-a09b-03c31647cb81
16/03/21 17:33:46 INFO HttpServer: Starting HTTP Server
16/03/21 17:33:46 INFO Utils: Successfully started service 'HTTP file server' on port 57542.
16/03/21 17:33:46 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:33:46 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:33:46 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:33:46 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-456dbd76-4cbd-47dd-acaa-a6d8926958b7/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:33:46 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561826219
16/03/21 17:33:46 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:33:46 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:33:46 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57148.
16/03/21 17:33:46 INFO NettyBlockTransferService: Server created on 57148
16/03/21 17:33:46 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:33:46 INFO BlockManagerMasterEndpoint: Registering block manager localhost:57148 with 800.9 MB RAM, BlockManagerId(driver, localhost, 57148)
16/03/21 17:33:46 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:33:46 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561826242
16/03/21 17:33:46 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:33:46 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:46 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:33:46 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:33:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:33:46 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:33:46 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=839791411
16/03/21 17:33:46 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 800.9 MB)
16/03/21 17:33:46 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=839791411
16/03/21 17:33:46 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 800.9 MB)
16/03/21 17:33:46 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:57148 (size: 4.1 KB, free: 800.9 MB)
16/03/21 17:33:46 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:33:46 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:46 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:33:46 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:33:46 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:33:46 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:33:46 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561826219
16/03/21 17:33:46 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-456dbd76-4cbd-47dd-acaa-a6d8926958b7/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:33:46 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:33:46 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=839791411
16/03/21 17:33:46 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 800.9 MB)
16/03/21 17:33:46 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:57148 (size: 166.0 B, free: 800.9 MB)
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: area
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: issue
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: planning
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: permission
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: economy
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: composition
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: agency
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:33:54 INFO PythonRunner: Times: total = 8068, boot = 472, init = 365, finish = 7231
16/03/21 17:33:54 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:33:54 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:33:54 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:33:54 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:33:54 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=839791411
16/03/21 17:33:54 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 800.9 MB)
16/03/21 17:33:54 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:57148 (size: 155.0 B, free: 800.9 MB)
16/03/21 17:33:54 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8148 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: set
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: bend
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): adding to parents: syn =  Synset('bend.n.01') ; keyword:  segment  in syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= [u'bend']
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: giant
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: astatine
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: present
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: area
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
16/03/21 17:33:54 INFO PythonRunner: Times: total = 436, boot = 175, init = 162, finish = 99
16/03/21 17:33:54 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:33:54 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 465 ms on localhost (2/2)
16/03/21 17:33:54 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:33:54 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.595 s
16/03/21 17:33:54 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:33:54 INFO DAGScheduler: running: Set()
16/03/21 17:33:54 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:33:54 INFO DAGScheduler: failed: Set()
16/03/21 17:33:54 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:33:54 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:33:54 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=839791411
16/03/21 17:33:54 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 800.9 MB)
16/03/21 17:33:54 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16030, maxMem=839791411
16/03/21 17:33:54 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 800.9 MB)
16/03/21 17:33:55 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:57148 (size: 3.0 KB, free: 800.9 MB)
16/03/21 17:33:55 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:33:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:55 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:33:55 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:33:55 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:33:55 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:33:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:33:55 INFO PythonRunner: Times: total = 145, boot = 144, init = 1, finish = 0
16/03/21 17:33:55 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:33:55 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:33:55 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:33:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:33:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:33:55 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 169 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'bend']
16/03/21 17:33:55 INFO PythonRunner: Times: total = 161, boot = 160, init = 1, finish = 0
16/03/21 17:33:55 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1230 bytes result sent to driver
16/03/21 17:33:55 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.326 s
16/03/21 17:33:55 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.971226 s
16/03/21 17:33:55 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 177 ms on localhost (2/2)
16/03/21 17:33:55 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:33:55 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:33:55 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:33:55 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:55 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:33:55 INFO DAGScheduler: Missing parents: List()
16/03/21 17:33:55 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:33:55 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19078, maxMem=839791411
16/03/21 17:33:55 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 800.9 MB)
16/03/21 17:33:55 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24894, maxMem=839791411
16/03/21 17:33:55 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 800.9 MB)
16/03/21 17:33:55 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:57148 (size: 3.3 KB, free: 800.9 MB)
16/03/21 17:33:55 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:33:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:55 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:33:55 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:33:55 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:33:55 INFO PythonRunner: Times: total = 126, boot = 126, init = 0, finish = 0
16/03/21 17:33:55 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:33:55 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2260 bytes)
16/03/21 17:33:55 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:33:55 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 147 ms on localhost (1/2)
16/03/21 17:33:55 INFO PythonRunner: Times: total = 156, boot = 155, init = 1, finish = 0
16/03/21 17:33:55 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1296 bytes result sent to driver
16/03/21 17:33:55 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 175 ms on localhost (2/2)
16/03/21 17:33:55 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:33:55 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.311 s
16/03/21 17:33:55 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.339590 s
16/03/21 17:33:55 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:33:55 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:33:55 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:33:55 INFO MemoryStore: MemoryStore cleared
16/03/21 17:33:55 INFO BlockManager: BlockManager stopped
16/03/21 17:33:55 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:33:55 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:33:55 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:33:56 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:33:56 INFO SecurityManager: Changing view acls to: root
16/03/21 17:33:56 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:33:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:33:56 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:33:56 INFO Remoting: Starting remoting
16/03/21 17:33:56 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:41012]
16/03/21 17:33:56 INFO Utils: Successfully started service 'sparkDriver' on port 41012.
16/03/21 17:33:56 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:33:56 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:33:56 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b8c95d7a-e66b-4eb1-99af-292339b2b4da
16/03/21 17:33:56 INFO MemoryStore: MemoryStore started with capacity 798.0 MB
16/03/21 17:33:56 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-4f1d0c29-9b71-4abb-8fd0-0a0d932556b5
16/03/21 17:33:56 INFO HttpServer: Starting HTTP Server
16/03/21 17:33:56 INFO Utils: Successfully started service 'HTTP file server' on port 55902.
16/03/21 17:33:56 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:33:57 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:33:57 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:33:57 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-2a91980d-d239-4362-b7a6-5b3b24efcbf1/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:33:57 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561837036
16/03/21 17:33:57 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:33:57 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:33:57 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40232.
16/03/21 17:33:57 INFO NettyBlockTransferService: Server created on 40232
16/03/21 17:33:57 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:33:57 INFO BlockManagerMasterEndpoint: Registering block manager localhost:40232 with 798.0 MB RAM, BlockManagerId(driver, localhost, 40232)
16/03/21 17:33:57 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:33:57 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561837059
16/03/21 17:33:57 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:33:57 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:57 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:33:57 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:33:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:33:57 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:33:57 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=836712529
16/03/21 17:33:57 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 797.9 MB)
16/03/21 17:33:57 INFO MemoryStore: ensureFreeSpace(4147) called with curMem=6576, maxMem=836712529
16/03/21 17:33:57 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 797.9 MB)
16/03/21 17:33:57 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:40232 (size: 4.0 KB, free: 797.9 MB)
16/03/21 17:33:57 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:33:57 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:33:57 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:33:57 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:33:57 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:33:57 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:33:57 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561837036
16/03/21 17:33:57 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-2a91980d-d239-4362-b7a6-5b3b24efcbf1/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:33:57 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:33:57 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10723, maxMem=836712529
16/03/21 17:33:57 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 797.9 MB)
16/03/21 17:33:57 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:40232 (size: 166.0 B, free: 797.9 MB)
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: area
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: issue
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: planning
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: permission
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: economy
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: composition
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: agency
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:34:05 INFO PythonRunner: Times: total = 7748, boot = 454, init = 351, finish = 6943
16/03/21 17:34:05 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:34:05 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:34:05 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:34:05 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:34:05 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10889, maxMem=836712529
16/03/21 17:34:05 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 797.9 MB)
16/03/21 17:34:05 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7814 ms on localhost (1/2)
16/03/21 17:34:05 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:40232 (size: 155.0 B, free: 797.9 MB)
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: set
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: bend
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: giant
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: astatine
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  radioactive  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: present
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: area
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/21 17:34:05 INFO PythonRunner: Times: total = 263, boot = 168, init = 1, finish = 94
16/03/21 17:34:05 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:34:05 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 291 ms on localhost (2/2)
16/03/21 17:34:05 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:34:05 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.095 s
16/03/21 17:34:05 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:34:05 INFO DAGScheduler: running: Set()
16/03/21 17:34:05 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:34:05 INFO DAGScheduler: failed: Set()
16/03/21 17:34:05 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:34:05 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:34:05 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11044, maxMem=836712529
16/03/21 17:34:05 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 797.9 MB)
16/03/21 17:34:05 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16028, maxMem=836712529
16/03/21 17:34:05 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 797.9 MB)
16/03/21 17:34:05 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:40232 (size: 3.0 KB, free: 797.9 MB)
16/03/21 17:34:05 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:34:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:34:05 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:34:05 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:34:05 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:34:05 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:34:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:34:05 INFO PythonRunner: Times: total = 143, boot = 143, init = 0, finish = 0
16/03/21 17:34:05 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:34:05 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:34:05 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:34:05 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:34:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:34:05 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 171 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/03/21 17:34:05 INFO PythonRunner: Times: total = 164, boot = 163, init = 1, finish = 0
16/03/21 17:34:05 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1242 bytes result sent to driver
16/03/21 17:34:05 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.330 s
16/03/21 17:34:05 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.457781 s
16/03/21 17:34:05 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 181 ms on localhost (2/2)
16/03/21 17:34:05 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:34:05 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:34:05 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:34:05 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:34:05 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:34:05 INFO DAGScheduler: Missing parents: List()
16/03/21 17:34:05 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:34:05 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19076, maxMem=836712529
16/03/21 17:34:05 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 797.9 MB)
16/03/21 17:34:05 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24892, maxMem=836712529
16/03/21 17:34:05 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 797.9 MB)
16/03/21 17:34:05 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:40232 (size: 3.3 KB, free: 797.9 MB)
16/03/21 17:34:05 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:34:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:34:05 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:34:05 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:34:05 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:34:05 INFO PythonRunner: Times: total = 106, boot = 106, init = 0, finish = 0
16/03/21 17:34:05 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:34:05 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2272 bytes)
16/03/21 17:34:05 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 123 ms on localhost (1/2)
16/03/21 17:34:05 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:34:06 INFO PythonRunner: Times: total = 152, boot = 152, init = 0, finish = 0
16/03/21 17:34:06 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1311 bytes result sent to driver
16/03/21 17:34:06 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 177 ms on localhost (2/2)
16/03/21 17:34:06 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:34:06 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.284 s
16/03/21 17:34:06 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.311165 s
16/03/21 17:34:06 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:34:06 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:34:06 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:34:06 INFO MemoryStore: MemoryStore cleared
16/03/21 17:34:06 INFO BlockManager: BlockManager stopped
16/03/21 17:34:06 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:34:06 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:34:06 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:34:06 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:34:06 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:34:06 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:34:07 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:34:07 INFO SecurityManager: Changing view acls to: root
16/03/21 17:34:07 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:34:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:34:07 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:34:07 INFO Remoting: Starting remoting
16/03/21 17:34:07 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:58602]
16/03/21 17:34:07 INFO Utils: Successfully started service 'sparkDriver' on port 58602.
16/03/21 17:34:07 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:34:07 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:34:07 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-79762d76-628c-4e59-95a6-7ef4824268b0
16/03/21 17:34:07 INFO MemoryStore: MemoryStore started with capacity 798.0 MB
16/03/21 17:34:07 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-606803c6-5637-4434-a40d-f1725de51994
16/03/21 17:34:07 INFO HttpServer: Starting HTTP Server
16/03/21 17:34:07 INFO Utils: Successfully started service 'HTTP file server' on port 40622.
16/03/21 17:34:07 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:34:07 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:34:07 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:34:07 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-d776b4fd-6ed4-4a56-8c0b-5c77b63f1c4a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:34:07 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561847317
16/03/21 17:34:07 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:34:07 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:34:07 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42817.
16/03/21 17:34:07 INFO NettyBlockTransferService: Server created on 42817
16/03/21 17:34:07 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:34:07 INFO BlockManagerMasterEndpoint: Registering block manager localhost:42817 with 798.0 MB RAM, BlockManagerId(driver, localhost, 42817)
16/03/21 17:34:07 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:34:07 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561847348
16/03/21 17:34:07 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:34:07 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:34:07 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:34:07 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:34:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:34:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:34:07 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:34:07 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=836712529
16/03/21 17:34:07 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 797.9 MB)
16/03/21 17:34:07 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=836712529
16/03/21 17:34:07 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 797.9 MB)
16/03/21 17:34:07 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:42817 (size: 4.1 KB, free: 797.9 MB)
16/03/21 17:34:07 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:34:07 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:34:07 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:34:07 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:34:07 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:34:07 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:34:07 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561847317
16/03/21 17:34:07 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-d776b4fd-6ed4-4a56-8c0b-5c77b63f1c4a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:34:07 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:34:07 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=836712529
16/03/21 17:34:07 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 797.9 MB)
16/03/21 17:34:07 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:42817 (size: 166.0 B, free: 797.9 MB)
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: area
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: issue
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: planning
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: permission
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: economy
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: composition
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: agency
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:34:15 INFO PythonRunner: Times: total = 8163, boot = 550, init = 413, finish = 7200
16/03/21 17:34:15 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:34:15 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:34:15 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:34:15 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8247 ms on localhost (1/2)
16/03/21 17:34:15 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:34:15 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=836712529
16/03/21 17:34:15 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 797.9 MB)
16/03/21 17:34:15 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:42817 (size: 155.0 B, free: 797.9 MB)
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: set
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: bend
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: giant
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: astatine
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: present
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  happening  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: area
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: kilometer
16/03/21 17:34:15 INFO PythonRunner: Times: total = 244, boot = 148, init = 0, finish = 96
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/21 17:34:15 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:34:16 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.512 s
16/03/21 17:34:16 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:34:16 INFO DAGScheduler: running: Set()
16/03/21 17:34:16 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:34:16 INFO DAGScheduler: failed: Set()
16/03/21 17:34:16 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:34:16 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:34:16 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 269 ms on localhost (2/2)
16/03/21 17:34:16 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:34:16 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=836712529
16/03/21 17:34:16 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 797.9 MB)
16/03/21 17:34:16 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16030, maxMem=836712529
16/03/21 17:34:16 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 797.9 MB)
16/03/21 17:34:16 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:42817 (size: 3.0 KB, free: 797.9 MB)
16/03/21 17:34:16 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:34:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:34:16 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:34:16 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:34:16 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:34:16 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:34:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:34:16 INFO PythonRunner: Times: total = 169, boot = 168, init = 1, finish = 0
16/03/21 17:34:16 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:34:16 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:34:16 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:34:16 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:34:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:34:16 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 194 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'present']
16/03/21 17:34:16 INFO PythonRunner: Times: total = 151, boot = 150, init = 1, finish = 0
16/03/21 17:34:16 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/21 17:34:16 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 168 ms on localhost (2/2)
16/03/21 17:34:16 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:34:16 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.342 s
16/03/21 17:34:16 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.884697 s
16/03/21 17:34:16 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:34:16 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:34:16 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:34:16 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:34:16 INFO DAGScheduler: Missing parents: List()
16/03/21 17:34:16 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:34:16 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19078, maxMem=836712529
16/03/21 17:34:16 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 797.9 MB)
16/03/21 17:34:16 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24894, maxMem=836712529
16/03/21 17:34:16 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 797.9 MB)
16/03/21 17:34:16 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:42817 (size: 3.3 KB, free: 797.9 MB)
16/03/21 17:34:16 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:34:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:34:16 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:34:16 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:34:16 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:34:16 INFO PythonRunner: Times: total = 101, boot = 100, init = 0, finish = 1
16/03/21 17:34:16 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:34:16 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/21 17:34:16 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:34:16 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 116 ms on localhost (1/2)
16/03/21 17:34:16 INFO PythonRunner: Times: total = 174, boot = 173, init = 1, finish = 0
16/03/21 17:34:16 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1310 bytes result sent to driver
16/03/21 17:34:16 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 188 ms on localhost (2/2)
16/03/21 17:34:16 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:34:16 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.287 s
16/03/21 17:34:16 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.309825 s
16/03/21 17:34:16 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:34:16 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:34:16 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:34:16 INFO MemoryStore: MemoryStore cleared
16/03/21 17:34:16 INFO BlockManager: BlockManager stopped
16/03/21 17:34:16 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:34:16 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:34:16 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:34:16 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:34:16 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:34:16 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:34:17 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:34:17 INFO SecurityManager: Changing view acls to: root
16/03/21 17:34:17 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:34:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:34:17 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:34:17 INFO Remoting: Starting remoting
16/03/21 17:34:17 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:49311]
16/03/21 17:34:17 INFO Utils: Successfully started service 'sparkDriver' on port 49311.
16/03/21 17:34:17 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:34:17 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:34:17 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e229f21d-a33d-4bc3-9620-db92cfa87c3a
16/03/21 17:34:17 INFO MemoryStore: MemoryStore started with capacity 798.0 MB
16/03/21 17:34:17 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-f1e1a1cc-f890-493b-8a10-b0c920f2973c
16/03/21 17:34:17 INFO HttpServer: Starting HTTP Server
16/03/21 17:34:17 INFO Utils: Successfully started service 'HTTP file server' on port 49247.
16/03/21 17:34:17 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:34:18 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:34:18 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:34:18 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-5414dfaf-e0ae-485e-aaaf-db911a22f7e8/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:34:18 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561858049
16/03/21 17:34:18 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:34:18 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:34:18 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35127.
16/03/21 17:34:18 INFO NettyBlockTransferService: Server created on 35127
16/03/21 17:34:18 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:34:18 INFO BlockManagerMasterEndpoint: Registering block manager localhost:35127 with 798.0 MB RAM, BlockManagerId(driver, localhost, 35127)
16/03/21 17:34:18 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:34:18 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561858087
16/03/21 17:34:18 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:34:18 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:34:18 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:34:18 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:34:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:34:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:34:18 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:34:18 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=836712529
16/03/21 17:34:18 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 797.9 MB)
16/03/21 17:34:18 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=836712529
16/03/21 17:34:18 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 797.9 MB)
16/03/21 17:34:18 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:35127 (size: 4.1 KB, free: 797.9 MB)
16/03/21 17:34:18 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:34:18 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:34:18 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:34:18 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:34:18 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:34:18 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:34:18 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561858049
16/03/21 17:34:18 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-5414dfaf-e0ae-485e-aaaf-db911a22f7e8/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:34:18 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:34:18 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=836712529
16/03/21 17:34:18 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 797.9 MB)
16/03/21 17:34:18 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:35127 (size: 166.0 B, free: 797.9 MB)
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: area
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: issue
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: planning
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: permission
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: economy
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: composition
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: agency
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:34:26 INFO PythonRunner: Times: total = 7942, boot = 452, init = 361, finish = 7129
16/03/21 17:34:26 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:34:26 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:34:26 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:34:26 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:34:26 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=836712529
16/03/21 17:34:26 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 797.9 MB)
16/03/21 17:34:26 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:35127 (size: 155.0 B, free: 797.9 MB)
16/03/21 17:34:26 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8013 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: set
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: bend
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): adding to parents: syn =  Synset('bend.n.01') ; keyword:  curve  in syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= [u'bend']
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: giant
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: astatine
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: present
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: area
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
16/03/21 17:34:26 INFO PythonRunner: Times: total = 253, boot = 158, init = 1, finish = 94
16/03/21 17:34:26 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:34:26 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.286 s
16/03/21 17:34:26 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:34:26 INFO DAGScheduler: running: Set()
16/03/21 17:34:26 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:34:26 INFO DAGScheduler: failed: Set()
16/03/21 17:34:26 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:34:26 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:34:26 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=836712529
16/03/21 17:34:26 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 797.9 MB)
16/03/21 17:34:26 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16030, maxMem=836712529
16/03/21 17:34:26 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 797.9 MB)
16/03/21 17:34:26 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 283 ms on localhost (2/2)
16/03/21 17:34:26 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:34:26 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:35127 (size: 3.0 KB, free: 797.9 MB)
16/03/21 17:34:26 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:34:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:34:26 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:34:26 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:34:26 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:34:26 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:34:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:34:26 INFO PythonRunner: Times: total = 113, boot = 112, init = 0, finish = 1
16/03/21 17:34:26 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:34:26 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:34:26 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:34:26 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:34:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:34:26 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 138 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'bend']
16/03/21 17:34:26 INFO PythonRunner: Times: total = 176, boot = 175, init = 1, finish = 0
16/03/21 17:34:26 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1230 bytes result sent to driver
16/03/21 17:34:26 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.319 s
16/03/21 17:34:26 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.662921 s
16/03/21 17:34:26 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 192 ms on localhost (2/2)
16/03/21 17:34:26 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:34:26 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:34:26 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:34:26 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:34:26 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:34:26 INFO DAGScheduler: Missing parents: List()
16/03/21 17:34:26 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:34:26 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19078, maxMem=836712529
16/03/21 17:34:26 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 797.9 MB)
16/03/21 17:34:26 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24894, maxMem=836712529
16/03/21 17:34:26 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 797.9 MB)
16/03/21 17:34:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:35127 (size: 3.3 KB, free: 797.9 MB)
16/03/21 17:34:26 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:34:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:34:26 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:34:26 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:34:26 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:34:27 INFO PythonRunner: Times: total = 64, boot = 64, init = 0, finish = 0
16/03/21 17:34:27 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:34:27 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2260 bytes)
16/03/21 17:34:27 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 80 ms on localhost (1/2)
16/03/21 17:34:27 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:34:27 INFO PythonRunner: Times: total = 155, boot = 154, init = 0, finish = 1
16/03/21 17:34:27 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1296 bytes result sent to driver
16/03/21 17:34:27 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.239 s
16/03/21 17:34:27 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.270428 s
16/03/21 17:34:27 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 172 ms on localhost (2/2)
16/03/21 17:34:27 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:34:27 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:34:27 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:34:27 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:34:27 INFO MemoryStore: MemoryStore cleared
16/03/21 17:34:27 INFO BlockManager: BlockManager stopped
16/03/21 17:34:27 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:34:27 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:34:27 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:34:27 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:34:27 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:34:27 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:34:28 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:34:28 INFO SecurityManager: Changing view acls to: root
16/03/21 17:34:28 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:34:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:34:28 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:34:28 INFO Remoting: Starting remoting
16/03/21 17:34:28 INFO Utils: Successfully started service 'sparkDriver' on port 43352.
16/03/21 17:34:28 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:43352]
16/03/21 17:34:28 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:34:28 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:34:28 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c6ef30a1-0629-4ee1-9c0d-178dda033e8f
16/03/21 17:34:28 INFO MemoryStore: MemoryStore started with capacity 798.0 MB
16/03/21 17:34:28 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-c0f3da81-90b4-433a-8ae8-8bd023826880
16/03/21 17:34:28 INFO HttpServer: Starting HTTP Server
16/03/21 17:34:28 INFO Utils: Successfully started service 'HTTP file server' on port 55799.
16/03/21 17:34:28 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:34:28 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:34:28 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:34:28 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-fd4e853b-5ba6-475b-98d5-a689f69b9be6/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:34:28 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561868791
16/03/21 17:34:28 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:34:28 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:34:28 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60869.
16/03/21 17:34:28 INFO NettyBlockTransferService: Server created on 60869
16/03/21 17:34:28 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:34:28 INFO BlockManagerMasterEndpoint: Registering block manager localhost:60869 with 798.0 MB RAM, BlockManagerId(driver, localhost, 60869)
16/03/21 17:34:28 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:34:28 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561868808
16/03/21 17:34:28 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:34:28 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:34:28 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:34:28 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:34:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:34:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:34:28 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:34:28 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=836712529
16/03/21 17:34:28 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 797.9 MB)
16/03/21 17:34:28 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=836712529
16/03/21 17:34:28 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 797.9 MB)
16/03/21 17:34:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:60869 (size: 4.1 KB, free: 797.9 MB)
16/03/21 17:34:28 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:34:28 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:34:28 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:34:28 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:34:29 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:34:29 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:34:29 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561868791
16/03/21 17:34:29 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-fd4e853b-5ba6-475b-98d5-a689f69b9be6/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:34:29 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:34:29 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=836712529
16/03/21 17:34:29 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 797.9 MB)
16/03/21 17:34:29 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:60869 (size: 166.0 B, free: 797.9 MB)
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: area
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: issue
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: planning
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: permission
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: economy
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: composition
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: agency
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:34:37 INFO PythonRunner: Times: total = 8132, boot = 465, init = 357, finish = 7310
16/03/21 17:34:37 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:34:37 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:34:37 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:34:37 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8216 ms on localhost (1/2)
16/03/21 17:34:37 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:34:37 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=836712529
16/03/21 17:34:37 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 797.9 MB)
16/03/21 17:34:37 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:60869 (size: 155.0 B, free: 797.9 MB)
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: set
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  Synset('set.n.01') ; keyword:  together  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: bend
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: giant
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: astatine
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: present
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: area
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
16/03/21 17:34:37 INFO PythonRunner: Times: total = 244, boot = 148, init = 0, finish = 96
16/03/21 17:34:37 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:34:37 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 285 ms on localhost (2/2)
16/03/21 17:34:37 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:34:37 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.500 s
16/03/21 17:34:37 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:34:37 INFO DAGScheduler: running: Set()
16/03/21 17:34:37 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:34:37 INFO DAGScheduler: failed: Set()
16/03/21 17:34:37 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:34:37 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:34:37 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=836712529
16/03/21 17:34:37 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 797.9 MB)
16/03/21 17:34:37 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16030, maxMem=836712529
16/03/21 17:34:37 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 797.9 MB)
16/03/21 17:34:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:60869 (size: 3.0 KB, free: 797.9 MB)
16/03/21 17:34:37 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:34:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:34:37 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:34:37 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:34:37 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:34:37 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:34:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:34:37 INFO PythonRunner: Times: total = 268, boot = 267, init = 0, finish = 1
16/03/21 17:34:37 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:34:37 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:34:37 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:34:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:34:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:34:37 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 312 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'set']
16/03/21 17:34:38 INFO PythonRunner: Times: total = 215, boot = 213, init = 1, finish = 1
16/03/21 17:34:38 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1229 bytes result sent to driver
16/03/21 17:34:38 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.536 s
16/03/21 17:34:38 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.076670 s
16/03/21 17:34:38 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 242 ms on localhost (2/2)
16/03/21 17:34:38 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:34:38 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:34:38 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:34:38 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:34:38 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:34:38 INFO DAGScheduler: Missing parents: List()
16/03/21 17:34:38 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:34:38 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19078, maxMem=836712529
16/03/21 17:34:38 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 797.9 MB)
16/03/21 17:34:38 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24894, maxMem=836712529
16/03/21 17:34:38 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 797.9 MB)
16/03/21 17:34:38 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:60869 (size: 3.3 KB, free: 797.9 MB)
16/03/21 17:34:38 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:34:38 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:34:38 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:34:38 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:34:38 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:34:38 INFO PythonRunner: Times: total = 162, boot = 161, init = 1, finish = 0
16/03/21 17:34:38 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:34:38 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2259 bytes)
16/03/21 17:34:38 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 181 ms on localhost (1/2)
16/03/21 17:34:38 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:34:38 INFO PythonRunner: Times: total = 420, boot = 419, init = 1, finish = 0
16/03/21 17:34:38 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1295 bytes result sent to driver
16/03/21 17:34:38 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 450 ms on localhost (2/2)
16/03/21 17:34:38 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:34:38 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.625 s
16/03/21 17:34:38 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.662121 s
16/03/21 17:34:38 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:34:38 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:34:38 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:34:39 INFO MemoryStore: MemoryStore cleared
16/03/21 17:34:39 INFO BlockManager: BlockManager stopped
16/03/21 17:34:39 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:34:39 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:34:39 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:34:39 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:34:39 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:34:39 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:34:39 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:34:39 INFO SecurityManager: Changing view acls to: root
16/03/21 17:34:39 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:34:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:34:39 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:34:39 INFO Remoting: Starting remoting
16/03/21 17:34:40 INFO Utils: Successfully started service 'sparkDriver' on port 54897.
16/03/21 17:34:40 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:54897]
16/03/21 17:34:40 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:34:40 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:34:40 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-48bf5ebb-e163-4ac9-91fa-8f9c84168a52
16/03/21 17:34:40 INFO MemoryStore: MemoryStore started with capacity 798.0 MB
16/03/21 17:34:40 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-d7ecdc27-bbb4-499e-80ed-8ff9d394114b
16/03/21 17:34:40 INFO HttpServer: Starting HTTP Server
16/03/21 17:34:40 INFO Utils: Successfully started service 'HTTP file server' on port 60038.
16/03/21 17:34:40 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:34:40 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:34:40 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:34:40 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-6f4aefe6-4787-4fac-a4f0-45340f2f40b0/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:34:40 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561880222
16/03/21 17:34:40 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:34:40 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:34:40 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60873.
16/03/21 17:34:40 INFO NettyBlockTransferService: Server created on 60873
16/03/21 17:34:40 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:34:40 INFO BlockManagerMasterEndpoint: Registering block manager localhost:60873 with 798.0 MB RAM, BlockManagerId(driver, localhost, 60873)
16/03/21 17:34:40 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:34:40 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561880252
16/03/21 17:34:40 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:34:40 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:34:40 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:34:40 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:34:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:34:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:34:40 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:34:40 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=836712529
16/03/21 17:34:40 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 797.9 MB)
16/03/21 17:34:40 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=836712529
16/03/21 17:34:40 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 797.9 MB)
16/03/21 17:34:40 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:60873 (size: 4.1 KB, free: 797.9 MB)
16/03/21 17:34:40 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:34:40 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:34:40 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:34:40 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:34:40 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:34:40 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:34:40 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561880222
16/03/21 17:34:40 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-6f4aefe6-4787-4fac-a4f0-45340f2f40b0/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:34:40 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:34:40 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=836712529
16/03/21 17:34:40 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 797.9 MB)
16/03/21 17:34:40 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:60873 (size: 166.0 B, free: 797.9 MB)
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: area
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: issue
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: planning
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: permission
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: economy
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: composition
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: agency
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:34:50 INFO PythonRunner: Times: total = 9863, boot = 637, init = 411, finish = 8815
16/03/21 17:34:50 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:34:50 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:34:50 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:34:50 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:34:50 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=836712529
16/03/21 17:34:50 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 797.9 MB)
16/03/21 17:34:50 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:60873 (size: 155.0 B, free: 797.9 MB)
16/03/21 17:34:50 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 10009 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: set
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: bend
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: giant
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: astatine
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  element  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: present
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: area
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/21 17:34:50 INFO PythonRunner: Times: total = 479, boot = 301, init = 80, finish = 98
16/03/21 17:34:50 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:34:50 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 10.506 s
16/03/21 17:34:50 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:34:50 INFO DAGScheduler: running: Set()
16/03/21 17:34:50 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:34:50 INFO DAGScheduler: failed: Set()
16/03/21 17:34:50 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:34:50 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:34:50 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=836712529
16/03/21 17:34:50 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 797.9 MB)
16/03/21 17:34:50 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16030, maxMem=836712529
16/03/21 17:34:50 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 797.9 MB)
16/03/21 17:34:50 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 516 ms on localhost (2/2)
16/03/21 17:34:50 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:34:50 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:60873 (size: 3.0 KB, free: 797.9 MB)
16/03/21 17:34:50 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:34:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:34:50 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:34:50 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:34:50 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:34:50 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:34:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:34:51 INFO PythonRunner: Times: total = 138, boot = 138, init = 0, finish = 0
16/03/21 17:34:51 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:34:51 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:34:51 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:34:51 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:34:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:34:51 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 165 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/03/21 17:34:51 INFO PythonRunner: Times: total = 157, boot = 156, init = 0, finish = 1
16/03/21 17:34:51 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1242 bytes result sent to driver
16/03/21 17:34:51 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.327 s
16/03/21 17:34:51 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 10.875690 s
16/03/21 17:34:51 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 174 ms on localhost (2/2)
16/03/21 17:34:51 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:34:51 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:34:51 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:34:51 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:34:51 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:34:51 INFO DAGScheduler: Missing parents: List()
16/03/21 17:34:51 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:34:51 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19078, maxMem=836712529
16/03/21 17:34:51 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 797.9 MB)
16/03/21 17:34:51 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24894, maxMem=836712529
16/03/21 17:34:51 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 797.9 MB)
16/03/21 17:34:51 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:60873 (size: 3.3 KB, free: 797.9 MB)
16/03/21 17:34:51 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:34:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:34:51 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:34:51 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:34:51 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:34:51 INFO PythonRunner: Times: total = 128, boot = 128, init = 0, finish = 0
16/03/21 17:34:51 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:34:51 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2272 bytes)
16/03/21 17:34:51 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 145 ms on localhost (1/2)
16/03/21 17:34:51 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:34:51 INFO PythonRunner: Times: total = 153, boot = 153, init = 0, finish = 0
16/03/21 17:34:51 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1311 bytes result sent to driver
16/03/21 17:34:51 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 173 ms on localhost (2/2)
16/03/21 17:34:51 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:34:51 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.304 s
16/03/21 17:34:51 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.324713 s
16/03/21 17:34:51 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:34:51 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:34:51 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:34:51 INFO MemoryStore: MemoryStore cleared
16/03/21 17:34:51 INFO BlockManager: BlockManager stopped
16/03/21 17:34:51 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:34:51 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:34:51 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:34:51 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:34:51 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:34:51 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:34:52 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:34:52 INFO SecurityManager: Changing view acls to: root
16/03/21 17:34:52 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:34:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:34:52 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:34:52 INFO Remoting: Starting remoting
16/03/21 17:34:52 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:50855]
16/03/21 17:34:52 INFO Utils: Successfully started service 'sparkDriver' on port 50855.
16/03/21 17:34:52 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:34:52 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:34:52 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e272cc9e-09f5-4d6e-8385-d5fa37f347d8
16/03/21 17:34:52 INFO MemoryStore: MemoryStore started with capacity 795.3 MB
16/03/21 17:34:52 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-8d7353c0-3b91-47e8-b0ac-7f1465d8db3c
16/03/21 17:34:52 INFO HttpServer: Starting HTTP Server
16/03/21 17:34:52 INFO Utils: Successfully started service 'HTTP file server' on port 39921.
16/03/21 17:34:52 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:34:52 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:34:52 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:34:52 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-835a5b3e-44f4-4e26-a95d-bb02c6fb5fc6/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:34:52 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561892969
16/03/21 17:34:52 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:34:52 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:34:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 48117.
16/03/21 17:34:53 INFO NettyBlockTransferService: Server created on 48117
16/03/21 17:34:53 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:34:53 INFO BlockManagerMasterEndpoint: Registering block manager localhost:48117 with 795.3 MB RAM, BlockManagerId(driver, localhost, 48117)
16/03/21 17:34:53 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:34:53 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561892985
16/03/21 17:34:53 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:34:53 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:34:53 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:34:53 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:34:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:34:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:34:53 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:34:53 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=833952153
16/03/21 17:34:53 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 795.3 MB)
16/03/21 17:34:53 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6576, maxMem=833952153
16/03/21 17:34:53 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 795.3 MB)
16/03/21 17:34:53 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:48117 (size: 4.1 KB, free: 795.3 MB)
16/03/21 17:34:53 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:34:53 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:34:53 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:34:53 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:34:53 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:34:53 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:34:53 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561892969
16/03/21 17:34:53 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-835a5b3e-44f4-4e26-a95d-bb02c6fb5fc6/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:34:53 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:34:53 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10724, maxMem=833952153
16/03/21 17:34:53 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 795.3 MB)
16/03/21 17:34:53 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:48117 (size: 166.0 B, free: 795.3 MB)
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: area
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: issue
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: planning
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: permission
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: economy
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: composition
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: agency
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:35:01 INFO PythonRunner: Times: total = 8573, boot = 463, init = 356, finish = 7754
16/03/21 17:35:01 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:35:01 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:35:01 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:35:01 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:35:01 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10890, maxMem=833952153
16/03/21 17:35:01 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 795.3 MB)
16/03/21 17:35:01 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:48117 (size: 155.0 B, free: 795.3 MB)
16/03/21 17:35:01 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8642 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: set
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: bend
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: giant
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): adding to parents: syn =  Synset('colossus.n.02') ; keyword:  person  in syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= [u'giant']
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: astatine
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: present
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: area
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
16/03/21 17:35:02 INFO PythonRunner: Times: total = 252, boot = 157, init = 1, finish = 94
16/03/21 17:35:02 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:35:02 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 282 ms on localhost (2/2)
16/03/21 17:35:02 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:35:02 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.915 s
16/03/21 17:35:02 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:35:02 INFO DAGScheduler: running: Set()
16/03/21 17:35:02 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:35:02 INFO DAGScheduler: failed: Set()
16/03/21 17:35:02 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:35:02 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:35:02 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11045, maxMem=833952153
16/03/21 17:35:02 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 795.3 MB)
16/03/21 17:35:02 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16029, maxMem=833952153
16/03/21 17:35:02 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 795.3 MB)
16/03/21 17:35:02 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:48117 (size: 3.0 KB, free: 795.3 MB)
16/03/21 17:35:02 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:35:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:35:02 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:35:02 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:35:02 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:35:02 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:35:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:35:02 INFO PythonRunner: Times: total = 144, boot = 143, init = 1, finish = 0
16/03/21 17:35:02 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:35:02 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:35:02 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:35:02 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:35:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:35:02 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 160 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'giant']
16/03/21 17:35:02 INFO PythonRunner: Times: total = 167, boot = 166, init = 0, finish = 1
16/03/21 17:35:02 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1239 bytes result sent to driver
16/03/21 17:35:02 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.340 s
16/03/21 17:35:02 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.282534 s
16/03/21 17:35:02 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 182 ms on localhost (2/2)
16/03/21 17:35:02 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:35:02 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:35:02 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:35:02 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:35:02 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:35:02 INFO DAGScheduler: Missing parents: List()
16/03/21 17:35:02 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:35:02 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19076, maxMem=833952153
16/03/21 17:35:02 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 795.3 MB)
16/03/21 17:35:02 INFO MemoryStore: ensureFreeSpace(3374) called with curMem=24892, maxMem=833952153
16/03/21 17:35:02 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 795.3 MB)
16/03/21 17:35:02 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:48117 (size: 3.3 KB, free: 795.3 MB)
16/03/21 17:35:02 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:35:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:35:02 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:35:02 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:35:02 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:35:02 INFO PythonRunner: Times: total = 92, boot = 92, init = 0, finish = 0
16/03/21 17:35:02 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:35:02 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2269 bytes)
16/03/21 17:35:02 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 109 ms on localhost (1/2)
16/03/21 17:35:02 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:35:02 INFO PythonRunner: Times: total = 152, boot = 151, init = 0, finish = 1
16/03/21 17:35:02 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1308 bytes result sent to driver
16/03/21 17:35:02 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.272 s
16/03/21 17:35:02 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.292490 s
16/03/21 17:35:02 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 169 ms on localhost (2/2)
16/03/21 17:35:02 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:35:02 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:35:02 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:35:02 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:35:02 INFO MemoryStore: MemoryStore cleared
16/03/21 17:35:02 INFO BlockManager: BlockManager stopped
16/03/21 17:35:02 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:35:02 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:35:02 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:35:02 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:35:02 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:35:02 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:35:03 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:35:03 INFO SecurityManager: Changing view acls to: root
16/03/21 17:35:03 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:35:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:35:03 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:35:03 INFO Remoting: Starting remoting
16/03/21 17:35:03 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:58440]
16/03/21 17:35:03 INFO Utils: Successfully started service 'sparkDriver' on port 58440.
16/03/21 17:35:03 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:35:03 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:35:03 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-be8515b6-99ba-4039-8458-bb6f166b5de1
16/03/21 17:35:03 INFO MemoryStore: MemoryStore started with capacity 795.3 MB
16/03/21 17:35:03 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-4cb356a3-3b07-4bf0-9137-fc596a695226
16/03/21 17:35:03 INFO HttpServer: Starting HTTP Server
16/03/21 17:35:03 INFO Utils: Successfully started service 'HTTP file server' on port 52066.
16/03/21 17:35:03 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:35:04 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:35:04 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:35:04 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-892ebe27-bd36-4dc6-b4a4-63532ee9842b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:35:04 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561904032
16/03/21 17:35:04 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:35:04 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:35:04 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33534.
16/03/21 17:35:04 INFO NettyBlockTransferService: Server created on 33534
16/03/21 17:35:04 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:35:04 INFO BlockManagerMasterEndpoint: Registering block manager localhost:33534 with 795.3 MB RAM, BlockManagerId(driver, localhost, 33534)
16/03/21 17:35:04 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:35:04 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561904055
16/03/21 17:35:04 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:35:04 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:35:04 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:35:04 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:35:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:35:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:35:04 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:35:04 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=833952153
16/03/21 17:35:04 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 795.3 MB)
16/03/21 17:35:04 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=833952153
16/03/21 17:35:04 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 795.3 MB)
16/03/21 17:35:04 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:33534 (size: 4.1 KB, free: 795.3 MB)
16/03/21 17:35:04 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:35:04 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:35:04 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:35:04 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:35:04 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:35:04 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:35:04 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561904032
16/03/21 17:35:04 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-892ebe27-bd36-4dc6-b4a4-63532ee9842b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:35:04 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:35:04 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=833952153
16/03/21 17:35:04 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 795.3 MB)
16/03/21 17:35:04 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:33534 (size: 166.0 B, free: 795.3 MB)
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: area
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: issue
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: planning
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: permission
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: economy
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: composition
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: agency
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:35:12 INFO PythonRunner: Times: total = 7826, boot = 461, init = 356, finish = 7009
16/03/21 17:35:12 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:35:12 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:35:12 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:35:12 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:35:12 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7896 ms on localhost (1/2)
16/03/21 17:35:12 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=833952153
16/03/21 17:35:12 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 795.3 MB)
16/03/21 17:35:12 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:33534 (size: 155.0 B, free: 795.3 MB)
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: set
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: bend
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: giant
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): adding to parents: syn =  Synset('colossus.n.02') ; keyword:  reputation  in syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= [u'giant']
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: astatine
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: present
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: area
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
16/03/21 17:35:12 INFO PythonRunner: Times: total = 262, boot = 167, init = 0, finish = 95
16/03/21 17:35:12 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:35:12 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 299 ms on localhost (2/2)
16/03/21 17:35:12 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:35:12 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.180 s
16/03/21 17:35:12 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:35:12 INFO DAGScheduler: running: Set()
16/03/21 17:35:12 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:35:12 INFO DAGScheduler: failed: Set()
16/03/21 17:35:12 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:35:12 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:35:12 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=833952153
16/03/21 17:35:12 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 795.3 MB)
16/03/21 17:35:12 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16030, maxMem=833952153
16/03/21 17:35:12 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 795.3 MB)
16/03/21 17:35:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:33534 (size: 3.0 KB, free: 795.3 MB)
16/03/21 17:35:12 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:35:12 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:35:12 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:35:12 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:35:12 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:35:12 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:35:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:35:12 INFO PythonRunner: Times: total = 164, boot = 164, init = 0, finish = 0
16/03/21 17:35:12 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:35:12 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:35:12 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:35:12 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:35:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:35:12 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 192 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'giant']
16/03/21 17:35:12 INFO PythonRunner: Times: total = 204, boot = 203, init = 0, finish = 1
16/03/21 17:35:12 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1239 bytes result sent to driver
16/03/21 17:35:12 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.398 s
16/03/21 17:35:12 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.620735 s
16/03/21 17:35:12 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 217 ms on localhost (2/2)
16/03/21 17:35:12 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:35:12 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:35:12 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:35:12 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:35:12 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:35:12 INFO DAGScheduler: Missing parents: List()
16/03/21 17:35:12 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:35:12 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19078, maxMem=833952153
16/03/21 17:35:12 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 795.3 MB)
16/03/21 17:35:12 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24894, maxMem=833952153
16/03/21 17:35:12 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 795.3 MB)
16/03/21 17:35:12 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:33534 (size: 3.3 KB, free: 795.3 MB)
16/03/21 17:35:12 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:35:12 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:35:12 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:35:12 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:35:12 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:35:13 INFO PythonRunner: Times: total = 88, boot = 88, init = 0, finish = 0
16/03/21 17:35:13 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:35:13 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2269 bytes)
16/03/21 17:35:13 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 106 ms on localhost (1/2)
16/03/21 17:35:13 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:35:13 INFO PythonRunner: Times: total = 167, boot = 167, init = 0, finish = 0
16/03/21 17:35:13 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1308 bytes result sent to driver
16/03/21 17:35:13 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 192 ms on localhost (2/2)
16/03/21 17:35:13 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:35:13 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.294 s
16/03/21 17:35:13 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.309938 s
16/03/21 17:35:13 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:35:13 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:35:13 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:35:13 INFO MemoryStore: MemoryStore cleared
16/03/21 17:35:13 INFO BlockManager: BlockManager stopped
16/03/21 17:35:13 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:35:13 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:35:13 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:35:13 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:35:13 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:35:13 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:35:14 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:35:14 INFO SecurityManager: Changing view acls to: root
16/03/21 17:35:14 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:35:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:35:14 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:35:14 INFO Remoting: Starting remoting
16/03/21 17:35:14 INFO Utils: Successfully started service 'sparkDriver' on port 35239.
16/03/21 17:35:14 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:35239]
16/03/21 17:35:14 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:35:14 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:35:14 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1d00df5f-7de2-45e2-8741-c09edf31a8aa
16/03/21 17:35:14 INFO MemoryStore: MemoryStore started with capacity 795.3 MB
16/03/21 17:35:14 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-dd04554f-686e-453b-8fe6-04f2ad4e794a
16/03/21 17:35:14 INFO HttpServer: Starting HTTP Server
16/03/21 17:35:14 INFO Utils: Successfully started service 'HTTP file server' on port 60725.
16/03/21 17:35:14 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:35:14 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:35:14 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:35:14 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-0513a02c-b291-4359-8a89-dc6b1af3812b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:35:14 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561914634
16/03/21 17:35:14 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:35:14 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:35:14 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51229.
16/03/21 17:35:14 INFO NettyBlockTransferService: Server created on 51229
16/03/21 17:35:14 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:35:14 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51229 with 795.3 MB RAM, BlockManagerId(driver, localhost, 51229)
16/03/21 17:35:14 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:35:14 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561914650
16/03/21 17:35:14 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:35:14 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:35:14 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:35:14 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:35:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:35:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:35:14 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:35:14 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=833952153
16/03/21 17:35:14 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 795.3 MB)
16/03/21 17:35:14 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=833952153
16/03/21 17:35:14 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 795.3 MB)
16/03/21 17:35:14 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51229 (size: 4.1 KB, free: 795.3 MB)
16/03/21 17:35:14 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:35:14 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:35:14 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:35:14 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:35:14 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:35:14 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:35:14 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561914634
16/03/21 17:35:14 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-0513a02c-b291-4359-8a89-dc6b1af3812b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:35:14 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:35:14 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=833952153
16/03/21 17:35:14 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 795.3 MB)
16/03/21 17:35:14 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:51229 (size: 166.0 B, free: 795.3 MB)
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: area
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: issue
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: planning
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: permission
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: economy
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: composition
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: agency
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:35:23 INFO PythonRunner: Times: total = 8976, boot = 608, init = 423, finish = 7945
16/03/21 17:35:23 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:35:23 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:35:23 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:35:23 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:35:23 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=833952153
16/03/21 17:35:23 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 795.3 MB)
16/03/21 17:35:23 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:51229 (size: 155.0 B, free: 795.3 MB)
16/03/21 17:35:23 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9106 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: set
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: bend
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: giant
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: astatine
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: present
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  time  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: area
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/21 17:35:24 INFO PythonRunner: Times: total = 343, boot = 208, init = 0, finish = 135
16/03/21 17:35:24 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:35:24 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.486 s
16/03/21 17:35:24 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:35:24 INFO DAGScheduler: running: Set()
16/03/21 17:35:24 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:35:24 INFO DAGScheduler: failed: Set()
16/03/21 17:35:24 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:35:24 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:35:24 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 396 ms on localhost (2/2)
16/03/21 17:35:24 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:35:24 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=833952153
16/03/21 17:35:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 795.3 MB)
16/03/21 17:35:24 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16030, maxMem=833952153
16/03/21 17:35:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 795.3 MB)
16/03/21 17:35:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51229 (size: 3.0 KB, free: 795.3 MB)
16/03/21 17:35:24 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:35:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:35:24 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:35:24 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:35:24 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:35:24 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:35:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:35:24 INFO PythonRunner: Times: total = 174, boot = 173, init = 0, finish = 1
16/03/21 17:35:24 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:35:24 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:35:24 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:35:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:35:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:35:24 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 206 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'present']
16/03/21 17:35:24 INFO PythonRunner: Times: total = 186, boot = 185, init = 1, finish = 0
16/03/21 17:35:24 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/21 17:35:24 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 208 ms on localhost (2/2)
16/03/21 17:35:24 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:35:24 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.395 s
16/03/21 17:35:24 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.953717 s
16/03/21 17:35:25 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:35:25 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:35:25 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:35:25 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:35:25 INFO DAGScheduler: Missing parents: List()
16/03/21 17:35:25 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:35:25 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19078, maxMem=833952153
16/03/21 17:35:25 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 795.3 MB)
16/03/21 17:35:25 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24894, maxMem=833952153
16/03/21 17:35:25 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 795.3 MB)
16/03/21 17:35:25 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:51229 (size: 3.3 KB, free: 795.3 MB)
16/03/21 17:35:25 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:35:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:35:25 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:35:25 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:35:25 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:35:25 INFO PythonRunner: Times: total = 22, boot = 22, init = 0, finish = 0
16/03/21 17:35:25 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:35:25 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/21 17:35:25 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 37 ms on localhost (1/2)
16/03/21 17:35:25 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:35:25 INFO PythonRunner: Times: total = 201, boot = 201, init = 0, finish = 0
16/03/21 17:35:25 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1310 bytes result sent to driver
16/03/21 17:35:25 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 218 ms on localhost (2/2)
16/03/21 17:35:25 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:35:25 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.256 s
16/03/21 17:35:25 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.276846 s
16/03/21 17:35:25 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:35:25 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:35:25 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:35:25 INFO MemoryStore: MemoryStore cleared
16/03/21 17:35:25 INFO BlockManager: BlockManager stopped
16/03/21 17:35:25 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:35:25 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:35:25 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:35:25 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:35:25 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:35:25 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:35:26 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:35:26 INFO SecurityManager: Changing view acls to: root
16/03/21 17:35:26 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:35:26 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:35:26 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:35:26 INFO Remoting: Starting remoting
16/03/21 17:35:26 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:50300]
16/03/21 17:35:26 INFO Utils: Successfully started service 'sparkDriver' on port 50300.
16/03/21 17:35:26 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:35:26 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:35:26 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ba55454f-3e2b-40c7-abe1-f92487e692e5
16/03/21 17:35:26 INFO MemoryStore: MemoryStore started with capacity 795.3 MB
16/03/21 17:35:26 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-1d1c84a5-336f-4338-a3bf-ec6d030501dc
16/03/21 17:35:26 INFO HttpServer: Starting HTTP Server
16/03/21 17:35:26 INFO Utils: Successfully started service 'HTTP file server' on port 50766.
16/03/21 17:35:26 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:35:26 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:35:26 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:35:26 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-f3a4dba8-bd9a-4b87-92ca-faeec2d17169/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:35:26 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561926791
16/03/21 17:35:26 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:35:26 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:35:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37975.
16/03/21 17:35:26 INFO NettyBlockTransferService: Server created on 37975
16/03/21 17:35:26 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:35:26 INFO BlockManagerMasterEndpoint: Registering block manager localhost:37975 with 795.3 MB RAM, BlockManagerId(driver, localhost, 37975)
16/03/21 17:35:26 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:35:26 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561926805
16/03/21 17:35:26 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:35:26 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:35:26 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:35:26 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:35:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:35:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:35:26 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:35:26 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=833952153
16/03/21 17:35:26 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 795.3 MB)
16/03/21 17:35:26 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=833952153
16/03/21 17:35:26 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 795.3 MB)
16/03/21 17:35:26 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:37975 (size: 4.1 KB, free: 795.3 MB)
16/03/21 17:35:26 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:35:26 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:35:26 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:35:26 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:35:26 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:35:27 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:35:27 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561926791
16/03/21 17:35:27 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-f3a4dba8-bd9a-4b87-92ca-faeec2d17169/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:35:27 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:35:27 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=833952153
16/03/21 17:35:27 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 795.3 MB)
16/03/21 17:35:27 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:37975 (size: 166.0 B, free: 795.3 MB)
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: area
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: issue
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: planning
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: permission
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: economy
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: composition
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: agency
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:35:35 INFO PythonRunner: Times: total = 8393, boot = 564, init = 373, finish = 7456
16/03/21 17:35:35 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:35:35 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:35:35 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:35:35 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:35:35 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=833952153
16/03/21 17:35:35 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 795.3 MB)
16/03/21 17:35:35 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:37975 (size: 155.0 B, free: 795.3 MB)
16/03/21 17:35:35 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8533 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: set
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: bend
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: giant
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: astatine
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: present
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  position  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: area
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
16/03/21 17:35:35 INFO PythonRunner: Times: total = 337, boot = 219, init = 1, finish = 117
16/03/21 17:35:35 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:35:35 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.894 s
16/03/21 17:35:35 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:35:35 INFO DAGScheduler: running: Set()
16/03/21 17:35:35 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:35:35 INFO DAGScheduler: failed: Set()
16/03/21 17:35:35 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:35:35 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:35:35 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=833952153
16/03/21 17:35:35 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 795.3 MB)
16/03/21 17:35:35 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 363 ms on localhost (2/2)
16/03/21 17:35:35 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:35:35 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16030, maxMem=833952153
16/03/21 17:35:35 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 795.3 MB)
16/03/21 17:35:35 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:37975 (size: 3.0 KB, free: 795.3 MB)
16/03/21 17:35:35 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:35:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:35:35 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:35:35 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:35:35 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:35:35 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:35:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/21 17:35:36 INFO PythonRunner: Times: total = 144, boot = 144, init = 0, finish = 0
16/03/21 17:35:36 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:35:36 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:35:36 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:35:36 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:35:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:35:36 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 169 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'metropolitan']
16/03/21 17:35:36 INFO PythonRunner: Times: total = 180, boot = 179, init = 0, finish = 1
16/03/21 17:35:36 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1246 bytes result sent to driver
16/03/21 17:35:36 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.349 s
16/03/21 17:35:36 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.278893 s
16/03/21 17:35:36 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 197 ms on localhost (2/2)
16/03/21 17:35:36 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:35:36 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:35:36 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:35:36 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:35:36 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:35:36 INFO DAGScheduler: Missing parents: List()
16/03/21 17:35:36 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:35:36 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19078, maxMem=833952153
16/03/21 17:35:36 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 795.3 MB)
16/03/21 17:35:36 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24894, maxMem=833952153
16/03/21 17:35:36 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 795.3 MB)
16/03/21 17:35:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:37975 (size: 3.3 KB, free: 795.3 MB)
16/03/21 17:35:36 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:35:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:35:36 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:35:36 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:35:36 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:35:36 INFO PythonRunner: Times: total = 104, boot = 104, init = 0, finish = 0
16/03/21 17:35:36 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:35:36 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2276 bytes)
16/03/21 17:35:36 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 119 ms on localhost (1/2)
16/03/21 17:35:36 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:35:36 INFO PythonRunner: Times: total = 198, boot = 192, init = 5, finish = 1
16/03/21 17:35:36 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1315 bytes result sent to driver
16/03/21 17:35:36 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 214 ms on localhost (2/2)
16/03/21 17:35:36 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:35:36 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.324 s
16/03/21 17:35:36 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.344332 s
16/03/21 17:35:36 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:35:36 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:35:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:35:36 INFO MemoryStore: MemoryStore cleared
16/03/21 17:35:36 INFO BlockManager: BlockManager stopped
16/03/21 17:35:36 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:35:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:35:36 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:35:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:35:36 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:35:36 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:35:37 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:35:37 INFO SecurityManager: Changing view acls to: root
16/03/21 17:35:37 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:35:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:35:37 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:35:37 INFO Remoting: Starting remoting
16/03/21 17:35:37 INFO Utils: Successfully started service 'sparkDriver' on port 43796.
16/03/21 17:35:37 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:43796]
16/03/21 17:35:37 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:35:37 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:35:37 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-58df598c-be82-4963-b77a-8da44503f64a
16/03/21 17:35:37 INFO MemoryStore: MemoryStore started with capacity 795.3 MB
16/03/21 17:35:37 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-fc54c882-08bd-4ec8-bc68-707325aa69e0
16/03/21 17:35:37 INFO HttpServer: Starting HTTP Server
16/03/21 17:35:37 INFO Utils: Successfully started service 'HTTP file server' on port 55940.
16/03/21 17:35:37 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:35:38 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:35:38 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:35:38 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-45a1ffa8-5643-48b6-8d1a-ae88faf09e5b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:35:38 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561938249
16/03/21 17:35:38 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:35:38 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:35:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59257.
16/03/21 17:35:38 INFO NettyBlockTransferService: Server created on 59257
16/03/21 17:35:38 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:35:38 INFO BlockManagerMasterEndpoint: Registering block manager localhost:59257 with 795.3 MB RAM, BlockManagerId(driver, localhost, 59257)
16/03/21 17:35:38 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:35:38 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561938264
16/03/21 17:35:38 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:35:38 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:35:38 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:35:38 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:35:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:35:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:35:38 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:35:38 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=833952153
16/03/21 17:35:38 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 795.3 MB)
16/03/21 17:35:38 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6576, maxMem=833952153
16/03/21 17:35:38 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 795.3 MB)
16/03/21 17:35:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:59257 (size: 4.1 KB, free: 795.3 MB)
16/03/21 17:35:38 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:35:38 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:35:38 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:35:38 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/21 17:35:38 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:35:38 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:35:38 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561938249
16/03/21 17:35:38 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-45a1ffa8-5643-48b6-8d1a-ae88faf09e5b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:35:38 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:35:38 INFO MemoryStore: ensureFreeSpace(166) called with curMem=10725, maxMem=833952153
16/03/21 17:35:38 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 166.0 B, free 795.3 MB)
16/03/21 17:35:38 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:59257 (size: 166.0 B, free: 795.3 MB)
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: area
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: issue
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: planning
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: permission
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: economy
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: composition
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: agency
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:35:47 INFO PythonRunner: Times: total = 8501, boot = 501, init = 375, finish = 7625
16/03/21 17:35:47 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:35:47 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/21 17:35:47 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:35:47 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:35:47 INFO MemoryStore: ensureFreeSpace(155) called with curMem=10891, maxMem=833952153
16/03/21 17:35:47 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 155.0 B, free 795.3 MB)
16/03/21 17:35:47 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:59257 (size: 155.0 B, free: 795.3 MB)
16/03/21 17:35:47 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8592 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: set
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: bend
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: giant
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: astatine
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: present
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: area
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/21 17:35:47 INFO PythonRunner: Times: total = 327, boot = 230, init = 0, finish = 97
16/03/21 17:35:47 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:35:47 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 366 ms on localhost (2/2)
16/03/21 17:35:47 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:35:47 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.934 s
16/03/21 17:35:47 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:35:47 INFO DAGScheduler: running: Set()
16/03/21 17:35:47 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:35:47 INFO DAGScheduler: failed: Set()
16/03/21 17:35:47 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:35:47 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/21 17:35:47 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11046, maxMem=833952153
16/03/21 17:35:47 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 795.3 MB)
16/03/21 17:35:47 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=16030, maxMem=833952153
16/03/21 17:35:47 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 795.3 MB)
16/03/21 17:35:47 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:59257 (size: 3.0 KB, free: 795.3 MB)
16/03/21 17:35:47 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:35:47 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:35:47 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:35:47 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:35:47 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:35:47 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:35:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:35:47 INFO PythonRunner: Times: total = 160, boot = 159, init = 1, finish = 0
16/03/21 17:35:47 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:35:47 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:35:47 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:35:47 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 182 ms on localhost (1/2)
16/03/21 17:35:47 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:35:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', 'None']
16/03/21 17:35:48 INFO PythonRunner: Times: total = 206, boot = 205, init = 1, finish = 0
16/03/21 17:35:48 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1227 bytes result sent to driver
16/03/21 17:35:48 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 225 ms on localhost (2/2)
16/03/21 17:35:48 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:35:48 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.398 s
16/03/21 17:35:48 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.374088 s
16/03/21 17:35:48 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/21 17:35:48 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/21 17:35:48 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:35:48 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:35:48 INFO DAGScheduler: Missing parents: List()
16/03/21 17:35:48 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/21 17:35:48 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19078, maxMem=833952153
16/03/21 17:35:48 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 795.3 MB)
16/03/21 17:35:48 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24894, maxMem=833952153
16/03/21 17:35:48 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 795.3 MB)
16/03/21 17:35:48 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:59257 (size: 3.3 KB, free: 795.3 MB)
16/03/21 17:35:48 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:35:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/21 17:35:48 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:35:48 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:35:48 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:35:48 INFO PythonRunner: Times: total = 77, boot = 76, init = 1, finish = 0
16/03/21 17:35:48 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:35:48 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2257 bytes)
16/03/21 17:35:48 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 94 ms on localhost (1/2)
16/03/21 17:35:48 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:35:48 INFO PythonRunner: Times: total = 136, boot = 136, init = 0, finish = 0
16/03/21 17:35:48 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1296 bytes result sent to driver
16/03/21 17:35:48 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.252 s
16/03/21 17:35:48 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.273219 s
16/03/21 17:35:48 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 172 ms on localhost (2/2)
16/03/21 17:35:48 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:35:48 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:35:48 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:35:48 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:35:48 INFO MemoryStore: MemoryStore cleared
16/03/21 17:35:48 INFO BlockManager: BlockManager stopped
16/03/21 17:35:48 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:35:48 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:35:48 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:35:48 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:35:48 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:35:48 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:35:49 INFO SparkContext: Running Spark version 1.5.2
16/03/21 17:35:49 INFO SecurityManager: Changing view acls to: root
16/03/21 17:35:49 INFO SecurityManager: Changing modify acls to: root
16/03/21 17:35:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/21 17:35:49 INFO Slf4jLogger: Slf4jLogger started
16/03/21 17:35:49 INFO Remoting: Starting remoting
16/03/21 17:35:49 INFO Utils: Successfully started service 'sparkDriver' on port 54043.
16/03/21 17:35:49 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:54043]
16/03/21 17:35:49 INFO SparkEnv: Registering MapOutputTracker
16/03/21 17:35:49 INFO SparkEnv: Registering BlockManagerMaster
16/03/21 17:35:49 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-89013d0c-0eb1-49c4-8a2c-99b83bf2c734
16/03/21 17:35:49 INFO MemoryStore: MemoryStore started with capacity 793.6 MB
16/03/21 17:35:49 INFO HttpFileServer: HTTP File server directory is /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/httpd-f5eed515-9105-45d8-864a-7f9454218363
16/03/21 17:35:49 INFO HttpServer: Starting HTTP Server
16/03/21 17:35:49 INFO Utils: Successfully started service 'HTTP file server' on port 51860.
16/03/21 17:35:49 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/21 17:35:50 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/21 17:35:50 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/21 17:35:50 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-63b5746c-a31b-48d6-8d59-66a2edb846dc/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:35:50 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561950300
16/03/21 17:35:50 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/21 17:35:50 INFO Executor: Starting executor ID driver on host localhost
16/03/21 17:35:50 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36935.
16/03/21 17:35:50 INFO NettyBlockTransferService: Server created on 36935
16/03/21 17:35:50 INFO BlockManagerMaster: Trying to register BlockManager
16/03/21 17:35:50 INFO BlockManagerMasterEndpoint: Registering block manager localhost:36935 with 793.6 MB RAM, BlockManagerId(driver, localhost, 36935)
16/03/21 17:35:50 INFO BlockManagerMaster: Registered BlockManager
16/03/21 17:35:50 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1458561950315
16/03/21 17:35:50 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230
16/03/21 17:35:50 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/21 17:35:50 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) with 2 output partitions
16/03/21 17:35:50 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/21 17:35:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/21 17:35:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/21 17:35:50 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230), which has no missing parents
16/03/21 17:35:50 INFO MemoryStore: ensureFreeSpace(6560) called with curMem=0, maxMem=832147292
16/03/21 17:35:50 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 793.6 MB)
16/03/21 17:35:50 INFO MemoryStore: ensureFreeSpace(4140) called with curMem=6560, maxMem=832147292
16/03/21 17:35:50 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 793.6 MB)
16/03/21 17:35:50 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:36935 (size: 4.0 KB, free: 793.6 MB)
16/03/21 17:35:50 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/21 17:35:50 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/21 17:35:50 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/21 17:35:50 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2927 bytes)
16/03/21 17:35:50 INFO ExecutorAllocationManager: New executor driver has registered (new total is 1)
16/03/21 17:35:50 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/21 17:35:50 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458561950300
16/03/21 17:35:50 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/userFiles-63b5746c-a31b-48d6-8d59-66a2edb846dc/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/21 17:35:50 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/21 17:35:50 INFO MemoryStore: ensureFreeSpace(634) called with curMem=10700, maxMem=832147292
16/03/21 17:35:50 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 634.0 B, free 793.6 MB)
16/03/21 17:35:50 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:36935 (size: 634.0 B, free: 793.6 MB)
mapFunction(): freqterms1: serving
mapFunction(): freqterms1: Madras
mapFunction(): freqterms1: Bengal
mapFunction(): freqterms1: course
mapFunction(): freqterms1: relation
mapFunction(): freqterms1: geography
mapFunction(): freqterms1: group
mapFunction(): freqterms1: decay
mapFunction(): freqterms1: program
mapFunction(): freqterms1: Tamil
mapFunction(): freqterms1: exceptional
mapFunction(): freqterms1: Bay
mapFunction(): freqterms1: formulating
mapFunction(): freqterms1: serves
mapFunction(): freqterms1: item
mapFunction(): freqterms1: miles
mapFunction(): freqterms1: unstable
mapFunction(): freqterms1: including
mapFunction(): freqterms1: people
mapFunction(): freqterms1: series
mapFunction(): freqterms1: Christianity
mapFunction(): freqterms1: culture
mapFunction(): freqterms1: meters
mapFunction(): freqterms1: special
mapFunction(): freqterms1: 0.621371
mapFunction(): freqterms1: Orthodox
mapFunction(): freqterms1: definite
mapFunction(): freqterms1: boundary
mapFunction(): freqterms1: business
mapFunction(): freqterms1: importance
mapFunction(): freqterms1: equivalent
mapFunction(): freqterms1: thorium
mapFunction(): freqterms1: approval
mapFunction(): freqterms1: providing
mapFunction(): freqterms1: region
mapFunction(): freqterms1: title
mapFunction(): freqterms1: equal
mapFunction(): freqterms1: length
mapFunction(): freqterms1: resulting
mapFunction(): freqterms1: act
mapFunction(): freqterms1: action
mapFunction(): freqterms1: whole
mapFunction(): freqterms1: businesses
mapFunction(): freqterms1: 1000
mapFunction(): freqterms1: formerly
mapFunction(): freqterms1: period
mapFunction(): freqterms1: highly
mapFunction(): freqterms1: production
mapFunction(): freqterms1: indefinite
mapFunction(): freqterms1: unit
16/03/21 17:35:59 INFO PythonRunner: Times: total = 9232, boot = 497, init = 381, finish = 8354
16/03/21 17:35:59 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1731 bytes result sent to driver
16/03/21 17:35:59 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2968 bytes)
16/03/21 17:35:59 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/21 17:35:59 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/21 17:35:59 INFO MemoryStore: ensureFreeSpace(656) called with curMem=11334, maxMem=832147292
16/03/21 17:35:59 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 656.0 B, free 793.6 MB)
16/03/21 17:35:59 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9314 ms on localhost (1/2)
16/03/21 17:35:59 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:36935 (size: 656.0 B, free: 793.6 MB)
mapFunction(): freqterms1: city
mapFunction(): freqterms1: use
mapFunction(): freqterms1: consumption
mapFunction(): freqterms1: Eastern
mapFunction(): freqterms1: stretch
mapFunction(): freqterms1: archbishop
mapFunction(): freqterms1: system
mapFunction(): freqterms1: halogen
mapFunction(): freqterms1: continuous
mapFunction(): freqterms1: western
mapFunction(): freqterms1: particular
mapFunction(): freqterms1: given
mapFunction(): freqterms1: kind
mapFunction(): freqterms1: official
mapFunction(): freqterms1: patriarch
mapFunction(): freqterms1: Church
mapFunction(): freqterms1: distribution
mapFunction(): freqterms1: property
mapFunction(): freqterms1: distinguished
mapFunction(): freqterms1: metric
mapFunction(): freqterms1: heaviest
mapFunction(): freqterms1: purposes
mapFunction(): freqterms1: general
mapFunction(): freqterms1: something
mapFunction(): freqterms1: bishop
mapFunction(): freqterms1: things
mapFunction(): freqterms1: belong
mapFunction(): freqterms1: uranium
mapFunction(): freqterms1: arrangement
mapFunction(): freqterms1: parts
mapFunction(): freqterms1: speech
mapFunction(): freqterms1: geographical
mapFunction(): freqterms1: spatial
mapFunction(): freqterms1: Nadu
mapFunction(): freqterms1: circular
mapFunction(): freqterms1: product
mapFunction(): freqterms1: used
mapFunction(): freqterms1: usually
mapFunction(): freqterms1: moment
mapFunction(): freqterms1: purpose
mapFunction(): freqterms1: segment
mapFunction(): freqterms1: radioactive
mapFunction(): freqterms1: happening
mapFunction(): freqterms1: curve
mapFunction(): freqterms1: together
mapFunction(): freqterms1: element
mapFunction(): freqterms1: person
mapFunction(): freqterms1: reputation
mapFunction(): freqterms1: time
mapFunction(): freqterms1: position
mapFunction(): freqterms1: quantity
16/03/21 17:36:01 INFO PythonRunner: Times: total = 1373, boot = 165, init = 1, finish = 1207
16/03/21 17:36:01 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1731 bytes result sent to driver
16/03/21 17:36:01 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1424 ms on localhost (2/2)
16/03/21 17:36:01 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/21 17:36:01 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) finished in 10.728 s
16/03/21 17:36:01 INFO DAGScheduler: looking for newly runnable stages
16/03/21 17:36:01 INFO DAGScheduler: running: Set()
16/03/21 17:36:01 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/21 17:36:01 INFO DAGScheduler: failed: Set()
16/03/21 17:36:01 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/21 17:36:01 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230), which is now runnable
16/03/21 17:36:01 INFO MemoryStore: ensureFreeSpace(4976) called with curMem=11990, maxMem=832147292
16/03/21 17:36:01 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 793.6 MB)
16/03/21 17:36:01 INFO MemoryStore: ensureFreeSpace(3041) called with curMem=16966, maxMem=832147292
16/03/21 17:36:01 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 793.6 MB)
16/03/21 17:36:01 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:36935 (size: 3.0 KB, free: 793.6 MB)
16/03/21 17:36:01 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/21 17:36:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/21 17:36:01 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/21 17:36:01 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:36:01 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/21 17:36:01 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 2 blocks
16/03/21 17:36:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:36:01 INFO PythonRunner: Times: total = 169, boot = 169, init = 0, finish = 0
16/03/21 17:36:01 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/21 17:36:01 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/21 17:36:01 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/21 17:36:01 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/21 17:36:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/21 17:36:01 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 215 ms on localhost (1/2)
16/03/21 17:36:01 INFO PythonRunner: Times: total = 180, boot = 177, init = 0, finish = 3
16/03/21 17:36:01 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 10972 bytes result sent to driver
16/03/21 17:36:01 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 196 ms on localhost (2/2)
16/03/21 17:36:01 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/21 17:36:01 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) finished in 0.398 s
16/03/21 17:36:01 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230, took 11.154863 s
16/03/21 17:36:01 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230
16/03/21 17:36:01 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) with 2 output partitions
16/03/21 17:36:01 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/21 17:36:01 INFO DAGScheduler: Parents of final stage: List()
16/03/21 17:36:01 INFO DAGScheduler: Missing parents: List()
16/03/21 17:36:01 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230), which has no missing parents
16/03/21 17:36:01 INFO MemoryStore: ensureFreeSpace(5872) called with curMem=20007, maxMem=832147292
16/03/21 17:36:01 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 793.6 MB)
16/03/21 17:36:01 INFO MemoryStore: ensureFreeSpace(3416) called with curMem=25879, maxMem=832147292
16/03/21 17:36:01 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 793.6 MB)
16/03/21 17:36:01 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:36935 (size: 3.3 KB, free: 793.6 MB)
16/03/21 17:36:01 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/21 17:36:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/21 17:36:01 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/21 17:36:01 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/21 17:36:01 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/21 17:36:01 INFO PythonRunner: Times: total = 103, boot = 102, init = 1, finish = 0
16/03/21 17:36:01 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/21 17:36:01 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 11918 bytes)
16/03/21 17:36:01 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 120 ms on localhost (1/2)
16/03/21 17:36:01 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/21 17:36:02 INFO PythonRunner: Times: total = 157, boot = 156, init = 0, finish = 1
16/03/21 17:36:02 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 11279 bytes result sent to driver
16/03/21 17:36:02 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 198 ms on localhost (2/2)
16/03/21 17:36:02 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/21 17:36:02 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) finished in 0.313 s
16/03/21 17:36:02 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230, took 0.323865 s
16/03/21 17:36:02 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/21 17:36:02 INFO DAGScheduler: Stopping DAGScheduler
16/03/21 17:36:02 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/21 17:36:02 INFO MemoryStore: MemoryStore cleared
16/03/21 17:36:02 INFO BlockManager: BlockManager stopped
16/03/21 17:36:02 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/21 17:36:02 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/21 17:36:02 INFO SparkContext: Successfully stopped SparkContext
16/03/21 17:36:02 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/21 17:36:02 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/21 17:36:02 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/21 17:38:02 INFO ShutdownHookManager: Shutdown hook called
16/03/21 17:38:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/pyspark-f25b6d62-cd1f-48af-86ed-d61a395fd838
16/03/21 17:38:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/pyspark-f357f7c8-2ea9-4993-b2c1-1874c6dd89b7
16/03/21 17:38:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/pyspark-0a354d75-e9ee-491b-a9b5-abcb2aca520a
16/03/21 17:38:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/pyspark-02d227a0-16c8-4ffa-8722-986b4f2279ed
16/03/21 17:38:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/pyspark-90e8d802-a4f3-4590-8a73-8416294e94e2
16/03/21 17:38:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/pyspark-1532f666-84aa-4973-92ab-addf96d69483
16/03/21 17:38:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/pyspark-bdb75d98-0a4a-404a-b07c-8c74c231563f
16/03/21 17:38:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/pyspark-ae616642-cc6c-4765-ad1e-9791f4f53003
16/03/21 17:38:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/pyspark-9cf9ed15-49be-4f46-906d-aa95a7ed2d9b
16/03/21 17:38:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/pyspark-6b15ce50-8ee2-4b93-af65-e346e4909df6
16/03/21 17:38:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/pyspark-f443ceca-a98e-4074-8bbc-cda1183a8762
16/03/21 17:38:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/pyspark-65189a64-fece-4651-8327-c043bce99545
16/03/21 17:38:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/pyspark-ececcda4-9795-4da4-b5d6-dc3e7970b370
16/03/21 17:38:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/pyspark-fc7923c1-3007-48b1-9273-5279725af165
16/03/21 17:38:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/pyspark-00867156-c4ad-4dba-ab4a-ced7b815852b
16/03/21 17:38:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/pyspark-075b5809-a920-4541-b3f0-2dc5f236bf1b
16/03/21 17:38:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/pyspark-6d002be4-bbeb-427a-bd69-9561b42fccea
16/03/21 17:38:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/pyspark-2eb61b73-d230-4823-be9b-d98f2c007786
16/03/21 17:38:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/pyspark-3463e460-1450-4eef-b3cc-b37b41db2821
16/03/21 17:38:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/pyspark-dceb716e-af5b-4d3d-a939-3aa4a3d776d4
16/03/21 17:38:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/pyspark-e8a25a38-2785-41ff-90b4-fceb6d2f4c7f
16/03/21 17:38:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/pyspark-169d39ee-1e2c-4e1f-bd50-892d9d0eac4a
16/03/21 17:38:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/pyspark-6d23b171-5d7c-49de-97b9-60f657b18114
16/03/21 17:38:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/pyspark-db2e6fa3-1608-4ad3-8dd5-94c90e680875
16/03/21 17:38:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c/pyspark-a8603a65-a19a-4eb7-8a87-087e5958d005
16/03/21 17:38:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-852b4f48-094b-4740-a167-6c24b30e1b1c
