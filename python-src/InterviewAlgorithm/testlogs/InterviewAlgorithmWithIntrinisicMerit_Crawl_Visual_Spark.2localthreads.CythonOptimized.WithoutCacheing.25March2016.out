mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: serving
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: formerly
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: people
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: culture
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/25 13:08:22 INFO PythonRunner: Times: total = 8886, boot = 490, init = 436, finish = 7960
16/03/25 13:08:22 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:08:22 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 8.983 s
16/03/25 13:08:22 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8998 ms on localhost (2/2)
16/03/25 13:08:22 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:08:22 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:08:22 INFO DAGScheduler: running: Set()
16/03/25 13:08:22 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:08:22 INFO DAGScheduler: failed: Set()
16/03/25 13:08:22 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:08:22 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:08:22 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11160, maxMem=555755765
16/03/25 13:08:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.0 MB)
16/03/25 13:08:22 INFO MemoryStore: ensureFreeSpace(3057) called with curMem=16144, maxMem=555755765
16/03/25 13:08:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.0 MB)
16/03/25 13:08:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:37523 (size: 3.0 KB, free: 530.0 MB)
16/03/25 13:08:22 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:08:22 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:08:22 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:08:22 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:08:22 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:08:22 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:08:22 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:08:22 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:08:22 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:08:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/25 13:08:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
reduceFunction_Parents(): returns= ['None', u'area', 'None']
16/03/25 13:08:22 INFO PythonRunner: Times: total = 64, boot = 63, init = 0, finish = 1
16/03/25 13:08:22 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1280 bytes result sent to driver
16/03/25 13:08:22 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 79 ms on localhost (1/2)
16/03/25 13:08:22 INFO PythonRunner: Times: total = 360, boot = 359, init = 0, finish = 1
16/03/25 13:08:22 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:08:22 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 379 ms on localhost (2/2)
16/03/25 13:08:22 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:08:22 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.376 s
16/03/25 13:08:22 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 9.450358 s
16/03/25 13:08:23 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:08:23 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:08:23 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:08:23 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:08:23 INFO DAGScheduler: Missing parents: List()
16/03/25 13:08:23 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:08:23 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19201, maxMem=555755765
16/03/25 13:08:23 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.0 MB)
16/03/25 13:08:23 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25017, maxMem=555755765
16/03/25 13:08:23 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
16/03/25 13:08:23 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:37523 (size: 3.3 KB, free: 530.0 MB)
16/03/25 13:08:23 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:08:23 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:08:23 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:08:23 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:08:23 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2361 bytes)
16/03/25 13:08:23 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:08:23 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:08:23 INFO PythonRunner: Times: total = 14, boot = -264, init = 278, finish = 0
16/03/25 13:08:23 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:08:23 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 54 ms on localhost (1/2)
16/03/25 13:08:23 INFO PythonRunner: Times: total = 128, boot = 128, init = 0, finish = 0
16/03/25 13:08:23 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/03/25 13:08:23 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 144 ms on localhost (2/2)
16/03/25 13:08:23 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:08:23 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.128 s
16/03/25 13:08:23 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.165735 s
16/03/25 13:08:23 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:08:23 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:08:23 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:08:23 INFO MemoryStore: MemoryStore cleared
16/03/25 13:08:23 INFO BlockManager: BlockManager stopped
16/03/25 13:08:23 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:08:23 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:08:23 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:08:23 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:08:23 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:08:23 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1ef4e6c>, {'4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], '2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras']})
asfer_pickle_string_dump(): picklef.write(): boundary
16/03/25 13:08:24 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:08:24 INFO SecurityManager: Changing view acls to: root
16/03/25 13:08:24 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:08:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:08:24 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:08:24 INFO Remoting: Starting remoting
16/03/25 13:08:24 INFO Utils: Successfully started service 'sparkDriver' on port 36403.
16/03/25 13:08:24 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:36403]
16/03/25 13:08:24 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:08:24 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:08:24 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ab0d29c3-380c-426d-a101-ffa26c504551
16/03/25 13:08:24 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
16/03/25 13:08:24 INFO HttpFileServer: HTTP File server directory is /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/httpd-0d8ad2f9-7419-46f8-809f-1c5659d7a92f
16/03/25 13:08:24 INFO HttpServer: Starting HTTP Server
16/03/25 13:08:24 INFO Utils: Successfully started service 'HTTP file server' on port 39010.
16/03/25 13:08:24 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:08:24 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:08:24 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:08:24 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-31277eaa-20a1-48bc-8b0b-3e8a2ff69edd/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:08:24 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891504549
16/03/25 13:08:24 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:08:24 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:08:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 47846.
16/03/25 13:08:24 INFO NettyBlockTransferService: Server created on 47846
16/03/25 13:08:24 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:08:24 INFO BlockManagerMasterEndpoint: Registering block manager localhost:47846 with 530.0 MB RAM, BlockManagerId(driver, localhost, 47846)
16/03/25 13:08:24 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:08:24 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:08:24 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:08:24 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:08:24 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:08:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:08:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:08:24 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:08:24 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555755765
16/03/25 13:08:24 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)
16/03/25 13:08:24 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555755765
16/03/25 13:08:24 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)
16/03/25 13:08:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:47846 (size: 4.1 KB, free: 530.0 MB)
16/03/25 13:08:24 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:08:24 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:08:24 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:08:24 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2479 bytes)
16/03/25 13:08:24 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2471 bytes)
16/03/25 13:08:24 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:08:24 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891504549
16/03/25 13:08:24 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:08:24 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-31277eaa-20a1-48bc-8b0b-3e8a2ff69edd/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:08:24 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:08:24 INFO MemoryStore: ensureFreeSpace(216) called with curMem=10732, maxMem=555755765
16/03/25 13:08:24 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 216.0 B, free 530.0 MB)
16/03/25 13:08:24 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:08:24 INFO MemoryStore: ensureFreeSpace(218) called with curMem=10948, maxMem=555755765
16/03/25 13:08:24 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 218.0 B, free 530.0 MB)
16/03/25 13:08:24 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:47846 (size: 216.0 B, free: 530.0 MB)
16/03/25 13:08:24 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:47846 (size: 218.0 B, free: 530.0 MB)
asfer_pickle_string_load(): picklef.readlines():asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: Chennai
 boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: special
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: area
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  boundary  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: expansion
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: serving
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: formerly
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: people
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: culture
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: bishop
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/25 13:08:34 INFO PythonRunner: Times: total = 9239, boot = 595, init = 423, finish = 8221
16/03/25 13:08:34 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:08:34 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9332 ms on localhost (1/2)
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: geography
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: city
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: given
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: Madras
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: sum
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: expressed
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: geographical
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: boundary
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/25 13:08:34 INFO PythonRunner: Times: total = 9678, boot = 592, init = 426, finish = 8660
16/03/25 13:08:34 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:08:34 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 9.769 s
16/03/25 13:08:34 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:08:34 INFO DAGScheduler: running: Set()
16/03/25 13:08:34 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:08:34 INFO DAGScheduler: failed: Set()
16/03/25 13:08:34 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:08:34 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:08:34 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11166, maxMem=555755765
16/03/25 13:08:34 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.0 MB)
16/03/25 13:08:34 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9772 ms on localhost (2/2)
16/03/25 13:08:34 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:08:34 INFO MemoryStore: ensureFreeSpace(3057) called with curMem=16150, maxMem=555755765
16/03/25 13:08:34 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.0 MB)
16/03/25 13:08:34 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:47846 (size: 3.0 KB, free: 530.0 MB)
16/03/25 13:08:34 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:08:34 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:08:34 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:08:34 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:08:34 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:08:34 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:08:34 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:08:34 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:08:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/25 13:08:34 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:08:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
16/03/25 13:08:34 INFO PythonRunner: Times: total = 41, boot = -244, init = 284, finish = 1
16/03/25 13:08:34 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:08:34 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 78 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'area', 'None']
16/03/25 13:08:34 INFO PythonRunner: Times: total = 194, boot = 192, init = 0, finish = 2
16/03/25 13:08:34 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1280 bytes result sent to driver
16/03/25 13:08:34 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.203 s
16/03/25 13:08:34 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 10.041055 s
16/03/25 13:08:34 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 214 ms on localhost (2/2)
16/03/25 13:08:34 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:08:34 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:08:34 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:08:34 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:08:34 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:08:34 INFO DAGScheduler: Missing parents: List()
16/03/25 13:08:34 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:08:34 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19207, maxMem=555755765
16/03/25 13:08:34 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.0 MB)
16/03/25 13:08:34 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25023, maxMem=555755765
16/03/25 13:08:34 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
16/03/25 13:08:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:47846 (size: 3.3 KB, free: 530.0 MB)
16/03/25 13:08:34 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:08:34 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:08:34 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:08:35 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:08:35 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2361 bytes)
16/03/25 13:08:35 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:08:35 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:08:35 INFO PythonRunner: Times: total = 12, boot = -19, init = 31, finish = 0
16/03/25 13:08:35 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:08:35 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 29 ms on localhost (1/2)
16/03/25 13:08:35 INFO PythonRunner: Times: total = 42, boot = -86, init = 128, finish = 0
16/03/25 13:08:35 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/03/25 13:08:35 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.048 s
16/03/25 13:08:35 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.076550 s
16/03/25 13:08:35 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 57 ms on localhost (2/2)
16/03/25 13:08:35 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:08:35 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:08:35 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:08:35 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:08:35 INFO MemoryStore: MemoryStore cleared
16/03/25 13:08:35 INFO BlockManager: BlockManager stopped
16/03/25 13:08:35 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:08:35 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:08:35 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:08:35 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:08:35 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:08:35 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1ef4e6c>, {'4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], '2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras']})
asfer_pickle_string_dump(): picklef.write(): Tamil
16/03/25 13:08:36 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:08:36 INFO SecurityManager: Changing view acls to: root
16/03/25 13:08:36 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:08:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:08:36 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:08:36 INFO Remoting: Starting remoting
16/03/25 13:08:36 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:58686]
16/03/25 13:08:36 INFO Utils: Successfully started service 'sparkDriver' on port 58686.
16/03/25 13:08:36 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:08:36 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:08:36 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3610294e-157b-4c98-a0f8-9660ae915db4
16/03/25 13:08:36 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
16/03/25 13:08:36 INFO HttpFileServer: HTTP File server directory is /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/httpd-bc1d7c26-921b-4dcb-ad2e-24de23460d72
16/03/25 13:08:36 INFO HttpServer: Starting HTTP Server
16/03/25 13:08:36 INFO Utils: Successfully started service 'HTTP file server' on port 50088.
16/03/25 13:08:36 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:08:36 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:08:36 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:08:36 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-20d1a49b-8137-47b4-8df6-36ff8ba14292/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:08:36 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891516581
16/03/25 13:08:36 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:08:36 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:08:36 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52343.
16/03/25 13:08:36 INFO NettyBlockTransferService: Server created on 52343
16/03/25 13:08:36 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:08:36 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52343 with 530.0 MB RAM, BlockManagerId(driver, localhost, 52343)
16/03/25 13:08:36 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:08:36 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:08:36 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:08:36 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:08:36 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:08:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:08:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:08:36 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:08:36 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555755765
16/03/25 13:08:36 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)
16/03/25 13:08:36 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555755765
16/03/25 13:08:36 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)
16/03/25 13:08:36 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52343 (size: 4.1 KB, free: 530.0 MB)
16/03/25 13:08:36 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:08:36 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:08:36 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:08:36 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2479 bytes)
16/03/25 13:08:36 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2500 bytes)
16/03/25 13:08:36 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:08:36 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891516581
16/03/25 13:08:36 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:08:36 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-20d1a49b-8137-47b4-8df6-36ff8ba14292/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:08:36 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:08:36 INFO MemoryStore: ensureFreeSpace(245) called with curMem=10732, maxMem=555755765
16/03/25 13:08:36 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 245.0 B, free 530.0 MB)
16/03/25 13:08:36 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:52343 (size: 245.0 B, free: 530.0 MB)
16/03/25 13:08:36 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:08:36 INFO MemoryStore: ensureFreeSpace(218) called with curMem=10977, maxMem=555755765
16/03/25 13:08:36 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 218.0 B, free 530.0 MB)
16/03/25 13:08:36 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:52343 (size: 218.0 B, free: 530.0 MB)
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: special
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: geography
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: city
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: given
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Tamil  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: area
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: expansion
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: serving
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: formerly
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: people
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: culture
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'for'mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: indefinite
, u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['NmapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: bishop
one']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: Madras
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'on', u';'16/03/25 13:08:45 INFO PythonRunner: Times: total = 8635, boot = 484, init = 455, finish = 7696
, u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: Eastern
16/03/25 13:08:45 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:08:45 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8734 ms on localhost (1/2)
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: sum
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: expressed
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: geographical
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: boundary
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/25 13:08:45 INFO PythonRunner: Times: total = 8808, boot = 487, init = 362, finish = 7959
16/03/25 13:08:45 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:08:45 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8904 ms on localhost (2/2)
16/03/25 13:08:45 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:08:45 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 8.914 s
16/03/25 13:08:45 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:08:45 INFO DAGScheduler: running: Set()
16/03/25 13:08:45 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:08:45 INFO DAGScheduler: failed: Set()
16/03/25 13:08:45 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:08:45 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:08:45 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11195, maxMem=555755765
16/03/25 13:08:45 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.0 MB)
16/03/25 13:08:45 INFO MemoryStore: ensureFreeSpace(3057) called with curMem=16179, maxMem=555755765
16/03/25 13:08:45 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.0 MB)
16/03/25 13:08:45 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52343 (size: 3.0 KB, free: 530.0 MB)
16/03/25 13:08:45 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:08:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:08:45 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:08:45 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:08:45 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:08:45 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:08:45 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:08:45 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:08:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/25 13:08:45 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:08:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
reduceFunction_Parents(): returns= [u'Chennai', 'None']
16/03/25 13:08:45 INFO PythonRunner: Times: total = 70, boot = 67, init = 1, finish = 2
16/03/25 13:08:45 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1275 bytes result sent to driver
16/03/25 13:08:45 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 110 ms on localhost (1/2)
16/03/25 13:08:46 INFO PythonRunner: Times: total = 225, boot = 224, init = 1, finish = 0
16/03/25 13:08:46 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:08:46 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.251 s
16/03/25 13:08:46 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 9.218424 s
16/03/25 13:08:46 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 251 ms on localhost (2/2)
16/03/25 13:08:46 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:08:46 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:08:46 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:08:46 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:08:46 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:08:46 INFO DAGScheduler: Missing parents: List()
16/03/25 13:08:46 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:08:46 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19236, maxMem=555755765
16/03/25 13:08:46 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.0 MB)
16/03/25 13:08:46 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25052, maxMem=555755765
16/03/25 13:08:46 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
16/03/25 13:08:46 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:52343 (size: 3.3 KB, free: 530.0 MB)
16/03/25 13:08:46 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:08:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:08:46 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:08:46 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:08:46 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2356 bytes)
16/03/25 13:08:46 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:08:46 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:08:46 INFO PythonRunner: Times: total = 9, boot = -72, init = 81, finish = 0
16/03/25 13:08:46 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:08:46 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 71 ms on localhost (1/2)
16/03/25 13:08:46 INFO PythonRunner: Times: total = 151, boot = 151, init = 0, finish = 0
16/03/25 13:08:46 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1340 bytes result sent to driver
16/03/25 13:08:46 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 163 ms on localhost (2/2)
16/03/25 13:08:46 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:08:46 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.155 s
16/03/25 13:08:46 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.183286 s
16/03/25 13:08:46 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:08:46 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:08:46 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:08:46 INFO MemoryStore: MemoryStore cleared
16/03/25 13:08:46 INFO BlockManager: BlockManager stopped
16/03/25 13:08:46 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:08:46 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:08:46 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:08:46 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:08:46 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:08:46 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1ef4e6c>, {'4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], '2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras']})
asfer_pickle_string_dump(): picklef.write(): Nadu
16/03/25 13:08:47 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:08:47 INFO SecurityManager: Changing view acls to: root
16/03/25 13:08:47 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:08:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:08:47 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:08:47 INFO Remoting: Starting remoting
16/03/25 13:08:47 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:35027]
16/03/25 13:08:47 INFO Utils: Successfully started service 'sparkDriver' on port 35027.
16/03/25 13:08:47 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:08:47 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:08:47 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-dad5ef33-5548-4f52-a7b9-94be39c868f5
16/03/25 13:08:47 INFO MemoryStore: MemoryStore started with capacity 540.8 MB
16/03/25 13:08:47 INFO HttpFileServer: HTTP File server directory is /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/httpd-a1588671-812e-4718-b1b9-6861b59ec0d4
16/03/25 13:08:47 INFO HttpServer: Starting HTTP Server
16/03/25 13:08:47 INFO Utils: Successfully started service 'HTTP file server' on port 60775.
16/03/25 13:08:47 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:08:48 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:08:48 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:08:48 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-ba29c64f-3ac5-4e7e-988c-024087440d0d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:08:48 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891528198
16/03/25 13:08:48 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:08:48 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:08:48 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35754.
16/03/25 13:08:48 INFO NettyBlockTransferService: Server created on 35754
16/03/25 13:08:48 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:08:48 INFO BlockManagerMasterEndpoint: Registering block manager localhost:35754 with 540.8 MB RAM, BlockManagerId(driver, localhost, 35754)
16/03/25 13:08:48 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:08:48 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:08:48 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:08:48 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:08:48 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:08:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:08:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:08:48 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:08:48 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=567080386
16/03/25 13:08:48 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 540.8 MB)
16/03/25 13:08:48 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=567080386
16/03/25 13:08:48 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 540.8 MB)
16/03/25 13:08:48 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:35754 (size: 4.1 KB, free: 540.8 MB)
16/03/25 13:08:48 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:08:48 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:08:48 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:08:48 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2493 bytes)
16/03/25 13:08:48 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2480 bytes)
16/03/25 13:08:48 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:08:48 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891528198
16/03/25 13:08:48 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:08:48 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-ba29c64f-3ac5-4e7e-988c-024087440d0d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:08:48 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:08:48 INFO MemoryStore: ensureFreeSpace(220) called with curMem=10732, maxMem=567080386
16/03/25 13:08:48 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 220.0 B, free 540.8 MB)
16/03/25 13:08:48 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:35754 (size: 220.0 B, free: 540.8 MB)
16/03/25 13:08:48 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:08:48 INFO MemoryStore: ensureFreeSpace(228) called with curMem=10952, maxMem=567080386
16/03/25 13:08:48 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 228.0 B, free 540.8 MB)
16/03/25 13:08:48 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:35754 (size: 228.0 B, free: 540.8 MB)
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: Chennai
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: geography
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: city
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: given
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: Madras
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: sum
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: expressed
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: geographical
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: boundary
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/25 13:08:58 INFO PythonRunner: Times: total = 9892, boot = 536, init = 729, finish = 8627
16/03/25 13:08:58 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:08:58 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 10027 ms on localhost (1/2)
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Nadu  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: area
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: expansion
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: serving
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: formerly
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: people
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: culture
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: bishop
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: special
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
16/03/25 13:08:58 INFO PythonRunner: Times: total = 10069, boot = 540, init = 565, finish = 8964
16/03/25 13:08:58 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:08:58 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 10.231 s
16/03/25 13:08:58 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:08:58 INFO DAGScheduler: running: Set()
16/03/25 13:08:58 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:08:58 INFO DAGScheduler: failed: Set()
16/03/25 13:08:58 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:08:58 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:08:58 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11180, maxMem=567080386
16/03/25 13:08:58 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 540.8 MB)
16/03/25 13:08:58 INFO MemoryStore: ensureFreeSpace(3057) called with curMem=16164, maxMem=567080386
16/03/25 13:08:58 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 540.8 MB)
16/03/25 13:08:58 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 10220 ms on localhost (2/2)
16/03/25 13:08:58 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:08:58 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:35754 (size: 3.0 KB, free: 540.8 MB)
16/03/25 13:08:58 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:08:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:08:58 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:08:58 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:08:58 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:08:58 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:08:58 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:08:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/25 13:08:58 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:08:58 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:08:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/25 13:08:58 INFO PythonRunner: Times: total = 147, boot = 146, init = 1, finish = 0
16/03/25 13:08:58 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:08:58 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 162 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'Chennai', 'None']
16/03/25 13:08:58 INFO PythonRunner: Times: total = 228, boot = 227, init = 0, finish = 1
16/03/25 13:08:58 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1275 bytes result sent to driver
16/03/25 13:08:58 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.248 s
16/03/25 13:08:58 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 250 ms on localhost (2/2)
16/03/25 13:08:58 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:08:58 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 10.509484 s
16/03/25 13:08:58 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:08:58 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:08:58 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:08:58 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:08:58 INFO DAGScheduler: Missing parents: List()
16/03/25 13:08:58 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:08:58 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19221, maxMem=567080386
16/03/25 13:08:58 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 540.8 MB)
16/03/25 13:08:58 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25037, maxMem=567080386
16/03/25 13:08:58 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 540.8 MB)
16/03/25 13:08:59 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:35754 (size: 3.3 KB, free: 540.8 MB)
16/03/25 13:08:59 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:08:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:08:59 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:08:59 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:08:59 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2356 bytes)
16/03/25 13:08:59 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:08:59 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:08:59 INFO PythonRunner: Times: total = 119, boot = 118, init = 1, finish = 0
16/03/25 13:08:59 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1340 bytes result sent to driver
16/03/25 13:08:59 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 129 ms on localhost (1/2)
16/03/25 13:08:59 INFO PythonRunner: Times: total = 257, boot = 257, init = 0, finish = 0
16/03/25 13:08:59 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:08:59 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 272 ms on localhost (2/2)
16/03/25 13:08:59 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:08:59 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.267 s
16/03/25 13:08:59 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.293968 s
16/03/25 13:08:59 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:08:59 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:08:59 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:08:59 INFO MemoryStore: MemoryStore cleared
16/03/25 13:08:59 INFO BlockManager: BlockManager stopped
16/03/25 13:08:59 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:08:59 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:08:59 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:08:59 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:08:59 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:08:59 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1ef4e6c>, {'4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], '2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras']})
asfer_pickle_string_dump(): picklef.write(): function
16/03/25 13:09:00 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:09:00 INFO SecurityManager: Changing view acls to: root
16/03/25 13:09:00 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:09:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:09:00 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:09:00 INFO Remoting: Starting remoting
16/03/25 13:09:00 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:42601]
16/03/25 13:09:00 INFO Utils: Successfully started service 'sparkDriver' on port 42601.
16/03/25 13:09:00 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:09:00 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:09:00 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-fd1dfcd0-17f5-4700-b08e-fc98d5fbb5e1
16/03/25 13:09:00 INFO MemoryStore: MemoryStore started with capacity 540.8 MB
16/03/25 13:09:00 INFO HttpFileServer: HTTP File server directory is /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/httpd-325547ea-51bb-44cd-b0a4-bbb08c967a9b
16/03/25 13:09:00 INFO HttpServer: Starting HTTP Server
16/03/25 13:09:00 INFO Utils: Successfully started service 'HTTP file server' on port 43966.
16/03/25 13:09:00 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:09:00 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:09:00 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:09:00 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-eb78f894-1979-4e6e-afa8-cb32a1f94ec8/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:09:00 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891540559
16/03/25 13:09:00 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:09:00 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:09:00 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43878.
16/03/25 13:09:00 INFO NettyBlockTransferService: Server created on 43878
16/03/25 13:09:00 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:09:00 INFO BlockManagerMasterEndpoint: Registering block manager localhost:43878 with 540.8 MB RAM, BlockManagerId(driver, localhost, 43878)
16/03/25 13:09:00 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:09:00 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:09:00 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:09:00 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:09:00 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:09:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:09:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:09:00 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:09:00 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=567080386
16/03/25 13:09:00 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 540.8 MB)
16/03/25 13:09:00 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=567080386
16/03/25 13:09:00 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 540.8 MB)
16/03/25 13:09:00 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:43878 (size: 4.1 KB, free: 540.8 MB)
16/03/25 13:09:00 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:09:00 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:09:00 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:09:00 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2493 bytes)
16/03/25 13:09:00 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2512 bytes)
16/03/25 13:09:00 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:09:00 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891540559
16/03/25 13:09:00 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:09:00 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-eb78f894-1979-4e6e-afa8-cb32a1f94ec8/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:09:00 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:09:00 INFO MemoryStore: ensureFreeSpace(246) called with curMem=10732, maxMem=567080386
16/03/25 13:09:00 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 246.0 B, free 540.8 MB)
16/03/25 13:09:00 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:43878 (size: 246.0 B, free: 540.8 MB)
16/03/25 13:09:00 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:09:00 INFO MemoryStore: ensureFreeSpace(228) called with curMem=10978, maxMem=567080386
16/03/25 13:09:00 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 228.0 B, free 540.8 MB)
16/03/25 13:09:00 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:43878 (size: 228.0 B, free: 540.8 MB)
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: Chennai
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: geography
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: area
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: expansion
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): adding to parents: syn =  Synset('expansion.n.02') ; keyword:  function  in syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= [u'expansion']
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: serving
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: formerly
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: people
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: culture
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: bishop
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: special
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
16/03/25 13:09:10 INFO PythonRunner: Times: total = 9282, boot = 471, init = 406, finish = 8405
16/03/25 13:09:10 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:09:10 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9409 ms on localhost (1/2)
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: city
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: given
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: Madras
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: sum
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: expressed
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: geographical
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: boundary
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: function
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): adding to parents: syn =  Synset('function.n.01') ; keyword:  function  in syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= [u'function']
reduceFunction_Parents(): returns= ['None', u'function']
16/03/25 13:09:11 INFO PythonRunner: Times: total = 10228, boot = 463, init = 423, finish = 9342
16/03/25 13:09:11 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:09:11 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 10.337 s
16/03/25 13:09:11 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:09:11 INFO DAGScheduler: running: Set()
16/03/25 13:09:11 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:09:11 INFO DAGScheduler: failed: Set()
16/03/25 13:09:11 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:09:11 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:09:11 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11206, maxMem=567080386
16/03/25 13:09:11 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 540.8 MB)
16/03/25 13:09:11 INFO MemoryStore: ensureFreeSpace(3057) called with curMem=16190, maxMem=567080386
16/03/25 13:09:11 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 540.8 MB)
16/03/25 13:09:11 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 10334 ms on localhost (2/2)
16/03/25 13:09:11 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:09:11 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:43878 (size: 3.0 KB, free: 540.8 MB)
16/03/25 13:09:11 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:09:11 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:09:11 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:09:11 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:09:11 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:09:11 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:09:11 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:09:11 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:09:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/25 13:09:11 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:09:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'expansion', 'None', u'function']
16/03/25 13:09:11 INFO PythonRunner: Times: total = 40, boot = -704, init = 744, finish = 0
16/03/25 13:09:11 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1300 bytes result sent to driver
16/03/25 13:09:11 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 69 ms on localhost (1/2)
16/03/25 13:09:11 INFO PythonRunner: Times: total = 336, boot = 336, init = 0, finish = 0
16/03/25 13:09:11 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:09:11 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.354 s
16/03/25 13:09:11 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 10.754288 s
16/03/25 13:09:11 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 360 ms on localhost (2/2)
16/03/25 13:09:11 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:09:11 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:09:11 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:09:11 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:09:11 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:09:11 INFO DAGScheduler: Missing parents: List()
16/03/25 13:09:11 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:09:11 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19247, maxMem=567080386
16/03/25 13:09:11 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 540.8 MB)
16/03/25 13:09:11 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25063, maxMem=567080386
16/03/25 13:09:11 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 540.8 MB)
16/03/25 13:09:11 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:43878 (size: 3.3 KB, free: 540.8 MB)
16/03/25 13:09:11 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:09:11 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:09:11 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:09:11 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:09:11 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2381 bytes)
16/03/25 13:09:11 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:09:11 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:09:11 INFO PythonRunner: Times: total = 48, boot = -86, init = 134, finish = 0
16/03/25 13:09:11 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1368 bytes result sent to driver
16/03/25 13:09:11 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 71 ms on localhost (1/2)
16/03/25 13:09:12 INFO PythonRunner: Times: total = 290, boot = 280, init = 10, finish = 0
16/03/25 13:09:12 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:09:12 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 308 ms on localhost (2/2)
16/03/25 13:09:12 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:09:12 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.308 s
16/03/25 13:09:12 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.361655 s
16/03/25 13:09:12 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:09:12 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:09:12 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:09:12 INFO MemoryStore: MemoryStore cleared
16/03/25 13:09:12 INFO BlockManager: BlockManager stopped
16/03/25 13:09:12 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:09:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:09:12 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:09:12 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:09:12 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:09:12 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1ef4e6c>, {'4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], '2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras']})
asfer_pickle_string_dump(): picklef.write(): product
16/03/25 13:09:13 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:09:13 INFO SecurityManager: Changing view acls to: root
16/03/25 13:09:13 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:09:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:09:13 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:09:13 INFO Remoting: Starting remoting
16/03/25 13:09:13 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:60765]
16/03/25 13:09:13 INFO Utils: Successfully started service 'sparkDriver' on port 60765.
16/03/25 13:09:13 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:09:13 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:09:13 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d3e54176-e1a7-4703-aebc-2e6f54eefa1c
16/03/25 13:09:13 INFO MemoryStore: MemoryStore started with capacity 540.8 MB
16/03/25 13:09:13 INFO HttpFileServer: HTTP File server directory is /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/httpd-08491ded-58b0-44ee-9667-e6a47ee4d795
16/03/25 13:09:13 INFO HttpServer: Starting HTTP Server
16/03/25 13:09:13 INFO Utils: Successfully started service 'HTTP file server' on port 35995.
16/03/25 13:09:13 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:09:14 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:09:14 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:09:14 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-2cf53964-f349-434f-84c8-26caf5399a13/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:09:14 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891554040
16/03/25 13:09:14 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:09:14 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:09:14 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38363.
16/03/25 13:09:14 INFO NettyBlockTransferService: Server created on 38363
16/03/25 13:09:14 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:09:14 INFO BlockManagerMasterEndpoint: Registering block manager localhost:38363 with 540.8 MB RAM, BlockManagerId(driver, localhost, 38363)
16/03/25 13:09:14 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:09:14 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:09:14 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:09:14 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:09:14 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:09:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:09:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:09:14 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:09:14 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=567080386
16/03/25 13:09:14 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 540.8 MB)
16/03/25 13:09:14 INFO MemoryStore: ensureFreeSpace(4151) called with curMem=6576, maxMem=567080386
16/03/25 13:09:14 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 540.8 MB)
16/03/25 13:09:14 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:38363 (size: 4.1 KB, free: 540.8 MB)
16/03/25 13:09:14 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:09:14 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:09:14 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:09:14 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2509 bytes)
16/03/25 13:09:14 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2493 bytes)
16/03/25 13:09:14 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:09:14 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:09:14 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891554040
16/03/25 13:09:14 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-2cf53964-f349-434f-84c8-26caf5399a13/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:09:14 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:09:14 INFO MemoryStore: ensureFreeSpace(244) called with curMem=10727, maxMem=567080386
16/03/25 13:09:14 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:09:14 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 244.0 B, free 540.8 MB)
16/03/25 13:09:14 INFO MemoryStore: ensureFreeSpace(232) called with curMem=10971, maxMem=567080386
16/03/25 13:09:14 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:38363 (size: 244.0 B, free: 540.8 MB)
16/03/25 13:09:14 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 232.0 B, free 540.8 MB)
16/03/25 13:09:14 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:38363 (size: 232.0 B, free: 540.8 MB)
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: Chennai
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: city
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: given
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: Madras
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: sum
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: expressed
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: geographical
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: boundary
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: function
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: product
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/25 13:09:28 INFO PythonRunner: Times: total = 13740, boot = 610, init = 841, finish = 12289
16/03/25 13:09:28 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:09:28 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 13874 ms on localhost (1/2)
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: area
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: expansion
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): adding to parents: syn =  Synset('expansion.n.02') ; keyword:  product  in syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= [u'expansion']
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: serving
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: formerly
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: people
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: culture
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: bishop
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: special
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: geography
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
16/03/25 13:09:28 INFO PythonRunner: Times: total = 14414, boot = 598, init = 645, finish = 13171
16/03/25 13:09:28 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:09:28 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 14.533 s
16/03/25 13:09:28 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:09:28 INFO DAGScheduler: running: Set()
16/03/25 13:09:28 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:09:28 INFO DAGScheduler: failed: Set()
16/03/25 13:09:28 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:09:28 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:09:28 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11203, maxMem=567080386
16/03/25 13:09:28 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 540.8 MB)
16/03/25 13:09:28 INFO MemoryStore: ensureFreeSpace(3057) called with curMem=16187, maxMem=567080386
16/03/25 13:09:28 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 540.8 MB)
16/03/25 13:09:28 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 14531 ms on localhost (2/2)
16/03/25 13:09:28 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:09:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:38363 (size: 3.0 KB, free: 540.8 MB)
16/03/25 13:09:28 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:09:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:09:28 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:09:28 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:09:28 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:09:28 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:09:28 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:09:28 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:09:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
16/03/25 13:09:28 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:09:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
16/03/25 13:09:28 INFO PythonRunner: Times: total = 38, boot = -388, init = 425, finish = 1
reduceFunction_Parents(): returns= ['None', u'expansion', 'None']
16/03/25 13:09:28 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1285 bytes result sent to driver
16/03/25 13:09:28 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 91 ms on localhost (1/2)
16/03/25 13:09:29 INFO PythonRunner: Times: total = 248, boot = 247, init = 1, finish = 0
16/03/25 13:09:29 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:09:29 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 294 ms on localhost (2/2)
16/03/25 13:09:29 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:09:29 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.268 s
16/03/25 13:09:29 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 14.888472 s
16/03/25 13:09:29 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:09:29 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:09:29 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:09:29 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:09:29 INFO DAGScheduler: Missing parents: List()
16/03/25 13:09:29 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:09:29 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19244, maxMem=567080386
16/03/25 13:09:29 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 540.8 MB)
16/03/25 13:09:29 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25060, maxMem=567080386
16/03/25 13:09:29 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 540.8 MB)
16/03/25 13:09:29 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:38363 (size: 3.3 KB, free: 540.8 MB)
16/03/25 13:09:29 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:09:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:09:29 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:09:29 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:09:29 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2366 bytes)
16/03/25 13:09:29 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:09:29 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:09:29 INFO PythonRunner: Times: total = 63, boot = -178, init = 241, finish = 0
16/03/25 13:09:29 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:09:29 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 85 ms on localhost (1/2)
16/03/25 13:09:29 INFO PythonRunner: Times: total = 245, boot = 244, init = 1, finish = 0
16/03/25 13:09:29 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1353 bytes result sent to driver
16/03/25 13:09:29 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 261 ms on localhost (2/2)
16/03/25 13:09:29 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:09:29 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.261 s
16/03/25 13:09:29 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.289647 s
16/03/25 13:09:29 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:09:29 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:09:29 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:09:29 INFO MemoryStore: MemoryStore cleared
16/03/25 13:09:29 INFO BlockManager: BlockManager stopped
16/03/25 13:09:29 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:09:29 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:09:29 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:09:29 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:09:29 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:09:29 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1ef4e6c>, {'2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras'], '4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], '25439f8325592e4ecd8b06f5f799b57a': [u'None', u'expansion', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None']})
asfer_pickle_string_dump(): picklef.write(): terms
16/03/25 13:09:30 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:09:30 INFO SecurityManager: Changing view acls to: root
16/03/25 13:09:30 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:09:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:09:30 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:09:30 INFO Remoting: Starting remoting
16/03/25 13:09:30 INFO Utils: Successfully started service 'sparkDriver' on port 46720.
16/03/25 13:09:30 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:46720]
16/03/25 13:09:30 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:09:30 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:09:30 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9e7dd8ff-2375-403e-8236-0cc6f7eacea4
16/03/25 13:09:30 INFO MemoryStore: MemoryStore started with capacity 540.8 MB
16/03/25 13:09:30 INFO HttpFileServer: HTTP File server directory is /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/httpd-37474596-2304-4fd4-913a-c35f8f36f1be
16/03/25 13:09:30 INFO HttpServer: Starting HTTP Server
16/03/25 13:09:30 INFO Utils: Successfully started service 'HTTP file server' on port 46456.
16/03/25 13:09:30 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:09:30 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:09:30 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:09:30 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-659c6f12-0c81-4d74-9db6-61bf683d70a2/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:09:30 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891570790
16/03/25 13:09:30 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:09:30 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:09:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46190.
16/03/25 13:09:30 INFO NettyBlockTransferService: Server created on 46190
16/03/25 13:09:30 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:09:30 INFO BlockManagerMasterEndpoint: Registering block manager localhost:46190 with 540.8 MB RAM, BlockManagerId(driver, localhost, 46190)
16/03/25 13:09:30 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:09:30 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:09:30 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:09:30 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:09:30 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:09:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:09:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:09:30 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:09:30 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=567080386
16/03/25 13:09:30 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 540.8 MB)
16/03/25 13:09:30 INFO MemoryStore: ensureFreeSpace(4151) called with curMem=6576, maxMem=567080386
16/03/25 13:09:30 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 540.8 MB)
16/03/25 13:09:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:46190 (size: 4.1 KB, free: 540.8 MB)
16/03/25 13:09:30 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:09:30 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:09:30 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:09:31 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2509 bytes)
16/03/25 13:09:31 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2522 bytes)
16/03/25 13:09:31 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:09:31 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891570790
16/03/25 13:09:31 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:09:31 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-659c6f12-0c81-4d74-9db6-61bf683d70a2/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:09:31 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:09:31 INFO MemoryStore: ensureFreeSpace(258) called with curMem=10727, maxMem=567080386
16/03/25 13:09:31 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 258.0 B, free 540.8 MB)
16/03/25 13:09:31 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:09:31 INFO MemoryStore: ensureFreeSpace(244) called with curMem=10985, maxMem=567080386
16/03/25 13:09:31 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 244.0 B, free 540.8 MB)
16/03/25 13:09:31 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:46190 (size: 244.0 B, free: 540.8 MB)
16/03/25 13:09:31 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:46190 (size: 258.0 B, free: 540.8 MB)
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: city
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: given
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: Madras
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: sum
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: expressed
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: geographical
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: boundary
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: function
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: product
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: terms
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'status', u'people', u'relations', u'to', u'groups', u'between', u'respect', u'the', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/25 13:09:42 INFO PythonRunner: Times: total = 11618, boot = 693, init = 399, finish = 10526
16/03/25 13:09:42 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:09:42 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 11782 ms on localhost (1/2)
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: area
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: expansion
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): adding to parents: syn =  Synset('expansion.n.02') ; keyword:  terms  in syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= [u'expansion']
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: serving
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: formerly
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: people
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: culture
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: bishop
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: special
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: geography
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
16/03/25 13:09:43 INFO PythonRunner: Times: total = 11963, boot = 694, init = 426, finish = 10843
16/03/25 13:09:43 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:09:43 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 12112 ms on localhost (2/2)
16/03/25 13:09:43 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:09:43 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 12.093 s
16/03/25 13:09:43 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:09:43 INFO DAGScheduler: running: Set()
16/03/25 13:09:43 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:09:43 INFO DAGScheduler: failed: Set()
16/03/25 13:09:43 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:09:43 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:09:43 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11229, maxMem=567080386
16/03/25 13:09:43 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 540.8 MB)
16/03/25 13:09:43 INFO MemoryStore: ensureFreeSpace(3057) called with curMem=16213, maxMem=567080386
16/03/25 13:09:43 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 540.8 MB)
16/03/25 13:09:43 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:46190 (size: 3.0 KB, free: 540.8 MB)
16/03/25 13:09:43 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:09:43 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:09:43 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:09:43 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:09:43 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:09:43 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:09:43 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:09:43 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:09:43 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:09:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/25 13:09:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
reduceFunction_Parents(): returns= ['None', u'expansion', 'None']
16/03/25 13:09:43 INFO PythonRunner: Times: total = 75, boot = -208, init = 283, finish = 0
16/03/25 13:09:43 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1285 bytes result sent to driver
16/03/25 13:09:43 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 106 ms on localhost (1/2)
16/03/25 13:09:43 INFO PythonRunner: Times: total = 307, boot = 306, init = 0, finish = 1
16/03/25 13:09:43 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:09:43 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.330 s
16/03/25 13:09:43 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 12.533844 s
16/03/25 13:09:43 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 329 ms on localhost (2/2)
16/03/25 13:09:43 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:09:43 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:09:43 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:09:43 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:09:43 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:09:43 INFO DAGScheduler: Missing parents: List()
16/03/25 13:09:43 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:09:43 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19270, maxMem=567080386
16/03/25 13:09:43 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 540.8 MB)
16/03/25 13:09:43 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25086, maxMem=567080386
16/03/25 13:09:43 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 540.8 MB)
16/03/25 13:09:43 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:46190 (size: 3.3 KB, free: 540.8 MB)
16/03/25 13:09:43 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:09:43 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:09:43 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:09:43 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:09:43 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2366 bytes)
16/03/25 13:09:43 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:09:43 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:09:43 INFO PythonRunner: Times: total = 57, boot = -40, init = 97, finish = 0
16/03/25 13:09:43 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1353 bytes result sent to driver
16/03/25 13:09:43 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 67 ms on localhost (1/2)
16/03/25 13:09:43 INFO PythonRunner: Times: total = 159, boot = 159, init = 0, finish = 0
16/03/25 13:09:43 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:09:43 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 169 ms on localhost (2/2)
16/03/25 13:09:43 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:09:43 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.170 s
16/03/25 13:09:43 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.191986 s
16/03/25 13:09:43 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:09:43 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:09:43 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:09:43 INFO MemoryStore: MemoryStore cleared
16/03/25 13:09:43 INFO BlockManager: BlockManager stopped
16/03/25 13:09:43 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:09:43 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:09:43 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:09:43 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:09:43 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:09:43 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1ef4e6c>, {'2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '3cd540871242471e0d89bea4eabc06ea': [u'None', u'expansion', u'None'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras'], '4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], '25439f8325592e4ecd8b06f5f799b57a': [u'None', u'expansion', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None']})
asfer_pickle_string_dump(): picklef.write(): equivalent
16/03/25 13:09:44 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:09:44 INFO SecurityManager: Changing view acls to: root
16/03/25 13:09:44 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:09:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:09:44 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:09:44 INFO Remoting: Starting remoting
16/03/25 13:09:44 INFO Utils: Successfully started service 'sparkDriver' on port 45530.
16/03/25 13:09:44 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:45530]
16/03/25 13:09:44 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:09:44 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:09:44 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0e4a086c-ce8c-4f1a-aabe-509b11ad352a
16/03/25 13:09:44 INFO MemoryStore: MemoryStore started with capacity 540.8 MB
16/03/25 13:09:44 INFO HttpFileServer: HTTP File server directory is /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/httpd-e64368f6-9725-44b2-8604-c57ff8b98605
16/03/25 13:09:44 INFO HttpServer: Starting HTTP Server
16/03/25 13:09:45 INFO Utils: Successfully started service 'HTTP file server' on port 34165.
16/03/25 13:09:45 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:09:45 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:09:45 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:09:45 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-864cdf2d-0301-4fd1-ac37-7b80f66b5065/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:09:45 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891585097
16/03/25 13:09:45 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:09:45 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:09:45 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36153.
16/03/25 13:09:45 INFO NettyBlockTransferService: Server created on 36153
16/03/25 13:09:45 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:09:45 INFO BlockManagerMasterEndpoint: Registering block manager localhost:36153 with 540.8 MB RAM, BlockManagerId(driver, localhost, 36153)
16/03/25 13:09:45 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:09:45 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:09:45 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:09:45 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:09:45 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:09:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:09:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:09:45 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:09:45 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=567080386
16/03/25 13:09:45 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 540.8 MB)
16/03/25 13:09:45 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=567080386
16/03/25 13:09:45 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 540.8 MB)
16/03/25 13:09:45 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:36153 (size: 4.1 KB, free: 540.8 MB)
16/03/25 13:09:45 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:09:45 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:09:45 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:09:45 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2520 bytes)
16/03/25 13:09:45 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2511 bytes)
16/03/25 13:09:45 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:09:45 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891585097
16/03/25 13:09:45 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:09:45 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-864cdf2d-0301-4fd1-ac37-7b80f66b5065/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:09:45 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:09:45 INFO MemoryStore: ensureFreeSpace(254) called with curMem=10732, maxMem=567080386
16/03/25 13:09:45 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:09:45 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 254.0 B, free 540.8 MB)
16/03/25 13:09:45 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:36153 (size: 254.0 B, free: 540.8 MB)
16/03/25 13:09:45 INFO MemoryStore: ensureFreeSpace(255) called with curMem=10986, maxMem=567080386
16/03/25 13:09:45 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 255.0 B, free 540.8 MB)
16/03/25 13:09:45 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:36153 (size: 255.0 B, free: 540.8 MB)
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: Chennai
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: given
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  equivalent  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: area
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: expansion
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: serving
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: formerly
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: people
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: culture
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: bishop
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: special
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: geography
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: city
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
16/03/25 13:09:54 INFO PythonRunner: Times: total = 9221, boot = 480, init = 395, finish = 8346
16/03/25 13:09:54 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:09:54 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9458 ms on localhost (1/2)
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: Madras
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: sum
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: expressed
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: geographical
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: boundary
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: function
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: product
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: terms
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'status', u'people', u'relations', u'to', u'groups', u'between', u'respect', u'the', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: equivalent
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/25 13:09:55 INFO PythonRunner: Times: total = 9574, boot = 464, init = 506, finish = 8604
16/03/25 13:09:55 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:09:55 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 9.819 s
16/03/25 13:09:55 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9817 ms on localhost (2/2)
16/03/25 13:09:55 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:09:55 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:09:55 INFO DAGScheduler: running: Set()
16/03/25 13:09:55 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:09:55 INFO DAGScheduler: failed: Set()
16/03/25 13:09:55 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:09:55 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:09:55 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11241, maxMem=567080386
16/03/25 13:09:55 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 540.8 MB)
16/03/25 13:09:55 INFO MemoryStore: ensureFreeSpace(3057) called with curMem=16225, maxMem=567080386
16/03/25 13:09:55 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 540.8 MB)
16/03/25 13:09:55 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:36153 (size: 3.0 KB, free: 540.8 MB)
16/03/25 13:09:55 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:09:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:09:55 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:09:55 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:09:55 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:09:55 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:09:55 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:09:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/25 13:09:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
16/03/25 13:09:55 INFO PythonRunner: Times: total = 38, boot = -128, init = 165, finish = 1
16/03/25 13:09:55 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:09:55 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 113 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'metropolitan', 'None']
16/03/25 13:09:55 INFO PythonRunner: Times: total = 296, boot = 295, init = 1, finish = 0
16/03/25 13:09:55 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1280 bytes result sent to driver
16/03/25 13:09:55 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.310 s
16/03/25 13:09:55 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 10.237118 s
16/03/25 13:09:55 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 309 ms on localhost (2/2)
16/03/25 13:09:55 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:09:55 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:09:55 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:09:55 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:09:55 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:09:55 INFO DAGScheduler: Missing parents: List()
16/03/25 13:09:55 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:09:55 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19282, maxMem=567080386
16/03/25 13:09:55 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 540.8 MB)
16/03/25 13:09:55 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25098, maxMem=567080386
16/03/25 13:09:55 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 540.8 MB)
16/03/25 13:09:55 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:36153 (size: 3.3 KB, free: 540.8 MB)
16/03/25 13:09:55 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:09:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:09:55 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:09:55 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:09:55 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2361 bytes)
16/03/25 13:09:55 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:09:55 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:09:55 INFO PythonRunner: Times: total = 54, boot = -183, init = 237, finish = 0
16/03/25 13:09:55 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1345 bytes result sent to driver
16/03/25 13:09:55 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 71 ms on localhost (1/2)
16/03/25 13:09:55 INFO PythonRunner: Times: total = 110, boot = 110, init = 0, finish = 0
16/03/25 13:09:55 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:09:55 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 124 ms on localhost (2/2)
16/03/25 13:09:55 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:09:55 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.123 s
16/03/25 13:09:55 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.147514 s
16/03/25 13:09:55 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:09:55 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:09:55 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:09:55 INFO MemoryStore: MemoryStore cleared
16/03/25 13:09:55 INFO BlockManager: BlockManager stopped
16/03/25 13:09:55 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:09:55 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:09:55 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:09:55 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:09:55 INFO SparkContext: Successfully stopped SparkContext
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1ef4e6c>, {'2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], '57466dae2c092869867908c5c54e241c': [u'metropolitan', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '3cd540871242471e0d89bea4eabc06ea': [u'None', u'expansion', u'None'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras'], '4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], '25439f8325592e4ecd8b06f5f799b57a': [u'None', u'expansion', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None']})
asfer_pickle_string_dump(): picklef.write(): Bay
16/03/25 13:09:56 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:09:56 INFO SecurityManager: Changing view acls to: root
16/03/25 13:09:56 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:09:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:09:56 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:09:56 INFO Remoting: Starting remoting
16/03/25 13:09:56 INFO Utils: Successfully started service 'sparkDriver' on port 51012.
16/03/25 13:09:56 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:51012]
16/03/25 13:09:56 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:09:56 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:09:56 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b93ddb40-b670-4aba-82d9-8f64611eb7b6
16/03/25 13:09:56 INFO MemoryStore: MemoryStore started with capacity 541.2 MB
16/03/25 13:09:57 INFO HttpFileServer: HTTP File server directory is /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/httpd-13b12653-ad73-42c4-b121-2890cef13f78
16/03/25 13:09:57 INFO HttpServer: Starting HTTP Server
16/03/25 13:09:57 INFO Utils: Successfully started service 'HTTP file server' on port 59404.
16/03/25 13:09:57 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:09:57 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:09:57 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:09:57 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-3a547027-08b6-46cd-b0fb-9682d88e9f90/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:09:57 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891597209
16/03/25 13:09:57 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:09:57 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:09:57 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36841.
16/03/25 13:09:57 INFO NettyBlockTransferService: Server created on 36841
16/03/25 13:09:57 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:09:57 INFO BlockManagerMasterEndpoint: Registering block manager localhost:36841 with 541.2 MB RAM, BlockManagerId(driver, localhost, 36841)
16/03/25 13:09:57 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:09:57 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:09:57 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:09:57 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:09:57 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:09:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:09:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:09:57 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:09:57 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=567505059
16/03/25 13:09:57 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 541.2 MB)
16/03/25 13:09:57 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=567505059
16/03/25 13:09:57 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 541.2 MB)
16/03/25 13:09:57 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:36841 (size: 4.1 KB, free: 541.2 MB)
16/03/25 13:09:57 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:09:57 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:09:57 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:09:57 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2520 bytes)
16/03/25 13:09:57 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2538 bytes)
16/03/25 13:09:57 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:09:57 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891597209
16/03/25 13:09:57 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:09:57 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-3a547027-08b6-46cd-b0fb-9682d88e9f90/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:09:57 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:09:57 INFO MemoryStore: ensureFreeSpace(277) called with curMem=10732, maxMem=567505059
16/03/25 13:09:57 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 277.0 B, free 541.2 MB)
16/03/25 13:09:57 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:36841 (size: 277.0 B, free: 541.2 MB)
16/03/25 13:09:57 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:09:57 INFO MemoryStore: ensureFreeSpace(255) called with curMem=11009, maxMem=567505059
16/03/25 13:09:57 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 255.0 B, free 541.2 MB)
16/03/25 13:09:57 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:36841 (size: 255.0 B, free: 541.2 MB)
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: given
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: Madras
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): adding to parents: syn =  Synset('tamil_nadu.n.01') ; keyword:  Bay  in syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= [u'Madras']
reduceFunction_Parents(): returns= [u'Madras']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Madras']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Madras']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: sum
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Madras']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: expressed
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Madras']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: geographical
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Madras']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: boundary
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Madras']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Madras']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Madras']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: function
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Madras']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: product
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Madras']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: terms
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'status', u'people', u'relations', u'to', u'groups', u'between', u'respect', u'the', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Madras']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: equivalent
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Madras']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: Bay
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'smaller', u'shoreline', u'gulf', u'of', u'larger', u'cove', u'but', u'an', u'indentation', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Madras']
16/03/25 13:10:07 INFO PythonRunner: Times: total = 10315, boot = 481, init = 394, finish = 9440
16/03/25 13:10:07 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:10:07 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 10407 ms on localhost (1/2)
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Bay  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: area
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: expansion
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: serving
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: formerly
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: people
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: culture
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: bishop
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: special
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: geography
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: city
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
16/03/25 13:10:08 INFO PythonRunner: Times: total = 10724, boot = 483, init = 497, finish = 9744
16/03/25 13:10:08 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:10:08 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 10.822 s
16/03/25 13:10:08 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:10:08 INFO DAGScheduler: running: Set()
16/03/25 13:10:08 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:10:08 INFO DAGScheduler: failed: Set()
16/03/25 13:10:08 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:10:08 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:10:08 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11264, maxMem=567505059
16/03/25 13:10:08 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 541.2 MB)
16/03/25 13:10:08 INFO MemoryStore: ensureFreeSpace(3057) called with curMem=16248, maxMem=567505059
16/03/25 13:10:08 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 10819 ms on localhost (2/2)
16/03/25 13:10:08 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:10:08 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 541.2 MB)
16/03/25 13:10:08 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:36841 (size: 3.0 KB, free: 541.2 MB)
16/03/25 13:10:08 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:10:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:10:08 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:10:08 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:10:08 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:10:08 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:10:08 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:10:08 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/25 13:10:08 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/25 13:10:08 INFO PythonRunner: Times: total = 38, boot = -274, init = 311, finish = 1
16/03/25 13:10:08 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:10:08 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 70 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'Chennai', u'Madras']
16/03/25 13:10:08 INFO PythonRunner: Times: total = 281, boot = 280, init = 1, finish = 0
16/03/25 13:10:08 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1280 bytes result sent to driver
16/03/25 13:10:08 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.308 s
16/03/25 13:10:08 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 309 ms on localhost (2/2)
16/03/25 13:10:08 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:10:08 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 11.215857 s
16/03/25 13:10:08 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:10:08 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:10:08 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:10:08 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:10:08 INFO DAGScheduler: Missing parents: List()
16/03/25 13:10:08 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:10:08 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19305, maxMem=567505059
16/03/25 13:10:08 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 541.2 MB)
16/03/25 13:10:08 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25121, maxMem=567505059
16/03/25 13:10:08 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 541.2 MB)
16/03/25 13:10:08 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:36841 (size: 3.3 KB, free: 541.2 MB)
16/03/25 13:10:08 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:10:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:10:08 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:10:08 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:10:08 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2361 bytes)
16/03/25 13:10:08 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:10:08 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:10:08 INFO PythonRunner: Times: total = 56, boot = -25, init = 81, finish = 0
16/03/25 13:10:08 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:10:08 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 71 ms on localhost (1/2)
16/03/25 13:10:09 INFO PythonRunner: Times: total = 438, boot = 438, init = 0, finish = 0
16/03/25 13:10:09 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1342 bytes result sent to driver
16/03/25 13:10:09 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 449 ms on localhost (2/2)
16/03/25 13:10:09 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:10:09 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.448 s
16/03/25 13:10:09 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.488912 s
16/03/25 13:10:09 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:10:09 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:10:09 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:10:09 INFO MemoryStore: MemoryStore cleared
16/03/25 13:10:09 INFO BlockManager: BlockManager stopped
16/03/25 13:10:09 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:10:09 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:10:09 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:10:09 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:10:09 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:10:09 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1ef4e6c>, {'2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], '4b7e9f2659636820e82592ed034512f9': [u'Chennai', u'Madras'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], '57466dae2c092869867908c5c54e241c': [u'metropolitan', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '3cd540871242471e0d89bea4eabc06ea': [u'None', u'expansion', u'None'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras'], '4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], '25439f8325592e4ecd8b06f5f799b57a': [u'None', u'expansion', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None']})
asfer_pickle_string_dump(): picklef.write(): western
16/03/25 13:10:10 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:10:10 INFO SecurityManager: Changing view acls to: root
16/03/25 13:10:10 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:10:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:10:10 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:10:10 INFO Remoting: Starting remoting
16/03/25 13:10:10 INFO Utils: Successfully started service 'sparkDriver' on port 41715.
16/03/25 13:10:10 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:41715]
16/03/25 13:10:10 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:10:10 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:10:10 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-aa11bb54-e865-4568-b932-26f1abb670a6
16/03/25 13:10:10 INFO MemoryStore: MemoryStore started with capacity 541.2 MB
16/03/25 13:10:10 INFO HttpFileServer: HTTP File server directory is /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/httpd-4449592c-9d33-4d8b-b6bd-10a3f3f1278c
16/03/25 13:10:10 INFO HttpServer: Starting HTTP Server
16/03/25 13:10:10 INFO Utils: Successfully started service 'HTTP file server' on port 60184.
16/03/25 13:10:10 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:10:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:10:10 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:10:10 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-6e4a2771-d05f-4150-b7e2-188bbaa59e2d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:10:10 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891610461
16/03/25 13:10:10 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:10:10 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:10:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44392.
16/03/25 13:10:10 INFO NettyBlockTransferService: Server created on 44392
16/03/25 13:10:10 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:10:10 INFO BlockManagerMasterEndpoint: Registering block manager localhost:44392 with 541.2 MB RAM, BlockManagerId(driver, localhost, 44392)
16/03/25 13:10:10 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:10:10 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:10:10 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:10:10 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:10:10 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:10:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:10:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:10:10 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:10:10 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=567505059
16/03/25 13:10:10 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 541.2 MB)
16/03/25 13:10:10 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=567505059
16/03/25 13:10:10 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 541.2 MB)
16/03/25 13:10:10 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:44392 (size: 4.1 KB, free: 541.2 MB)
16/03/25 13:10:10 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:10:10 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:10:10 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:10:10 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2532 bytes)
16/03/25 13:10:10 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2523 bytes)
16/03/25 13:10:10 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:10:10 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891610461
16/03/25 13:10:10 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:10:10 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-6e4a2771-d05f-4150-b7e2-188bbaa59e2d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:10:10 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:10:10 INFO MemoryStore: ensureFreeSpace(268) called with curMem=10732, maxMem=567505059
16/03/25 13:10:10 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 268.0 B, free 541.2 MB)
16/03/25 13:10:10 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:44392 (size: 268.0 B, free: 541.2 MB)
16/03/25 13:10:10 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:10:10 INFO MemoryStore: ensureFreeSpace(266) called with curMem=11000, maxMem=567505059
16/03/25 13:10:10 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 266.0 B, free 541.2 MB)
16/03/25 13:10:10 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:44392 (size: 266.0 B, free: 541.2 MB)
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: Madras
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  western  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: area
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: expansion
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: serving
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: formerly
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: people
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: culture
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: bishop
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: special
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: geography
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: city
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: given
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
16/03/25 13:10:22 INFO PythonRunner: Times: total = 12138, boot = 459, init = 638, finish = 11041
16/03/25 13:10:22 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:10:22 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 12228 ms on localhost (1/2)
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: sum
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: expressed
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: geographical
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: boundary
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: function
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: product
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: terms
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'status', u'people', u'relations', u'to', u'groups', u'between', u'respect', u'the', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: equivalent
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: Bay
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'smaller', u'shoreline', u'gulf', u'of', u'larger', u'cove', u'but', u'an', u'indentation', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: western
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'and', u'about', u'United', u'development', u'of', u'life', u'period', u'States', u'exploration', u'western', u'in', u'during', u'the', u'film'])
mapFunction_Parents(): adding to parents: syn =  Synset('western.n.01') ; keyword:  western  in syndef_tokens= set([u'a', u'and', u'about', u'United', u'development', u'of', u'life', u'period', u'States', u'exploration', u'western', u'in', u'during', u'the', u'film'])
mapFunction_Parents(): returns= [u'western']
reduceFunction_Parents(): returns= ['None', u'western']
16/03/25 13:10:23 INFO PythonRunner: Times: total = 12630, boot = 461, init = 453, finish = 11716
16/03/25 13:10:23 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:10:23 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 12.712 s
16/03/25 13:10:23 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:10:23 INFO DAGScheduler: running: Set()
16/03/25 13:10:23 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:10:23 INFO DAGScheduler: failed: Set()
16/03/25 13:10:23 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:10:23 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:10:23 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11266, maxMem=567505059
16/03/25 13:10:23 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 541.2 MB)
16/03/25 13:10:23 INFO MemoryStore: ensureFreeSpace(3057) called with curMem=16250, maxMem=567505059
16/03/25 13:10:23 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 12707 ms on localhost (2/2)
16/03/25 13:10:23 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:10:23 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 541.2 MB)
16/03/25 13:10:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:44392 (size: 3.0 KB, free: 541.2 MB)
16/03/25 13:10:23 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:10:23 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:10:23 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:10:23 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:10:23 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:10:23 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:10:23 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:10:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:10:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/03/25 13:10:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:10:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
reduceFunction_Parents(): returns= [u'metropolitan', 'None', u'western']
16/03/25 13:10:23 INFO PythonRunner: Times: total = 25, boot = -250, init = 274, finish = 1
16/03/25 13:10:23 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1294 bytes result sent to driver
16/03/25 13:10:23 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 51 ms on localhost (1/2)
16/03/25 13:10:23 INFO PythonRunner: Times: total = 302, boot = 301, init = 1, finish = 0
16/03/25 13:10:23 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:10:23 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.316 s
16/03/25 13:10:23 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 13.075349 s
16/03/25 13:10:23 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 329 ms on localhost (2/2)
16/03/25 13:10:23 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:10:23 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:10:23 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:10:23 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:10:23 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:10:23 INFO DAGScheduler: Missing parents: List()
16/03/25 13:10:23 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:10:23 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19307, maxMem=567505059
16/03/25 13:10:23 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 541.2 MB)
16/03/25 13:10:23 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25123, maxMem=567505059
16/03/25 13:10:23 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 541.2 MB)
16/03/25 13:10:23 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:44392 (size: 3.3 KB, free: 541.2 MB)
16/03/25 13:10:23 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:10:23 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:10:23 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:10:23 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:10:23 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2375 bytes)
16/03/25 13:10:23 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:10:23 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:10:23 INFO PythonRunner: Times: total = 65, boot = -43, init = 108, finish = 0
16/03/25 13:10:23 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1359 bytes result sent to driver
16/03/25 13:10:23 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 81 ms on localhost (1/2)
16/03/25 13:10:24 INFO PythonRunner: Times: total = 341, boot = 341, init = 0, finish = 0
16/03/25 13:10:24 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:10:24 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 355 ms on localhost (2/2)
16/03/25 13:10:24 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:10:24 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.357 s
16/03/25 13:10:24 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.374206 s
16/03/25 13:10:24 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:10:24 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:10:24 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:10:24 INFO MemoryStore: MemoryStore cleared
16/03/25 13:10:24 INFO BlockManager: BlockManager stopped
16/03/25 13:10:24 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:10:24 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:10:24 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:10:24 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:10:24 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:10:24 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1ef4e6c>, {'2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], '4b7e9f2659636820e82592ed034512f9': [u'Chennai', u'Madras'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], '57466dae2c092869867908c5c54e241c': [u'metropolitan', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], '3a2fbf91abebcac17538118b2e02315d': [u'metropolitan', u'None', u'western'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '3cd540871242471e0d89bea4eabc06ea': [u'None', u'expansion', u'None'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras'], '4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], '25439f8325592e4ecd8b06f5f799b57a': [u'None', u'expansion', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None']})
asfer_pickle_string_dump(): picklef.write(): particular
16/03/25 13:10:25 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:10:25 INFO SecurityManager: Changing view acls to: root
16/03/25 13:10:25 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:10:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:10:25 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:10:25 INFO Remoting: Starting remoting
16/03/25 13:10:25 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:52111]
16/03/25 13:10:25 INFO Utils: Successfully started service 'sparkDriver' on port 52111.
16/03/25 13:10:25 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:10:25 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:10:25 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-13f122bd-1b75-4c43-a1dd-4a9aeeb32125
16/03/25 13:10:25 INFO MemoryStore: MemoryStore started with capacity 541.2 MB
16/03/25 13:10:25 INFO HttpFileServer: HTTP File server directory is /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/httpd-56876c90-ac84-4d8e-8b2c-7f5b78eec16f
16/03/25 13:10:25 INFO HttpServer: Starting HTTP Server
16/03/25 13:10:25 INFO Utils: Successfully started service 'HTTP file server' on port 39195.
16/03/25 13:10:25 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:10:25 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:10:25 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:10:25 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-ab144ce6-b023-4c83-8721-ddbf43aea69c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:10:25 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891625585
16/03/25 13:10:25 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:10:25 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:10:25 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58604.
16/03/25 13:10:25 INFO NettyBlockTransferService: Server created on 58604
16/03/25 13:10:25 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:10:25 INFO BlockManagerMasterEndpoint: Registering block manager localhost:58604 with 541.2 MB RAM, BlockManagerId(driver, localhost, 58604)
16/03/25 13:10:25 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:10:25 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:10:25 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:10:25 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:10:25 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:10:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:10:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:10:25 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:10:25 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=567505059
16/03/25 13:10:25 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 541.2 MB)
16/03/25 13:10:25 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=567505059
16/03/25 13:10:25 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 541.2 MB)
16/03/25 13:10:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:58604 (size: 4.1 KB, free: 541.2 MB)
16/03/25 13:10:25 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:10:25 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:10:25 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:10:25 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2532 bytes)
16/03/25 13:10:25 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2557 bytes)
16/03/25 13:10:25 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:10:25 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891625585
16/03/25 13:10:25 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:10:26 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-ab144ce6-b023-4c83-8721-ddbf43aea69c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:10:26 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:10:26 INFO MemoryStore: ensureFreeSpace(292) called with curMem=10732, maxMem=567505059
16/03/25 13:10:26 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 292.0 B, free 541.2 MB)
16/03/25 13:10:26 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:10:26 INFO MemoryStore: ensureFreeSpace(266) called with curMem=11024, maxMem=567505059
16/03/25 13:10:26 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 266.0 B, free 541.2 MB)
16/03/25 13:10:26 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:58604 (size: 266.0 B, free: 541.2 MB)
16/03/25 13:10:26 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:58604 (size: 292.0 B, free: 541.2 MB)
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: Chennai
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: Madras
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: area
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  particular  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: expansion
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: serving
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: formerly
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: people
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: culture
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): adding to parents: syn =  Synset('culture.n.01') ; keyword:  particular  in syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= [u'culture']
reduceFunction_Parents(): returns= ['None', u'area', u'culture']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area', u'culture']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: bishop
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area', u'culture']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: special
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area', u'culture']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: geography
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area', u'culture']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: city
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area', u'culture']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: given
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area', u'culture']
16/03/25 13:10:40 INFO PythonRunner: Times: total = 14301, boot = 698, init = 661, finish = 12942
16/03/25 13:10:40 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:10:40 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 14456 ms on localhost (1/2)
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: sum
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: expressed
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: geographical
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: boundary
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: function
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: product
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: terms
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'status', u'people', u'relations', u'to', u'groups', u'between', u'respect', u'the', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: equivalent
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: Bay
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'smaller', u'shoreline', u'gulf', u'of', u'larger', u'cove', u'but', u'an', u'indentation', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: western
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'and', u'about', u'United', u'development', u'of', u'life', u'period', u'States', u'exploration', u'western', u'in', u'during', u'the', u'film'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: particular
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'about', u')', u'(', u'some', u'general', u'to', u'as', u'part', u'opposed', u'fact'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/25 13:10:40 INFO PythonRunner: Times: total = 14859, boot = 702, init = 676, finish = 13481
16/03/25 13:10:40 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:10:40 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 15035 ms on localhost (2/2)
16/03/25 13:10:40 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 15.036 s
16/03/25 13:10:40 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:10:40 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:10:40 INFO DAGScheduler: running: Set()
16/03/25 13:10:40 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:10:40 INFO DAGScheduler: failed: Set()
16/03/25 13:10:40 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:10:40 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:10:40 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11290, maxMem=567505059
16/03/25 13:10:40 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 541.2 MB)
16/03/25 13:10:40 INFO MemoryStore: ensureFreeSpace(3057) called with curMem=16274, maxMem=567505059
16/03/25 13:10:40 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 541.2 MB)
16/03/25 13:10:40 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:58604 (size: 3.0 KB, free: 541.2 MB)
16/03/25 13:10:40 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:10:40 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:10:40 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:10:40 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:10:40 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:10:40 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:10:40 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:10:40 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:10:40 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:10:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/25 13:10:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
reduceFunction_Parents(): returns= ['None', u'area', u'culture', 'None']
16/03/25 13:10:41 INFO PythonRunner: Times: total = 63, boot = -245, init = 308, finish = 0
16/03/25 13:10:41 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1294 bytes result sent to driver
16/03/25 13:10:41 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 88 ms on localhost (1/2)
16/03/25 13:10:41 INFO PythonRunner: Times: total = 307, boot = 306, init = 1, finish = 0
16/03/25 13:10:41 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:10:41 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.330 s
16/03/25 13:10:41 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 15.407148 s
16/03/25 13:10:41 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 328 ms on localhost (2/2)
16/03/25 13:10:41 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:10:41 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:10:41 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:10:41 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:10:41 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:10:41 INFO DAGScheduler: Missing parents: List()
16/03/25 13:10:41 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:10:41 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19331, maxMem=567505059
16/03/25 13:10:41 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 541.2 MB)
16/03/25 13:10:41 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25147, maxMem=567505059
16/03/25 13:10:41 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 541.2 MB)
16/03/25 13:10:41 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:58604 (size: 3.3 KB, free: 541.2 MB)
16/03/25 13:10:41 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:10:41 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:10:41 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:10:41 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:10:41 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2375 bytes)
16/03/25 13:10:41 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:10:41 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:10:41 INFO PythonRunner: Times: total = 149, boot = 148, init = 1, finish = 0
16/03/25 13:10:41 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1362 bytes result sent to driver
16/03/25 13:10:41 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 163 ms on localhost (1/2)
16/03/25 13:10:41 INFO PythonRunner: Times: total = 201, boot = 196, init = 5, finish = 0
16/03/25 13:10:41 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:10:41 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 217 ms on localhost (2/2)
16/03/25 13:10:41 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:10:41 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.204 s
16/03/25 13:10:41 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.233714 s
16/03/25 13:10:41 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:10:41 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:10:41 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:10:41 INFO MemoryStore: MemoryStore cleared
16/03/25 13:10:41 INFO BlockManager: BlockManager stopped
16/03/25 13:10:41 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:10:41 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:10:41 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:10:41 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:10:41 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:10:41 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1ef4e6c>, {'2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], '4b7e9f2659636820e82592ed034512f9': [u'Chennai', u'Madras'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], '57466dae2c092869867908c5c54e241c': [u'metropolitan', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], 'e9da57cf07c9f8d232e2c9c1a07d1a0a': [u'None', u'area', u'culture', u'None'], '3a2fbf91abebcac17538118b2e02315d': [u'metropolitan', u'None', u'western'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '3cd540871242471e0d89bea4eabc06ea': [u'None', u'expansion', u'None'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras'], '4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], '25439f8325592e4ecd8b06f5f799b57a': [u'None', u'expansion', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None']})
asfer_pickle_string_dump(): picklef.write(): Bengal
16/03/25 13:10:42 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:10:42 INFO SecurityManager: Changing view acls to: root
16/03/25 13:10:42 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:10:42 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:10:42 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:10:42 INFO Remoting: Starting remoting
16/03/25 13:10:42 INFO Utils: Successfully started service 'sparkDriver' on port 56749.
16/03/25 13:10:42 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:56749]
16/03/25 13:10:42 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:10:42 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:10:42 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0ebf2f1b-cdab-46a7-8cb5-7c248013a2a9
16/03/25 13:10:42 INFO MemoryStore: MemoryStore started with capacity 541.2 MB
16/03/25 13:10:42 INFO HttpFileServer: HTTP File server directory is /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/httpd-aa7abc08-9734-4751-b7d8-ab8a0a3052f5
16/03/25 13:10:42 INFO HttpServer: Starting HTTP Server
16/03/25 13:10:42 INFO Utils: Successfully started service 'HTTP file server' on port 58512.
16/03/25 13:10:42 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:10:42 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:10:42 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:10:43 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-fb7cd00c-c65d-4d34-a996-9730dd0d9e69/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:10:43 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891643051
16/03/25 13:10:43 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:10:43 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:10:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38805.
16/03/25 13:10:43 INFO NettyBlockTransferService: Server created on 38805
16/03/25 13:10:43 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:10:43 INFO BlockManagerMasterEndpoint: Registering block manager localhost:38805 with 541.2 MB RAM, BlockManagerId(driver, localhost, 38805)
16/03/25 13:10:43 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:10:43 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:10:43 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:10:43 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:10:43 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:10:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:10:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:10:43 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:10:43 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=567505059
16/03/25 13:10:43 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 541.2 MB)
16/03/25 13:10:43 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=567505059
16/03/25 13:10:43 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 541.2 MB)
16/03/25 13:10:43 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:38805 (size: 4.1 KB, free: 541.2 MB)
16/03/25 13:10:43 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:10:43 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:10:43 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:10:43 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2545 bytes)
16/03/25 13:10:43 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2540 bytes)
16/03/25 13:10:43 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:10:43 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891643051
16/03/25 13:10:43 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:10:43 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-fb7cd00c-c65d-4d34-a996-9730dd0d9e69/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:10:43 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:10:43 INFO MemoryStore: ensureFreeSpace(276) called with curMem=10732, maxMem=567505059
16/03/25 13:10:43 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:10:43 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 276.0 B, free 541.2 MB)
16/03/25 13:10:43 INFO MemoryStore: ensureFreeSpace(283) called with curMem=11008, maxMem=567505059
16/03/25 13:10:43 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 283.0 B, free 541.2 MB)
16/03/25 13:10:43 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:38805 (size: 283.0 B, free: 541.2 MB)
16/03/25 13:10:43 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:38805 (size: 276.0 B, free: 541.2 MB)
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: Eastern
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Bengal  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: area
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: expansion
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: serving
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: formerly
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: people
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: culture
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: bishop
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: special
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: geography
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: city
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: given
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: Madras
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): adding to parents: syn =  Synset('tamil_nadu.n.01') ; keyword:  Bengal  in syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= [u'Madras']
reduceFunction_Parents(): returns= [u'Chennai', u'Madras']
16/03/25 13:10:55 INFO PythonRunner: Times: total = 12253, boot = 561, init = 672, finish = 11020
16/03/25 13:10:55 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:10:55 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 12433 ms on localhost (1/2)
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: sum
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: expressed
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: geographical
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: boundary
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: function
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: product
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: terms
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'status', u'people', u'relations', u'to', u'groups', u'between', u'respect', u'the', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: equivalent
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: Bay
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'smaller', u'shoreline', u'gulf', u'of', u'larger', u'cove', u'but', u'an', u'indentation', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: western
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'and', u'about', u'United', u'development', u'of', u'life', u'period', u'States', u'exploration', u'western', u'in', u'during', u'the', u'film'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: particular
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'about', u')', u'(', u'some', u'general', u'to', u'as', u'part', u'opposed', u'fact'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: Bengal
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'whose', u'and', u'Bangladesh', u'eastern', u'region', u'India', u'part', u'western', u'in', u'included', u'now', u'is'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/25 13:10:58 INFO PythonRunner: Times: total = 14562, boot = 550, init = 620, finish = 13392
16/03/25 13:10:58 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:10:58 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 14754 ms on localhost (2/2)
16/03/25 13:10:58 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 14.793 s
16/03/25 13:10:58 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:10:58 INFO DAGScheduler: running: Set()
16/03/25 13:10:58 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:10:58 INFO DAGScheduler: failed: Set()
16/03/25 13:10:58 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:10:58 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:10:58 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11291, maxMem=567505059
16/03/25 13:10:58 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 541.2 MB)
16/03/25 13:10:58 INFO MemoryStore: ensureFreeSpace(3057) called with curMem=16275, maxMem=567505059
16/03/25 13:10:58 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 541.2 MB)
16/03/25 13:10:58 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:10:58 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:38805 (size: 3.0 KB, free: 541.2 MB)
16/03/25 13:10:58 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:10:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:10:58 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:10:58 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:10:58 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:10:58 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:10:58 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:10:58 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:10:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/03/25 13:10:58 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:10:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/03/25 13:10:58 INFO PythonRunner: Times: total = 79, boot = -2157, init = 2235, finish = 1
16/03/25 13:10:58 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:10:58 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 122 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'Chennai', u'Madras', 'None']
16/03/25 13:10:58 INFO PythonRunner: Times: total = 351, boot = 349, init = 0, finish = 2
16/03/25 13:10:58 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1288 bytes result sent to driver
16/03/25 13:10:58 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 380 ms on localhost (2/2)
16/03/25 13:10:58 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:10:58 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.382 s
16/03/25 13:10:58 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 15.243246 s
16/03/25 13:10:58 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:10:58 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:10:58 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:10:58 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:10:58 INFO DAGScheduler: Missing parents: List()
16/03/25 13:10:58 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:10:58 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19332, maxMem=567505059
16/03/25 13:10:58 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 541.2 MB)
16/03/25 13:10:58 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25148, maxMem=567505059
16/03/25 13:10:58 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 541.2 MB)
16/03/25 13:10:58 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:38805 (size: 3.3 KB, free: 541.2 MB)
16/03/25 13:10:58 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:10:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:10:58 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:10:58 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:10:58 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2369 bytes)
16/03/25 13:10:58 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:10:58 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:10:58 INFO PythonRunner: Times: total = 77, boot = -74, init = 151, finish = 0
16/03/25 13:10:58 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1353 bytes result sent to driver
16/03/25 13:10:58 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 95 ms on localhost (1/2)
16/03/25 13:10:59 INFO PythonRunner: Times: total = 190, boot = 190, init = 0, finish = 0
16/03/25 13:10:59 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:10:59 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 205 ms on localhost (2/2)
16/03/25 13:10:59 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:10:59 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.189 s
16/03/25 13:10:59 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.249472 s
16/03/25 13:10:59 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:10:59 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:10:59 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:10:59 INFO MemoryStore: MemoryStore cleared
16/03/25 13:10:59 INFO BlockManager: BlockManager stopped
16/03/25 13:10:59 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:10:59 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:10:59 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:10:59 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:10:59 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:10:59 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1ef4e6c>, {'2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], '4b7e9f2659636820e82592ed034512f9': [u'Chennai', u'Madras'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], 'ff4fcba188cd7bb550ed88e9ee5dc6f1': [u'Chennai', u'Madras', u'None'], '57466dae2c092869867908c5c54e241c': [u'metropolitan', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], 'e9da57cf07c9f8d232e2c9c1a07d1a0a': [u'None', u'area', u'culture', u'None'], '3a2fbf91abebcac17538118b2e02315d': [u'metropolitan', u'None', u'western'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '3cd540871242471e0d89bea4eabc06ea': [u'None', u'expansion', u'None'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras'], '4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], '25439f8325592e4ecd8b06f5f799b57a': [u'None', u'expansion', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None']})
asfer_pickle_string_dump(): picklef.write(): Orthodox
16/03/25 13:11:00 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:11:00 INFO SecurityManager: Changing view acls to: root
16/03/25 13:11:00 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:11:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:11:00 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:11:00 INFO Remoting: Starting remoting
16/03/25 13:11:00 INFO Utils: Successfully started service 'sparkDriver' on port 54173.
16/03/25 13:11:00 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:54173]
16/03/25 13:11:00 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:11:00 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:11:00 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8d8b2863-d13e-43b2-b653-6a6c696a9069
16/03/25 13:11:00 INFO MemoryStore: MemoryStore started with capacity 541.2 MB
16/03/25 13:11:00 INFO HttpFileServer: HTTP File server directory is /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/httpd-30430fee-9723-4646-af06-64f9884dc91b
16/03/25 13:11:00 INFO HttpServer: Starting HTTP Server
16/03/25 13:11:00 INFO Utils: Successfully started service 'HTTP file server' on port 59277.
16/03/25 13:11:00 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:11:00 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:11:00 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:11:00 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-b21edf6e-f0d5-42bb-abda-b60ffeafecaf/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:11:00 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891660419
16/03/25 13:11:00 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:11:00 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:11:00 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 47965.
16/03/25 13:11:00 INFO NettyBlockTransferService: Server created on 47965
16/03/25 13:11:00 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:11:00 INFO BlockManagerMasterEndpoint: Registering block manager localhost:47965 with 541.2 MB RAM, BlockManagerId(driver, localhost, 47965)
16/03/25 13:11:00 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:11:00 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:11:00 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:11:00 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:11:00 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:11:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:11:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:11:00 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:11:00 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=567505059
16/03/25 13:11:00 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 541.2 MB)
16/03/25 13:11:00 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=567505059
16/03/25 13:11:00 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 541.2 MB)
16/03/25 13:11:00 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:47965 (size: 4.1 KB, free: 541.2 MB)
16/03/25 13:11:00 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:11:00 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:11:00 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:11:00 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2545 bytes)
16/03/25 13:11:00 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2572 bytes)
16/03/25 13:11:00 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:11:00 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891660419
16/03/25 13:11:00 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:11:00 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-b21edf6e-f0d5-42bb-abda-b60ffeafecaf/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:11:00 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:11:00 INFO MemoryStore: ensureFreeSpace(309) called with curMem=10732, maxMem=567505059
16/03/25 13:11:00 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 309.0 B, free 541.2 MB)
16/03/25 13:11:00 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:47965 (size: 309.0 B, free: 541.2 MB)
16/03/25 13:11:00 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:11:00 INFO MemoryStore: ensureFreeSpace(276) called with curMem=11041, maxMem=567505059
16/03/25 13:11:00 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 276.0 B, free 541.2 MB)
16/03/25 13:11:00 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:47965 (size: 276.0 B, free: 541.2 MB)
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: Eastern
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  Orthodox  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: area
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: expansion
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: serving
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: formerly
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: people
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: culture
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: bishop
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: special
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: geography
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: city
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: given
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: Madras
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
16/03/25 13:11:13 INFO PythonRunner: Times: total = 13024, boot = 734, init = 858, finish = 11432
16/03/25 13:11:13 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:11:13 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 13136 ms on localhost (1/2)
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: sum
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: expressed
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: geographical
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: boundary
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: function
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: product
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: terms
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'status', u'people', u'relations', u'to', u'groups', u'between', u'respect', u'the', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: equivalent
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: Bay
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'smaller', u'shoreline', u'gulf', u'of', u'larger', u'cove', u'but', u'an', u'indentation', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: western
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'and', u'about', u'United', u'development', u'of', u'life', u'period', u'States', u'exploration', u'western', u'in', u'during', u'the', u'film'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: particular
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'about', u')', u'(', u'some', u'general', u'to', u'as', u'part', u'opposed', u'fact'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: Bengal
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'whose', u'and', u'Bangladesh', u'eastern', u'region', u'India', u'part', u'western', u'in', u'included', u'now', u'is'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: Orthodox
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'pertaining', u'Judaism', u'characteristic', u'to', u'of', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/25 13:11:15 INFO PythonRunner: Times: total = 15020, boot = 712, init = 494, finish = 13814
16/03/25 13:11:15 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:11:15 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 15128 ms on localhost (2/2)
16/03/25 13:11:15 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:11:15 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 15.125 s
16/03/25 13:11:15 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:11:15 INFO DAGScheduler: running: Set()
16/03/25 13:11:15 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:11:15 INFO DAGScheduler: failed: Set()
16/03/25 13:11:15 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:11:15 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:11:15 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11317, maxMem=567505059
16/03/25 13:11:15 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 541.2 MB)
16/03/25 13:11:15 INFO MemoryStore: ensureFreeSpace(3057) called with curMem=16301, maxMem=567505059
16/03/25 13:11:15 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 541.2 MB)
16/03/25 13:11:15 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:47965 (size: 3.0 KB, free: 541.2 MB)
16/03/25 13:11:15 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:11:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:11:15 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:11:15 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:11:15 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:11:15 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:11:15 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:11:15 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:11:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/25 13:11:15 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:11:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
reduceFunction_Parents(): returns= [u'metropolitan', 'None']
16/03/25 13:11:15 INFO PythonRunner: Times: total = 59, boot = -1680, init = 1739, finish = 0
16/03/25 13:11:15 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1280 bytes result sent to driver
16/03/25 13:11:15 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 93 ms on localhost (1/2)
16/03/25 13:11:16 INFO PythonRunner: Times: total = 287, boot = 286, init = 0, finish = 1
16/03/25 13:11:16 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:11:16 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 331 ms on localhost (2/2)
16/03/25 13:11:16 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:11:16 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.332 s
16/03/25 13:11:16 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 15.541232 s
16/03/25 13:11:16 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:11:16 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:11:16 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:11:16 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:11:16 INFO DAGScheduler: Missing parents: List()
16/03/25 13:11:16 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:11:16 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19358, maxMem=567505059
16/03/25 13:11:16 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 541.2 MB)
16/03/25 13:11:16 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25174, maxMem=567505059
16/03/25 13:11:16 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 541.2 MB)
16/03/25 13:11:16 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:47965 (size: 3.3 KB, free: 541.2 MB)
16/03/25 13:11:16 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:47965 in memory (size: 3.0 KB, free: 541.2 MB)
16/03/25 13:11:16 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:11:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:11:16 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:11:16 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:11:16 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2361 bytes)
16/03/25 13:11:16 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:11:16 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:11:16 INFO PythonRunner: Times: total = 13, boot = -70, init = 83, finish = 0
16/03/25 13:11:16 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:11:16 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 87 ms on localhost (1/2)
16/03/25 13:11:16 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:47965 in memory (size: 4.1 KB, free: 541.2 MB)
16/03/25 13:11:16 INFO PythonRunner: Times: total = 93, boot = -369, init = 462, finish = 0
16/03/25 13:11:16 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1345 bytes result sent to driver
16/03/25 13:11:16 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 118 ms on localhost (2/2)
16/03/25 13:11:16 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:11:16 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.120 s
16/03/25 13:11:16 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.518658 s
16/03/25 13:11:17 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:11:17 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:11:17 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:11:17 INFO MemoryStore: MemoryStore cleared
16/03/25 13:11:17 INFO BlockManager: BlockManager stopped
16/03/25 13:11:17 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:11:17 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:11:17 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:11:17 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:11:17 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:11:17 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1ef4e6c>, {'2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], '4b7e9f2659636820e82592ed034512f9': [u'Chennai', u'Madras'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], 'ff4fcba188cd7bb550ed88e9ee5dc6f1': [u'Chennai', u'Madras', u'None'], '57466dae2c092869867908c5c54e241c': [u'metropolitan', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], 'e9da57cf07c9f8d232e2c9c1a07d1a0a': [u'None', u'area', u'culture', u'None'], '3a2fbf91abebcac17538118b2e02315d': [u'metropolitan', u'None', u'western'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '3cd540871242471e0d89bea4eabc06ea': [u'None', u'expansion', u'None'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras'], '4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '39c21ff4448a2910600584a0d49f93e8': [u'metropolitan', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], '25439f8325592e4ecd8b06f5f799b57a': [u'None', u'expansion', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None']})
asfer_pickle_string_dump(): picklef.write(): region
16/03/25 13:11:17 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:11:17 INFO SecurityManager: Changing view acls to: root
16/03/25 13:11:17 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:11:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:11:18 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:11:18 INFO Remoting: Starting remoting
16/03/25 13:11:18 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:58170]
16/03/25 13:11:18 INFO Utils: Successfully started service 'sparkDriver' on port 58170.
16/03/25 13:11:18 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:11:18 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:11:18 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a0eb4f93-9c00-4ee7-8a40-933c0f89c02e
16/03/25 13:11:18 INFO MemoryStore: MemoryStore started with capacity 535.3 MB
16/03/25 13:11:18 INFO HttpFileServer: HTTP File server directory is /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/httpd-b4b2da24-a8de-4a46-9b91-f050f1883126
16/03/25 13:11:18 INFO HttpServer: Starting HTTP Server
16/03/25 13:11:18 INFO Utils: Successfully started service 'HTTP file server' on port 50335.
16/03/25 13:11:18 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:11:18 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:11:18 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:11:18 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-33839e2d-aea1-426c-8c1a-4b7e136e4b4a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:11:18 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891678302
16/03/25 13:11:18 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:11:18 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:11:18 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52141.
16/03/25 13:11:18 INFO NettyBlockTransferService: Server created on 52141
16/03/25 13:11:18 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:11:18 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52141 with 535.3 MB RAM, BlockManagerId(driver, localhost, 52141)
16/03/25 13:11:18 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:11:18 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:11:18 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:11:18 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:11:18 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:11:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:11:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:11:18 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:11:18 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=561276518
16/03/25 13:11:18 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 535.3 MB)
16/03/25 13:11:18 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=561276518
16/03/25 13:11:18 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 535.3 MB)
16/03/25 13:11:18 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52141 (size: 4.1 KB, free: 535.3 MB)
16/03/25 13:11:18 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:11:18 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:11:18 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:11:18 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2559 bytes)
16/03/25 13:11:18 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2554 bytes)
16/03/25 13:11:18 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:11:18 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891678302
16/03/25 13:11:18 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:11:18 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-33839e2d-aea1-426c-8c1a-4b7e136e4b4a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:11:18 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:11:18 INFO MemoryStore: ensureFreeSpace(291) called with curMem=10732, maxMem=561276518
16/03/25 13:11:18 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 291.0 B, free 535.3 MB)
16/03/25 13:11:18 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:52141 (size: 291.0 B, free: 535.3 MB)
16/03/25 13:11:18 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:11:18 INFO MemoryStore: ensureFreeSpace(286) called with curMem=11023, maxMem=561276518
16/03/25 13:11:18 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 286.0 B, free 535.3 MB)
16/03/25 13:11:18 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:52141 (size: 286.0 B, free: 535.3 MB)
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: archbishop
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: sum
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: expressed
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: geographical
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: boundary
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: function
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: product
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: terms
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'status', u'people', u'relations', u'to', u'groups', u'between', u'respect', u'the', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: equivalent
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: Bay
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'smaller', u'shoreline', u'gulf', u'of', u'larger', u'cove', u'but', u'an', u'indentation', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: western
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'and', u'about', u'United', u'development', u'of', u'life', u'period', u'States', u'exploration', u'western', u'in', u'during', u'the', u'film'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: particular
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'about', u')', u'(', u'some', u'general', u'to', u'as', u'part', u'opposed', u'fact'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: Bengal
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'whose', u'and', u'Bangladesh', u'eastern', u'region', u'India', u'part', u'western', u'in', u'included', u'now', u'is'])
mapFunction_Parents(): adding to parents: syn =  Synset('bengal.n.01') ; keyword:  region  in syndef_tokens= set([u'a', u'whose', u'and', u'Bangladesh', u'eastern', u'region', u'India', u'part', u'western', u'in', u'included', u'now', u'is'])
mapFunction_Parents(): returns= [u'Bengal']
reduceFunction_Parents(): returns= ['None', u'Bengal']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: Orthodox
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'pertaining', u'Judaism', u'characteristic', u'to', u'of', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Bengal']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: region
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'extended', u'of', u'something', u'spatial', u'the', u'location'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Bengal']
16/03/25 13:11:33 INFO PythonRunner: Times: total = 15209, boot = 798, init = 809, finish = 13602
16/03/25 13:11:33 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:11:33 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 15397 ms on localhost (1/2)
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: area
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  region  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: expansion
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: serving
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: formerly
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: people
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: culture
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: bishop
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: special
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: geography
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: city
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: given
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: Madras
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/25 13:11:34 INFO PythonRunner: Times: total = 16290, boot = 785, init = 813, finish = 14692
16/03/25 13:11:34 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:11:34 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 16.456 s
16/03/25 13:11:34 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:11:34 INFO DAGScheduler: running: Set()
16/03/25 13:11:34 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:11:34 INFO DAGScheduler: failed: Set()
16/03/25 13:11:34 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:11:34 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:11:34 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11309, maxMem=561276518
16/03/25 13:11:34 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 535.3 MB)
16/03/25 13:11:34 INFO MemoryStore: ensureFreeSpace(3057) called with curMem=16293, maxMem=561276518
16/03/25 13:11:34 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 535.3 MB)
16/03/25 13:11:34 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 16469 ms on localhost (2/2)
16/03/25 13:11:34 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:11:34 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52141 (size: 3.0 KB, free: 535.3 MB)
16/03/25 13:11:34 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:11:34 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:11:34 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:11:35 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:11:35 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:11:35 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:11:35 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:11:35 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:11:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/25 13:11:35 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:11:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/25 13:11:35 INFO PythonRunner: Times: total = 19, boot = -776, init = 795, finish = 0
16/03/25 13:11:35 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:11:35 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 93 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'area', 'None', u'Bengal']
16/03/25 13:11:35 INFO PythonRunner: Times: total = 329, boot = 328, init = 1, finish = 0
16/03/25 13:11:35 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1293 bytes result sent to driver
16/03/25 13:11:35 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.357 s
16/03/25 13:11:35 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 16.877381 s
16/03/25 13:11:35 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 353 ms on localhost (2/2)
16/03/25 13:11:35 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:11:35 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:11:35 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:11:35 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:11:35 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:11:35 INFO DAGScheduler: Missing parents: List()
16/03/25 13:11:35 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:11:35 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19350, maxMem=561276518
16/03/25 13:11:35 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 535.3 MB)
16/03/25 13:11:35 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25166, maxMem=561276518
16/03/25 13:11:35 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 535.2 MB)
16/03/25 13:11:35 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:52141 (size: 3.3 KB, free: 535.3 MB)
16/03/25 13:11:35 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:11:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:11:35 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:11:35 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:11:35 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2374 bytes)
16/03/25 13:11:35 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:11:35 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:11:35 INFO PythonRunner: Times: total = 47, boot = -22, init = 69, finish = 0
16/03/25 13:11:35 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:11:35 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 91 ms on localhost (1/2)
16/03/25 13:11:35 INFO PythonRunner: Times: total = 251, boot = 250, init = 1, finish = 0
16/03/25 13:11:35 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1361 bytes result sent to driver
16/03/25 13:11:35 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 271 ms on localhost (2/2)
16/03/25 13:11:35 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:11:35 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.271 s
16/03/25 13:11:35 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.297437 s
16/03/25 13:11:35 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:11:35 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:11:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:11:36 INFO MemoryStore: MemoryStore cleared
16/03/25 13:11:36 INFO BlockManager: BlockManager stopped
16/03/25 13:11:36 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:11:36 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:11:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:11:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:11:36 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:11:36 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1ef4e6c>, {'2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], '4b7e9f2659636820e82592ed034512f9': [u'Chennai', u'Madras'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], '1d1c5d8e5b55f6916d7d9218c4a0fe34': [u'None', u'area', u'None', u'Bengal'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], 'ff4fcba188cd7bb550ed88e9ee5dc6f1': [u'Chennai', u'Madras', u'None'], '57466dae2c092869867908c5c54e241c': [u'metropolitan', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], 'e9da57cf07c9f8d232e2c9c1a07d1a0a': [u'None', u'area', u'culture', u'None'], '3a2fbf91abebcac17538118b2e02315d': [u'metropolitan', u'None', u'western'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '3cd540871242471e0d89bea4eabc06ea': [u'None', u'expansion', u'None'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras'], '4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '39c21ff4448a2910600584a0d49f93e8': [u'metropolitan', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], '25439f8325592e4ecd8b06f5f799b57a': [u'None', u'expansion', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None']})
asfer_pickle_string_dump(): picklef.write(): title
16/03/25 13:11:36 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:11:36 INFO SecurityManager: Changing view acls to: root
16/03/25 13:11:36 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:11:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:11:36 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:11:36 INFO Remoting: Starting remoting
16/03/25 13:11:37 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:41640]
16/03/25 13:11:37 INFO Utils: Successfully started service 'sparkDriver' on port 41640.
16/03/25 13:11:37 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:11:37 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:11:37 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-03f3b771-c07b-4fa5-a5f4-765fdb4c697e
16/03/25 13:11:37 INFO MemoryStore: MemoryStore started with capacity 535.3 MB
16/03/25 13:11:37 INFO HttpFileServer: HTTP File server directory is /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/httpd-e8796df7-b290-4022-99b0-adb613e02852
16/03/25 13:11:37 INFO HttpServer: Starting HTTP Server
16/03/25 13:11:37 INFO Utils: Successfully started service 'HTTP file server' on port 39015.
16/03/25 13:11:37 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:11:37 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:11:37 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:11:37 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-51c462d7-73c7-480f-948e-5302c95b7a47/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:11:37 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891697229
16/03/25 13:11:37 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:11:37 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:11:37 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50950.
16/03/25 13:11:37 INFO NettyBlockTransferService: Server created on 50950
16/03/25 13:11:37 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:11:37 INFO BlockManagerMasterEndpoint: Registering block manager localhost:50950 with 535.3 MB RAM, BlockManagerId(driver, localhost, 50950)
16/03/25 13:11:37 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:11:37 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:11:37 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:11:37 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:11:37 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:11:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:11:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:11:37 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:11:37 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=561276518
16/03/25 13:11:37 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 535.3 MB)
16/03/25 13:11:37 INFO MemoryStore: ensureFreeSpace(4155) called with curMem=6576, maxMem=561276518
16/03/25 13:11:37 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 535.3 MB)
16/03/25 13:11:37 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:50950 (size: 4.1 KB, free: 535.3 MB)
16/03/25 13:11:37 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:11:37 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:11:37 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:11:37 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2559 bytes)
16/03/25 13:11:37 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2583 bytes)
16/03/25 13:11:37 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:11:37 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891697229
16/03/25 13:11:37 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:11:37 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-51c462d7-73c7-480f-948e-5302c95b7a47/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:11:37 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:11:37 INFO MemoryStore: ensureFreeSpace(314) called with curMem=10731, maxMem=561276518
16/03/25 13:11:37 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 314.0 B, free 535.3 MB)
16/03/25 13:11:37 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:50950 (size: 314.0 B, free: 535.3 MB)
16/03/25 13:11:37 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:11:37 INFO MemoryStore: ensureFreeSpace(286) called with curMem=11045, maxMem=561276518
16/03/25 13:11:37 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 286.0 B, free 535.3 MB)
16/03/25 13:11:37 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:50950 (size: 286.0 B, free: 535.3 MB)
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: archbishop
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  title  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: area
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: expansion
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: serving
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: formerly
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: people
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: culture
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: bishop
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: special
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: geography
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: city
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: given
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: Madras
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
16/03/25 13:11:53 INFO PythonRunner: Times: total = 16266, boot = 753, init = 811, finish = 14702
16/03/25 13:11:54 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:11:54 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 16423 ms on localhost (1/2)
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: sum
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: expressed
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: geographical
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: boundary
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: function
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: product
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: terms
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'status', u'people', u'relations', u'to', u'groups', u'between', u'respect', u'the', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: equivalent
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: Bay
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'smaller', u'shoreline', u'gulf', u'of', u'larger', u'cove', u'but', u'an', u'indentation', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: western
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'and', u'about', u'United', u'development', u'of', u'life', u'period', u'States', u'exploration', u'western', u'in', u'during', u'the', u'film'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: particular
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'about', u')', u'(', u'some', u'general', u'to', u'as', u'part', u'opposed', u'fact'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: Bengal
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'whose', u'and', u'Bangladesh', u'eastern', u'region', u'India', u'part', u'western', u'in', u'included', u'now', u'is'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: Orthodox
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'pertaining', u'Judaism', u'characteristic', u'to', u'of', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: region
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'extended', u'of', u'something', u'spatial', u'the', u'location'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: title
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'statute', u'give', u'that', u'may', u'of', u'the', u'bill', u'brief', u'heading', u'deals', u'matters', u'names', u'it', u';', u'summary', u'with', u'or', u'legislative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/25 13:11:54 INFO PythonRunner: Times: total = 17137, boot = 753, init = 599, finish = 15785
16/03/25 13:11:54 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:11:54 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 17304 ms on localhost (2/2)
16/03/25 13:11:54 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:11:54 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 17.298 s
16/03/25 13:11:54 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:11:54 INFO DAGScheduler: running: Set()
16/03/25 13:11:54 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:11:54 INFO DAGScheduler: failed: Set()
16/03/25 13:11:54 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:11:54 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:11:54 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11331, maxMem=561276518
16/03/25 13:11:54 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 535.3 MB)
16/03/25 13:11:54 INFO MemoryStore: ensureFreeSpace(3057) called with curMem=16315, maxMem=561276518
16/03/25 13:11:54 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 535.3 MB)
16/03/25 13:11:54 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:50950 (size: 3.0 KB, free: 535.3 MB)
16/03/25 13:11:54 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:11:54 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:11:54 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:11:54 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:11:54 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:11:54 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:11:54 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:11:54 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:11:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
16/03/25 13:11:54 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:11:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/25 13:11:54 INFO PythonRunner: Times: total = 26, boot = -448, init = 474, finish = 0
16/03/25 13:11:55 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:11:55 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 90 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'metropolitan', 'None']
16/03/25 13:11:55 INFO PythonRunner: Times: total = 284, boot = 281, init = 1, finish = 2
16/03/25 13:11:55 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1280 bytes result sent to driver
16/03/25 13:11:55 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 309 ms on localhost (2/2)
16/03/25 13:11:55 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:11:55 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.318 s
16/03/25 13:11:55 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 17.682219 s
16/03/25 13:11:55 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:11:55 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:11:55 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:11:55 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:11:55 INFO DAGScheduler: Missing parents: List()
16/03/25 13:11:55 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:11:55 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19372, maxMem=561276518
16/03/25 13:11:55 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 535.3 MB)
16/03/25 13:11:55 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25188, maxMem=561276518
16/03/25 13:11:55 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 535.2 MB)
16/03/25 13:11:55 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:50950 (size: 3.3 KB, free: 535.3 MB)
16/03/25 13:11:55 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:11:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:11:55 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:11:55 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:11:55 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2361 bytes)
16/03/25 13:11:55 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:11:55 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:11:55 INFO PythonRunner: Times: total = 179, boot = 178, init = 1, finish = 0
16/03/25 13:11:55 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1345 bytes result sent to driver
16/03/25 13:11:55 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 188 ms on localhost (1/2)
16/03/25 13:11:55 INFO PythonRunner: Times: total = 310, boot = 302, init = 8, finish = 0
16/03/25 13:11:55 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:11:55 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 319 ms on localhost (2/2)
16/03/25 13:11:55 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:11:55 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.316 s
16/03/25 13:11:55 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.350261 s
16/03/25 13:11:55 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:11:55 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:11:55 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:11:56 INFO MemoryStore: MemoryStore cleared
16/03/25 13:11:56 INFO BlockManager: BlockManager stopped
16/03/25 13:11:56 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:11:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:11:56 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:11:56 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:11:56 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:11:56 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1ef4e6c>, {'2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], '98acf8f6223b3758ff4a9dc22afb0e3b': [u'metropolitan', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], '4b7e9f2659636820e82592ed034512f9': [u'Chennai', u'Madras'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], '1d1c5d8e5b55f6916d7d9218c4a0fe34': [u'None', u'area', u'None', u'Bengal'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], 'ff4fcba188cd7bb550ed88e9ee5dc6f1': [u'Chennai', u'Madras', u'None'], '57466dae2c092869867908c5c54e241c': [u'metropolitan', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], 'e9da57cf07c9f8d232e2c9c1a07d1a0a': [u'None', u'area', u'culture', u'None'], '3a2fbf91abebcac17538118b2e02315d': [u'metropolitan', u'None', u'western'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '3cd540871242471e0d89bea4eabc06ea': [u'None', u'expansion', u'None'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras'], '4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '39c21ff4448a2910600584a0d49f93e8': [u'metropolitan', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], '25439f8325592e4ecd8b06f5f799b57a': [u'None', u'expansion', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None']})
asfer_pickle_string_dump(): picklef.write(): patriarch
16/03/25 13:11:56 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:11:56 INFO SecurityManager: Changing view acls to: root
16/03/25 13:11:56 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:11:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:11:56 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:11:56 INFO Remoting: Starting remoting
16/03/25 13:11:57 INFO Utils: Successfully started service 'sparkDriver' on port 43839.
16/03/25 13:11:57 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:43839]
16/03/25 13:11:57 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:11:57 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:11:57 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0314b6ac-6c4f-4548-96bc-5f2c87f3fc08
16/03/25 13:11:57 INFO MemoryStore: MemoryStore started with capacity 535.3 MB
16/03/25 13:11:57 INFO HttpFileServer: HTTP File server directory is /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/httpd-330ed2d7-eb02-474b-a816-876ffbf5114d
16/03/25 13:11:57 INFO HttpServer: Starting HTTP Server
16/03/25 13:11:57 INFO Utils: Successfully started service 'HTTP file server' on port 39057.
16/03/25 13:11:57 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:11:57 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:11:57 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:11:57 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-7326a3a8-57b6-40b1-bdbc-766494761fd0/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:11:57 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891717307
16/03/25 13:11:57 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:11:57 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:11:57 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60500.
16/03/25 13:11:57 INFO NettyBlockTransferService: Server created on 60500
16/03/25 13:11:57 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:11:57 INFO BlockManagerMasterEndpoint: Registering block manager localhost:60500 with 535.3 MB RAM, BlockManagerId(driver, localhost, 60500)
16/03/25 13:11:57 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:11:57 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:11:57 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:11:57 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:11:57 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:11:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:11:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:11:57 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:11:57 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=561276518
16/03/25 13:11:57 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 535.3 MB)
16/03/25 13:11:57 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=561276518
16/03/25 13:11:57 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 535.3 MB)
16/03/25 13:11:57 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:60500 (size: 4.1 KB, free: 535.3 MB)
16/03/25 13:11:57 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:11:57 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:11:57 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:11:57 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2576 bytes)
16/03/25 13:11:57 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2565 bytes)
16/03/25 13:11:57 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:11:57 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891717307
16/03/25 13:11:57 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:11:57 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-7326a3a8-57b6-40b1-bdbc-766494761fd0/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:11:57 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:11:57 INFO MemoryStore: ensureFreeSpace(295) called with curMem=10732, maxMem=561276518
16/03/25 13:11:57 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 295.0 B, free 535.3 MB)
16/03/25 13:11:57 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:60500 (size: 295.0 B, free: 535.3 MB)
16/03/25 13:11:57 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:11:57 INFO MemoryStore: ensureFreeSpace(301) called with curMem=11027, maxMem=561276518
16/03/25 13:11:57 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 301.0 B, free 535.3 MB)
16/03/25 13:11:57 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:60500 (size: 301.0 B, free: 535.3 MB)
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: Chennai
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: sum
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  patriarch  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: area
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: expansion
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: serving
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: formerly
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: people
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: culture
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: bishop
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: special
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: geography
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: city
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: given
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: expressed
mapFunction_Parents(): keyword=mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: Madras
 patriarch ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: Eastern
patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: geographical
mapFunction_Parents(): keyword=mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
 patriarch ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: boundary
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: function
16/03/25 13:12:15 INFO PythonRunner: Times: total = 18040, boot = 955, init = 780, finish = 16305
16/03/25 13:12:15 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:12:15 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 18252 ms on localhost (1/2)
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: product
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: terms
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'status', u'people', u'relations', u'to', u'groups', u'between', u'respect', u'the', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: equivalent
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: Bay
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'smaller', u'shoreline', u'gulf', u'of', u'larger', u'cove', u'but', u'an', u'indentation', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: western
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'and', u'about', u'United', u'development', u'of', u'life', u'period', u'States', u'exploration', u'western', u'in', u'during', u'the', u'film'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: particular
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'about', u')', u'(', u'some', u'general', u'to', u'as', u'part', u'opposed', u'fact'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: Bengal
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'whose', u'and', u'Bangladesh', u'eastern', u'region', u'India', u'part', u'western', u'in', u'included', u'now', u'is'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: Orthodox
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'pertaining', u'Judaism', u'characteristic', u'to', u'of', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: region
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'extended', u'of', u'something', u'spatial', u'the', u'location'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: title
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'statute', u'give', u'that', u'may', u'of', u'the', u'bill', u'brief', u'heading', u'deals', u'matters', u'names', u'it', u';', u'summary', u'with', u'or', u'legislative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: patriarch
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'and', u'older', u'is', u'who', u'rank', u'yourself', u'in', u'higher', u'than', u'man'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/25 13:12:16 INFO PythonRunner: Times: total = 18438, boot = 966, init = 880, finish = 16592
16/03/25 13:12:16 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:12:16 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 18632 ms on localhost (2/2)
16/03/25 13:12:16 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:12:16 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 18.641 s
16/03/25 13:12:16 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:12:16 INFO DAGScheduler: running: Set()
16/03/25 13:12:16 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:12:16 INFO DAGScheduler: failed: Set()
16/03/25 13:12:16 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:12:16 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:12:16 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11328, maxMem=561276518
16/03/25 13:12:16 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 535.3 MB)
16/03/25 13:12:16 INFO MemoryStore: ensureFreeSpace(3057) called with curMem=16312, maxMem=561276518
16/03/25 13:12:16 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 535.3 MB)
16/03/25 13:12:16 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:60500 (size: 3.0 KB, free: 535.3 MB)
16/03/25 13:12:16 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:12:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:12:16 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:12:16 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:12:16 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:12:16 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:12:16 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:12:16 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:12:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/25 13:12:16 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:12:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
reduceFunction_Parents(): returns= [u'metropolitan', 'None']
16/03/25 13:12:16 INFO PythonRunner: Times: total = 148, boot = 141, init = 0, finish = 7
16/03/25 13:12:16 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1280 bytes result sent to driver
16/03/25 13:12:16 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 170 ms on localhost (1/2)
16/03/25 13:12:16 INFO PythonRunner: Times: total = 489, boot = 488, init = 0, finish = 1
16/03/25 13:12:16 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:12:16 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.533 s
16/03/25 13:12:16 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 19.241298 s
16/03/25 13:12:16 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 543 ms on localhost (2/2)
16/03/25 13:12:16 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:12:16 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:12:16 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:12:16 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:12:16 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:12:16 INFO DAGScheduler: Missing parents: List()
16/03/25 13:12:16 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:12:16 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19369, maxMem=561276518
16/03/25 13:12:16 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 535.3 MB)
16/03/25 13:12:16 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25185, maxMem=561276518
16/03/25 13:12:16 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 535.2 MB)
16/03/25 13:12:16 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:60500 (size: 3.3 KB, free: 535.3 MB)
16/03/25 13:12:16 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:12:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:12:16 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:12:16 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:12:16 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2361 bytes)
16/03/25 13:12:16 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:12:16 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:12:17 INFO PythonRunner: Times: total = 13, boot = -200, init = 213, finish = 0
16/03/25 13:12:17 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:12:17 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 84 ms on localhost (1/2)
16/03/25 13:12:17 INFO PythonRunner: Times: total = 349, boot = 348, init = 0, finish = 1
16/03/25 13:12:17 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1345 bytes result sent to driver
16/03/25 13:12:17 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 361 ms on localhost (2/2)
16/03/25 13:12:17 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:12:17 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.352 s
16/03/25 13:12:17 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.385697 s
16/03/25 13:12:17 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:12:17 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:12:17 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:12:17 INFO MemoryStore: MemoryStore cleared
16/03/25 13:12:17 INFO BlockManager: BlockManager stopped
16/03/25 13:12:17 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:12:17 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:12:17 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:12:17 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:12:17 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:12:17 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1ef4e6c>, {'c9e46d6d893b45343d5c7e9c6ec9851b': [u'metropolitan', u'None'], '2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], '98acf8f6223b3758ff4a9dc22afb0e3b': [u'metropolitan', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], '4b7e9f2659636820e82592ed034512f9': [u'Chennai', u'Madras'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], '1d1c5d8e5b55f6916d7d9218c4a0fe34': [u'None', u'area', u'None', u'Bengal'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], 'ff4fcba188cd7bb550ed88e9ee5dc6f1': [u'Chennai', u'Madras', u'None'], '57466dae2c092869867908c5c54e241c': [u'metropolitan', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], 'e9da57cf07c9f8d232e2c9c1a07d1a0a': [u'None', u'area', u'culture', u'None'], '3a2fbf91abebcac17538118b2e02315d': [u'metropolitan', u'None', u'western'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '3cd540871242471e0d89bea4eabc06ea': [u'None', u'expansion', u'None'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras'], '4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '39c21ff4448a2910600584a0d49f93e8': [u'metropolitan', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], '25439f8325592e4ecd8b06f5f799b57a': [u'None', u'expansion', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None']})
asfer_pickle_string_dump(): picklef.write(): Church
16/03/25 13:12:18 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:12:18 INFO SecurityManager: Changing view acls to: root
16/03/25 13:12:18 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:12:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:12:18 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:12:18 INFO Remoting: Starting remoting
16/03/25 13:12:18 INFO Utils: Successfully started service 'sparkDriver' on port 49453.
16/03/25 13:12:18 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:49453]
16/03/25 13:12:18 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:12:18 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:12:18 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0dff391a-b963-474c-8f30-f1a7907e497b
16/03/25 13:12:18 INFO MemoryStore: MemoryStore started with capacity 535.3 MB
16/03/25 13:12:18 INFO HttpFileServer: HTTP File server directory is /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/httpd-4f3a0405-239b-4589-9365-2212a0140564
16/03/25 13:12:18 INFO HttpServer: Starting HTTP Server
16/03/25 13:12:18 INFO Utils: Successfully started service 'HTTP file server' on port 44973.
16/03/25 13:12:18 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:12:18 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:12:18 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:12:18 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-cb83fc31-c0c0-4581-8cfe-d4304a16af0f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:12:18 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891738589
16/03/25 13:12:18 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:12:18 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:12:18 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45335.
16/03/25 13:12:18 INFO NettyBlockTransferService: Server created on 45335
16/03/25 13:12:18 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:12:18 INFO BlockManagerMasterEndpoint: Registering block manager localhost:45335 with 535.3 MB RAM, BlockManagerId(driver, localhost, 45335)
16/03/25 13:12:18 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:12:18 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:12:19 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:12:19 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:12:19 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:12:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:12:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:12:19 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:12:19 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=561276518
16/03/25 13:12:19 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 535.3 MB)
16/03/25 13:12:19 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=561276518
16/03/25 13:12:19 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 535.3 MB)
16/03/25 13:12:19 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:45335 (size: 4.1 KB, free: 535.3 MB)
16/03/25 13:12:19 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:12:19 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:12:19 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:12:19 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2576 bytes)
16/03/25 13:12:19 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2595 bytes)
16/03/25 13:12:19 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:12:19 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891738589
16/03/25 13:12:19 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:12:19 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-cb83fc31-c0c0-4581-8cfe-d4304a16af0f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:12:19 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:12:19 INFO MemoryStore: ensureFreeSpace(322) called with curMem=10732, maxMem=561276518
16/03/25 13:12:19 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:12:19 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 322.0 B, free 535.3 MB)
16/03/25 13:12:19 INFO MemoryStore: ensureFreeSpace(301) called with curMem=11054, maxMem=561276518
16/03/25 13:12:19 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:45335 (size: 322.0 B, free: 535.3 MB)
16/03/25 13:12:19 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 301.0 B, free 535.3 MB)
16/03/25 13:12:19 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:45335 (size: 301.0 B, free: 535.3 MB)
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: Chennai
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: sum
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: expressed
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: geographical
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: boundary
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: function
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: product
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: terms
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'status', u'people', u'relations', u'to', u'groups', u'between', u'respect', u'the', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: equivalent
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: Bay
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'smaller', u'shoreline', u'gulf', u'of', u'larger', u'cove', u'but', u'an', u'indentation', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: western
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'and', u'about', u'United', u'development', u'of', u'life', u'period', u'States', u'exploration', u'western', u'in', u'during', u'the', u'film'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: particular
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'about', u')', u'(', u'some', u'general', u'to', u'as', u'part', u'opposed', u'fact'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: Bengal
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'whose', u'and', u'Bangladesh', u'eastern', u'region', u'India', u'part', u'western', u'in', u'included', u'now', u'is'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: Orthodox
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'pertaining', u'Judaism', u'characteristic', u'to', u'of', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: region
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'extended', u'of', u'something', u'spatial', u'the', u'location'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: title
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'statute', u'give', u'that', u'may', u'of', u'the', u'bill', u'brief', u'heading', u'deals', u'matters', u'names', u'it', u';', u'summary', u'with', u'or', u'legislative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: patriarch
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'and', u'older', u'is', u'who', u'rank', u'yourself', u'in', u'higher', u'than', u'man'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: Church
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'and', u'own', u'have', u'of', u'who', u'one', u'forms', u'their', u'groups', u'the', u'worship', u'beliefs', u'Christians'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/25 13:12:32 INFO PythonRunner: Times: total = 13556, boot = 633, init = 859, finish = 12064
16/03/25 13:12:32 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:12:32 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 13635 ms on localhost (1/2)
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  Church  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: area
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: expansion
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: serving
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: formerly
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: people
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: culture
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: bishop
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: special
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: geography
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: city
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: given
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: Madras
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
16/03/25 13:12:34 INFO PythonRunner: Times: total = 15666, boot = 646, init = 725, finish = 14295
16/03/25 13:12:34 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:12:34 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 15763 ms on localhost (2/2)
16/03/25 13:12:34 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 15.769 s
16/03/25 13:12:34 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:12:34 INFO DAGScheduler: running: Set()
16/03/25 13:12:34 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:12:34 INFO DAGScheduler: failed: Set()
16/03/25 13:12:34 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:12:34 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:12:34 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:12:34 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11355, maxMem=561276518
16/03/25 13:12:34 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 535.3 MB)
16/03/25 13:12:34 INFO MemoryStore: ensureFreeSpace(3057) called with curMem=16339, maxMem=561276518
16/03/25 13:12:34 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 535.3 MB)
16/03/25 13:12:34 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:45335 (size: 3.0 KB, free: 535.3 MB)
16/03/25 13:12:34 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:12:34 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:12:34 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:12:34 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:12:34 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:12:34 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:12:34 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:12:34 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:12:34 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:12:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/25 13:12:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
reduceFunction_Parents(): returns= [u'metropolitan', 'None']
16/03/25 13:12:34 INFO PythonRunner: Times: total = 45, boot = -1570, init = 1614, finish = 1
16/03/25 13:12:34 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1280 bytes result sent to driver
16/03/25 13:12:34 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 89 ms on localhost (1/2)
16/03/25 13:12:35 INFO PythonRunner: Times: total = 461, boot = 460, init = 1, finish = 0
16/03/25 13:12:35 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:12:35 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.488 s
16/03/25 13:12:35 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 16.313101 s
16/03/25 13:12:35 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 486 ms on localhost (2/2)
16/03/25 13:12:35 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:12:35 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:12:35 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:12:35 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:12:35 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:12:35 INFO DAGScheduler: Missing parents: List()
16/03/25 13:12:35 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:12:35 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19396, maxMem=561276518
16/03/25 13:12:35 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 535.3 MB)
16/03/25 13:12:35 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25212, maxMem=561276518
16/03/25 13:12:35 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 535.2 MB)
16/03/25 13:12:35 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:45335 (size: 3.3 KB, free: 535.3 MB)
16/03/25 13:12:35 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:12:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:12:35 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:12:35 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:12:35 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2361 bytes)
16/03/25 13:12:35 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:12:35 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:12:35 INFO PythonRunner: Times: total = 85, boot = -258, init = 343, finish = 0
16/03/25 13:12:35 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1345 bytes result sent to driver
16/03/25 13:12:35 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 95 ms on localhost (1/2)
16/03/25 13:12:35 INFO PythonRunner: Times: total = 104, boot = 103, init = 1, finish = 0
16/03/25 13:12:35 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:12:35 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 113 ms on localhost (2/2)
16/03/25 13:12:35 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:12:35 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.114 s
16/03/25 13:12:35 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.143980 s
16/03/25 13:12:35 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:12:35 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:12:35 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:12:35 INFO MemoryStore: MemoryStore cleared
16/03/25 13:12:35 INFO BlockManager: BlockManager stopped
16/03/25 13:12:35 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:12:35 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:12:35 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:12:35 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:12:35 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:12:35 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1ef4e6c>, {'c9e46d6d893b45343d5c7e9c6ec9851b': [u'metropolitan', u'None'], '2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], '98acf8f6223b3758ff4a9dc22afb0e3b': [u'metropolitan', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], '4b7e9f2659636820e82592ed034512f9': [u'Chennai', u'Madras'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], '1d1c5d8e5b55f6916d7d9218c4a0fe34': [u'None', u'area', u'None', u'Bengal'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], 'ff4fcba188cd7bb550ed88e9ee5dc6f1': [u'Chennai', u'Madras', u'None'], '57466dae2c092869867908c5c54e241c': [u'metropolitan', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], 'e9da57cf07c9f8d232e2c9c1a07d1a0a': [u'None', u'area', u'culture', u'None'], '3a2fbf91abebcac17538118b2e02315d': [u'metropolitan', u'None', u'western'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '3cd540871242471e0d89bea4eabc06ea': [u'None', u'expansion', u'None'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras'], '4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], 'ed457e104ac489b5ec0bf242d39416e3': [u'metropolitan', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '39c21ff4448a2910600584a0d49f93e8': [u'metropolitan', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], '25439f8325592e4ecd8b06f5f799b57a': [u'None', u'expansion', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None']})
asfer_pickle_string_dump(): picklef.write(): usually
16/03/25 13:12:36 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:12:36 INFO SecurityManager: Changing view acls to: root
16/03/25 13:12:36 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:12:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:12:36 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:12:36 INFO Remoting: Starting remoting
16/03/25 13:12:36 INFO Utils: Successfully started service 'sparkDriver' on port 39994.
16/03/25 13:12:36 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:39994]
16/03/25 13:12:36 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:12:36 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:12:36 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b493303e-edc0-4703-ba08-e96cd61a8c6c
16/03/25 13:12:36 INFO MemoryStore: MemoryStore started with capacity 535.3 MB
16/03/25 13:12:36 INFO HttpFileServer: HTTP File server directory is /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/httpd-6daf92b1-92a5-43ed-a963-81504009d29d
16/03/25 13:12:36 INFO HttpServer: Starting HTTP Server
16/03/25 13:12:37 INFO Utils: Successfully started service 'HTTP file server' on port 53746.
16/03/25 13:12:37 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:12:37 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:12:37 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:12:37 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-48f319c0-113b-422e-8f41-ecc86f4a4f07/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:12:37 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891757193
16/03/25 13:12:37 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:12:37 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:12:37 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51702.
16/03/25 13:12:37 INFO NettyBlockTransferService: Server created on 51702
16/03/25 13:12:37 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:12:37 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51702 with 535.3 MB RAM, BlockManagerId(driver, localhost, 51702)
16/03/25 13:12:37 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:12:37 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:12:37 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:12:37 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:12:37 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:12:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:12:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:12:37 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:12:37 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=561276518
16/03/25 13:12:37 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 535.3 MB)
16/03/25 13:12:37 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=561276518
16/03/25 13:12:37 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 535.3 MB)
16/03/25 13:12:37 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51702 (size: 4.1 KB, free: 535.3 MB)
16/03/25 13:12:37 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:12:37 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:12:37 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:12:37 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2586 bytes)
16/03/25 13:12:37 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2582 bytes)
16/03/25 13:12:37 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:12:37 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891757193
16/03/25 13:12:37 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:12:37 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-48f319c0-113b-422e-8f41-ecc86f4a4f07/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:12:37 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:12:37 INFO MemoryStore: ensureFreeSpace(316) called with curMem=10732, maxMem=561276518
16/03/25 13:12:37 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 316.0 B, free 535.3 MB)
16/03/25 13:12:37 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:51702 (size: 316.0 B, free: 535.3 MB)
16/03/25 13:12:37 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:12:37 INFO MemoryStore: ensureFreeSpace(307) called with curMem=11048, maxMem=561276518
16/03/25 13:12:37 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 307.0 B, free 535.3 MB)
16/03/25 13:12:37 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:51702 (size: 307.0 B, free: 535.3 MB)
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: expressed
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: geographical
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: boundary
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: function
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: product
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: terms
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'status', u'people', u'relations', u'to', u'groups', u'between', u'respect', u'the', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: equivalent
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Bay
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'smaller', u'shoreline', u'gulf', u'of', u'larger', u'cove', u'but', u'an', u'indentation', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: western
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'about', u'United', u'development', u'of', u'life', u'period', u'States', u'exploration', u'western', u'in', u'during', u'the', u'film'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: particular
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'about', u')', u'(', u'some', u'general', u'to', u'as', u'part', u'opposed', u'fact'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Bengal
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'whose', u'and', u'Bangladesh', u'eastern', u'region', u'India', u'part', u'western', u'in', u'included', u'now', u'is'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Orthodox
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'pertaining', u'Judaism', u'characteristic', u'to', u'of', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: region
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'extended', u'of', u'something', u'spatial', u'the', u'location'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: title
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'statute', u'give', u'that', u'may', u'of', u'the', u'bill', u'brief', u'heading', u'deals', u'matters', u'names', u'it', u';', u'summary', u'with', u'or', u'legislative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: patriarch
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'older', u'is', u'who', u'rank', u'yourself', u'in', u'higher', u'than', u'man'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Church
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'and', u'own', u'have', u'of', u'who', u'one', u'forms', u'their', u'groups', u'the', u'worship', u'beliefs', u'Christians'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: usually
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'normal', u'conditions', u'under'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/25 13:12:55 INFO PythonRunner: Times: total = 17331, boot = 790, init = 635, finish = 15906
16/03/25 13:12:55 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:12:55 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 17540 ms on localhost (1/2)
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: area
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  usually  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: expansion
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: serving
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: formerly
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: people
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: culture
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: bishop
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: special
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): adding to parents: syn =  Synset('special.n.01') ; keyword:  usually  in syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= [u'special']
reduceFunction_Parents(): returns= ['None', u'area', u'special']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: geography
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area', u'special']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: city
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area', u'special']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: given
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area', u'special']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Madras
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area', u'special']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area', u'special']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area', u'special']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: sum
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area', u'special']
16/03/25 13:12:55 INFO PythonRunner: Times: total = 18063, boot = 786, init = 825, finish = 16452
16/03/25 13:12:55 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:12:55 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 18.305 s
16/03/25 13:12:55 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:12:55 INFO DAGScheduler: running: Set()
16/03/25 13:12:55 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:12:55 INFO DAGScheduler: failed: Set()
16/03/25 13:12:55 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:12:55 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:12:55 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11355, maxMem=561276518
16/03/25 13:12:55 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 535.3 MB)
16/03/25 13:12:55 INFO MemoryStore: ensureFreeSpace(3057) called with curMem=16339, maxMem=561276518
16/03/25 13:12:55 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 535.3 MB)
16/03/25 13:12:55 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 18303 ms on localhost (2/2)
16/03/25 13:12:55 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:12:55 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51702 (size: 3.0 KB, free: 535.3 MB)
16/03/25 13:12:55 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:12:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:12:55 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:12:55 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:12:55 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:12:55 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:12:55 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:12:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:12:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/25 13:12:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:12:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
reduceFunction_Parents(): returns= ['None', u'area', u'special', 'None']
16/03/25 13:12:55 INFO PythonRunner: Times: total = 53, boot = -378, init = 430, finish = 1
16/03/25 13:12:55 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1294 bytes result sent to driver
16/03/25 13:12:56 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 120 ms on localhost (1/2)
16/03/25 13:12:56 INFO PythonRunner: Times: total = 361, boot = 360, init = 0, finish = 1
16/03/25 13:12:56 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:12:56 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.366 s
16/03/25 13:12:56 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 18.739814 s
16/03/25 13:12:56 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 376 ms on localhost (2/2)
16/03/25 13:12:56 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:12:56 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:12:56 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:12:56 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:12:56 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:12:56 INFO DAGScheduler: Missing parents: List()
16/03/25 13:12:56 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:12:56 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19396, maxMem=561276518
16/03/25 13:12:56 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 535.3 MB)
16/03/25 13:12:56 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25212, maxMem=561276518
16/03/25 13:12:56 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 535.2 MB)
16/03/25 13:12:56 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:51702 (size: 3.3 KB, free: 535.3 MB)
16/03/25 13:12:56 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:51702 in memory (size: 3.0 KB, free: 535.3 MB)
16/03/25 13:12:56 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:12:56 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:12:56 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:12:56 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:12:56 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2375 bytes)
16/03/25 13:12:56 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:12:56 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:12:56 INFO PythonRunner: Times: total = 21, boot = -9, init = 30, finish = 0
16/03/25 13:12:56 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1362 bytes result sent to driver
16/03/25 13:12:56 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 52 ms on localhost (1/2)
16/03/25 13:12:56 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:51702 in memory (size: 4.1 KB, free: 535.3 MB)
16/03/25 13:12:56 INFO PythonRunner: Times: total = 61, boot = -279, init = 340, finish = 0
16/03/25 13:12:56 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:12:56 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 75 ms on localhost (2/2)
16/03/25 13:12:56 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:12:56 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.076 s
16/03/25 13:12:56 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.341341 s
16/03/25 13:12:56 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:12:56 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:12:56 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:12:56 INFO MemoryStore: MemoryStore cleared
16/03/25 13:12:56 INFO BlockManager: BlockManager stopped
16/03/25 13:12:56 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:12:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:12:56 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:12:56 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:12:56 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:12:56 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1ef4e6c>, {'c9e46d6d893b45343d5c7e9c6ec9851b': [u'metropolitan', u'None'], '2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], '98acf8f6223b3758ff4a9dc22afb0e3b': [u'metropolitan', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], '4b7e9f2659636820e82592ed034512f9': [u'Chennai', u'Madras'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], '1d1c5d8e5b55f6916d7d9218c4a0fe34': [u'None', u'area', u'None', u'Bengal'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], 'ff4fcba188cd7bb550ed88e9ee5dc6f1': [u'Chennai', u'Madras', u'None'], '57466dae2c092869867908c5c54e241c': [u'metropolitan', u'None'], '3c28f836cfdab5d2af70e9fd66287ad9': [u'None', u'area', u'special', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], 'e9da57cf07c9f8d232e2c9c1a07d1a0a': [u'None', u'area', u'culture', u'None'], '3a2fbf91abebcac17538118b2e02315d': [u'metropolitan', u'None', u'western'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '3cd540871242471e0d89bea4eabc06ea': [u'None', u'expansion', u'None'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras'], '4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], 'ed457e104ac489b5ec0bf242d39416e3': [u'metropolitan', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '39c21ff4448a2910600584a0d49f93e8': [u'metropolitan', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], '25439f8325592e4ecd8b06f5f799b57a': [u'None', u'expansion', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None']})
asfer_pickle_string_dump(): picklef.write(): position
16/03/25 13:12:57 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:12:57 INFO SecurityManager: Changing view acls to: root
16/03/25 13:12:57 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:12:57 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:12:57 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:12:57 INFO Remoting: Starting remoting
16/03/25 13:12:57 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:47213]
16/03/25 13:12:57 INFO Utils: Successfully started service 'sparkDriver' on port 47213.
16/03/25 13:12:57 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:12:57 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:12:57 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a9a42d3f-263a-4827-984e-ea853434a92d
16/03/25 13:12:57 INFO MemoryStore: MemoryStore started with capacity 535.9 MB
16/03/25 13:12:57 INFO HttpFileServer: HTTP File server directory is /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/httpd-128db76b-dfbb-4dd1-b5db-d244d0a3a536
16/03/25 13:12:57 INFO HttpServer: Starting HTTP Server
16/03/25 13:12:57 INFO Utils: Successfully started service 'HTTP file server' on port 49497.
16/03/25 13:12:57 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:12:58 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:12:58 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:12:58 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-b3e41fb9-0699-4793-bb2e-c98a19232449/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:12:58 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891778029
16/03/25 13:12:58 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:12:58 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:12:58 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53501.
16/03/25 13:12:58 INFO NettyBlockTransferService: Server created on 53501
16/03/25 13:12:58 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:12:58 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53501 with 535.9 MB RAM, BlockManagerId(driver, localhost, 53501)
16/03/25 13:12:58 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:12:58 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:12:58 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:12:58 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:12:58 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:12:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:12:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:12:58 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:12:58 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=561984307
16/03/25 13:12:58 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 535.9 MB)
16/03/25 13:12:58 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=561984307
16/03/25 13:12:58 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 535.9 MB)
16/03/25 13:12:58 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53501 (size: 4.1 KB, free: 535.9 MB)
16/03/25 13:12:58 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:12:58 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:12:58 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:12:58 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2586 bytes)
16/03/25 13:12:58 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2614 bytes)
16/03/25 13:12:58 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:12:58 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891778029
16/03/25 13:12:58 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:12:58 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-b3e41fb9-0699-4793-bb2e-c98a19232449/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:12:58 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:12:58 INFO MemoryStore: ensureFreeSpace(342) called with curMem=10732, maxMem=561984307
16/03/25 13:12:58 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:12:58 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 342.0 B, free 535.9 MB)
16/03/25 13:12:58 INFO MemoryStore: ensureFreeSpace(307) called with curMem=11074, maxMem=561984307
16/03/25 13:12:58 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 307.0 B, free 535.9 MB)
16/03/25 13:12:58 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:53501 (size: 342.0 B, free: 535.9 MB)
16/03/25 13:12:58 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:53501 (size: 307.0 B, free: 535.9 MB)
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: expressed
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: geographical
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: boundary
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: function
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: product
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: terms
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'status', u'people', u'relations', u'to', u'groups', u'between', u'respect', u'the', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: equivalent
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Bay
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'smaller', u'shoreline', u'gulf', u'of', u'larger', u'cove', u'but', u'an', u'indentation', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: western
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'about', u'United', u'development', u'of', u'life', u'period', u'States', u'exploration', u'western', u'in', u'during', u'the', u'film'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: particular
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'about', u')', u'(', u'some', u'general', u'to', u'as', u'part', u'opposed', u'fact'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Bengal
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'whose', u'and', u'Bangladesh', u'eastern', u'region', u'India', u'part', u'western', u'in', u'included', u'now', u'is'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Orthodox
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'pertaining', u'Judaism', u'characteristic', u'to', u'of', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: region
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'extended', u'of', u'something', u'spatial', u'the', u'location'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: title
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'statute', u'give', u'that', u'may', u'of', u'the', u'bill', u'brief', u'heading', u'deals', u'matters', u'names', u'it', u';', u'summary', u'with', u'or', u'legislative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: patriarch
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'older', u'is', u'who', u'rank', u'yourself', u'in', u'higher', u'than', u'man'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Church
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'own', u'have', u'of', u'who', u'one', u'forms', u'their', u'groups', u'the', u'worship', u'beliefs', u'Christians'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: usually
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'normal', u'conditions', u'under'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: position
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  position  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: area
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: expansion
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: serving
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: formerly
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: people
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: culture
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: bishop
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: special
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: geography
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: city
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: given
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Madras
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: sum
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
16/03/25 13:13:10 INFO PythonRunner: Times: total = 12653, boot = 508, init = 477, finish = 11668
16/03/25 13:13:10 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'space', u'of', u'portion', u'something', u'particular', u'the', u'occupied', u'by'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/25 13:13:10 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 12768 ms on localhost (1/2)
16/03/25 13:13:10 INFO PythonRunner: Times: total = 12681, boot = 512, init = 470, finish = 11699
16/03/25 13:13:10 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:13:10 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 12804 ms on localhost (2/2)
16/03/25 13:13:10 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:13:10 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 12.796 s
16/03/25 13:13:10 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:13:10 INFO DAGScheduler: running: Set()
16/03/25 13:13:10 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:13:10 INFO DAGScheduler: failed: Set()
16/03/25 13:13:10 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:13:10 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:13:10 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11381, maxMem=561984307
16/03/25 13:13:10 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 535.9 MB)
16/03/25 13:13:11 INFO MemoryStore: ensureFreeSpace(3057) called with curMem=16365, maxMem=561984307
16/03/25 13:13:11 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 535.9 MB)
16/03/25 13:13:11 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53501 (size: 3.0 KB, free: 535.9 MB)
16/03/25 13:13:11 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:13:11 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:13:11 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:13:11 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:13:11 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:13:11 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:13:11 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:13:11 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:13:11 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:13:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/25 13:13:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
reduceFunction_Parents(): returns= [u'metropolitan', 'None']
16/03/25 13:13:11 INFO PythonRunner: Times: total = 203, boot = 202, init = 0, finish = 1
16/03/25 13:13:11 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1280 bytes result sent to driver
16/03/25 13:13:11 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 228 ms on localhost (1/2)
16/03/25 13:13:11 INFO PythonRunner: Times: total = 251, boot = 251, init = 0, finish = 0
16/03/25 13:13:11 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:13:11 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.280 s
16/03/25 13:13:11 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 13.124915 s
16/03/25 13:13:11 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 282 ms on localhost (2/2)
16/03/25 13:13:11 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:13:11 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:13:11 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:13:11 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:13:11 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:13:11 INFO DAGScheduler: Missing parents: List()
16/03/25 13:13:11 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:13:11 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19422, maxMem=561984307
16/03/25 13:13:11 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 535.9 MB)
16/03/25 13:13:11 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25238, maxMem=561984307
16/03/25 13:13:11 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 535.9 MB)
16/03/25 13:13:11 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53501 (size: 3.3 KB, free: 535.9 MB)
16/03/25 13:13:11 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:13:11 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:13:11 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:13:11 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:13:11 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2361 bytes)
16/03/25 13:13:11 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:13:11 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:13:11 INFO PythonRunner: Times: total = 135, boot = 134, init = 1, finish = 0
16/03/25 13:13:11 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1345 bytes result sent to driver
16/03/25 13:13:11 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 147 ms on localhost (1/2)
16/03/25 13:13:11 INFO PythonRunner: Times: total = 222, boot = 221, init = 1, finish = 0
16/03/25 13:13:11 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:13:11 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 236 ms on localhost (2/2)
16/03/25 13:13:11 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:13:11 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.236 s
16/03/25 13:13:11 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.273196 s
16/03/25 13:13:11 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:13:11 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:13:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:13:11 INFO MemoryStore: MemoryStore cleared
16/03/25 13:13:11 INFO BlockManager: BlockManager stopped
16/03/25 13:13:11 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:13:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:13:11 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:13:11 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:13:11 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:13:11 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1ef4e6c>, {'c9e46d6d893b45343d5c7e9c6ec9851b': [u'metropolitan', u'None'], '2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], '98acf8f6223b3758ff4a9dc22afb0e3b': [u'metropolitan', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], '4503bafd06fb20136c689c645a03eefa': [u'metropolitan', u'None'], '4b7e9f2659636820e82592ed034512f9': [u'Chennai', u'Madras'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], '1d1c5d8e5b55f6916d7d9218c4a0fe34': [u'None', u'area', u'None', u'Bengal'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], 'ff4fcba188cd7bb550ed88e9ee5dc6f1': [u'Chennai', u'Madras', u'None'], '57466dae2c092869867908c5c54e241c': [u'metropolitan', u'None'], '3c28f836cfdab5d2af70e9fd66287ad9': [u'None', u'area', u'special', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], 'e9da57cf07c9f8d232e2c9c1a07d1a0a': [u'None', u'area', u'culture', u'None'], '3a2fbf91abebcac17538118b2e02315d': [u'metropolitan', u'None', u'western'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '3cd540871242471e0d89bea4eabc06ea': [u'None', u'expansion', u'None'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras'], '4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], 'ed457e104ac489b5ec0bf242d39416e3': [u'metropolitan', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '39c21ff4448a2910600584a0d49f93e8': [u'metropolitan', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], '25439f8325592e4ecd8b06f5f799b57a': [u'None', u'expansion', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None']})
asfer_pickle_string_dump(): picklef.write(): distinguished
16/03/25 13:13:12 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:13:12 INFO SecurityManager: Changing view acls to: root
16/03/25 13:13:12 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:13:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:13:12 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:13:12 INFO Remoting: Starting remoting
16/03/25 13:13:12 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:40466]
16/03/25 13:13:12 INFO Utils: Successfully started service 'sparkDriver' on port 40466.
16/03/25 13:13:12 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:13:12 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:13:12 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-af661e15-6442-4594-8505-a30af08182b7
16/03/25 13:13:12 INFO MemoryStore: MemoryStore started with capacity 535.9 MB
16/03/25 13:13:12 INFO HttpFileServer: HTTP File server directory is /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/httpd-85c4a874-6b2f-406f-b907-51fa67feb29d
16/03/25 13:13:12 INFO HttpServer: Starting HTTP Server
16/03/25 13:13:12 INFO Utils: Successfully started service 'HTTP file server' on port 40653.
16/03/25 13:13:12 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:13:12 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:13:12 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:13:12 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-d12c96cd-664f-4011-8ffb-24d46f826240/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:13:12 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891792920
16/03/25 13:13:12 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:13:12 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:13:12 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52892.
16/03/25 13:13:12 INFO NettyBlockTransferService: Server created on 52892
16/03/25 13:13:12 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:13:12 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52892 with 535.9 MB RAM, BlockManagerId(driver, localhost, 52892)
16/03/25 13:13:12 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:13:13 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:13:13 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:13:13 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:13:13 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:13:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:13:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:13:13 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:13:13 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=561984307
16/03/25 13:13:13 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 535.9 MB)
16/03/25 13:13:13 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=561984307
16/03/25 13:13:13 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 535.9 MB)
16/03/25 13:13:13 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52892 (size: 4.1 KB, free: 535.9 MB)
16/03/25 13:13:13 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:13:13 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:13:13 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:13:13 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2602 bytes)
16/03/25 13:13:13 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2601 bytes)
16/03/25 13:13:13 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:13:13 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891792920
16/03/25 13:13:13 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:13:13 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-d12c96cd-664f-4011-8ffb-24d46f826240/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:13:13 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:13:13 INFO MemoryStore: ensureFreeSpace(323) called with curMem=10732, maxMem=561984307
16/03/25 13:13:13 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 323.0 B, free 535.9 MB)
16/03/25 13:13:13 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:13:13 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:52892 (size: 323.0 B, free: 535.9 MB)
16/03/25 13:13:13 INFO MemoryStore: ensureFreeSpace(321) called with curMem=11055, maxMem=561984307
16/03/25 13:13:13 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 321.0 B, free 535.9 MB)
16/03/25 13:13:13 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:52892 (size: 321.0 B, free: 535.9 MB)
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: geographical
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: boundary
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: function
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: product
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: terms
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'status', u'people', u'relations', u'to', u'groups', u'between', u'respect', u'the', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: equivalent
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: Bay
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'smaller', u'shoreline', u'gulf', u'of', u'larger', u'cove', u'but', u'an', u'indentation', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: western
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'and', u'about', u'United', u'development', u'of', u'life', u'period', u'States', u'exploration', u'western', u'in', u'during', u'the', u'film'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: particular
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'about', u')', u'(', u'some', u'general', u'to', u'as', u'part', u'opposed', u'fact'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: Bengal
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'whose', u'and', u'Bangladesh', u'eastern', u'region', u'India', u'part', u'western', u'in', u'included', u'now', u'is'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: Orthodox
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'pertaining', u'Judaism', u'characteristic', u'to', u'of', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: region
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'extended', u'of', u'something', u'spatial', u'the', u'location'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: title
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'statute', u'give', u'that', u'may', u'of', u'the', u'bill', u'brief', u'heading', u'deals', u'matters', u'names', u'it', u';', u'summary', u'with', u'or', u'legislative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: patriarch
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'and', u'older', u'is', u'who', u'rank', u'yourself', u'in', u'higher', u'than', u'man'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: Church
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'and', u'own', u'have', u'of', u'who', u'one', u'forms', u'their', u'groups', u'the', u'worship', u'beliefs', u'Christians'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: usually
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'normal', u'conditions', u'under'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: position
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'space', u'of', u'portion', u'something', u'particular', u'the', u'occupied', u'by'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: distinguished
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'as', u'different', u'mark'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/25 13:13:22 INFO PythonRunner: Times: total = 9184, boot = 467, init = 374, finish = 8343
16/03/25 13:13:22 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:13:22 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9298 ms on localhost (1/2)
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: area
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  distinguished  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: expansion
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: serving
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: formerly
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: people
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: culture
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: bishop
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: special
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: geography
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: city
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: given
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: Madras
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: sum
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: expressed
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/25 13:13:22 INFO PythonRunner: Times: total = 9531, boot = 467, init = 446, finish = 8618
16/03/25 13:13:22 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:13:22 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9645 ms on localhost (2/2)
16/03/25 13:13:22 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:13:22 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 9.646 s
16/03/25 13:13:22 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:13:22 INFO DAGScheduler: running: Set()
16/03/25 13:13:22 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:13:22 INFO DAGScheduler: failed: Set()
16/03/25 13:13:22 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:13:22 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:13:22 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11376, maxMem=561984307
16/03/25 13:13:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 535.9 MB)
16/03/25 13:13:22 INFO MemoryStore: ensureFreeSpace(3057) called with curMem=16360, maxMem=561984307
16/03/25 13:13:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 535.9 MB)
16/03/25 13:13:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52892 (size: 3.0 KB, free: 535.9 MB)
16/03/25 13:13:22 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:13:22 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:13:22 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:13:22 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:13:22 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:13:22 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:13:22 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:13:22 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:13:22 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:13:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/25 13:13:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
reduceFunction_Parents(): returns= ['None', u'area', 'None']
16/03/25 13:13:22 INFO PythonRunner: Times: total = 59, boot = -163, init = 221, finish = 1
16/03/25 13:13:22 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1280 bytes result sent to driver
16/03/25 13:13:22 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 74 ms on localhost (1/2)
16/03/25 13:13:22 INFO PythonRunner: Times: total = 213, boot = 212, init = 1, finish = 0
16/03/25 13:13:22 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:13:22 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 240 ms on localhost (2/2)
16/03/25 13:13:22 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:13:22 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.233 s
16/03/25 13:13:22 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 9.941590 s
16/03/25 13:13:23 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:13:23 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:13:23 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:13:23 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:13:23 INFO DAGScheduler: Missing parents: List()
16/03/25 13:13:23 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:13:23 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19417, maxMem=561984307
16/03/25 13:13:23 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 535.9 MB)
16/03/25 13:13:23 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25233, maxMem=561984307
16/03/25 13:13:23 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 535.9 MB)
16/03/25 13:13:23 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:52892 (size: 3.3 KB, free: 535.9 MB)
16/03/25 13:13:23 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:13:23 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:13:23 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:13:23 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:13:23 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2361 bytes)
16/03/25 13:13:23 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:13:23 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:13:23 INFO PythonRunner: Times: total = 72, boot = -60, init = 132, finish = 0
16/03/25 13:13:23 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/03/25 13:13:23 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 98 ms on localhost (1/2)
16/03/25 13:13:23 INFO PythonRunner: Times: total = 132, boot = 131, init = 1, finish = 0
16/03/25 13:13:23 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:13:23 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 156 ms on localhost (2/2)
16/03/25 13:13:23 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:13:23 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.156 s
16/03/25 13:13:23 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.169179 s
16/03/25 13:13:23 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:13:23 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:13:23 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:13:23 INFO MemoryStore: MemoryStore cleared
16/03/25 13:13:23 INFO BlockManager: BlockManager stopped
16/03/25 13:13:23 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:13:23 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:13:23 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:13:23 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:13:23 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:13:23 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1ef4e6c>, {'c9e46d6d893b45343d5c7e9c6ec9851b': [u'metropolitan', u'None'], '2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], '98acf8f6223b3758ff4a9dc22afb0e3b': [u'metropolitan', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], '4503bafd06fb20136c689c645a03eefa': [u'metropolitan', u'None'], '4b7e9f2659636820e82592ed034512f9': [u'Chennai', u'Madras'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], '1d1c5d8e5b55f6916d7d9218c4a0fe34': [u'None', u'area', u'None', u'Bengal'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], 'ff4fcba188cd7bb550ed88e9ee5dc6f1': [u'Chennai', u'Madras', u'None'], '57466dae2c092869867908c5c54e241c': [u'metropolitan', u'None'], '3c28f836cfdab5d2af70e9fd66287ad9': [u'None', u'area', u'special', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], 'e9da57cf07c9f8d232e2c9c1a07d1a0a': [u'None', u'area', u'culture', u'None'], '3a2fbf91abebcac17538118b2e02315d': [u'metropolitan', u'None', u'western'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '3cd540871242471e0d89bea4eabc06ea': [u'None', u'expansion', u'None'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras'], '4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], 'ed457e104ac489b5ec0bf242d39416e3': [u'metropolitan', u'None'], 'c251e6e2e2631354c71580629bbab1b4': [u'None', u'area', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '39c21ff4448a2910600584a0d49f93e8': [u'metropolitan', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], '25439f8325592e4ecd8b06f5f799b57a': [u'None', u'expansion', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None']})
asfer_pickle_string_dump(): picklef.write(): purpose
16/03/25 13:13:24 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:13:24 INFO SecurityManager: Changing view acls to: root
16/03/25 13:13:24 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:13:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:13:24 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:13:24 INFO Remoting: Starting remoting
16/03/25 13:13:24 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:44507]
16/03/25 13:13:24 INFO Utils: Successfully started service 'sparkDriver' on port 44507.
16/03/25 13:13:24 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:13:24 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:13:24 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5fb8b713-ef44-4a51-9903-46bbbbcbe24c
16/03/25 13:13:24 INFO MemoryStore: MemoryStore started with capacity 535.9 MB
16/03/25 13:13:24 INFO HttpFileServer: HTTP File server directory is /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/httpd-081d4a9d-d8e6-4861-9ce3-4ac676ee1cf8
16/03/25 13:13:24 INFO HttpServer: Starting HTTP Server
16/03/25 13:13:24 INFO Utils: Successfully started service 'HTTP file server' on port 48493.
16/03/25 13:13:24 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:13:24 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:13:24 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:13:24 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-69b342cc-0621-4f9d-ade8-598f0b58aec9/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:13:24 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891804653
16/03/25 13:13:24 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:13:24 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:13:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41410.
16/03/25 13:13:24 INFO NettyBlockTransferService: Server created on 41410
16/03/25 13:13:24 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:13:24 INFO BlockManagerMasterEndpoint: Registering block manager localhost:41410 with 535.9 MB RAM, BlockManagerId(driver, localhost, 41410)
16/03/25 13:13:24 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:13:24 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:13:24 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:13:24 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:13:24 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:13:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:13:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:13:24 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:13:24 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=561984307
16/03/25 13:13:24 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 535.9 MB)
16/03/25 13:13:24 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=561984307
16/03/25 13:13:24 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 535.9 MB)
16/03/25 13:13:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:41410 (size: 4.1 KB, free: 535.9 MB)
16/03/25 13:13:24 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:13:24 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:13:24 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:13:24 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2602 bytes)
16/03/25 13:13:24 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2632 bytes)
16/03/25 13:13:24 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:13:24 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891804653
16/03/25 13:13:24 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:13:24 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-69b342cc-0621-4f9d-ade8-598f0b58aec9/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:13:24 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:13:24 INFO MemoryStore: ensureFreeSpace(321) called with curMem=10732, maxMem=561984307
16/03/25 13:13:24 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 321.0 B, free 535.9 MB)
16/03/25 13:13:24 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:41410 (size: 321.0 B, free: 535.9 MB)
16/03/25 13:13:25 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:13:25 INFO MemoryStore: ensureFreeSpace(348) called with curMem=11053, maxMem=561984307
16/03/25 13:13:25 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 348.0 B, free 535.9 MB)
16/03/25 13:13:25 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:41410 (size: 348.0 B, free: 535.9 MB)
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Chennai
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: geographical
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: area
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  purpose  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: expansion
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: serving
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: formerly
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: people
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: culture
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: bishop
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: special
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: geography
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: city
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: given
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Madras
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: sum
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: expressed
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: boundary
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Tamil
16/03/25 13:13:33 INFO PythonRunner: Times: total = 8626, boot = 490, init = 396, finish = 7740
16/03/25 13:13:33 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: function
16/03/25 13:13:33 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8718 ms on localhost (1/2)
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: product
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: terms
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'status', u'people', u'relations', u'to', u'groups', u'between', u'respect', u'the', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: equivalent
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Bay
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'smaller', u'shoreline', u'gulf', u'of', u'larger', u'cove', u'but', u'an', u'indentation', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: western
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'about', u'United', u'development', u'of', u'life', u'period', u'States', u'exploration', u'western', u'in', u'during', u'the', u'film'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: particular
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'about', u')', u'(', u'some', u'general', u'to', u'as', u'part', u'opposed', u'fact'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Bengal
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'whose', u'and', u'Bangladesh', u'eastern', u'region', u'India', u'part', u'western', u'in', u'included', u'now', u'is'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Orthodox
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'pertaining', u'Judaism', u'characteristic', u'to', u'of', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: region
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'extended', u'of', u'something', u'spatial', u'the', u'location'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: title
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'statute', u'give', u'that', u'may', u'of', u'the', u'bill', u'brief', u'heading', u'deals', u'matters', u'names', u'it', u';', u'summary', u'with', u'or', u'legislative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: patriarch
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'older', u'is', u'who', u'rank', u'yourself', u'in', u'higher', u'than', u'man'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Church
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'and', u'own', u'have', u'of', u'who', u'one', u'forms', u'their', u'groups', u'the', u'worship', u'beliefs', u'Christians'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: usually
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'normal', u'conditions', u'under'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: position
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'space', u'of', u'portion', u'something', u'particular', u'the', u'occupied', u'by'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: distinguished
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'as', u'different', u'mark'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: purpose
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'your', u'an', u'intended', u'that', u'is', u'actions', u'anticipated', u'planned', u'outcome', u'guides', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/25 13:13:33 INFO PythonRunner: Times: total = 8925, boot = 490, init = 404, finish = 8031
16/03/25 13:13:33 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:13:33 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9001 ms on localhost (2/2)
16/03/25 13:13:33 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:13:33 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 9.004 s
16/03/25 13:13:33 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:13:33 INFO DAGScheduler: running: Set()
16/03/25 13:13:33 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:13:33 INFO DAGScheduler: failed: Set()
16/03/25 13:13:33 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:13:33 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:13:33 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11401, maxMem=561984307
16/03/25 13:13:33 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 535.9 MB)
16/03/25 13:13:33 INFO MemoryStore: ensureFreeSpace(3057) called with curMem=16385, maxMem=561984307
16/03/25 13:13:33 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 535.9 MB)
16/03/25 13:13:33 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:41410 (size: 3.0 KB, free: 535.9 MB)
16/03/25 13:13:33 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:13:33 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:13:33 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:13:33 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:13:33 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:13:33 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:13:33 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:13:33 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:13:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/25 13:13:33 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:13:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
16/03/25 13:13:34 INFO PythonRunner: Times: total = 23, boot = -117, init = 140, finish = 0
16/03/25 13:13:34 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:13:34 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 60 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'area', 'None']
16/03/25 13:13:34 INFO PythonRunner: Times: total = 341, boot = 340, init = 1, finish = 0
16/03/25 13:13:34 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1280 bytes result sent to driver
16/03/25 13:13:34 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 372 ms on localhost (2/2)
16/03/25 13:13:34 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:13:34 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.356 s
16/03/25 13:13:34 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 9.420707 s
16/03/25 13:13:34 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:13:34 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:13:34 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:13:34 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:13:34 INFO DAGScheduler: Missing parents: List()
16/03/25 13:13:34 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:13:34 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19442, maxMem=561984307
16/03/25 13:13:34 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 535.9 MB)
16/03/25 13:13:34 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25258, maxMem=561984307
16/03/25 13:13:34 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 535.9 MB)
16/03/25 13:13:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:41410 (size: 3.3 KB, free: 535.9 MB)
16/03/25 13:13:34 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:13:34 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:13:34 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:13:34 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:13:34 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2361 bytes)
16/03/25 13:13:34 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:13:34 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:13:34 INFO PythonRunner: Times: total = 81, boot = -251, init = 332, finish = 0
16/03/25 13:13:34 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:13:34 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 90 ms on localhost (1/2)
16/03/25 13:13:34 INFO PythonRunner: Times: total = 235, boot = 234, init = 1, finish = 0
16/03/25 13:13:34 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/03/25 13:13:34 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 248 ms on localhost (2/2)
16/03/25 13:13:34 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:13:34 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.232 s
16/03/25 13:13:34 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.281191 s
16/03/25 13:13:34 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:13:34 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:13:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:13:34 INFO MemoryStore: MemoryStore cleared
16/03/25 13:13:34 INFO BlockManager: BlockManager stopped
16/03/25 13:13:34 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:13:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:13:34 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:13:34 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:13:34 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:13:34 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1ef4e6c>, {'c9e46d6d893b45343d5c7e9c6ec9851b': [u'metropolitan', u'None'], '2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], '98acf8f6223b3758ff4a9dc22afb0e3b': [u'metropolitan', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], '4503bafd06fb20136c689c645a03eefa': [u'metropolitan', u'None'], '4b7e9f2659636820e82592ed034512f9': [u'Chennai', u'Madras'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], '1d1c5d8e5b55f6916d7d9218c4a0fe34': [u'None', u'area', u'None', u'Bengal'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], 'ff4fcba188cd7bb550ed88e9ee5dc6f1': [u'Chennai', u'Madras', u'None'], '57466dae2c092869867908c5c54e241c': [u'metropolitan', u'None'], '3c28f836cfdab5d2af70e9fd66287ad9': [u'None', u'area', u'special', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], 'e9da57cf07c9f8d232e2c9c1a07d1a0a': [u'None', u'area', u'culture', u'None'], '3a2fbf91abebcac17538118b2e02315d': [u'metropolitan', u'None', u'western'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '3cd540871242471e0d89bea4eabc06ea': [u'None', u'expansion', u'None'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras'], '4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], 'ed457e104ac489b5ec0bf242d39416e3': [u'metropolitan', u'None'], '625feaadbb337eeb25fb2203afc35e5a': [u'None', u'area', u'None'], 'c251e6e2e2631354c71580629bbab1b4': [u'None', u'area', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '39c21ff4448a2910600584a0d49f93e8': [u'metropolitan', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], '25439f8325592e4ecd8b06f5f799b57a': [u'None', u'expansion', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None']})
InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:freqterms1= [u'serving', u'formerly', u'people', u'Christianity', u'culture', u'indefinite', u'bishop', u'special', u'geography', u'city', u'given', u'Madras', u'Eastern', u'archbishop', u'sum', u'expressed', u'geographical', u'boundary', u'Tamil', u'Nadu', u'function', u'product', u'terms', u'equivalent', u'Bay', u'western', u'particular', u'Bengal', u'Orthodox', u'region', u'title', u'patriarch', u'Church', u'usually', u'position', u'distinguished', u'purpose']
16/03/25 13:13:35 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:13:35 INFO SecurityManager: Changing view acls to: root
16/03/25 13:13:35 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:13:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:13:35 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:13:35 INFO Remoting: Starting remoting
16/03/25 13:13:35 INFO Utils: Successfully started service 'sparkDriver' on port 58914.
16/03/25 13:13:35 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:58914]
16/03/25 13:13:35 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:13:35 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:13:35 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-217b100d-f99e-4a72-a1d4-833a24cea063
16/03/25 13:13:35 INFO MemoryStore: MemoryStore started with capacity 535.9 MB
16/03/25 13:13:35 INFO HttpFileServer: HTTP File server directory is /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/httpd-8bcd9379-e3c8-4f4a-86cf-570164513465
16/03/25 13:13:35 INFO HttpServer: Starting HTTP Server
16/03/25 13:13:35 INFO Utils: Successfully started service 'HTTP file server' on port 39445.
16/03/25 13:13:35 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:13:36 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:13:36 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:13:36 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-0b31ec1f-76af-49ae-8c81-f2071676a965/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:13:36 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891816502
16/03/25 13:13:36 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:13:36 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:13:36 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37435.
16/03/25 13:13:36 INFO NettyBlockTransferService: Server created on 37435
16/03/25 13:13:36 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:13:36 INFO BlockManagerMasterEndpoint: Registering block manager localhost:37435 with 535.9 MB RAM, BlockManagerId(driver, localhost, 37435)
16/03/25 13:13:36 INFO BlockManagerMaster: Registered BlockManager
Spark_MapReduce(): wordsatthislevel: [u'serving', u'formerly', u'people', u'Christianity', u'culture', u'indefinite', u'bishop', u'special', u'geography', u'city', u'given', u'Madras', u'Eastern', u'archbishop', u'sum', u'expressed', u'geographical', u'boundary', u'Tamil', u'Nadu', u'function', u'product', u'terms', u'equivalent', u'Bay', u'western', u'particular', u'Bengal', u'Orthodox', u'region', u'title', u'patriarch', u'Church', u'usually', u'position', u'distinguished', u'purpose']
16/03/25 13:13:36 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236
16/03/25 13:13:36 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236)
16/03/25 13:13:36 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236) with 2 output partitions
16/03/25 13:13:36 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236)
16/03/25 13:13:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:13:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:13:36 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236), which has no missing parents
16/03/25 13:13:36 INFO MemoryStore: ensureFreeSpace(6560) called with curMem=0, maxMem=561984307
16/03/25 13:13:36 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 535.9 MB)
16/03/25 13:13:36 INFO MemoryStore: ensureFreeSpace(4147) called with curMem=6560, maxMem=561984307
16/03/25 13:13:36 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 535.9 MB)
16/03/25 13:13:36 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:37435 (size: 4.0 KB, free: 535.9 MB)
16/03/25 13:13:36 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:13:36 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236)
16/03/25 13:13:36 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:13:36 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2576 bytes)
16/03/25 13:13:36 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2598 bytes)
16/03/25 13:13:36 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:13:36 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458891816502
16/03/25 13:13:36 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:13:36 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-89d59770-5d76-4732-8d4b-06a1596b6243/userFiles-0b31ec1f-76af-49ae-8c81-f2071676a965/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:13:36 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:13:36 INFO MemoryStore: ensureFreeSpace(318) called with curMem=10707, maxMem=561984307
16/03/25 13:13:36 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 318.0 B, free 535.9 MB)
16/03/25 13:13:36 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:37435 (size: 318.0 B, free: 535.9 MB)
16/03/25 13:13:36 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:13:36 INFO MemoryStore: ensureFreeSpace(301) called with curMem=11025, maxMem=561984307
16/03/25 13:13:36 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 301.0 B, free 535.9 MB)
16/03/25 13:13:36 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:37435 (size: 301.0 B, free: 535.9 MB)
mapFunction(): freqterms1: Tamil
mapFunction(): freqterms1: serving
mapFunction(): freqterms1: Nadu
mapFunction(): freqterms1: function
mapFunction(): freqterms1: product
mapFunction(): freqterms1: terms
mapFunction(): freqterms1: equivalent
mapFunction(): freqterms1: Bay
mapFunction(): freqterms1: western
mapFunction(): freqterms1: particular
mapFunction(): freqterms1: Bengal
mapFunction(): freqterms1: Orthodox
mapFunction(): freqterms1: region
mapFunction(): freqterms1: title
mapFunction(): freqterms1: patriarch
mapFunction(): freqterms1: Church
mapFunction(): freqterms1: usually
mapFunction(): freqterms1: position
mapFunction(): freqterms1: distinguished
mapFunction(): freqterms1: purpose
16/03/25 13:13:45 INFO PythonRunner: Times: total = 9149, boot = 509, init = 400, finish = 8240
16/03/25 13:13:45 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:13:45 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9223 ms on localhost (1/2)
mapFunction(): freqterms1: formerly
mapFunction(): freqterms1: people
mapFunction(): freqterms1: Christianity
mapFunction(): freqterms1: culture
mapFunction(): freqterms1: indefinite
mapFunction(): freqterms1: bishop
mapFunction(): freqterms1: special
mapFunction(): freqterms1: geography
mapFunction(): freqterms1: city
mapFunction(): freqterms1: given
mapFunction(): freqterms1: Madras
mapFunction(): freqterms1: Eastern
mapFunction(): freqterms1: archbishop
mapFunction(): freqterms1: sum
mapFunction(): freqterms1: expressed
mapFunction(): freqterms1: geographical
mapFunction(): freqterms1: boundary
16/03/25 13:13:46 INFO PythonRunner: Times: total = 9501, boot = 504, init = 648, finish = 8349
16/03/25 13:13:46 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:13:46 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236) finished in 9.584 s
16/03/25 13:13:46 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:13:46 INFO DAGScheduler: running: Set()
16/03/25 13:13:46 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:13:46 INFO DAGScheduler: failed: Set()
16/03/25 13:13:46 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:13:46 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236), which is now runnable
16/03/25 13:13:46 INFO MemoryStore: ensureFreeSpace(4976) called with curMem=11326, maxMem=561984307
16/03/25 13:13:46 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 535.9 MB)
16/03/25 13:13:46 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9573 ms on localhost (2/2)
16/03/25 13:13:46 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:13:46 INFO MemoryStore: ensureFreeSpace(3049) called with curMem=16302, maxMem=561984307
16/03/25 13:13:46 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 535.9 MB)
16/03/25 13:13:46 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:37435 (size: 3.0 KB, free: 535.9 MB)
16/03/25 13:13:46 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:13:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236)
16/03/25 13:13:46 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:13:46 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:13:46 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:13:46 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:13:46 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:13:46 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:13:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/25 13:13:46 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:13:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/25 13:13:46 INFO PythonRunner: Times: total = 44, boot = -218, init = 262, finish = 0
16/03/25 13:13:46 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:13:46 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 67 ms on localhost (1/2)
16/03/25 13:13:46 INFO PythonRunner: Times: total = 183, boot = 180, init = 1, finish = 2
16/03/25 13:13:46 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 4550 bytes result sent to driver
16/03/25 13:13:46 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236) finished in 0.200 s
16/03/25 13:13:46 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236, took 9.866529 s
16/03/25 13:13:46 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 211 ms on localhost (2/2)
16/03/25 13:13:46 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:13:46 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236
16/03/25 13:13:46 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236) with 2 output partitions
16/03/25 13:13:46 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236)
16/03/25 13:13:46 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:13:46 INFO DAGScheduler: Missing parents: List()
16/03/25 13:13:46 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236), which has no missing parents
16/03/25 13:13:46 INFO MemoryStore: ensureFreeSpace(5872) called with curMem=19351, maxMem=561984307
16/03/25 13:13:46 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 535.9 MB)
16/03/25 13:13:46 INFO MemoryStore: ensureFreeSpace(3417) called with curMem=25223, maxMem=561984307
16/03/25 13:13:46 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 535.9 MB)
16/03/25 13:13:46 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:37435 (size: 3.3 KB, free: 535.9 MB)
16/03/25 13:13:46 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:13:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236)
16/03/25 13:13:46 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:13:46 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:13:46 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 5541 bytes)
16/03/25 13:13:46 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:13:46 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:13:46 INFO PythonRunner: Times: total = 48, boot = -33, init = 81, finish = 0
16/03/25 13:13:46 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 4852 bytes result sent to driver
16/03/25 13:13:46 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 88 ms on localhost (1/2)
16/03/25 13:13:46 INFO PythonRunner: Times: total = 113, boot = 113, init = 0, finish = 0
16/03/25 13:13:46 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:13:46 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 129 ms on localhost (2/2)
16/03/25 13:13:46 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:13:46 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236) finished in 0.120 s
16/03/25 13:13:46 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236, took 0.154933 s
graphcache_mapreduce updated: defaultdict(<cyfunction <lambda> at 0xb1ef4bcc>, {'70d7d53d7ab05e91c9f0c0600910ca35': Row(tokensatthislevel=[u'city', u'Tamil', u'Nadu', u'Bay', u'Bengal', u'formerly', u'Madras', u'Eastern', u'Orthodox', u'Church', u'title', u'given', u'position', u'bishop', u'patriarch', u'equivalent', u'archbishop', u'western', u'Christianity', u'particular', u'geographical', u'region', u'indefinite', u'boundary', u'usually', u'serving', u'special', u'purpose', u'distinguished', u'people', u'culture', u'geography', u'function', u'expressed', u'sum', u'product', u'terms']), '410bbddf7a28d78bd61df79edc29c2bb': Row(tokensatthislevel=[u'individual', u'quantity', u'food', u'drink', u'taken', u'part', u'meal', u'previous', u'time', u'plural', u'group', u'human', u'beings', u'men', u'women', u'children', u'collectively', u'monotheistic', u'system', u'beliefs', u'practices', u'based', u'Old', u'Testament', u'teachings', u'Jesus', u'embodied', u'New', u'Testament', u'emphasizing', u'role', u'Jesus', u'savior', u'particular', u'society', u'particular', u'time', u'place', u'vague', u'clearly', u'defined', u'stated', u'senior', u'member', u'Christian', u'clergy', u'spiritual', u'administrative', u'authority', u'appointed', u'Christian', u'churches', u'oversee', u'priests', u'ministers', u'considered', u'churches', u'successors', u'twelve', u'Apostles', u'Christ', u'special', u'offering', u'usually', u'temporary', u'reduced', u'price', u'featured', u'advertising', u'study', u'earth', u'surface', u'includes', u'people', u'responses', u'topography', u'climate', u'soil', u'vegetation', u'large', u'densely', u'populated', u'urban', u'area', u'include', u'several', u'independent', u'administrative', u'districts', u'assumption', u'taken', u'granted', u'state', u'southeastern', u'India', u'Bay', u'Bengal', u'south', u'Andhra', u'Pradesh', u'formerly', u'Madras', u'lying', u'toward', u'situated', u'east', u'bishop', u'highest', u'rank', u'quantity', u'money', u'give', u'expression', u'relating', u'science', u'geography', u'line', u'determining', u'limits', u'area', u'member', u'mixed', u'Dravidian', u'Caucasian', u'people', u'southern', u'India', u'Sri', u'Lanka', u'mathematics', u'mathematical', u'relation', u'element', u'given', u'set', u'domain', u'function', u'associated', u'element', u'another', u'set', u'range', u'function', u'commodities', u'offered', u'sale', u'status', u'respect', u'relations', u'people', u'groups', u'person', u'thing', u'equal', u'another', u'value', u'measure', u'force', u'effect', u'significance', u'etc', u'indentation', u'shoreline', u'larger', u'cove', u'smaller', u'gulf', u'film', u'life', u'western', u'United', u'States', u'period', u'exploration', u'development', u'fact', u'part', u'opposed', u'general', u'region', u'whose', u'eastern', u'part', u'Bangladesh', u'whose', u'western', u'part', u'included', u'India', u'pertaining', u'characteristic', u'Judaism', u'extended', u'spatial', u'location', u'something', u'heading', u'names', u'statute', u'legislative', u'bill', u'give', u'brief', u'summary', u'matters', u'deals', u'man', u'older', u'higher', u'rank', u'one', u'groups', u'Christians', u'beliefs', u'forms', u'worship', u'normal', u'conditions', u'particular', u'portion', u'space', u'occupied', u'something', u'mark', u'different', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions'])})
16/03/25 13:13:46 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:13:46 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:13:46 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:13:46 INFO MemoryStore: MemoryStore cleared
16/03/25 13:13:46 INFO BlockManager: BlockManager stopped
16/03/25 13:13:46 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:13:46 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:13:46 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:13:46 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:13:46 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:13:46 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:tokensofthislevel: [u'individual', u'quantity', u'food', u'drink', u'taken', u'part', u'meal', u'previous', u'time', u'plural', u'group', u'human', u'beings', u'men', u'women', u'children', u'collectively', u'monotheistic', u'system', u'beliefs', u'practices', u'based', u'Old', u'Testament', u'teachings', u'Jesus', u'embodied', u'New', u'Testament', u'emphasizing', u'role', u'Jesus', u'savior', u'particular', u'society', u'particular', u'time', u'place', u'vague', u'clearly', u'defined', u'stated', u'senior', u'member', u'Christian', u'clergy', u'spiritual', u'administrative', u'authority', u'appointed', u'Christian', u'churches', u'oversee', u'priests', u'ministers', u'considered', u'churches', u'successors', u'twelve', u'Apostles', u'Christ', u'special', u'offering', u'usually', u'temporary', u'reduced', u'price', u'featured', u'advertising', u'study', u'earth', u'surface', u'includes', u'people', u'responses', u'topography', u'climate', u'soil', u'vegetation', u'large', u'densely', u'populated', u'urban', u'area', u'include', u'several', u'independent', u'administrative', u'districts', u'assumption', u'taken', u'granted', u'state', u'southeastern', u'India', u'Bay', u'Bengal', u'south', u'Andhra', u'Pradesh', u'formerly', u'Madras', u'lying', u'toward', u'situated', u'east', u'bishop', u'highest', u'rank', u'quantity', u'money', u'give', u'expression', u'relating', u'science', u'geography', u'line', u'determining', u'limits', u'area', u'member', u'mixed', u'Dravidian', u'Caucasian', u'people', u'southern', u'India', u'Sri', u'Lanka', u'mathematics', u'mathematical', u'relation', u'element', u'given', u'set', u'domain', u'function', u'associated', u'element', u'another', u'set', u'range', u'function', u'commodities', u'offered', u'sale', u'status', u'respect', u'relations', u'people', u'groups', u'person', u'thing', u'equal', u'another', u'value', u'measure', u'force', u'effect', u'significance', u'etc', u'indentation', u'shoreline', u'larger', u'cove', u'smaller', u'gulf', u'film', u'life', u'western', u'United', u'States', u'period', u'exploration', u'development', u'fact', u'part', u'opposed', u'general', u'region', u'whose', u'eastern', u'part', u'Bangladesh', u'whose', u'western', u'part', u'included', u'India', u'pertaining', u'characteristic', u'Judaism', u'extended', u'spatial', u'location', u'something', u'heading', u'names', u'statute', u'legislative', u'bill', u'give', u'brief', u'summary', u'matters', u'deals', u'man', u'older', u'higher', u'rank', u'one', u'groups', u'Christians', u'beliefs', u'forms', u'worship', u'normal', u'conditions', u'particular', u'portion', u'space', u'occupied', u'something', u'mark', u'different', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions']
prevlevelsynsets: [Synset('tamil.n.01'), Synset('function.n.01'), Synset('merchandise.n.01'), Synset('footing.n.01'), Synset('equivalent.n.01'), Synset('bay.n.01'), Synset('western.n.01'), Synset('particular.n.01'), Synset('bengal.n.01'), Synset('orthodox.a.01'), Synset('region.n.01'), Synset('title.n.01'), Synset('patriarch.n.01'), Synset('church.n.01'), Synset('normally.r.01'), Synset('position.n.01'), Synset('distinguish.v.01'), Synset('purpose.n.01'), Synset('helping.n.01'), Synset('once.r.01'), Synset('people.n.01'), Synset('christianity.n.01'), Synset('culture.n.01'), Synset('indefinite.a.01'), Synset('bishop.n.01'), Synset('special.n.01'), Synset('geography.n.01'), Synset('city.n.01'), Synset('given.n.01'), Synset('tamil_nadu.n.01'), Synset('eastern.s.01'), Synset('archbishop.n.01'), Synset('sum.n.01'), Synset('express.n.01'), Synset('geographic.a.01'), Synset('boundary.n.01')]
defaultdict(<type 'list'>, {u'serving': [u'None', u'area'], u'Madras': [u'Chennai', u'None', u'Madras'], u'people': [u'None', u'area', u'None'], u'Christianity': [u'metropolitan', u'None'], u'culture': [u'None', u'area', u'None'], u'indefinite': [u'None', u'area', u'None'], u'bishop': [u'metropolitan', u'None'], u'special': [u'None', u'area', u'None', u'special'], u'geography': [u'None', u'area', u'None'], u'city': [u'Chennai', u'None'], u'given': [u'metropolitan', u'None'], u'position': [u'metropolitan', u'None'], u'formerly': [u'Chennai', u'None'], u'Eastern': [u'metropolitan', u'None'], u'archbishop': [u'metropolitan', u'None'], u'sum': [u'None', u'expansion', u'None'], u'expressed': [u'None', u'expansion', u'None'], u'geographical': [u'None', u'area', u'None'], u'boundary': [u'None', u'area', u'None'], u'Tamil': [u'Chennai', u'None'], u'Nadu': [u'Chennai', u'None'], u'function': [u'None', u'expansion', u'None', u'function'], u'product': [u'None', u'expansion', u'None'], u'terms': [u'None', u'expansion', u'None'], u'equivalent': [u'metropolitan', u'None'], u'Bay': [u'Chennai', u'Madras'], u'western': [u'metropolitan', u'None', u'western'], u'particular': [u'None', u'area', u'culture', u'None'], u'Bengal': [u'Chennai', u'Madras', u'None'], u'region': [u'None', u'area', u'None', u'Bengal'], u'Orthodox': [u'metropolitan', u'None'], u'patriarch': [u'metropolitan', u'None'], u'Church': [u'metropolitan', u'None'], u'usually': [u'None', u'area', u'special', u'None'], u'title': [u'metropolitan', u'None'], u'distinguished': [u'None', u'area', u'None'], u'purpose': [u'None', u'area', u'None']})
ksynset= Synset('helping.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('helping.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('tamil_nadu.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('special.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('chennai.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('none.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('sum.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('sum.n.01')
lsynset= Synset('expansion.n.01')
ksynset= Synset('sum.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('express.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('express.v.01')
lsynset= Synset('expansion.n.01')
ksynset= Synset('express.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('function.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('function.n.01')
lsynset= Synset('expansion.n.01')
ksynset= Synset('function.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('function.n.01')
lsynset= Synset('function.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('expansion.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('footing.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('footing.n.01')
lsynset= Synset('expansion.n.01')
ksynset= Synset('footing.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('tamil_nadu.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('western.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('culture.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('tamil_nadu.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('bengal.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('area.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('special.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('area.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('none.n.01')
Core number (sorted) : [(u'area', 13), (u'metropolitan', 12), (u'Chennai', 7), (u'Madras', 5), (u'expansion', 5), (u'Bengal', 5), (u'culture', 4), (u'special', 4), (u'Bay', 4), (u'particular', 4), (u'region', 4), (u'usually', 4), (u'serving', 2), (u'people', 2), (u'Christianity', 2), (u'indefinite', 2), (u'bishop', 2), (u'geography', 2), (u'city', 2), (u'given', 2), (u'archbishop', 2), (u'sum', 2), (u'expressed', 2), (u'geographical', 2), (u'boundary', 2), (u'Tamil', 2), (u'Nadu', 2), (u'function', 2), (u'product', 2), (u'terms', 2), (u'equivalent', 2), (u'western', 2), (u'Orthodox', 2), (u'title', 2), (u'patriarch', 2), (u'Eastern', 2), (u'formerly', 2), (u'Church', 2), (u'position', 2), (u'distinguished', 2), (u'purpose', 2), (u'None', 0)]
=============================================================================================================
Unsupervised Classification based on top percentile Core numbers of the definition graph(subgraph of WordNet)
=============================================================================================================
This document belongs to class: area ,core number= 13
This document belongs to class: metropolitan ,core number= 12
This document belongs to class: Chennai ,core number= 7
This document belongs to class: Madras ,core number= 5
This document belongs to class: expansion ,core number= 5
This document belongs to class: Bengal ,core number= 5
max_core_number 13
===================================================================
Page Rank of the vertices of RGO Definition Graph
===================================================================
[(u'metropolitan', 0.14711476124956654), (u'area', 0.1324330177438469), (u'Chennai', 0.070218911144783), (u'expansion', 0.06896076372844066), (u'Bengal', 0.029161228094978266), (u'Madras', 0.029112804827554094), (u'culture', 0.021398752531447705), (u'special', 0.021398752531447705), (u'particular', 0.021398752531447705), (u'usually', 0.021398752531447705), (u'region', 0.02056663085554685), (u'Bay', 0.020420410259860057), (u'product', 0.015369451142525727), (u'sum', 0.015369451142525727), (u'expressed', 0.015369451142525727), (u'function', 0.015369451142525727), (u'terms', 0.015369451142525727), (u'Christianity', 0.014066884517173625), (u'bishop', 0.014066884517173625), (u'given', 0.014066884517173625), (u'archbishop', 0.014066884517173625), (u'equivalent', 0.014066884517173625), (u'position', 0.014066884517173625), (u'western', 0.014066884517173625), (u'Orthodox', 0.014066884517173625), (u'patriarch', 0.014066884517173625), (u'Eastern', 0.014066884517173625), (u'Church', 0.014066884517173625), (u'title', 0.014066884517173625), (u'serving', 0.01230428277059196), (u'people', 0.01230428277059196), (u'indefinite', 0.01230428277059196), (u'geography', 0.01230428277059196), (u'geographical', 0.01230428277059196), (u'boundary', 0.01230428277059196), (u'distinguished', 0.01230428277059196), (u'purpose', 0.01230428277059196), (u'city', 0.012171782350039574), (u'Tamil', 0.012171782350039574), (u'Nadu', 0.012171782350039574), (u'formerly', 0.012171782350039574), (u'None', 0.003645200486026732)]
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - connectivity of RGO Definition Graph - Mengers Theorem
==========================================================================================================

