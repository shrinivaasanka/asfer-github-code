9-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:11:04 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=548394762
16/03/16 17:11:04 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.0 MB)
16/03/16 17:11:04 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=548394762
16/03/16 17:11:04 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.0 MB)
16/03/16 17:11:04 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:44971 (size: 4.1 KB, free: 523.0 MB)
16/03/16 17:11:04 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 17:11:04 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:11:04 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 17:11:04 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/16 17:11:04 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/16 17:11:04 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 17:11:04 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128464532
16/03/16 17:11:04 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 17:11:04 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-b9f820bb-777c-4641-8531-c3b03d0ef3e3/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: area
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: issue
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  Synset('set.n.01') ; keyword:  belong  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: bend
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: planning
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: permission
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: giant
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: economy
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: composition
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: astatine
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: agency
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: present
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['NomapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: metropolitan
ne']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: area
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
16/03/16 17:11:13 INFO PythonRunner: Times: total = 8586, boot = 472, init = 418, finish = 7696
16/03/16 17:11:13 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/16 17:11:13 INFO PythonRunner: Times: total = 8600, boot = 464, init = 379, finish = 7757
16/03/16 17:11:13 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8678 ms on localhost (1/2)
16/03/16 17:11:13 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/16 17:11:13 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8698 ms on localhost (2/2)
16/03/16 17:11:13 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 17:11:13 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.699 s
16/03/16 17:11:13 INFO DAGScheduler: looking for newly runnable stages
16/03/16 17:11:13 INFO DAGScheduler: running: Set()
16/03/16 17:11:13 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 17:11:13 INFO DAGScheduler: failed: Set()
16/03/16 17:11:13 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 17:11:13 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 17:11:13 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=548394762
16/03/16 17:11:13 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.0 MB)
16/03/16 17:11:13 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=548394762
16/03/16 17:11:13 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.0 MB)
16/03/16 17:11:13 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:44971 (size: 3.0 KB, free: 523.0 MB)
16/03/16 17:11:13 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 17:11:13 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:11:13 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 17:11:13 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:11:13 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:11:13 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 17:11:13 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 17:11:13 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:11:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 17:11:13 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:11:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/16 17:11:13 INFO PythonRunner: Times: total = 13, boot = -8, init = 21, finish = 0
16/03/16 17:11:13 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
reduceFunction_Parents(): returns= ['None', u'set']
16/03/16 17:11:13 INFO PythonRunner: Times: total = 41, boot = -88, init = 128, finish = 1
16/03/16 17:11:13 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1271 bytes result sent to driver
16/03/16 17:11:13 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 71 ms on localhost (1/2)
16/03/16 17:11:13 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 84 ms on localhost (2/2)
16/03/16 17:11:13 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 17:11:13 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.085 s
16/03/16 17:11:13 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.275554 s
16/03/16 17:11:14 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:11:14 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:11:14 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:11:14 INFO DAGScheduler: Parents of final stage: List()
16/03/16 17:11:14 INFO DAGScheduler: Missing parents: List()
16/03/16 17:11:14 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:11:14 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=548394762
16/03/16 17:11:14 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.0 MB)
16/03/16 17:11:14 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=548394762
16/03/16 17:11:14 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.0 MB)
16/03/16 17:11:14 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:44971 (size: 3.3 KB, free: 523.0 MB)
16/03/16 17:11:14 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 17:11:14 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:11:14 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 17:11:14 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/16 17:11:14 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 17:11:14 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 17:11:14 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 17:11:14 INFO PythonRunner: Times: total = 120, boot = 120, init = 0, finish = 0
16/03/16 17:11:14 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1336 bytes result sent to driver
16/03/16 17:11:14 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 130 ms on localhost (1/2)
16/03/16 17:11:14 INFO PythonRunner: Times: total = 134, boot = 134, init = 0, finish = 0
16/03/16 17:11:14 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/16 17:11:14 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 145 ms on localhost (2/2)
16/03/16 17:11:14 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 17:11:14 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.144 s
16/03/16 17:11:14 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.184185 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 17:11:14 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 17:11:14 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 17:11:14 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 17:11:14 INFO MemoryStore: MemoryStore cleared
16/03/16 17:11:14 INFO BlockManager: BlockManager stopped
16/03/16 17:11:14 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 17:11:14 INFO SparkContext: Successfully stopped SparkContext
16/03/16 17:11:14 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 17:11:14 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 17:11:14 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 17:11:14 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'set']
16/03/16 17:11:15 INFO SparkContext: Running Spark version 1.5.2
16/03/16 17:11:15 INFO SecurityManager: Changing view acls to: root
16/03/16 17:11:15 INFO SecurityManager: Changing modify acls to: root
16/03/16 17:11:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 17:11:15 INFO Slf4jLogger: Slf4jLogger started
16/03/16 17:11:15 INFO Remoting: Starting remoting
16/03/16 17:11:15 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:41067]
16/03/16 17:11:15 INFO Utils: Successfully started service 'sparkDriver' on port 41067.
16/03/16 17:11:15 INFO SparkEnv: Registering MapOutputTracker
16/03/16 17:11:15 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 17:11:15 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-cfbca3e5-4b30-4848-9974-47b986da899e
16/03/16 17:11:15 INFO MemoryStore: MemoryStore started with capacity 523.1 MB
16/03/16 17:11:15 INFO HttpFileServer: HTTP File server directory is /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/httpd-5cad63c6-1cc5-4333-848c-4ba2c7b49d9a
16/03/16 17:11:15 INFO HttpServer: Starting HTTP Server
16/03/16 17:11:15 INFO Utils: Successfully started service 'HTTP file server' on port 35072.
16/03/16 17:11:15 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 17:11:15 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 17:11:15 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 17:11:15 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-d0c9c915-8cda-45de-8da3-936cd8c6ed1e/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 17:11:15 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128475529
16/03/16 17:11:15 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 17:11:15 INFO Executor: Starting executor ID driver on host localhost
16/03/16 17:11:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50720.
16/03/16 17:11:15 INFO NettyBlockTransferService: Server created on 50720
16/03/16 17:11:15 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 17:11:15 INFO BlockManagerMasterEndpoint: Registering block manager localhost:50720 with 523.1 MB RAM, BlockManagerId(driver, localhost, 50720)
16/03/16 17:11:15 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): uranium
16/03/16 17:11:15 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:11:15 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:11:15 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:11:15 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:11:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 17:11:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 17:11:15 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:11:15 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=548536320
16/03/16 17:11:15 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.1 MB)
16/03/16 17:11:15 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=548536320
16/03/16 17:11:15 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.1 MB)
16/03/16 17:11:15 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:50720 (size: 4.1 KB, free: 523.1 MB)
16/03/16 17:11:15 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 17:11:15 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:11:15 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 17:11:15 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/16 17:11:15 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/16 17:11:15 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 17:11:15 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128475529
16/03/16 17:11:15 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 17:11:15 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-d0c9c915-8cda-45de-8da3-936cd8c6ed1e/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: area
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: bend
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: giant
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: astatine
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  uranium  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: present
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: area
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/16 17:11:24 INFO PythonRunner: Times: total = 8287, boot = 475, init = 391, finish = 7421
16/03/16 17:11:24 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/16 17:11:24 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8356 ms on localhost (1/2)
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: issue
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: planning
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: permission
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: economy
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: composition
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: agency
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 17:11:24 INFO PythonRunner: Times: total = 8473, boot = 481, init = 410, finish = 7582
16/03/16 17:11:24 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/16 17:11:24 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8560 ms on localhost (2/2)
16/03/16 17:11:24 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 17:11:24 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.562 s
16/03/16 17:11:24 INFO DAGScheduler: looking for newly runnable stages
16/03/16 17:11:24 INFO DAGScheduler: running: Set()
16/03/16 17:11:24 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 17:11:24 INFO DAGScheduler: failed: Set()
16/03/16 17:11:24 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 17:11:24 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 17:11:24 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=548536320
16/03/16 17:11:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.1 MB)
16/03/16 17:11:24 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=548536320
16/03/16 17:11:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.1 MB)
16/03/16 17:11:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:50720 (size: 3.0 KB, free: 523.1 MB)
16/03/16 17:11:24 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 17:11:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:11:24 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 17:11:24 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:11:24 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:11:24 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 17:11:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:11:24 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 17:11:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:11:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 17:11:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/03/16 17:11:24 INFO PythonRunner: Times: total = 113, boot = 111, init = 1, finish = 1
16/03/16 17:11:24 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/03/16 17:11:24 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 132 ms on localhost (1/2)
16/03/16 17:11:24 INFO PythonRunner: Times: total = 199, boot = 198, init = 0, finish = 1
16/03/16 17:11:24 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/16 17:11:24 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.223 s
16/03/16 17:11:24 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.809403 s
16/03/16 17:11:24 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 222 ms on localhost (2/2)
16/03/16 17:11:24 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 17:11:24 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:11:24 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:11:24 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:11:24 INFO DAGScheduler: Parents of final stage: List()
16/03/16 17:11:24 INFO DAGScheduler: Missing parents: List()
16/03/16 17:11:24 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:11:24 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=548536320
16/03/16 17:11:24 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.1 MB)
16/03/16 17:11:24 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=548536320
16/03/16 17:11:24 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.1 MB)
16/03/16 17:11:24 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:50720 (size: 3.3 KB, free: 523.1 MB)
16/03/16 17:11:24 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 17:11:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:11:24 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 17:11:24 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/16 17:11:24 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/03/16 17:11:24 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 17:11:24 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 17:11:24 INFO PythonRunner: Times: total = 84, boot = 84, init = 0, finish = 0
16/03/16 17:11:24 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/16 17:11:24 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 90 ms on localhost (1/2)
16/03/16 17:11:24 INFO PythonRunner: Times: total = 198, boot = 198, init = 0, finish = 0
16/03/16 17:11:24 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/03/16 17:11:24 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 206 ms on localhost (2/2)
16/03/16 17:11:24 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 17:11:24 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.209 s
16/03/16 17:11:24 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.230186 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 17:11:24 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 17:11:24 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 17:11:24 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 17:11:25 INFO MemoryStore: MemoryStore cleared
16/03/16 17:11:25 INFO BlockManager: BlockManager stopped
16/03/16 17:11:25 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 17:11:25 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 17:11:25 INFO SparkContext: Successfully stopped SparkContext
16/03/16 17:11:25 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 17:11:25 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 17:11:25 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'astatine']
16/03/16 17:11:25 INFO SparkContext: Running Spark version 1.5.2
16/03/16 17:11:25 INFO SecurityManager: Changing view acls to: root
16/03/16 17:11:25 INFO SecurityManager: Changing modify acls to: root
16/03/16 17:11:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 17:11:25 INFO Slf4jLogger: Slf4jLogger started
16/03/16 17:11:25 INFO Remoting: Starting remoting
16/03/16 17:11:25 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:35988]
16/03/16 17:11:25 INFO Utils: Successfully started service 'sparkDriver' on port 35988.
16/03/16 17:11:25 INFO SparkEnv: Registering MapOutputTracker
16/03/16 17:11:25 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 17:11:25 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-dbe7f2e0-6c26-4e53-a6af-5948bda67a78
16/03/16 17:11:25 INFO MemoryStore: MemoryStore started with capacity 523.1 MB
16/03/16 17:11:25 INFO HttpFileServer: HTTP File server directory is /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/httpd-a92e9248-23d2-49fb-a65a-ffe9a5b8ce91
16/03/16 17:11:25 INFO HttpServer: Starting HTTP Server
16/03/16 17:11:26 INFO Utils: Successfully started service 'HTTP file server' on port 52260.
16/03/16 17:11:26 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 17:11:26 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 17:11:26 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 17:11:26 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-ced741bd-529d-41fa-9f8a-23a33d2696ff/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 17:11:26 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128486081
16/03/16 17:11:26 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 17:11:26 INFO Executor: Starting executor ID driver on host localhost
16/03/16 17:11:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54494.
16/03/16 17:11:26 INFO NettyBlockTransferService: Server created on 54494
16/03/16 17:11:26 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 17:11:26 INFO BlockManagerMasterEndpoint: Registering block manager localhost:54494 with 523.1 MB RAM, BlockManagerId(driver, localhost, 54494)
16/03/16 17:11:26 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): arrangement
16/03/16 17:11:26 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:11:26 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:11:26 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:11:26 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:11:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 17:11:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 17:11:26 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:11:26 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=548536320
16/03/16 17:11:26 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.1 MB)
16/03/16 17:11:26 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=548536320
16/03/16 17:11:26 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.1 MB)
16/03/16 17:11:26 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:54494 (size: 4.1 KB, free: 523.1 MB)
16/03/16 17:11:26 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 17:11:26 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:11:26 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 17:11:26 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/16 17:11:26 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/16 17:11:26 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 17:11:26 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128486081
16/03/16 17:11:26 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 17:11:26 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-ced741bd-529d-41fa-9f8a-23a33d2696ff/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: set
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: issue
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: planning
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: permission
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: economy
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: composition
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  arrangement  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: agency
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/16 17:11:34 INFO PythonRunner: Times: total = 8221, boot = 479, init = 381, finish = 7361
16/03/16 17:11:34 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/16 17:11:34 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8289 ms on localhost (1/2)
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: bend
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: giant
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: astatine
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: present
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: area
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 17:11:34 INFO PythonRunner: Times: total = 8487, boot = 468, init = 410, finish = 7609
16/03/16 17:11:34 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/16 17:11:34 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.562 s
16/03/16 17:11:34 INFO DAGScheduler: looking for newly runnable stages
16/03/16 17:11:34 INFO DAGScheduler: running: Set()
16/03/16 17:11:34 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 17:11:34 INFO DAGScheduler: failed: Set()
16/03/16 17:11:34 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 17:11:34 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 17:11:34 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=548536320
16/03/16 17:11:34 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8559 ms on localhost (2/2)
16/03/16 17:11:34 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.1 MB)
16/03/16 17:11:34 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 17:11:34 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=548536320
16/03/16 17:11:34 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.1 MB)
16/03/16 17:11:34 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:54494 (size: 3.0 KB, free: 523.1 MB)
16/03/16 17:11:34 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 17:11:34 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:11:34 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 17:11:34 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:11:34 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:11:34 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 17:11:34 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:11:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 17:11:34 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 17:11:34 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:11:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 17:11:34 INFO PythonRunner: Times: total = 34, boot = -91, init = 125, finish = 0
16/03/16 17:11:34 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/16 17:11:34 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 56 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'composition', 'None']
16/03/16 17:11:35 INFO PythonRunner: Times: total = 249, boot = 248, init = 0, finish = 1
16/03/16 17:11:35 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1287 bytes result sent to driver
16/03/16 17:11:35 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.250 s
16/03/16 17:11:35 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.845920 s
16/03/16 17:11:35 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 264 ms on localhost (2/2)
16/03/16 17:11:35 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 17:11:35 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:11:35 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:11:35 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:11:35 INFO DAGScheduler: Parents of final stage: List()
16/03/16 17:11:35 INFO DAGScheduler: Missing parents: List()
16/03/16 17:11:35 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:11:35 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=548536320
16/03/16 17:11:35 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.1 MB)
16/03/16 17:11:35 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=548536320
16/03/16 17:11:35 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.1 MB)
16/03/16 17:11:35 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:54494 (size: 3.3 KB, free: 523.1 MB)
16/03/16 17:11:35 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 17:11:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:11:35 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 17:11:35 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/16 17:11:35 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2368 bytes)
16/03/16 17:11:35 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 17:11:35 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 17:11:35 INFO PythonRunner: Times: total = 62, boot = -110, init = 172, finish = 0
16/03/16 17:11:35 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/16 17:11:35 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 75 ms on localhost (1/2)
16/03/16 17:11:35 INFO PythonRunner: Times: total = 134, boot = 133, init = 0, finish = 1
16/03/16 17:11:35 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1355 bytes result sent to driver
16/03/16 17:11:35 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 144 ms on localhost (2/2)
16/03/16 17:11:35 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 17:11:35 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.129 s
16/03/16 17:11:35 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.156297 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 17:11:35 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 17:11:35 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 17:11:35 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 17:11:35 INFO MemoryStore: MemoryStore cleared
16/03/16 17:11:35 INFO BlockManager: BlockManager stopped
16/03/16 17:11:35 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 17:11:35 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 17:11:35 INFO SparkContext: Successfully stopped SparkContext
16/03/16 17:11:35 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 17:11:35 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 17:11:35 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'composition', u'None']
16/03/16 17:11:36 INFO SparkContext: Running Spark version 1.5.2
16/03/16 17:11:36 INFO SecurityManager: Changing view acls to: root
16/03/16 17:11:36 INFO SecurityManager: Changing modify acls to: root
16/03/16 17:11:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 17:11:36 INFO Slf4jLogger: Slf4jLogger started
16/03/16 17:11:36 INFO Remoting: Starting remoting
16/03/16 17:11:36 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:48224]
16/03/16 17:11:36 INFO Utils: Successfully started service 'sparkDriver' on port 48224.
16/03/16 17:11:36 INFO SparkEnv: Registering MapOutputTracker
16/03/16 17:11:36 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 17:11:36 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-99787ca3-1581-4b20-a093-826c47cc0e34
16/03/16 17:11:36 INFO MemoryStore: MemoryStore started with capacity 523.1 MB
16/03/16 17:11:36 INFO HttpFileServer: HTTP File server directory is /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/httpd-91a98dde-97fc-4e03-91bb-59b9b8d21552
16/03/16 17:11:36 INFO HttpServer: Starting HTTP Server
16/03/16 17:11:36 INFO Utils: Successfully started service 'HTTP file server' on port 46550.
16/03/16 17:11:36 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 17:11:36 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 17:11:36 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 17:11:36 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-bf189af9-bcf1-4003-93cd-5b9204d6fd0a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 17:11:36 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128496549
16/03/16 17:11:36 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 17:11:36 INFO Executor: Starting executor ID driver on host localhost
16/03/16 17:11:36 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59011.
16/03/16 17:11:36 INFO NettyBlockTransferService: Server created on 59011
16/03/16 17:11:36 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 17:11:36 INFO BlockManagerMasterEndpoint: Registering block manager localhost:59011 with 523.1 MB RAM, BlockManagerId(driver, localhost, 59011)
16/03/16 17:11:36 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): parts
16/03/16 17:11:36 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:11:36 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:11:36 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:11:36 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:11:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 17:11:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 17:11:36 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:11:36 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=548536320
16/03/16 17:11:36 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.1 MB)
16/03/16 17:11:36 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=548536320
16/03/16 17:11:36 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.1 MB)
16/03/16 17:11:36 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:59011 (size: 4.1 KB, free: 523.1 MB)
16/03/16 17:11:36 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 17:11:36 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:11:36 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 17:11:36 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/16 17:11:36 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/16 17:11:36 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 17:11:36 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128496549
16/03/16 17:11:36 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 17:11:36 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-bf189af9-bcf1-4003-93cd-5b9204d6fd0a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: set
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: issue
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: planning
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: permission
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: economy
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: composition
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  parts  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: agency
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/16 17:11:45 INFO PythonRunner: Times: total = 8215, boot = 470, init = 392, finish = 7353
16/03/16 17:11:45 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/16 17:11:45 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8526 ms on localhost (1/2)
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: bend
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: giant
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: astatine
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: present
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: area
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 17:11:45 INFO PythonRunner: Times: total = 8452, boot = 463, init = 401, finish = 7588
16/03/16 17:11:45 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/16 17:11:45 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8755 ms on localhost (2/2)
16/03/16 17:11:45 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 17:11:45 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.746 s
16/03/16 17:11:45 INFO DAGScheduler: looking for newly runnable stages
16/03/16 17:11:45 INFO DAGScheduler: running: Set()
16/03/16 17:11:45 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 17:11:45 INFO DAGScheduler: failed: Set()
16/03/16 17:11:45 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 17:11:45 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 17:11:45 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=548536320
16/03/16 17:11:45 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.1 MB)
16/03/16 17:11:45 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=548536320
16/03/16 17:11:45 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.1 MB)
16/03/16 17:11:45 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:59011 (size: 3.0 KB, free: 523.1 MB)
16/03/16 17:11:45 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 17:11:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:11:45 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 17:11:45 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:11:45 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:11:45 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 17:11:45 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:11:45 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 17:11:45 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:11:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 17:11:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
reduceFunction_Parents(): returns= ['None', u'composition', 'None']
16/03/16 17:11:45 INFO PythonRunner: Times: total = 51, boot = -48, init = 99, finish = 0
16/03/16 17:11:45 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1287 bytes result sent to driver
16/03/16 17:11:45 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 79 ms on localhost (1/2)
16/03/16 17:11:45 INFO PythonRunner: Times: total = 200, boot = 199, init = 1, finish = 0
16/03/16 17:11:45 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/16 17:11:45 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.202 s
16/03/16 17:11:45 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.026715 s
16/03/16 17:11:45 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 233 ms on localhost (2/2)
16/03/16 17:11:45 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 17:11:45 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:11:45 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:11:45 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:11:45 INFO DAGScheduler: Parents of final stage: List()
16/03/16 17:11:45 INFO DAGScheduler: Missing parents: List()
16/03/16 17:11:45 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:11:45 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=548536320
16/03/16 17:11:45 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.1 MB)
16/03/16 17:11:45 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=548536320
16/03/16 17:11:45 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.1 MB)
16/03/16 17:11:45 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:59011 (size: 3.3 KB, free: 523.1 MB)
16/03/16 17:11:45 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 17:11:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:11:45 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 17:11:45 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/16 17:11:45 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2368 bytes)
16/03/16 17:11:45 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 17:11:45 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 17:11:45 INFO PythonRunner: Times: total = 137, boot = 137, init = 0, finish = 0
16/03/16 17:11:45 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/16 17:11:45 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 154 ms on localhost (1/2)
16/03/16 17:11:46 INFO PythonRunner: Times: total = 242, boot = 242, init = 0, finish = 0
16/03/16 17:11:46 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1355 bytes result sent to driver
16/03/16 17:11:46 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 258 ms on localhost (2/2)
16/03/16 17:11:46 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 17:11:46 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.260 s
16/03/16 17:11:46 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.272039 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 17:11:46 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 17:11:46 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 17:11:46 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 17:11:46 INFO MemoryStore: MemoryStore cleared
16/03/16 17:11:46 INFO BlockManager: BlockManager stopped
16/03/16 17:11:46 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 17:11:46 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 17:11:46 INFO SparkContext: Successfully stopped SparkContext
16/03/16 17:11:46 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 17:11:46 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 17:11:46 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'composition', u'None']
16/03/16 17:11:47 INFO SparkContext: Running Spark version 1.5.2
16/03/16 17:11:47 INFO SecurityManager: Changing view acls to: root
16/03/16 17:11:47 INFO SecurityManager: Changing modify acls to: root
16/03/16 17:11:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 17:11:47 INFO Slf4jLogger: Slf4jLogger started
16/03/16 17:11:47 INFO Remoting: Starting remoting
16/03/16 17:11:47 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:56684]
16/03/16 17:11:47 INFO Utils: Successfully started service 'sparkDriver' on port 56684.
16/03/16 17:11:47 INFO SparkEnv: Registering MapOutputTracker
16/03/16 17:11:47 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 17:11:47 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-87e6c46d-dccd-49fc-9d89-2acec4d6c429
16/03/16 17:11:47 INFO MemoryStore: MemoryStore started with capacity 517.0 MB
16/03/16 17:11:47 INFO HttpFileServer: HTTP File server directory is /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/httpd-66fc98ee-5243-4703-9924-4a22747dacbb
16/03/16 17:11:47 INFO HttpServer: Starting HTTP Server
16/03/16 17:11:47 INFO Utils: Successfully started service 'HTTP file server' on port 56093.
16/03/16 17:11:47 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 17:11:47 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 17:11:47 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 17:11:47 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-4de8a5c4-3c7c-4faf-ab1c-5a8770ffc96c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 17:11:47 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128507399
16/03/16 17:11:47 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 17:11:47 INFO Executor: Starting executor ID driver on host localhost
16/03/16 17:11:47 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55331.
16/03/16 17:11:47 INFO NettyBlockTransferService: Server created on 55331
16/03/16 17:11:47 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 17:11:47 INFO BlockManagerMasterEndpoint: Registering block manager localhost:55331 with 517.0 MB RAM, BlockManagerId(driver, localhost, 55331)
16/03/16 17:11:47 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): speech
16/03/16 17:11:47 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:11:47 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:11:47 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:11:47 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:11:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 17:11:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 17:11:47 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:11:47 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=542166220
16/03/16 17:11:47 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 517.0 MB)
16/03/16 17:11:47 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=542166220
16/03/16 17:11:47 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 517.0 MB)
16/03/16 17:11:47 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:55331 (size: 4.1 KB, free: 517.0 MB)
16/03/16 17:11:47 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 17:11:47 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:11:47 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 17:11:47 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/16 17:11:47 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/16 17:11:47 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 17:11:47 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128507399
16/03/16 17:11:47 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-4de8a5c4-3c7c-4faf-ab1c-5a8770ffc96c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 17:11:47 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: set
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: issue
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: planning
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: permission
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: economy
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: composition
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: agency
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 17:11:55 INFO PythonRunner: Times: total = 8165, boot = 466, init = 384, finish = 7315
16/03/16 17:11:55 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/16 17:11:55 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8240 ms on localhost (1/2)
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: bend
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: giant
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: astatine
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: present
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  speech  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: area
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/16 17:11:56 INFO PythonRunner: Times: total = 8505, boot = 460, init = 414, finish = 7631
16/03/16 17:11:56 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/16 17:11:56 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.574 s
16/03/16 17:11:56 INFO DAGScheduler: looking for newly runnable stages
16/03/16 17:11:56 INFO DAGScheduler: running: Set()
16/03/16 17:11:56 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 17:11:56 INFO DAGScheduler: failed: Set()
16/03/16 17:11:56 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 17:11:56 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 17:11:56 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=542166220
16/03/16 17:11:56 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 517.0 MB)
16/03/16 17:11:56 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=542166220
16/03/16 17:11:56 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 517.0 MB)
16/03/16 17:11:56 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8571 ms on localhost (2/2)
16/03/16 17:11:56 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 17:11:56 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:55331 (size: 3.0 KB, free: 517.0 MB)
16/03/16 17:11:56 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 17:11:56 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:11:56 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 17:11:56 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:11:56 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:11:56 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 17:11:56 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 17:11:56 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:11:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 17:11:56 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:11:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 17:11:56 INFO PythonRunner: Times: total = 21, boot = -165, init = 185, finish = 1
16/03/16 17:11:56 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/16 17:11:56 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 72 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'present']
16/03/16 17:11:56 INFO PythonRunner: Times: total = 252, boot = 251, init = 0, finish = 1
16/03/16 17:11:56 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/16 17:11:56 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.264 s
16/03/16 17:11:56 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.866577 s
16/03/16 17:11:56 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 263 ms on localhost (2/2)
16/03/16 17:11:56 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 17:11:56 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:11:56 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:11:56 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:11:56 INFO DAGScheduler: Parents of final stage: List()
16/03/16 17:11:56 INFO DAGScheduler: Missing parents: List()
16/03/16 17:11:56 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:11:56 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=542166220
16/03/16 17:11:56 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 517.0 MB)
16/03/16 17:11:56 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=542166220
16/03/16 17:11:56 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 517.0 MB)
16/03/16 17:11:56 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:55331 (size: 3.3 KB, free: 517.0 MB)
16/03/16 17:11:56 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 17:11:56 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:11:56 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 17:11:56 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/16 17:11:56 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/16 17:11:56 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 17:11:56 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 17:11:56 INFO PythonRunner: Times: total = 81, boot = -155, init = 236, finish = 0
16/03/16 17:11:56 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1351 bytes result sent to driver
16/03/16 17:11:56 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 96 ms on localhost (1/2)
16/03/16 17:11:56 INFO PythonRunner: Times: total = 138, boot = 138, init = 0, finish = 0
16/03/16 17:11:56 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/16 17:11:56 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 145 ms on localhost (2/2)
16/03/16 17:11:56 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 17:11:56 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.146 s
16/03/16 17:11:56 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.157898 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 17:11:56 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 17:11:56 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 17:11:56 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 17:11:56 INFO MemoryStore: MemoryStore cleared
16/03/16 17:11:56 INFO BlockManager: BlockManager stopped
16/03/16 17:11:56 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 17:11:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 17:11:56 INFO SparkContext: Successfully stopped SparkContext
16/03/16 17:11:56 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 17:11:56 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 17:11:56 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'present']
16/03/16 17:11:57 INFO SparkContext: Running Spark version 1.5.2
16/03/16 17:11:57 INFO SecurityManager: Changing view acls to: root
16/03/16 17:11:57 INFO SecurityManager: Changing modify acls to: root
16/03/16 17:11:57 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 17:11:57 INFO Slf4jLogger: Slf4jLogger started
16/03/16 17:11:57 INFO Remoting: Starting remoting
16/03/16 17:11:57 INFO Utils: Successfully started service 'sparkDriver' on port 47469.
16/03/16 17:11:57 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:47469]
16/03/16 17:11:57 INFO SparkEnv: Registering MapOutputTracker
16/03/16 17:11:57 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 17:11:57 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-6236eb06-cdf2-4b50-9545-9f6e715601ff
16/03/16 17:11:57 INFO MemoryStore: MemoryStore started with capacity 517.0 MB
16/03/16 17:11:57 INFO HttpFileServer: HTTP File server directory is /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/httpd-c8541f7c-38c6-473c-9cf5-6702dca601ed
16/03/16 17:11:57 INFO HttpServer: Starting HTTP Server
16/03/16 17:11:57 INFO Utils: Successfully started service 'HTTP file server' on port 36011.
16/03/16 17:11:57 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 17:11:57 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 17:11:57 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 17:11:57 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-89970ac9-fb80-44fa-bb62-f1319536509c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 17:11:57 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128517969
16/03/16 17:11:57 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 17:11:57 INFO Executor: Starting executor ID driver on host localhost
16/03/16 17:11:58 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60789.
16/03/16 17:11:58 INFO NettyBlockTransferService: Server created on 60789
16/03/16 17:11:58 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 17:11:58 INFO BlockManagerMasterEndpoint: Registering block manager localhost:60789 with 517.0 MB RAM, BlockManagerId(driver, localhost, 60789)
16/03/16 17:11:58 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): geographical
16/03/16 17:11:58 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:11:58 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:11:58 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:11:58 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:11:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 17:11:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 17:11:58 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:11:58 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=542166220
16/03/16 17:11:58 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 517.0 MB)
16/03/16 17:11:58 INFO MemoryStore: ensureFreeSpace(4150) called with curMem=6568, maxMem=542166220
16/03/16 17:11:58 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 517.0 MB)
16/03/16 17:11:58 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:60789 (size: 4.1 KB, free: 517.0 MB)
16/03/16 17:11:58 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 17:11:58 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:11:58 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 17:11:58 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/16 17:11:58 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/16 17:11:58 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 17:11:58 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128517969
16/03/16 17:11:58 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 17:11:58 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-89970ac9-fb80-44fa-bb62-f1319536509c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: area



mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: bend
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: giant
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: astatine
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: present
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: area
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  geographical  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/16 17:12:06 INFO PythonRunner: Times: total = 8314, boot = 460, init = 379, finish = 7475
16/03/16 17:12:06 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/16 17:12:06 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8377 ms on localhost (1/2)
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  geographical  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: issue
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: planning
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: permission
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: economy
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: composition
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: agency
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/16 17:12:06 INFO PythonRunner: Times: total = 8591, boot = 454, init = 432, finish = 7705
16/03/16 17:12:06 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/16 17:12:06 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.672 s
16/03/16 17:12:06 INFO DAGScheduler: looking for newly runnable stages
16/03/16 17:12:06 INFO DAGScheduler: running: Set()
16/03/16 17:12:06 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 17:12:06 INFO DAGScheduler: failed: Set()
16/03/16 17:12:06 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 17:12:06 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 17:12:06 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10718, maxMem=542166220
16/03/16 17:12:06 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 517.0 MB)
16/03/16 17:12:06 INFO MemoryStore: ensureFreeSpace(3059) called with curMem=15702, maxMem=542166220
16/03/16 17:12:06 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 517.0 MB)
16/03/16 17:12:06 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8670 ms on localhost (2/2)
16/03/16 17:12:06 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 17:12:06 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:60789 (size: 3.0 KB, free: 517.0 MB)
16/03/16 17:12:06 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 17:12:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:12:06 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 17:12:06 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:12:06 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:12:06 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 17:12:06 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:12:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 17:12:06 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 17:12:06 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:12:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
reduceFunction_Parents(): returns= [u'area', 'None', u'area']
16/03/16 17:12:06 INFO PythonRunner: Times: total = 29, boot = -119, init = 147, finish = 1
16/03/16 17:12:06 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/16 17:12:06 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 97 ms on localhost (1/2)
16/03/16 17:12:07 INFO PythonRunner: Times: total = 251, boot = 250, init = 1, finish = 0
16/03/16 17:12:07 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/16 17:12:07 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.275 s
16/03/16 17:12:07 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.968439 s
16/03/16 17:12:07 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 274 ms on localhost (2/2)
16/03/16 17:12:07 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 17:12:07 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:12:07 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:12:07 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:12:07 INFO DAGScheduler: Parents of final stage: List()
16/03/16 17:12:07 INFO DAGScheduler: Missing parents: List()
16/03/16 17:12:07 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:12:07 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18761, maxMem=542166220
16/03/16 17:12:07 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 517.0 MB)
16/03/16 17:12:07 INFO MemoryStore: ensureFreeSpace(3377) called with curMem=24577, maxMem=542166220
16/03/16 17:12:07 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 517.0 MB)
16/03/16 17:12:07 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:60789 (size: 3.3 KB, free: 517.0 MB)
16/03/16 17:12:07 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 17:12:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:12:07 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 17:12:07 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/16 17:12:07 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/16 17:12:07 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 17:12:07 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 17:12:07 INFO PythonRunner: Times: total = 53, boot = -41, init = 94, finish = 0
16/03/16 17:12:07 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/03/16 17:12:07 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 62 ms on localhost (1/2)
16/03/16 17:12:07 INFO PythonRunner: Times: total = 106, boot = 105, init = 1, finish = 0
16/03/16 17:12:07 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/16 17:12:07 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 117 ms on localhost (2/2)
16/03/16 17:12:07 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 17:12:07 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.099 s
16/03/16 17:12:07 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.137958 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 17:12:07 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 17:12:07 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 17:12:07 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 17:12:07 INFO MemoryStore: MemoryStore cleared
16/03/16 17:12:07 INFO BlockManager: BlockManager stopped
16/03/16 17:12:07 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 17:12:07 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 17:12:07 INFO SparkContext: Successfully stopped SparkContext
16/03/16 17:12:07 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 17:12:07 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'area', u'None', u'area']
16/03/16 17:12:08 INFO SparkContext: Running Spark version 1.5.2
16/03/16 17:12:08 INFO SecurityManager: Changing view acls to: root
16/03/16 17:12:08 INFO SecurityManager: Changing modify acls to: root
16/03/16 17:12:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 17:12:08 INFO Slf4jLogger: Slf4jLogger started
16/03/16 17:12:08 INFO Remoting: Starting remoting
16/03/16 17:12:08 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:51964]
16/03/16 17:12:08 INFO Utils: Successfully started service 'sparkDriver' on port 51964.
16/03/16 17:12:08 INFO SparkEnv: Registering MapOutputTracker
16/03/16 17:12:08 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 17:12:08 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1e606556-62de-484e-a37b-fa8f017e147d
16/03/16 17:12:08 INFO MemoryStore: MemoryStore started with capacity 517.0 MB
16/03/16 17:12:08 INFO HttpFileServer: HTTP File server directory is /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/httpd-c975f609-8b0b-4efa-a8c8-134db9600209
16/03/16 17:12:08 INFO HttpServer: Starting HTTP Server
16/03/16 17:12:08 INFO Utils: Successfully started service 'HTTP file server' on port 32992.
16/03/16 17:12:08 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 17:12:08 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 17:12:08 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 17:12:08 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-31896941-67cb-4b95-92e8-4e0f3b714e36/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 17:12:08 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128528607
16/03/16 17:12:08 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 17:12:08 INFO Executor: Starting executor ID driver on host localhost
16/03/16 17:12:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 32868.
16/03/16 17:12:08 INFO NettyBlockTransferService: Server created on 32868
16/03/16 17:12:08 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 17:12:08 INFO BlockManagerMasterEndpoint: Registering block manager localhost:32868 with 517.0 MB RAM, BlockManagerId(driver, localhost, 32868)
16/03/16 17:12:08 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): spatial
16/03/16 17:12:09 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:12:09 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:12:09 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:12:09 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:12:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 17:12:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 17:12:09 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:12:09 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=542166220
16/03/16 17:12:09 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 517.0 MB)
16/03/16 17:12:09 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=542166220
16/03/16 17:12:09 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 517.0 MB)
16/03/16 17:12:09 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:32868 (size: 4.1 KB, free: 517.0 MB)
16/03/16 17:12:09 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 17:12:09 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:12:09 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 17:12:09 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/16 17:12:09 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/16 17:12:09 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 17:12:09 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128528607
16/03/16 17:12:09 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 17:12:09 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-31896941-67cb-4b95-92e8-4e0f3b714e36/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: set
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: bend
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: giant
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: astatine
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: present
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: area
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: issue
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: planning
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: permission
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns=16/03/16 17:12:20 INFO PythonRunner: Times: total = 10896, boot = 587, init = 454, finish = 9855
16/03/16 17:12:20 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
 ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: economy
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None16/03/16 17:12:20 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 11027 ms on localhost (1/2)
']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: composition
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  spatial  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: agency
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/16 17:12:20 INFO PythonRunner: Times: total = 11051, boot = 587, init = 394, finish = 10070
16/03/16 17:12:20 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/16 17:12:20 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 11.219 s
16/03/16 17:12:20 INFO DAGScheduler: looking for newly runnable stages
16/03/16 17:12:20 INFO DAGScheduler: running: Set()
16/03/16 17:12:20 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 17:12:20 INFO DAGScheduler: failed: Set()
16/03/16 17:12:20 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 17:12:20 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 17:12:20 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=542166220
16/03/16 17:12:20 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 517.0 MB)
16/03/16 17:12:20 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=542166220
16/03/16 17:12:20 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 517.0 MB)
16/03/16 17:12:20 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 11213 ms on localhost (2/2)
16/03/16 17:12:20 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 17:12:20 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:32868 (size: 3.0 KB, free: 517.0 MB)
16/03/16 17:12:20 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 17:12:20 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:12:20 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 17:12:20 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:12:20 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:12:20 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 17:12:20 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 17:12:20 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:12:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/03/16 17:12:20 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:12:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
16/03/16 17:12:20 INFO PythonRunner: Times: total = 202, boot = 201, init = 1, finish = 0
16/03/16 17:12:20 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/16 17:12:20 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 220 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'composition', 'None']
16/03/16 17:12:20 INFO PythonRunner: Times: total = 492, boot = 489, init = 0, finish = 3
16/03/16 17:12:20 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1287 bytes result sent to driver
16/03/16 17:12:20 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 521 ms on localhost (2/2)
16/03/16 17:12:20 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.521 s
16/03/16 17:12:20 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 11.768820 s
16/03/16 17:12:20 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 17:12:20 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:12:20 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:12:20 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:12:20 INFO DAGScheduler: Parents of final stage: List()
16/03/16 17:12:20 INFO DAGScheduler: Missing parents: List()
16/03/16 17:12:20 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:12:20 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=542166220
16/03/16 17:12:20 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 517.0 MB)
16/03/16 17:12:20 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=542166220
16/03/16 17:12:20 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 517.0 MB)
16/03/16 17:12:20 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:32868 (size: 3.3 KB, free: 517.0 MB)
16/03/16 17:12:20 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 17:12:20 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:12:20 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 17:12:20 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/16 17:12:20 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2368 bytes)
16/03/16 17:12:20 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 17:12:20 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 17:12:20 INFO PythonRunner: Times: total = 71, boot = -163, init = 234, finish = 0
16/03/16 17:12:20 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/16 17:12:20 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 102 ms on localhost (1/2)
16/03/16 17:12:21 INFO PythonRunner: Times: total = 367, boot = 367, init = 0, finish = 0
16/03/16 17:12:21 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1355 bytes result sent to driver
16/03/16 17:12:21 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 376 ms on localhost (2/2)
16/03/16 17:12:21 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 17:12:21 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.378 s
16/03/16 17:12:21 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.394236 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 17:12:21 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 17:12:21 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 17:12:21 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 17:12:21 INFO MemoryStore: MemoryStore cleared
16/03/16 17:12:21 INFO BlockManager: BlockManager stopped
16/03/16 17:12:21 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 17:12:21 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 17:12:21 INFO SparkContext: Successfully stopped SparkContext
16/03/16 17:12:21 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'composition', u'None']
16/03/16 17:12:22 INFO SparkContext: Running Spark version 1.5.2
16/03/16 17:12:22 INFO SecurityManager: Changing view acls to: root
16/03/16 17:12:22 INFO SecurityManager: Changing modify acls to: root
16/03/16 17:12:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 17:12:22 INFO Slf4jLogger: Slf4jLogger started
16/03/16 17:12:22 INFO Remoting: Starting remoting
16/03/16 17:12:22 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:53959]
16/03/16 17:12:22 INFO Utils: Successfully started service 'sparkDriver' on port 53959.
16/03/16 17:12:22 INFO SparkEnv: Registering MapOutputTracker
16/03/16 17:12:22 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 17:12:22 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3570fca7-4c0c-45d6-9b95-7b3307b27aa8
16/03/16 17:12:22 INFO MemoryStore: MemoryStore started with capacity 522.6 MB
16/03/16 17:12:22 INFO HttpFileServer: HTTP File server directory is /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/httpd-ad5a90d7-f7c4-454e-8547-591102238b6b
16/03/16 17:12:22 INFO HttpServer: Starting HTTP Server
16/03/16 17:12:22 INFO Utils: Successfully started service 'HTTP file server' on port 43234.
16/03/16 17:12:22 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 17:12:22 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 17:12:22 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 17:12:22 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-185c98b8-ed9f-4280-872e-40a9788b9dfe/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 17:12:22 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128542716
16/03/16 17:12:22 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 17:12:22 INFO Executor: Starting executor ID driver on host localhost
16/03/16 17:12:22 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42224.
16/03/16 17:12:22 INFO NettyBlockTransferService: Server created on 42224
16/03/16 17:12:22 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 17:12:22 INFO BlockManagerMasterEndpoint: Registering block manager localhost:42224 with 522.6 MB RAM, BlockManagerId(driver, localhost, 42224)
16/03/16 17:12:22 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): Nadu
16/03/16 17:12:22 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:12:22 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:12:22 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:12:22 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:12:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 17:12:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 17:12:22 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:12:22 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=547970088
16/03/16 17:12:22 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 522.6 MB)
16/03/16 17:12:22 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=547970088
16/03/16 17:12:22 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 522.6 MB)
16/03/16 17:12:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:42224 (size: 4.1 KB, free: 522.6 MB)
16/03/16 17:12:22 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 17:12:22 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:12:22 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 17:12:22 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/16 17:12:22 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/16 17:12:22 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 17:12:22 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128542716
16/03/16 17:12:22 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 17:12:22 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-185c98b8-ed9f-4280-872e-40a9788b9dfe/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: set
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: issue
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: planning
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: permission
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: economy
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: composition
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: agency
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Nadu  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/16 17:12:35 INFO PythonRunner: Times: total = 12614, boot = 566, init = 954, finish = 11094
16/03/16 17:12:35 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/16 17:12:35 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 12736 ms on localhost (1/2)
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: bend
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: giant
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: astatine
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: present
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Nadu  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: area
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/16 17:12:36 INFO PythonRunner: Times: total = 13174, boot = 581, init = 949, finish = 11644
16/03/16 17:12:36 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/16 17:12:36 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 13317 ms on localhost (2/2)
16/03/16 17:12:36 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 17:12:36 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 13.305 s
16/03/16 17:12:36 INFO DAGScheduler: looking for newly runnable stages
16/03/16 17:12:36 INFO DAGScheduler: running: Set()
16/03/16 17:12:36 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 17:12:36 INFO DAGScheduler: failed: Set()
16/03/16 17:12:36 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 17:12:36 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 17:12:36 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=547970088
16/03/16 17:12:36 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 522.6 MB)
16/03/16 17:12:36 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=547970088
16/03/16 17:12:36 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 522.6 MB)
16/03/16 17:12:36 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:42224 (size: 3.0 KB, free: 522.6 MB)
16/03/16 17:12:36 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 17:12:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:12:36 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 17:12:36 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:12:36 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:12:36 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 17:12:36 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 17:12:36 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:12:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 17:12:36 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:12:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/16 17:12:36 INFO PythonRunner: Times: total = 56, boot = -280, init = 335, finish = 1
16/03/16 17:12:36 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1297 bytes result sent to driver
reduceFunction_Parents(): returns= ['None', u'Chennai', 'None', u'Chennai']
16/03/16 17:12:36 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 85 ms on localhost (1/2)
16/03/16 17:12:36 INFO PythonRunner: Times: total = 304, boot = 303, init = 1, finish = 0
16/03/16 17:12:36 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/16 17:12:36 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.332 s
16/03/16 17:12:36 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 13.687910 s
16/03/16 17:12:36 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 332 ms on localhost (2/2)
16/03/16 17:12:36 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 17:12:36 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:12:36 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:12:36 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:12:36 INFO DAGScheduler: Parents of final stage: List()
16/03/16 17:12:36 INFO DAGScheduler: Missing parents: List()
16/03/16 17:12:36 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:12:36 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=547970088
16/03/16 17:12:36 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 522.6 MB)
16/03/16 17:12:36 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=547970088
16/03/16 17:12:36 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 522.6 MB)
16/03/16 17:12:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:42224 (size: 3.3 KB, free: 522.6 MB)
16/03/16 17:12:36 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 17:12:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:12:36 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 17:12:36 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/16 17:12:36 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2378 bytes)
16/03/16 17:12:36 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 17:12:36 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 17:12:36 INFO PythonRunner: Times: total = 75, boot = -73, init = 148, finish = 0
16/03/16 17:12:36 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/16 17:12:36 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 88 ms on localhost (1/2)
16/03/16 17:12:36 INFO PythonRunner: Times: total = 152, boot = 151, init = 0, finish = 1
16/03/16 17:12:36 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1365 bytes result sent to driver
16/03/16 17:12:36 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 168 ms on localhost (2/2)
16/03/16 17:12:36 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 17:12:36 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.170 s
16/03/16 17:12:36 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.182172 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 17:12:36 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 17:12:36 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 17:12:37 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 17:12:37 INFO MemoryStore: MemoryStore cleared
16/03/16 17:12:37 INFO BlockManager: BlockManager stopped
16/03/16 17:12:37 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 17:12:37 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 17:12:37 INFO SparkContext: Successfully stopped SparkContext
16/03/16 17:12:37 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 17:12:37 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 17:12:37 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'Chennai', u'None', u'Chennai']
16/03/16 17:12:37 INFO SparkContext: Running Spark version 1.5.2
16/03/16 17:12:37 INFO SecurityManager: Changing view acls to: root
16/03/16 17:12:37 INFO SecurityManager: Changing modify acls to: root
16/03/16 17:12:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 17:12:37 INFO Slf4jLogger: Slf4jLogger started
16/03/16 17:12:37 INFO Remoting: Starting remoting
16/03/16 17:12:38 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:54499]
16/03/16 17:12:38 INFO Utils: Successfully started service 'sparkDriver' on port 54499.
16/03/16 17:12:38 INFO SparkEnv: Registering MapOutputTracker
16/03/16 17:12:38 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 17:12:38 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-037dbbff-c05f-447e-9104-0cb13395306a
16/03/16 17:12:38 INFO MemoryStore: MemoryStore started with capacity 522.6 MB
16/03/16 17:12:38 INFO HttpFileServer: HTTP File server directory is /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/httpd-aed66ea2-45b9-410c-b6c2-2afcc9b4d018
16/03/16 17:12:38 INFO HttpServer: Starting HTTP Server
16/03/16 17:12:38 INFO Utils: Successfully started service 'HTTP file server' on port 46677.
16/03/16 17:12:38 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 17:12:38 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 17:12:38 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 17:12:38 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-0f9f195c-5a23-4e89-9bc4-6ceff2026dbc/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 17:12:38 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128558174
16/03/16 17:12:38 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 17:12:38 INFO Executor: Starting executor ID driver on host localhost
16/03/16 17:12:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53636.
16/03/16 17:12:38 INFO NettyBlockTransferService: Server created on 53636
16/03/16 17:12:38 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 17:12:38 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53636 with 522.6 MB RAM, BlockManagerId(driver, localhost, 53636)
16/03/16 17:12:38 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): circular
16/03/16 17:12:38 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:12:38 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:12:38 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:12:38 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:12:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 17:12:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 17:12:38 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:12:38 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=547970088
16/03/16 17:12:38 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 522.6 MB)
16/03/16 17:12:38 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=547970088
16/03/16 17:12:38 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 522.6 MB)
16/03/16 17:12:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53636 (size: 4.1 KB, free: 522.6 MB)
16/03/16 17:12:38 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 17:12:38 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:12:38 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 17:12:38 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/16 17:12:38 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/16 17:12:38 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 17:12:38 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128558174
16/03/16 17:12:38 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 17:12:38 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-0f9f195c-5a23-4e89-9bc4-6ceff2026dbc/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: set
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: bend
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): adding to parents: syn =  Synset('bend.n.01') ; keyword:  circular  in syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= [u'bend']
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: giant
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: astatine
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: present
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: area
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: issue
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: planning
16/03/16 17:12:47 INFO PythonRunner: Times: total = 8771, boot = 498, init = 424, finish = 7849
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular16/03/16 17:12:47 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
 ; prevleveltokens: permission
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: economy
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: composition
16/03/16 17:12:47 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8875 ms on localhost (1/2)
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: agency
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 17:12:47 INFO PythonRunner: Times: total = 8856, boot = 484, init = 437, finish = 7935
16/03/16 17:12:47 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/16 17:12:47 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.966 s
16/03/16 17:12:47 INFO DAGScheduler: looking for newly runnable stages
16/03/16 17:12:47 INFO DAGScheduler: running: Set()
16/03/16 17:12:47 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 17:12:47 INFO DAGScheduler: failed: Set()
16/03/16 17:12:47 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 17:12:47 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 17:12:47 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8963 ms on localhost (2/2)
16/03/16 17:12:47 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 17:12:47 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=547970088
16/03/16 17:12:47 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 522.6 MB)
16/03/16 17:12:47 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=547970088
16/03/16 17:12:47 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 522.6 MB)
16/03/16 17:12:47 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53636 (size: 3.0 KB, free: 522.6 MB)
16/03/16 17:12:47 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 17:12:47 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:12:47 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 17:12:47 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:12:47 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:12:47 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 17:12:47 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 17:12:47 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:12:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
16/03/16 17:12:47 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:12:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
reduceFunction_Parents(): returns= ['None', u'bend']
16/03/16 17:12:47 INFO PythonRunner: Times: total = 221, boot = 219, init = 1, finish = 1
16/03/16 17:12:47 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1272 bytes result sent to driver
16/03/16 17:12:47 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 242 ms on localhost (1/2)
16/03/16 17:12:47 INFO PythonRunner: Times: total = 441, boot = 440, init = 0, finish = 1
16/03/16 17:12:47 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/16 17:12:47 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.472 s
16/03/16 17:12:47 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.478489 s
16/03/16 17:12:47 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 472 ms on localhost (2/2)
16/03/16 17:12:47 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 17:12:47 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:12:47 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:12:47 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:12:47 INFO DAGScheduler: Parents of final stage: List()
16/03/16 17:12:47 INFO DAGScheduler: Missing parents: List()
16/03/16 17:12:47 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:12:47 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=547970088
16/03/16 17:12:47 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 522.6 MB)
16/03/16 17:12:47 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=547970088
16/03/16 17:12:47 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 522.6 MB)
16/03/16 17:12:47 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53636 (size: 3.3 KB, free: 522.6 MB)
16/03/16 17:12:47 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 17:12:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:12:48 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 17:12:48 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/16 17:12:48 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2353 bytes)
16/03/16 17:12:48 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 17:12:48 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 17:12:48 INFO PythonRunner: Times: total = 24, boot = -167, init = 191, finish = 0
16/03/16 17:12:48 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1337 bytes result sent to driver
16/03/16 17:12:48 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 48 ms on localhost (1/2)
16/03/16 17:12:48 INFO PythonRunner: Times: total = 184, boot = 183, init = 0, finish = 1
16/03/16 17:12:48 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/16 17:12:48 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 191 ms on localhost (2/2)
16/03/16 17:12:48 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 17:12:48 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.192 s
16/03/16 17:12:48 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.213492 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 17:12:48 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 17:12:48 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 17:12:48 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 17:12:48 INFO MemoryStore: MemoryStore cleared
16/03/16 17:12:48 INFO BlockManager: BlockManager stopped
16/03/16 17:12:48 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 17:12:48 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 17:12:48 INFO SparkContext: Successfully stopped SparkContext
16/03/16 17:12:48 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 17:12:48 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'bend']
16/03/16 17:12:49 INFO SparkContext: Running Spark version 1.5.2
16/03/16 17:12:49 INFO SecurityManager: Changing view acls to: root
16/03/16 17:12:49 INFO SecurityManager: Changing modify acls to: root
16/03/16 17:12:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 17:12:49 INFO Slf4jLogger: Slf4jLogger started
16/03/16 17:12:49 INFO Remoting: Starting remoting
16/03/16 17:12:49 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:42476]
16/03/16 17:12:49 INFO Utils: Successfully started service 'sparkDriver' on port 42476.
16/03/16 17:12:49 INFO SparkEnv: Registering MapOutputTracker
16/03/16 17:12:49 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 17:12:49 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1869a7f0-f974-41c3-bf50-c421e13e6423
16/03/16 17:12:49 INFO MemoryStore: MemoryStore started with capacity 522.9 MB
16/03/16 17:12:49 INFO HttpFileServer: HTTP File server directory is /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/httpd-df2b0aac-67e5-4a0a-98bc-133068289b5e
16/03/16 17:12:49 INFO HttpServer: Starting HTTP Server
16/03/16 17:12:49 INFO Utils: Successfully started service 'HTTP file server' on port 53116.
16/03/16 17:12:49 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 17:12:49 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 17:12:49 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 17:12:49 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-677b6e58-e890-4742-9880-221f6cf60120/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 17:12:49 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128569737
16/03/16 17:12:49 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 17:12:49 INFO Executor: Starting executor ID driver on host localhost
16/03/16 17:12:49 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40256.
16/03/16 17:12:49 INFO NettyBlockTransferService: Server created on 40256
16/03/16 17:12:49 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 17:12:49 INFO BlockManagerMasterEndpoint: Registering block manager localhost:40256 with 522.9 MB RAM, BlockManagerId(driver, localhost, 40256)
16/03/16 17:12:49 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): product
16/03/16 17:12:49 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:12:49 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:12:49 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:12:49 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:12:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 17:12:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 17:12:49 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:12:49 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=548253204
16/03/16 17:12:49 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 522.8 MB)
16/03/16 17:12:49 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=548253204
16/03/16 17:12:49 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 522.8 MB)
16/03/16 17:12:49 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:40256 (size: 4.1 KB, free: 522.9 MB)
16/03/16 17:12:49 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 17:12:49 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:12:49 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 17:12:49 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/16 17:12:49 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/16 17:12:49 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 17:12:49 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128569737
16/03/16 17:12:49 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 17:12:49 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-677b6e58-e890-4742-9880-221f6cf60120/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: set
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: issue
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: planning
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: permission
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: economy
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: composition
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: agency
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: bend
16/03/16 17:12:59 INFO PythonRunner: Times: total = 9874, boot = 506, init = 393, finish = 8975
16/03/16 17:12:59 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/16 17:12:59 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9941 ms on localhost (1/2)
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: giant
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: astatine
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  product  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: present
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: area
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/16 17:12:59 INFO PythonRunner: Times: total = 10019, boot = 498, init = 448, finish = 9073
16/03/16 17:12:59 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/16 17:12:59 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 10081 ms on localhost (2/2)
16/03/16 17:12:59 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 17:12:59 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 10.083 s
16/03/16 17:12:59 INFO DAGScheduler: looking for newly runnable stages
16/03/16 17:12:59 INFO DAGScheduler: running: Set()
16/03/16 17:12:59 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 17:12:59 INFO DAGScheduler: failed: Set()
16/03/16 17:12:59 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 17:12:59 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 17:12:59 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=548253204
16/03/16 17:12:59 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 522.8 MB)
16/03/16 17:12:59 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=548253204
16/03/16 17:12:59 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 522.8 MB)
16/03/16 17:12:59 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:40256 (size: 3.0 KB, free: 522.8 MB)
16/03/16 17:12:59 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 17:12:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:12:59 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 17:12:59 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:12:59 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:12:59 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 17:12:59 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 17:12:59 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:12:59 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:12:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 17:12:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 17:13:00 INFO PythonRunner: Times: total = 134, boot = 133, init = 1, finish = 0
16/03/16 17:13:00 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/16 17:13:00 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 156 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/03/16 17:13:00 INFO PythonRunner: Times: total = 236, boot = 234, init = 0, finish = 2
16/03/16 17:13:00 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/03/16 17:13:00 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 252 ms on localhost (2/2)
16/03/16 17:13:00 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 17:13:00 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.252 s
16/03/16 17:13:00 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 10.374353 s
16/03/16 17:13:00 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:13:00 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:13:00 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:13:00 INFO DAGScheduler: Parents of final stage: List()
16/03/16 17:13:00 INFO DAGScheduler: Missing parents: List()
16/03/16 17:13:00 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:13:00 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=548253204
16/03/16 17:13:00 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 522.8 MB)
16/03/16 17:13:00 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=548253204
16/03/16 17:13:00 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 522.8 MB)
16/03/16 17:13:00 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:40256 (size: 3.3 KB, free: 522.8 MB)
16/03/16 17:13:00 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 17:13:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:13:00 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 17:13:00 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/16 17:13:00 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/03/16 17:13:00 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 17:13:00 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 17:13:00 INFO PythonRunner: Times: total = 20, boot = 19, init = 1, finish = 0
16/03/16 17:13:00 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/16 17:13:00 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 77 ms on localhost (1/2)
16/03/16 17:13:00 INFO PythonRunner: Times: total = 160, boot = 160, init = 0, finish = 0
16/03/16 17:13:00 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/03/16 17:13:00 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 171 ms on localhost (2/2)
16/03/16 17:13:00 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.159 s
16/03/16 17:13:00 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 17:13:00 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.186553 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 17:13:00 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 17:13:00 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 17:13:00 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 17:13:00 INFO MemoryStore: MemoryStore cleared
16/03/16 17:13:00 INFO BlockManager: BlockManager stopped
16/03/16 17:13:00 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 17:13:00 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 17:13:00 INFO SparkContext: Successfully stopped SparkContext
16/03/16 17:13:00 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 17:13:00 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 17:13:00 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'astatine']
16/03/16 17:13:01 INFO SparkContext: Running Spark version 1.5.2
16/03/16 17:13:01 INFO SecurityManager: Changing view acls to: root
16/03/16 17:13:01 INFO SecurityManager: Changing modify acls to: root
16/03/16 17:13:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 17:13:01 INFO Slf4jLogger: Slf4jLogger started
16/03/16 17:13:01 INFO Remoting: Starting remoting
16/03/16 17:13:01 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:38331]
16/03/16 17:13:01 INFO Utils: Successfully started service 'sparkDriver' on port 38331.
16/03/16 17:13:01 INFO SparkEnv: Registering MapOutputTracker
16/03/16 17:13:01 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 17:13:01 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-314e34b8-090c-4582-9286-5b7ad81684e1
16/03/16 17:13:01 INFO MemoryStore: MemoryStore started with capacity 522.9 MB
16/03/16 17:13:01 INFO HttpFileServer: HTTP File server directory is /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/httpd-cc73abc1-1050-4e56-82aa-748f3fdef113
16/03/16 17:13:01 INFO HttpServer: Starting HTTP Server
16/03/16 17:13:01 INFO Utils: Successfully started service 'HTTP file server' on port 51831.
16/03/16 17:13:01 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 17:13:01 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 17:13:01 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 17:13:01 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-a7282831-a175-4444-b6cf-6967fd7a6e61/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 17:13:01 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128581895
16/03/16 17:13:01 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 17:13:01 INFO Executor: Starting executor ID driver on host localhost
16/03/16 17:13:01 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55409.
16/03/16 17:13:01 INFO NettyBlockTransferService: Server created on 55409
16/03/16 17:13:01 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 17:13:01 INFO BlockManagerMasterEndpoint: Registering block manager localhost:55409 with 522.9 MB RAM, BlockManagerId(driver, localhost, 55409)
16/03/16 17:13:01 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): used
16/03/16 17:13:02 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:13:02 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:13:02 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:13:02 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:13:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 17:13:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 17:13:02 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:13:02 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=548253204
16/03/16 17:13:02 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 522.8 MB)
16/03/16 17:13:02 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=548253204
16/03/16 17:13:02 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 522.8 MB)
16/03/16 17:13:02 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:55409 (size: 4.1 KB, free: 522.9 MB)
16/03/16 17:13:02 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 17:13:02 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:13:02 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 17:13:02 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/16 17:13:02 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/16 17:13:02 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 17:13:02 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128581895
16/03/16 17:13:02 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 17:13:02 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-a7282831-a175-4444-b6cf-6967fd7a6e61/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: set
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  Synset('set.n.01') ; keyword:  used  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: bend
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: giant
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: astatine
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: present
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: area
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
16/03/16 17:13:11 INFO PythonRunner: Times: total = 8938, boot = 456, init = 434, finish = 8048
16/03/16 17:13:11 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/16 17:13:11 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9024 ms on localhost (1/2)
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: issue
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: planning
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: permission
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: economy
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: composition
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: agency
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 17:13:11 INFO PythonRunner: Times: total = 9294, boot = 462, init = 403, finish = 8429
16/03/16 17:13:11 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/16 17:13:11 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.358 s
16/03/16 17:13:11 INFO DAGScheduler: looking for newly runnable stages
16/03/16 17:13:11 INFO DAGScheduler: running: Set()
16/03/16 17:13:11 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 17:13:11 INFO DAGScheduler: failed: Set()
16/03/16 17:13:11 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 17:13:11 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 17:13:11 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=548253204
16/03/16 17:13:11 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 522.8 MB)
16/03/16 17:13:11 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=548253204
16/03/16 17:13:11 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 522.8 MB)
16/03/16 17:13:11 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:55409 (size: 3.0 KB, free: 522.8 MB)
16/03/16 17:13:11 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 17:13:11 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:13:11 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 17:13:11 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9371 ms on localhost (2/2)
16/03/16 17:13:11 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 17:13:11 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:13:11 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:13:11 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 17:13:11 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:13:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 17:13:11 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 17:13:11 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:13:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
reduceFunction_Parents(): returns= ['None', u'set']
16/03/16 17:13:11 INFO PythonRunner: Times: total = 29, boot = -171, init = 200, finish = 0
16/03/16 17:13:11 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1271 bytes result sent to driver
16/03/16 17:13:11 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 70 ms on localhost (1/2)
16/03/16 17:13:11 INFO PythonRunner: Times: total = 320, boot = 319, init = 0, finish = 1
16/03/16 17:13:11 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/16 17:13:11 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 345 ms on localhost (2/2)
16/03/16 17:13:11 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 17:13:11 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.335 s
16/03/16 17:13:11 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.740307 s
16/03/16 17:13:11 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:13:11 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:13:11 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:13:11 INFO DAGScheduler: Parents of final stage: List()
16/03/16 17:13:11 INFO DAGScheduler: Missing parents: List()
16/03/16 17:13:11 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:13:11 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=548253204
16/03/16 17:13:11 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 522.8 MB)
16/03/16 17:13:11 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=548253204
16/03/16 17:13:11 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 522.8 MB)
16/03/16 17:13:11 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:55409 (size: 3.3 KB, free: 522.8 MB)
16/03/16 17:13:11 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 17:13:11 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:13:11 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 17:13:11 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/16 17:13:11 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 17:13:11 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 17:13:11 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 17:13:12 INFO PythonRunner: Times: total = 102, boot = -193, init = 295, finish = 0
16/03/16 17:13:12 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/16 17:13:12 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 118 ms on localhost (1/2)
16/03/16 17:13:12 INFO PythonRunner: Times: total = 238, boot = 235, init = 3, finish = 0
16/03/16 17:13:12 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1336 bytes result sent to driver
16/03/16 17:13:12 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 255 ms on localhost (2/2)
16/03/16 17:13:12 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 17:13:12 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.235 s
16/03/16 17:13:12 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.279505 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 17:13:12 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 17:13:12 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 17:13:12 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 17:13:12 INFO MemoryStore: MemoryStore cleared
16/03/16 17:13:12 INFO BlockManager: BlockManager stopped
16/03/16 17:13:12 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 17:13:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 17:13:12 INFO SparkContext: Successfully stopped SparkContext
16/03/16 17:13:12 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 17:13:12 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 17:13:12 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'set']
16/03/16 17:13:13 INFO SparkContext: Running Spark version 1.5.2
16/03/16 17:13:13 INFO SecurityManager: Changing view acls to: root
16/03/16 17:13:13 INFO SecurityManager: Changing modify acls to: root
16/03/16 17:13:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 17:13:13 INFO Slf4jLogger: Slf4jLogger started
16/03/16 17:13:13 INFO Remoting: Starting remoting
16/03/16 17:13:13 INFO Utils: Successfully started service 'sparkDriver' on port 51225.
16/03/16 17:13:13 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:51225]
16/03/16 17:13:13 INFO SparkEnv: Registering MapOutputTracker
16/03/16 17:13:13 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 17:13:13 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-90cba519-29db-49a4-997e-34527ad173e5
16/03/16 17:13:13 INFO MemoryStore: MemoryStore started with capacity 522.9 MB
16/03/16 17:13:13 INFO HttpFileServer: HTTP File server directory is /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/httpd-4b562742-a849-4b82-9a5f-8ed4101a9b4a
16/03/16 17:13:13 INFO HttpServer: Starting HTTP Server
16/03/16 17:13:13 INFO Utils: Successfully started service 'HTTP file server' on port 46264.
16/03/16 17:13:13 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 17:13:13 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 17:13:13 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 17:13:13 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-3dc41fa2-18d6-436d-93df-000311709b5c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 17:13:13 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128593563
16/03/16 17:13:13 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 17:13:13 INFO Executor: Starting executor ID driver on host localhost
16/03/16 17:13:13 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51391.
16/03/16 17:13:13 INFO NettyBlockTransferService: Server created on 51391
16/03/16 17:13:13 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 17:13:13 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51391 with 522.9 MB RAM, BlockManagerId(driver, localhost, 51391)
16/03/16 17:13:13 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): usually
16/03/16 17:13:13 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:13:13 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:13:13 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:13:13 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:13:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 17:13:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 17:13:13 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:13:13 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=548253204
16/03/16 17:13:13 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 522.8 MB)
16/03/16 17:13:13 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=548253204
16/03/16 17:13:13 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 522.8 MB)
16/03/16 17:13:13 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51391 (size: 4.1 KB, free: 522.9 MB)
16/03/16 17:13:13 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 17:13:13 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:13:13 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 17:13:13 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/16 17:13:13 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/16 17:13:13 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 17:13:13 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128593563
16/03/16 17:13:13 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 17:13:13 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-3dc41fa2-18d6-436d-93df-000311709b5c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: set
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  usually  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: issue
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: planning
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: permission
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: economy
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: composition
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: agency
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/16 17:13:22 INFO PythonRunner: Times: total = 8226, boot = 465, init = 371, finish = 7390
16/03/16 17:13:22 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/16 17:13:22 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8675 ms on localhost (1/2)
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: bend
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: giant
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: astatine
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: present
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: area
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  usually  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/16 17:13:22 INFO PythonRunner: Times: total = 8891, boot = 472, init = 480, finish = 7939
16/03/16 17:13:22 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/16 17:13:22 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8967 ms on localhost (2/2)
16/03/16 17:13:22 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.977 s
16/03/16 17:13:22 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 17:13:22 INFO DAGScheduler: looking for newly runnable stages
16/03/16 17:13:22 INFO DAGScheduler: running: Set()
16/03/16 17:13:22 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 17:13:22 INFO DAGScheduler: failed: Set()
16/03/16 17:13:22 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 17:13:22 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 17:13:22 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=548253204
16/03/16 17:13:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 522.8 MB)
16/03/16 17:13:22 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=548253204
16/03/16 17:13:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 522.8 MB)
16/03/16 17:13:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51391 (size: 3.0 KB, free: 522.8 MB)
16/03/16 17:13:22 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 17:13:22 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:13:22 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 17:13:22 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:13:22 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:13:22 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 17:13:22 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 17:13:22 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:13:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 17:13:22 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:13:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
reduceFunction_Parents(): returns= [u'area', 'None', u'area']
16/03/16 17:13:22 INFO PythonRunner: Times: total = 35, boot = -422, init = 457, finish = 0
16/03/16 17:13:22 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/16 17:13:22 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 66 ms on localhost (1/2)
16/03/16 17:13:22 INFO PythonRunner: Times: total = 248, boot = 247, init = 1, finish = 0
16/03/16 17:13:22 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/16 17:13:22 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 265 ms on localhost (2/2)
16/03/16 17:13:22 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 17:13:22 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.254 s
16/03/16 17:13:22 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.261164 s
16/03/16 17:13:23 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:13:23 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:13:23 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:13:23 INFO DAGScheduler: Parents of final stage: List()
16/03/16 17:13:23 INFO DAGScheduler: Missing parents: List()
16/03/16 17:13:23 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:13:23 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=548253204
16/03/16 17:13:23 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 522.8 MB)
16/03/16 17:13:23 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=548253204
16/03/16 17:13:23 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 522.8 MB)
16/03/16 17:13:23 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:51391 (size: 3.3 KB, free: 522.8 MB)
16/03/16 17:13:23 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 17:13:23 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:13:23 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 17:13:23 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/16 17:13:23 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/16 17:13:23 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 17:13:23 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 17:13:23 INFO PythonRunner: Times: total = 73, boot = -124, init = 197, finish = 0
16/03/16 17:13:23 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/16 17:13:23 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 84 ms on localhost (1/2)
16/03/16 17:13:23 INFO PythonRunner: Times: total = 171, boot = 171, init = 0, finish = 0
16/03/16 17:13:23 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/03/16 17:13:23 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 182 ms on localhost (2/2)
16/03/16 17:13:23 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 17:13:23 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.184 s
16/03/16 17:13:23 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.194996 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 17:13:23 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 17:13:23 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 17:13:23 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 17:13:23 INFO MemoryStore: MemoryStore cleared
16/03/16 17:13:23 INFO BlockManager: BlockManager stopped
16/03/16 17:13:23 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 17:13:23 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 17:13:23 INFO SparkContext: Successfully stopped SparkContext
16/03/16 17:13:23 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 17:13:23 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 17:13:23 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'area', u'None', u'area']
16/03/16 17:13:24 INFO SparkContext: Running Spark version 1.5.2
16/03/16 17:13:24 INFO SecurityManager: Changing view acls to: root
16/03/16 17:13:24 INFO SecurityManager: Changing modify acls to: root
16/03/16 17:13:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 17:13:24 INFO Slf4jLogger: Slf4jLogger started
16/03/16 17:13:24 INFO Remoting: Starting remoting
16/03/16 17:13:24 INFO Utils: Successfully started service 'sparkDriver' on port 60110.
16/03/16 17:13:24 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:60110]
16/03/16 17:13:24 INFO SparkEnv: Registering MapOutputTracker
16/03/16 17:13:24 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 17:13:24 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-bec3127f-d584-417f-8952-106ce5fa900e
16/03/16 17:13:24 INFO MemoryStore: MemoryStore started with capacity 523.5 MB
16/03/16 17:13:24 INFO HttpFileServer: HTTP File server directory is /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/httpd-fb79cd27-f1ad-4c50-ab28-5236e0bbf23c
16/03/16 17:13:24 INFO HttpServer: Starting HTTP Server
16/03/16 17:13:24 INFO Utils: Successfully started service 'HTTP file server' on port 40370.
16/03/16 17:13:24 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 17:13:24 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 17:13:24 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 17:13:24 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-bc07e88b-9bd0-4ba6-a481-cf21cbc07efd/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 17:13:24 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128604556
16/03/16 17:13:24 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 17:13:24 INFO Executor: Starting executor ID driver on host localhost
16/03/16 17:13:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59400.
16/03/16 17:13:24 INFO NettyBlockTransferService: Server created on 59400
16/03/16 17:13:24 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 17:13:24 INFO BlockManagerMasterEndpoint: Registering block manager localhost:59400 with 523.5 MB RAM, BlockManagerId(driver, localhost, 59400)
16/03/16 17:13:24 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): moment
16/03/16 17:13:24 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:13:24 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:13:24 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:13:24 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:13:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 17:13:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 17:13:24 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:13:24 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=548960993
16/03/16 17:13:24 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.5 MB)
16/03/16 17:13:24 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=548960993
16/03/16 17:13:24 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.5 MB)
16/03/16 17:13:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:59400 (size: 4.1 KB, free: 523.5 MB)
16/03/16 17:13:24 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 17:13:24 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:13:24 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 17:13:24 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/16 17:13:24 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/16 17:13:24 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 17:13:24 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128604556
16/03/16 17:13:24 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 17:13:24 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-bc07e88b-9bd0-4ba6-a481-cf21cbc07efd/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: area
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: bend
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: giant
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: astatine
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: present
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  moment  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: area
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/16 17:13:33 INFO PythonRunner: Times: total = 9052, boot = 481, init = 442, finish = 8129
16/03/16 17:13:33 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/16 17:13:33 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9144 ms on localhost (1/2)
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: issue
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: planning
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: permission
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: economy
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: composition
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: agency
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 17:13:34 INFO PythonRunner: Times: total = 9307, boot = 488, init = 760, finish = 8059
16/03/16 17:13:34 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/16 17:13:34 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9400 ms on localhost (2/2)
16/03/16 17:13:34 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.401 s
16/03/16 17:13:34 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 17:13:34 INFO DAGScheduler: looking for newly runnable stages
16/03/16 17:13:34 INFO DAGScheduler: running: Set()
16/03/16 17:13:34 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 17:13:34 INFO DAGScheduler: failed: Set()
16/03/16 17:13:34 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 17:13:34 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 17:13:34 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=548960993
16/03/16 17:13:34 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.5 MB)
16/03/16 17:13:34 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=548960993
16/03/16 17:13:34 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.5 MB)
16/03/16 17:13:34 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:59400 (size: 3.0 KB, free: 523.5 MB)
16/03/16 17:13:34 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 17:13:34 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:13:34 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 17:13:34 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:13:34 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:13:34 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 17:13:34 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:13:34 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 17:13:34 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:13:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 17:13:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
reduceFunction_Parents(): returns= ['None', 'None', u'present']
16/03/16 17:13:34 INFO PythonRunner: Times: total = 50, boot = -37, init = 87, finish = 0
16/03/16 17:13:34 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/16 17:13:34 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 119 ms on localhost (1/2)
16/03/16 17:13:34 INFO PythonRunner: Times: total = 236, boot = 235, init = 0, finish = 1
16/03/16 17:13:34 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/16 17:13:34 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.247 s
16/03/16 17:13:34 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.700059 s
16/03/16 17:13:34 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 274 ms on localhost (2/2)
16/03/16 17:13:34 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 17:13:34 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:13:34 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:13:34 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:13:34 INFO DAGScheduler: Parents of final stage: List()
16/03/16 17:13:34 INFO DAGScheduler: Missing parents: List()
16/03/16 17:13:34 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:13:34 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=548960993
16/03/16 17:13:34 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.5 MB)
16/03/16 17:13:34 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=548960993
16/03/16 17:13:34 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.5 MB)
16/03/16 17:13:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:59400 (size: 3.3 KB, free: 523.5 MB)
16/03/16 17:13:34 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 17:13:34 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:13:34 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 17:13:34 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/16 17:13:34 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/16 17:13:34 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 17:13:34 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 17:13:34 INFO PythonRunner: Times: total = 72, boot = -48, init = 120, finish = 0
16/03/16 17:13:34 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/16 17:13:34 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 84 ms on localhost (1/2)
16/03/16 17:13:34 INFO PythonRunner: Times: total = 148, boot = 147, init = 1, finish = 0
16/03/16 17:13:34 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1351 bytes result sent to driver
16/03/16 17:13:34 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 162 ms on localhost (2/2)
16/03/16 17:13:34 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 17:13:34 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.149 s
16/03/16 17:13:34 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.174970 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 17:13:34 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 17:13:34 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 17:13:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 17:13:34 INFO MemoryStore: MemoryStore cleared
16/03/16 17:13:34 INFO BlockManager: BlockManager stopped
16/03/16 17:13:34 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 17:13:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 17:13:34 INFO SparkContext: Successfully stopped SparkContext
16/03/16 17:13:34 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 17:13:34 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'present']
16/03/16 17:13:35 INFO SparkContext: Running Spark version 1.5.2
16/03/16 17:13:35 INFO SecurityManager: Changing view acls to: root
16/03/16 17:13:35 INFO SecurityManager: Changing modify acls to: root
16/03/16 17:13:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 17:13:35 INFO Slf4jLogger: Slf4jLogger started
16/03/16 17:13:35 INFO Remoting: Starting remoting
16/03/16 17:13:35 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:55204]
16/03/16 17:13:35 INFO Utils: Successfully started service 'sparkDriver' on port 55204.
16/03/16 17:13:35 INFO SparkEnv: Registering MapOutputTracker
16/03/16 17:13:35 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 17:13:35 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7aeda049-b35d-493d-9641-984e0f2dde08
16/03/16 17:13:35 INFO MemoryStore: MemoryStore started with capacity 523.5 MB
16/03/16 17:13:35 INFO HttpFileServer: HTTP File server directory is /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/httpd-20cfd121-9e41-4fc9-924d-655d08226316
16/03/16 17:13:35 INFO HttpServer: Starting HTTP Server
16/03/16 17:13:35 INFO Utils: Successfully started service 'HTTP file server' on port 43319.
16/03/16 17:13:35 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 17:13:35 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 17:13:35 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 17:13:35 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-54e58170-3adb-4045-a4b3-17ed0c801773/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 17:13:35 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128615933
16/03/16 17:13:35 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 17:13:35 INFO Executor: Starting executor ID driver on host localhost
16/03/16 17:13:35 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39635.
16/03/16 17:13:35 INFO NettyBlockTransferService: Server created on 39635
16/03/16 17:13:35 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 17:13:35 INFO BlockManagerMasterEndpoint: Registering block manager localhost:39635 with 523.5 MB RAM, BlockManagerId(driver, localhost, 39635)
16/03/16 17:13:35 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): purpose
16/03/16 17:13:36 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:13:36 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:13:36 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:13:36 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:13:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 17:13:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 17:13:36 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:13:36 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=548960993
16/03/16 17:13:36 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.5 MB)
16/03/16 17:13:36 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6568, maxMem=548960993
16/03/16 17:13:36 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.5 MB)
16/03/16 17:13:36 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:39635 (size: 4.1 KB, free: 523.5 MB)
16/03/16 17:13:36 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 17:13:36 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:13:36 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 17:13:36 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/16 17:13:36 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/16 17:13:36 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 17:13:36 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128615933
16/03/16 17:13:36 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 17:13:36 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-54e58170-3adb-4045-a4b3-17ed0c801773/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: set
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: bend
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: giant
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: astatine
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: present
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  u'Bengal'Synset('area.n.01') ; keyword:  purpose  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines():,  purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: issue
u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword=mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: planning
 purpose ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: area
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: permission
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: economy
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: composition
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  purpose  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular'mapFunction_Parents(): keyword=,  purpose ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: agency
u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: kilometer
mapFunction_Parents(): keyword=mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: kilometer
 purpose ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Chennai
u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit'mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
, u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/16 17:13:44 INFO PythonRunner: Times: total = 8405, boot = 473, init = 370, finish = 7562
16/03/16 17:13:44 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/16 17:13:44 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8497 ms on localhost (1/2)
16/03/16 17:13:44 INFO PythonRunner: Times: total = 8437, boot = 465, init = 452, finish = 7520
16/03/16 17:13:44 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/16 17:13:44 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8540 ms on localhost (2/2)
16/03/16 17:13:44 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.535 s
16/03/16 17:13:44 INFO DAGScheduler: looking for newly runnable stages
16/03/16 17:13:44 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 17:13:44 INFO DAGScheduler: running: Set()
16/03/16 17:13:44 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 17:13:44 INFO DAGScheduler: failed: Set()
16/03/16 17:13:44 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 17:13:44 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 17:13:44 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10717, maxMem=548960993
16/03/16 17:13:44 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.5 MB)
16/03/16 17:13:44 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15701, maxMem=548960993
16/03/16 17:13:44 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.5 MB)
16/03/16 17:13:44 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:39635 (size: 3.0 KB, free: 523.5 MB)
16/03/16 17:13:44 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 17:13:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:13:44 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 17:13:44 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:13:44 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:13:44 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 17:13:44 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 17:13:44 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:13:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 17:13:44 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:13:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
reduceFunction_Parents(): returns= [u'area', 'None', u'area']
16/03/16 17:13:44 INFO PythonRunner: Times: total = 187, boot = 184, init = 1, finish = 2
16/03/16 17:13:44 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/16 17:13:44 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 213 ms on localhost (1/2)
16/03/16 17:13:44 INFO PythonRunner: Times: total = 235, boot = 234, init = 0, finish = 1
16/03/16 17:13:44 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/16 17:13:44 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.252 s
16/03/16 17:13:44 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.825918 s
16/03/16 17:13:44 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 254 ms on localhost (2/2)
16/03/16 17:13:44 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 17:13:45 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:13:45 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:13:45 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:13:45 INFO DAGScheduler: Parents of final stage: List()
16/03/16 17:13:45 INFO DAGScheduler: Missing parents: List()
16/03/16 17:13:45 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:13:45 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18757, maxMem=548960993
16/03/16 17:13:45 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.5 MB)
16/03/16 17:13:45 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24573, maxMem=548960993
16/03/16 17:13:45 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.5 MB)
16/03/16 17:13:45 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:39635 (size: 3.3 KB, free: 523.5 MB)
16/03/16 17:13:45 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 17:13:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:13:45 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 17:13:45 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/16 17:13:45 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/16 17:13:45 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 17:13:45 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 17:13:45 INFO PythonRunner: Times: total = 127, boot = 127, init = 0, finish = 0
16/03/16 17:13:45 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/16 17:13:45 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 136 ms on localhost (1/2)
16/03/16 17:13:45 INFO PythonRunner: Times: total = 158, boot = 158, init = 0, finish = 0
16/03/16 17:13:45 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/03/16 17:13:45 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 183 ms on localhost (2/2)
16/03/16 17:13:45 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 17:13:45 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.185 s
16/03/16 17:13:45 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.213937 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 17:13:45 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 17:13:45 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 17:13:45 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 17:13:45 INFO MemoryStore: MemoryStore cleared
16/03/16 17:13:45 INFO BlockManager: BlockManager stopped
16/03/16 17:13:45 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 17:13:45 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 17:13:45 INFO SparkContext: Successfully stopped SparkContext
16/03/16 17:13:45 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 17:13:45 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'area', u'None', u'area']
16/03/16 17:13:46 INFO SparkContext: Running Spark version 1.5.2
16/03/16 17:13:46 INFO SecurityManager: Changing view acls to: root
16/03/16 17:13:46 INFO SecurityManager: Changing modify acls to: root
16/03/16 17:13:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 17:13:46 INFO Slf4jLogger: Slf4jLogger started
16/03/16 17:13:46 INFO Remoting: Starting remoting
16/03/16 17:13:46 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:38054]
16/03/16 17:13:46 INFO Utils: Successfully started service 'sparkDriver' on port 38054.
16/03/16 17:13:46 INFO SparkEnv: Registering MapOutputTracker
16/03/16 17:13:46 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 17:13:46 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-6b4524be-7ebf-42b1-a4e2-b1bbcf371cfb
16/03/16 17:13:46 INFO MemoryStore: MemoryStore started with capacity 523.5 MB
16/03/16 17:13:46 INFO HttpFileServer: HTTP File server directory is /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/httpd-80e23638-ba4e-4b9f-9650-07c5d85a5666
16/03/16 17:13:46 INFO HttpServer: Starting HTTP Server
16/03/16 17:13:46 INFO Utils: Successfully started service 'HTTP file server' on port 50614.
16/03/16 17:13:46 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 17:13:46 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 17:13:46 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 17:13:46 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-93f4a0db-3797-47ef-9176-b5e2e54ebc18/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 17:13:46 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128626804
16/03/16 17:13:46 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 17:13:46 INFO Executor: Starting executor ID driver on host localhost
16/03/16 17:13:46 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36832.
16/03/16 17:13:46 INFO NettyBlockTransferService: Server created on 36832
16/03/16 17:13:46 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 17:13:46 INFO BlockManagerMasterEndpoint: Registering block manager localhost:36832 with 523.5 MB RAM, BlockManagerId(driver, localhost, 36832)
16/03/16 17:13:46 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): segment
16/03/16 17:13:47 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:13:47 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:13:47 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:13:47 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:13:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 17:13:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 17:13:47 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:13:47 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=548960993
16/03/16 17:13:47 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.5 MB)
16/03/16 17:13:47 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=6568, maxMem=548960993
16/03/16 17:13:47 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.5 MB)
16/03/16 17:13:47 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:36832 (size: 4.1 KB, free: 523.5 MB)
16/03/16 17:13:47 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 17:13:47 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:13:47 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 17:13:47 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/16 17:13:47 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/16 17:13:47 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 17:13:47 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128626804
16/03/16 17:13:47 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 17:13:47 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-93f4a0db-3797-47ef-9176-b5e2e54ebc18/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: area
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: issue
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: planning
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: permission
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: economy
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: composition
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: agency
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 17:13:59 INFO PythonRunner: Times: total = 12377, boot = 530, init = 413, finish = 11434
16/03/16 17:13:59 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/16 17:13:59 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 12513 ms on localhost (1/2)
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: bend
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): adding to parents: syn =  Synset('bend.n.01') ; keyword:  segment  in syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= [u'bend']
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: giant
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: astatine
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: present
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: area
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
16/03/16 17:14:00 INFO PythonRunner: Times: total = 12963, boot = 524, init = 382, finish = 12057
16/03/16 17:14:00 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/16 17:14:00 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 13093 ms on localhost (2/2)
16/03/16 17:14:00 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 13.088 s
16/03/16 17:14:00 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 17:14:00 INFO DAGScheduler: looking for newly runnable stages
16/03/16 17:14:00 INFO DAGScheduler: running: Set()
16/03/16 17:14:00 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 17:14:00 INFO DAGScheduler: failed: Set()
16/03/16 17:14:00 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 17:14:00 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 17:14:00 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10717, maxMem=548960993
16/03/16 17:14:00 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.5 MB)
16/03/16 17:14:00 INFO MemoryStore: ensureFreeSpace(3057) called with curMem=15701, maxMem=548960993
16/03/16 17:14:00 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.5 MB)
16/03/16 17:14:00 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:36832 (size: 3.0 KB, free: 523.5 MB)
16/03/16 17:14:00 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 17:14:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:14:00 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 17:14:00 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:14:00 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:14:00 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 17:14:00 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:14:00 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 17:14:00 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:14:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 17:14:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/03/16 17:14:00 INFO PythonRunner: Times: total = 77, boot = -351, init = 428, finish = 0
16/03/16 17:14:00 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/16 17:14:00 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 122 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'bend']
16/03/16 17:14:00 INFO PythonRunner: Times: total = 237, boot = 236, init = 0, finish = 1
16/03/16 17:14:00 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1272 bytes result sent to driver
16/03/16 17:14:00 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.245 s
16/03/16 17:14:00 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 13.403635 s
16/03/16 17:14:00 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 260 ms on localhost (2/2)
16/03/16 17:14:00 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 17:14:00 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:14:00 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:14:00 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:14:00 INFO DAGScheduler: Parents of final stage: List()
16/03/16 17:14:00 INFO DAGScheduler: Missing parents: List()
16/03/16 17:14:00 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:14:00 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18758, maxMem=548960993
16/03/16 17:14:00 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.5 MB)
16/03/16 17:14:00 INFO MemoryStore: ensureFreeSpace(3379) called with curMem=24574, maxMem=548960993
16/03/16 17:14:00 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.5 MB)
16/03/16 17:14:00 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:36832 (size: 3.3 KB, free: 523.5 MB)
16/03/16 17:14:00 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 17:14:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:14:00 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 17:14:00 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/16 17:14:00 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2353 bytes)
16/03/16 17:14:00 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 17:14:00 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 17:14:00 INFO PythonRunner: Times: total = 202, boot = 202, init = 0, finish = 0
16/03/16 17:14:00 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1337 bytes result sent to driver
16/03/16 17:14:00 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 208 ms on localhost (1/2)
16/03/16 17:14:00 INFO PythonRunner: Times: total = 255, boot = 254, init = 1, finish = 0
16/03/16 17:14:00 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/16 17:14:00 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 262 ms on localhost (2/2)
16/03/16 17:14:00 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 17:14:00 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.251 s
16/03/16 17:14:00 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.282522 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 17:14:01 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 17:14:01 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 17:14:01 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 17:14:01 INFO MemoryStore: MemoryStore cleared
16/03/16 17:14:01 INFO BlockManager: BlockManager stopped
16/03/16 17:14:01 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 17:14:01 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 17:14:01 INFO SparkContext: Successfully stopped SparkContext
16/03/16 17:14:01 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 17:14:01 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 17:14:01 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'bend']
16/03/16 17:14:02 INFO SparkContext: Running Spark version 1.5.2
16/03/16 17:14:02 INFO SecurityManager: Changing view acls to: root
16/03/16 17:14:02 INFO SecurityManager: Changing modify acls to: root
16/03/16 17:14:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 17:14:02 INFO Slf4jLogger: Slf4jLogger started
16/03/16 17:14:02 INFO Remoting: Starting remoting
16/03/16 17:14:02 INFO Utils: Successfully started service 'sparkDriver' on port 32980.
16/03/16 17:14:02 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:32980]
16/03/16 17:14:02 INFO SparkEnv: Registering MapOutputTracker
16/03/16 17:14:02 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 17:14:02 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1177ca46-f2e5-4426-8377-9ef5d18da49b
16/03/16 17:14:02 INFO MemoryStore: MemoryStore started with capacity 523.1 MB
16/03/16 17:14:02 INFO HttpFileServer: HTTP File server directory is /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/httpd-60571fe7-e648-43c7-95b9-8b799c130699
16/03/16 17:14:02 INFO HttpServer: Starting HTTP Server
16/03/16 17:14:02 INFO Utils: Successfully started service 'HTTP file server' on port 60295.
16/03/16 17:14:02 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 17:14:02 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 17:14:02 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 17:14:02 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-21f86de4-404d-49bd-a911-228a7d56d943/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 17:14:02 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128642312
16/03/16 17:14:02 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 17:14:02 INFO Executor: Starting executor ID driver on host localhost
16/03/16 17:14:02 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58705.
16/03/16 17:14:02 INFO NettyBlockTransferService: Server created on 58705
16/03/16 17:14:02 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 17:14:02 INFO BlockManagerMasterEndpoint: Registering block manager localhost:58705 with 523.1 MB RAM, BlockManagerId(driver, localhost, 58705)
16/03/16 17:14:02 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): radioactive
16/03/16 17:14:02 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:14:02 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:14:02 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:14:02 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:14:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 17:14:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 17:14:02 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:14:02 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=548536320
16/03/16 17:14:02 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.1 MB)
16/03/16 17:14:02 INFO MemoryStore: ensureFreeSpace(4146) called with curMem=6568, maxMem=548536320
16/03/16 17:14:02 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 523.1 MB)
16/03/16 17:14:02 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:58705 (size: 4.0 KB, free: 523.1 MB)
16/03/16 17:14:02 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 17:14:02 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:14:02 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 17:14:02 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/16 17:14:02 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/16 17:14:02 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 17:14:02 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128642312
16/03/16 17:14:02 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 17:14:02 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-21f86de4-404d-49bd-a911-228a7d56d943/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: area
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: bend
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: giant
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: astatine
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  radioactive  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: present
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: area
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/16 17:14:15 INFO PythonRunner: Times: total = 13196, boot = 630, init = 525, finish = 12041
16/03/16 17:14:15 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/16 17:14:15 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 13326 ms on localhost (1/2)
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: issue
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: planning
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: permission
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: economy
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: composition
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: agency
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 17:14:16 INFO PythonRunner: Times: total = 13458, boot = 607, init = 1128, finish = 11723
16/03/16 17:14:16 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/16 17:14:16 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 13609 ms on localhost (2/2)
16/03/16 17:14:16 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 17:14:16 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 13.611 s
16/03/16 17:14:16 INFO DAGScheduler: looking for newly runnable stages
16/03/16 17:14:16 INFO DAGScheduler: running: Set()
16/03/16 17:14:16 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 17:14:16 INFO DAGScheduler: failed: Set()
16/03/16 17:14:16 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 17:14:16 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 17:14:16 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10714, maxMem=548536320
16/03/16 17:14:16 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.1 MB)
16/03/16 17:14:16 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15698, maxMem=548536320
16/03/16 17:14:16 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.1 MB)
16/03/16 17:14:16 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:58705 (size: 3.0 KB, free: 523.1 MB)
16/03/16 17:14:16 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 17:14:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:14:16 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 17:14:16 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:14:16 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:14:16 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 17:14:16 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 17:14:16 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:14:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/16 17:14:16 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:14:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/03/16 17:14:16 INFO PythonRunner: Times: total = 66, boot = 24, init = 40, finish = 2
16/03/16 17:14:16 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/03/16 17:14:16 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 141 ms on localhost (1/2)
16/03/16 17:14:16 INFO PythonRunner: Times: total = 441, boot = 440, init = 1, finish = 0
16/03/16 17:14:16 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/16 17:14:16 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 465 ms on localhost (2/2)
16/03/16 17:14:16 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 17:14:16 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.465 s
16/03/16 17:14:16 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 14.107284 s
16/03/16 17:14:16 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:14:16 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:14:16 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:14:16 INFO DAGScheduler: Parents of final stage: List()
16/03/16 17:14:16 INFO DAGScheduler: Missing parents: List()
16/03/16 17:14:16 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:14:16 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18754, maxMem=548536320
16/03/16 17:14:16 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.1 MB)
16/03/16 17:14:16 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24570, maxMem=548536320
16/03/16 17:14:16 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.1 MB)
16/03/16 17:14:16 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:58705 (size: 3.3 KB, free: 523.1 MB)
16/03/16 17:14:16 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 17:14:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:14:16 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 17:14:16 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/16 17:14:16 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/03/16 17:14:16 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 17:14:16 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 17:14:16 INFO PythonRunner: Times: total = 66, boot = 65, init = 1, finish = 0
16/03/16 17:14:16 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/03/16 17:14:16 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 80 ms on localhost (1/2)
16/03/16 17:14:16 INFO PythonRunner: Times: total = 81, boot = -209, init = 290, finish = 0
16/03/16 17:14:16 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/16 17:14:16 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 88 ms on localhost (2/2)
16/03/16 17:14:16 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 17:14:16 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.073 s
16/03/16 17:14:16 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.125931 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 17:14:16 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 17:14:16 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 17:14:17 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 17:14:17 INFO MemoryStore: MemoryStore cleared
16/03/16 17:14:17 INFO BlockManager: BlockManager stopped
16/03/16 17:14:17 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 17:14:17 INFO SparkContext: Successfully stopped SparkContext
16/03/16 17:14:17 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 17:14:17 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 17:14:17 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 17:14:17 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'astatine']
16/03/16 17:14:17 INFO SparkContext: Running Spark version 1.5.2
16/03/16 17:14:17 INFO SecurityManager: Changing view acls to: root
16/03/16 17:14:17 INFO SecurityManager: Changing modify acls to: root
16/03/16 17:14:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 17:14:17 INFO Slf4jLogger: Slf4jLogger started
16/03/16 17:14:17 INFO Remoting: Starting remoting
16/03/16 17:14:18 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:43055]
16/03/16 17:14:18 INFO Utils: Successfully started service 'sparkDriver' on port 43055.
16/03/16 17:14:18 INFO SparkEnv: Registering MapOutputTracker
16/03/16 17:14:18 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 17:14:18 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-83858a7a-35c8-4f31-b1e1-ab6648d2a79f
16/03/16 17:14:18 INFO MemoryStore: MemoryStore started with capacity 523.1 MB
16/03/16 17:14:18 INFO HttpFileServer: HTTP File server directory is /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/httpd-64f94c08-44fa-472c-a40f-800a6d616d9c
16/03/16 17:14:18 INFO HttpServer: Starting HTTP Server
16/03/16 17:14:18 INFO Utils: Successfully started service 'HTTP file server' on port 47347.
16/03/16 17:14:18 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 17:14:23 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 17:14:23 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 17:14:23 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-fc1026c2-9c22-4fc0-8438-9bb36955e1ab/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 17:14:23 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128663219
16/03/16 17:14:23 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 17:14:23 INFO Executor: Starting executor ID driver on host localhost
16/03/16 17:14:23 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38899.
16/03/16 17:14:23 INFO NettyBlockTransferService: Server created on 38899
16/03/16 17:14:23 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 17:14:23 INFO BlockManagerMasterEndpoint: Registering block manager localhost:38899 with 523.1 MB RAM, BlockManagerId(driver, localhost, 38899)
16/03/16 17:14:23 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): happening
16/03/16 17:14:23 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:14:23 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:14:23 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:14:23 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:14:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 17:14:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 17:14:23 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:14:23 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=548536320
16/03/16 17:14:23 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.1 MB)
16/03/16 17:14:23 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=548536320
16/03/16 17:14:23 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.1 MB)
16/03/16 17:14:23 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:38899 (size: 4.1 KB, free: 523.1 MB)
16/03/16 17:14:23 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 17:14:23 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:14:23 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 17:14:23 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/16 17:14:23 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/16 17:14:23 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 17:14:23 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128663219
16/03/16 17:14:23 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 17:14:23 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-fc1026c2-9c22-4fc0-8438-9bb36955e1ab/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: set
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: issue
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: planning
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: permission
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: economy
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: composition
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: agency
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 17:14:36 INFO PythonRunner: Times: total = 12680, boot = 501, init = 537, finish = 11642
16/03/16 17:14:36 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/16 17:14:36 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 12785 ms on localhost (1/2)
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: bend
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: giant
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: astatine
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: present
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  happening  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: area
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/16 17:14:37 INFO PythonRunner: Times: total = 13524, boot = 469, init = 746, finish = 12309
16/03/16 17:14:37 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/16 17:14:37 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 13.634 s
16/03/16 17:14:37 INFO DAGScheduler: looking for newly runnable stages
16/03/16 17:14:37 INFO DAGScheduler: running: Set()
16/03/16 17:14:37 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 17:14:37 INFO DAGScheduler: failed: Set()
16/03/16 17:14:37 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 17:14:37 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 17:14:37 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=548536320
16/03/16 17:14:37 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.1 MB)
16/03/16 17:14:37 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=548536320
16/03/16 17:14:37 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.1 MB)
16/03/16 17:14:37 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 13624 ms on localhost (2/2)
16/03/16 17:14:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:38899 (size: 3.0 KB, free: 523.1 MB)
16/03/16 17:14:37 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 17:14:37 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 17:14:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:14:37 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 17:14:37 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:14:37 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:14:37 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 17:14:37 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 17:14:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:14:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 17:14:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:14:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
16/03/16 17:14:37 INFO PythonRunner: Times: total = 221, boot = 220, init = 0, finish = 1
reduceFunction_Parents(): returns= ['None', 'None', u'present']
16/03/16 17:14:37 INFO PythonRunner: Times: total = 371, boot = -670, init = 1041, finish = 0
16/03/16 17:14:37 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/16 17:14:37 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/16 17:14:37 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 438 ms on localhost (1/2)
16/03/16 17:14:37 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:38899 in memory (size: 4.1 KB, free: 523.1 MB)
16/03/16 17:14:37 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 445 ms on localhost (2/2)
16/03/16 17:14:37 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 17:14:37 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.446 s
16/03/16 17:14:37 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 14.111881 s
16/03/16 17:14:37 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:14:37 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:14:37 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:14:37 INFO DAGScheduler: Parents of final stage: List()
16/03/16 17:14:37 INFO DAGScheduler: Missing parents: List()
16/03/16 17:14:37 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:14:37 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=8040, maxMem=548536320
16/03/16 17:14:37 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.1 MB)
16/03/16 17:14:37 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=13856, maxMem=548536320
16/03/16 17:14:37 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.1 MB)
16/03/16 17:14:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:38899 (size: 3.3 KB, free: 523.1 MB)
16/03/16 17:14:37 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 17:14:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:14:37 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 17:14:37 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/16 17:14:37 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/16 17:14:37 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 17:14:37 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 17:14:37 INFO PythonRunner: Times: total = 21, boot = -88, init = 109, finish = 0
16/03/16 17:14:37 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/16 17:14:37 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 67 ms on localhost (1/2)
16/03/16 17:14:37 INFO PythonRunner: Times: total = 193, boot = 193, init = 0, finish = 0
16/03/16 17:14:37 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1351 bytes result sent to driver
16/03/16 17:14:37 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 204 ms on localhost (2/2)
16/03/16 17:14:37 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 17:14:37 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.206 s
16/03/16 17:14:37 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.229992 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 17:14:37 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 17:14:37 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 17:14:38 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 17:14:38 INFO MemoryStore: MemoryStore cleared
16/03/16 17:14:38 INFO BlockManager: BlockManager stopped
16/03/16 17:14:38 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 17:14:38 INFO SparkContext: Successfully stopped SparkContext
16/03/16 17:14:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 17:14:38 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 17:14:38 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 17:14:38 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'present']
16/03/16 17:14:38 INFO SparkContext: Running Spark version 1.5.2
16/03/16 17:14:38 INFO SecurityManager: Changing view acls to: root
16/03/16 17:14:38 INFO SecurityManager: Changing modify acls to: root
16/03/16 17:14:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 17:14:38 INFO Slf4jLogger: Slf4jLogger started
16/03/16 17:14:38 INFO Remoting: Starting remoting
16/03/16 17:14:38 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:42133]
16/03/16 17:14:38 INFO Utils: Successfully started service 'sparkDriver' on port 42133.
16/03/16 17:14:38 INFO SparkEnv: Registering MapOutputTracker
16/03/16 17:14:38 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 17:14:38 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0056b6d2-db29-4103-8196-c615cb93622d
16/03/16 17:14:38 INFO MemoryStore: MemoryStore started with capacity 525.0 MB
16/03/16 17:14:38 INFO HttpFileServer: HTTP File server directory is /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/httpd-a9d97eb4-9bf4-4c29-beeb-825dc485ae64
16/03/16 17:14:38 INFO HttpServer: Starting HTTP Server
16/03/16 17:14:39 INFO Utils: Successfully started service 'HTTP file server' on port 35878.
16/03/16 17:14:39 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 17:14:39 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 17:14:39 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 17:14:39 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-ee0d08fe-c4cf-487b-8015-4eefab3850b4/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 17:14:39 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128679112
16/03/16 17:14:39 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 17:14:39 INFO Executor: Starting executor ID driver on host localhost
16/03/16 17:14:39 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49637.
16/03/16 17:14:39 INFO NettyBlockTransferService: Server created on 49637
16/03/16 17:14:39 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 17:14:39 INFO BlockManagerMasterEndpoint: Registering block manager localhost:49637 with 525.0 MB RAM, BlockManagerId(driver, localhost, 49637)
16/03/16 17:14:39 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): curve
16/03/16 17:14:39 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:14:39 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:14:39 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:14:39 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:14:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 17:14:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 17:14:39 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:14:39 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=550518128
16/03/16 17:14:39 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 525.0 MB)
16/03/16 17:14:39 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=550518128
16/03/16 17:14:39 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 525.0 MB)
16/03/16 17:14:39 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:49637 (size: 4.1 KB, free: 525.0 MB)
16/03/16 17:14:39 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 17:14:39 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:14:39 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 17:14:39 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/16 17:14:39 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/16 17:14:39 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 17:14:39 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128679112
16/03/16 17:14:39 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 17:14:39 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-ee0d08fe-c4cf-487b-8015-4eefab3850b4/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: area
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: bend
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): adding to parents: syn =  Synset('bend.n.01') ; keyword:  curve  in syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= [u'bend']
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: giant
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: astatine
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: present
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: area
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
16/03/16 17:14:47 INFO PythonRunner: Times: total = 8615, boot = 471, init = 385, finish = 7759
16/03/16 17:14:47 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/16 17:14:47 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8704 ms on localhost (1/2)
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: issue
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: planning
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: permission
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: economy
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: composition
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: agency
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 17:14:48 INFO PythonRunner: Times: total = 9100, boot = 462, init = 441, finish = 8197
16/03/16 17:14:48 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/16 17:14:48 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.182 s
16/03/16 17:14:48 INFO DAGScheduler: looking for newly runnable stages
16/03/16 17:14:48 INFO DAGScheduler: running: Set()
16/03/16 17:14:48 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 17:14:48 INFO DAGScheduler: failed: Set()
16/03/16 17:14:48 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 17:14:48 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 17:14:48 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9180 ms on localhost (2/2)
16/03/16 17:14:48 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=550518128
16/03/16 17:14:48 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 525.0 MB)
16/03/16 17:14:48 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=550518128
16/03/16 17:14:48 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 17:14:48 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 525.0 MB)
16/03/16 17:14:48 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:49637 (size: 3.0 KB, free: 525.0 MB)
16/03/16 17:14:48 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 17:14:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:14:48 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 17:14:48 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:14:48 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:14:48 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 17:14:48 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:14:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 17:14:48 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 17:14:48 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:14:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 17:14:48 INFO PythonRunner: Times: total = 20, boot = -309, init = 328, finish = 1
16/03/16 17:14:48 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/16 17:14:48 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 76 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'bend']
16/03/16 17:14:48 INFO PythonRunner: Times: total = 236, boot = 233, init = 1, finish = 2
16/03/16 17:14:48 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1272 bytes result sent to driver
16/03/16 17:14:48 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.255 s
16/03/16 17:14:48 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.472981 s
16/03/16 17:14:48 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 262 ms on localhost (2/2)
16/03/16 17:14:48 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 17:14:48 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:14:48 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:14:48 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:14:48 INFO DAGScheduler: Parents of final stage: List()
16/03/16 17:14:48 INFO DAGScheduler: Missing parents: List()
16/03/16 17:14:48 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:14:48 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=550518128
16/03/16 17:14:48 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 525.0 MB)
16/03/16 17:14:48 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=550518128
16/03/16 17:14:48 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 525.0 MB)
16/03/16 17:14:48 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:49637 (size: 3.3 KB, free: 525.0 MB)
16/03/16 17:14:48 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 17:14:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:14:48 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 17:14:48 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/16 17:14:48 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2353 bytes)
16/03/16 17:14:48 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 17:14:48 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 17:14:48 INFO PythonRunner: Times: total = 73, boot = -113, init = 186, finish = 0
16/03/16 17:14:48 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/16 17:14:48 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 82 ms on localhost (1/2)
16/03/16 17:14:49 INFO PythonRunner: Times: total = 193, boot = 193, init = 0, finish = 0
16/03/16 17:14:49 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1337 bytes result sent to driver
16/03/16 17:14:49 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 208 ms on localhost (2/2)
16/03/16 17:14:49 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 17:14:49 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.194 s
16/03/16 17:14:49 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.220975 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 17:14:49 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 17:14:49 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 17:14:49 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 17:14:49 INFO MemoryStore: MemoryStore cleared
16/03/16 17:14:49 INFO BlockManager: BlockManager stopped
16/03/16 17:14:49 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 17:14:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 17:14:49 INFO SparkContext: Successfully stopped SparkContext
16/03/16 17:14:49 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 17:14:49 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 17:14:49 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'bend']
16/03/16 17:14:50 INFO SparkContext: Running Spark version 1.5.2
16/03/16 17:14:50 INFO SecurityManager: Changing view acls to: root
16/03/16 17:14:50 INFO SecurityManager: Changing modify acls to: root
16/03/16 17:14:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 17:14:50 INFO Slf4jLogger: Slf4jLogger started
16/03/16 17:14:50 INFO Remoting: Starting remoting
16/03/16 17:14:50 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:54455]
16/03/16 17:14:50 INFO Utils: Successfully started service 'sparkDriver' on port 54455.
16/03/16 17:14:50 INFO SparkEnv: Registering MapOutputTracker
16/03/16 17:14:50 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 17:14:50 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e110bf7b-5ed5-488e-8ce7-7ec12baee79a
16/03/16 17:14:50 INFO MemoryStore: MemoryStore started with capacity 525.0 MB
16/03/16 17:14:50 INFO HttpFileServer: HTTP File server directory is /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/httpd-63459e39-bfa9-400b-9b8a-50f5bb3be645
16/03/16 17:14:50 INFO HttpServer: Starting HTTP Server
16/03/16 17:14:50 INFO Utils: Successfully started service 'HTTP file server' on port 38151.
16/03/16 17:14:50 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 17:14:50 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 17:14:50 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 17:14:50 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-074639e1-5cbb-4cbd-af69-ec986612329a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 17:14:50 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128690326
16/03/16 17:14:50 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 17:14:50 INFO Executor: Starting executor ID driver on host localhost
16/03/16 17:14:50 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49313.
16/03/16 17:14:50 INFO NettyBlockTransferService: Server created on 49313
16/03/16 17:14:50 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 17:14:50 INFO BlockManagerMasterEndpoint: Registering block manager localhost:49313 with 525.0 MB RAM, BlockManagerId(driver, localhost, 49313)
16/03/16 17:14:50 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): together
16/03/16 17:14:50 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:14:50 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:14:50 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:14:50 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:14:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 17:14:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 17:14:50 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:14:50 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=550518128
16/03/16 17:14:50 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 525.0 MB)
16/03/16 17:14:50 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=550518128
16/03/16 17:14:50 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 525.0 MB)
16/03/16 17:14:50 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:49313 (size: 4.1 KB, free: 525.0 MB)
16/03/16 17:14:50 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 17:14:50 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:14:50 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 17:14:50 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/16 17:14:50 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/16 17:14:50 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 17:14:50 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128690326
16/03/16 17:14:50 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 17:14:50 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-074639e1-5cbb-4cbd-af69-ec986612329a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: area
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  Synset('set.n.01') ; keyword:  together  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: bend
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: giant
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: astatine
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: present
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: issue
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: area
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: planning
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: kilometer
mapFunction_Parents(): keyword=mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
 together ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: permission
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: economy
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: composition
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: agency
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 17:14:59 INFO PythonRunner: Times: total = 8893, boot = 465, init = 393, finish = 8035
16/03/16 17:14:59 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/16 17:14:59 INFO PythonRunner: Times: total = 8901, boot = 468, init = 452, finish = 7981
16/03/16 17:14:59 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/16 17:14:59 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9001 ms on localhost (1/2)
16/03/16 17:14:59 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9002 ms on localhost (2/2)
16/03/16 17:14:59 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 17:14:59 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.994 s
16/03/16 17:14:59 INFO DAGScheduler: looking for newly runnable stages
16/03/16 17:14:59 INFO DAGScheduler: running: Set()
16/03/16 17:14:59 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 17:14:59 INFO DAGScheduler: failed: Set()
16/03/16 17:14:59 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 17:14:59 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 17:14:59 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=550518128
16/03/16 17:14:59 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 525.0 MB)
16/03/16 17:14:59 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=550518128
16/03/16 17:14:59 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 525.0 MB)
16/03/16 17:14:59 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:49313 (size: 3.0 KB, free: 525.0 MB)
16/03/16 17:14:59 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 17:14:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:14:59 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 17:14:59 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:14:59 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:14:59 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 17:14:59 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:14:59 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 17:14:59 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:14:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
16/03/16 17:14:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
16/03/16 17:14:59 INFO PythonRunner: Times: total = 190, boot = 189, init = 0, finish = 1
16/03/16 17:14:59 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/16 17:14:59 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 223 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'set']
16/03/16 17:14:59 INFO PythonRunner: Times: total = 458, boot = 456, init = 0, finish = 2
16/03/16 17:14:59 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1271 bytes result sent to driver
16/03/16 17:15:00 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 488 ms on localhost (2/2)
16/03/16 17:15:00 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 17:15:00 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.466 s
16/03/16 17:15:00 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.552455 s
16/03/16 17:15:00 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:15:00 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:15:00 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:15:00 INFO DAGScheduler: Parents of final stage: List()
16/03/16 17:15:00 INFO DAGScheduler: Missing parents: List()
16/03/16 17:15:00 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:15:00 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=550518128
16/03/16 17:15:00 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 525.0 MB)
16/03/16 17:15:00 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=550518128
16/03/16 17:15:00 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 525.0 MB)
16/03/16 17:15:00 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:49313 (size: 3.3 KB, free: 525.0 MB)
16/03/16 17:15:00 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 17:15:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:15:00 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 17:15:00 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/16 17:15:00 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 17:15:00 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 17:15:00 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 17:15:00 INFO PythonRunner: Times: total = 62, boot = -90, init = 152, finish = 0
16/03/16 17:15:00 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1336 bytes result sent to driver
16/03/16 17:15:00 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 97 ms on localhost (1/2)
16/03/16 17:15:00 INFO PythonRunner: Times: total = 224, boot = 223, init = 0, finish = 1
16/03/16 17:15:00 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/16 17:15:00 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 238 ms on localhost (2/2)
16/03/16 17:15:00 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 17:15:00 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.222 s
16/03/16 17:15:00 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.261668 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 17:15:00 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 17:15:00 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 17:15:00 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 17:15:00 INFO MemoryStore: MemoryStore cleared
16/03/16 17:15:00 INFO BlockManager: BlockManager stopped
16/03/16 17:15:00 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 17:15:00 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 17:15:00 INFO SparkContext: Successfully stopped SparkContext
16/03/16 17:15:00 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 17:15:00 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 17:15:00 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'set']
16/03/16 17:15:01 INFO SparkContext: Running Spark version 1.5.2
16/03/16 17:15:01 INFO SecurityManager: Changing view acls to: root
16/03/16 17:15:01 INFO SecurityManager: Changing modify acls to: root
16/03/16 17:15:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 17:15:01 INFO Slf4jLogger: Slf4jLogger started
16/03/16 17:15:01 INFO Remoting: Starting remoting
16/03/16 17:15:01 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:46614]
16/03/16 17:15:01 INFO Utils: Successfully started service 'sparkDriver' on port 46614.
16/03/16 17:15:01 INFO SparkEnv: Registering MapOutputTracker
16/03/16 17:15:01 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 17:15:01 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-6cdef76a-1907-4982-adc6-5ca335d8d5eb
16/03/16 17:15:01 INFO MemoryStore: MemoryStore started with capacity 525.0 MB
16/03/16 17:15:01 INFO HttpFileServer: HTTP File server directory is /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/httpd-be7327cc-8870-4f97-941f-f99495a75664
16/03/16 17:15:01 INFO HttpServer: Starting HTTP Server
16/03/16 17:15:01 INFO Utils: Successfully started service 'HTTP file server' on port 36223.
16/03/16 17:15:01 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 17:15:01 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 17:15:01 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 17:15:01 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-4b9b7021-6a16-4723-85ee-276f032a5b89/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 17:15:02 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128701985
16/03/16 17:15:02 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 17:15:02 INFO Executor: Starting executor ID driver on host localhost
16/03/16 17:15:02 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57487.
16/03/16 17:15:02 INFO NettyBlockTransferService: Server created on 57487
16/03/16 17:15:02 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 17:15:02 INFO BlockManagerMasterEndpoint: Registering block manager localhost:57487 with 525.0 MB RAM, BlockManagerId(driver, localhost, 57487)
16/03/16 17:15:02 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): element
16/03/16 17:15:02 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:15:02 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:15:02 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:15:02 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:15:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 17:15:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 17:15:02 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:15:02 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=550518128
16/03/16 17:15:02 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 525.0 MB)
16/03/16 17:15:02 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=550518128
16/03/16 17:15:02 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 525.0 MB)
16/03/16 17:15:02 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:57487 (size: 4.1 KB, free: 525.0 MB)
16/03/16 17:15:02 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 17:15:02 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:15:02 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 17:15:02 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/16 17:15:02 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/16 17:15:02 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 17:15:02 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128701985
16/03/16 17:15:02 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 17:15:02 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-4b9b7021-6a16-4723-85ee-276f032a5b89/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: area
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: issue
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: planning
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: permission
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: economy
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: composition
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: agency
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 17:15:10 INFO PythonRunner: Times: total = 8464, boot = 499, init = 430, finish = 7535
16/03/16 17:15:10 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/16 17:15:10 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8560 ms on localhost (1/2)
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: bend
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: giant
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: astatine
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  element  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: present
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: area
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/16 17:15:10 INFO PythonRunner: Times: total = 8770, boot = 477, init = 399, finish = 7894
16/03/16 17:15:10 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/16 17:15:11 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8851 ms on localhost (2/2)
16/03/16 17:15:11 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 17:15:11 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.854 s
16/03/16 17:15:11 INFO DAGScheduler: looking for newly runnable stages
16/03/16 17:15:11 INFO DAGScheduler: running: Set()
16/03/16 17:15:11 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 17:15:11 INFO DAGScheduler: failed: Set()
16/03/16 17:15:11 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 17:15:11 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 17:15:11 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=550518128
16/03/16 17:15:11 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 525.0 MB)
16/03/16 17:15:11 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=550518128
16/03/16 17:15:11 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 525.0 MB)
16/03/16 17:15:11 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:57487 (size: 3.0 KB, free: 525.0 MB)
16/03/16 17:15:11 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 17:15:11 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:15:11 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 17:15:11 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:15:11 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:15:11 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 17:15:11 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 17:15:11 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:15:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 17:15:11 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:15:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/03/16 17:15:11 INFO PythonRunner: Times: total = 31, boot = -40, init = 70, finish = 1
16/03/16 17:15:11 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/03/16 17:15:11 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 78 ms on localhost (1/2)
16/03/16 17:15:11 INFO PythonRunner: Times: total = 293, boot = 292, init = 0, finish = 1
16/03/16 17:15:11 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/16 17:15:11 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.296 s
16/03/16 17:15:11 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.182754 s
16/03/16 17:15:11 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 308 ms on localhost (2/2)
16/03/16 17:15:11 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 17:15:11 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:15:11 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:15:11 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:15:11 INFO DAGScheduler: Parents of final stage: List()
16/03/16 17:15:11 INFO DAGScheduler: Missing parents: List()
16/03/16 17:15:11 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:15:11 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=550518128
16/03/16 17:15:11 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 525.0 MB)
16/03/16 17:15:11 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=550518128
16/03/16 17:15:11 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 525.0 MB)
16/03/16 17:15:11 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:57487 (size: 3.3 KB, free: 525.0 MB)
16/03/16 17:15:11 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 17:15:11 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:15:11 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 17:15:11 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/16 17:15:11 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/03/16 17:15:11 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 17:15:11 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 17:15:11 INFO PythonRunner: Times: total = 75, boot = -147, init = 222, finish = 0
16/03/16 17:15:11 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/16 17:15:11 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 84 ms on localhost (1/2)
16/03/16 17:15:11 INFO PythonRunner: Times: total = 118, boot = 118, init = 0, finish = 0
16/03/16 17:15:11 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/03/16 17:15:11 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 127 ms on localhost (2/2)
16/03/16 17:15:11 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 17:15:11 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.128 s
16/03/16 17:15:11 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.147375 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 17:15:11 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 17:15:11 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 17:15:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 17:15:11 INFO MemoryStore: MemoryStore cleared
16/03/16 17:15:11 INFO BlockManager: BlockManager stopped
16/03/16 17:15:11 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 17:15:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 17:15:11 INFO SparkContext: Successfully stopped SparkContext
16/03/16 17:15:11 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 17:15:11 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 17:15:11 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'astatine']
16/03/16 17:15:12 INFO SparkContext: Running Spark version 1.5.2
16/03/16 17:15:12 INFO SecurityManager: Changing view acls to: root
16/03/16 17:15:12 INFO SecurityManager: Changing modify acls to: root
16/03/16 17:15:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 17:15:12 INFO Slf4jLogger: Slf4jLogger started
16/03/16 17:15:12 INFO Remoting: Starting remoting
16/03/16 17:15:12 INFO Utils: Successfully started service 'sparkDriver' on port 59045.
16/03/16 17:15:12 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:59045]
16/03/16 17:15:12 INFO SparkEnv: Registering MapOutputTracker
16/03/16 17:15:12 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 17:15:12 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-403c36e4-1792-4d0c-bba1-16ed0a4a2a8b
16/03/16 17:15:12 INFO MemoryStore: MemoryStore started with capacity 524.3 MB
16/03/16 17:15:12 INFO HttpFileServer: HTTP File server directory is /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/httpd-840f273b-a27c-4c5c-8840-1beee07b1912
16/03/16 17:15:12 INFO HttpServer: Starting HTTP Server
16/03/16 17:15:12 INFO Utils: Successfully started service 'HTTP file server' on port 38891.
16/03/16 17:15:12 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 17:15:13 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 17:15:13 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 17:15:13 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-3b58bd5e-1d3a-4127-bbf4-5f6e28dd1ff6/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 17:15:13 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128713095
16/03/16 17:15:13 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 17:15:13 INFO Executor: Starting executor ID driver on host localhost
16/03/16 17:15:13 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39865.
16/03/16 17:15:13 INFO NettyBlockTransferService: Server created on 39865
16/03/16 17:15:13 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 17:15:13 INFO BlockManagerMasterEndpoint: Registering block manager localhost:39865 with 524.3 MB RAM, BlockManagerId(driver, localhost, 39865)
16/03/16 17:15:13 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): person
16/03/16 17:15:13 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:15:13 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:15:13 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:15:13 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:15:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 17:15:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 17:15:13 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:15:13 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=549810339
16/03/16 17:15:13 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 524.3 MB)
16/03/16 17:15:13 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=549810339
16/03/16 17:15:13 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 524.3 MB)
16/03/16 17:15:13 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:39865 (size: 4.1 KB, free: 524.3 MB)
16/03/16 17:15:13 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 17:15:13 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:15:13 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 17:15:13 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/16 17:15:13 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/16 17:15:13 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 17:15:13 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128713095
16/03/16 17:15:13 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 17:15:13 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-3b58bd5e-1d3a-4127-bbf4-5f6e28dd1ff6/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: area
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: bend
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: giant
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: issue
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): adding to parents: syn =  Synset('colossus.n.02') ; keyword:  person  in syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= [u'giant']
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: astatine
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: present
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: planning
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: permission
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: economy
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: area
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: composition
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: agency
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 17:15:24 INFO PythonRunner: Times: total = 11089, boot = 653, init = 432, finish = 10004
16/03/16 17:15:24 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/16 17:15:24 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 11197 ms on localhost (1/2)
16/03/16 17:15:24 INFO PythonRunner: Times: total = 11121, boot = 661, init = 641, finish = 9819
16/03/16 17:15:24 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/16 17:15:24 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 11.232 s
16/03/16 17:15:24 INFO DAGScheduler: looking for newly runnable stages
16/03/16 17:15:24 INFO DAGScheduler: running: Set()
16/03/16 17:15:24 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 17:15:24 INFO DAGScheduler: failed: Set()
16/03/16 17:15:24 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 17:15:24 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 17:15:24 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=549810339
16/03/16 17:15:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 524.3 MB)
16/03/16 17:15:24 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=549810339
16/03/16 17:15:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 524.3 MB)
16/03/16 17:15:24 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 11231 ms on localhost (2/2)
16/03/16 17:15:24 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 17:15:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:39865 (size: 3.0 KB, free: 524.3 MB)
16/03/16 17:15:24 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 17:15:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:15:24 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 17:15:24 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:15:24 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:15:24 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 17:15:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:15:24 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 17:15:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:15:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 17:15:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
reduceFunction_Parents(): returns= ['None', 'None', u'giant']
16/03/16 17:15:24 INFO PythonRunner: Times: total = 210, boot = 209, init = 1, finish = 0
16/03/16 17:15:24 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1281 bytes result sent to driver
16/03/16 17:15:24 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 238 ms on localhost (1/2)
16/03/16 17:15:24 INFO PythonRunner: Times: total = 407, boot = 406, init = 1, finish = 0
16/03/16 17:15:24 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/16 17:15:24 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.412 s
16/03/16 17:15:24 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 11.706026 s
16/03/16 17:15:24 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 428 ms on localhost (2/2)
16/03/16 17:15:24 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 17:15:25 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:15:25 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:15:25 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:15:25 INFO DAGScheduler: Parents of final stage: List()
16/03/16 17:15:25 INFO DAGScheduler: Missing parents: List()
16/03/16 17:15:25 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:15:25 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=549810339
16/03/16 17:15:25 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 524.3 MB)
16/03/16 17:15:25 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=549810339
16/03/16 17:15:25 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 524.3 MB)
16/03/16 17:15:25 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:39865 (size: 3.3 KB, free: 524.3 MB)
16/03/16 17:15:25 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 17:15:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:15:25 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 17:15:25 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/16 17:15:25 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2362 bytes)
16/03/16 17:15:25 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 17:15:25 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 17:15:25 INFO PythonRunner: Times: total = 32, boot = -47, init = 78, finish = 1
16/03/16 17:15:25 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/16 17:15:25 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 47 ms on localhost (1/2)
16/03/16 17:15:25 INFO PythonRunner: Times: total = 187, boot = 186, init = 1, finish = 0
16/03/16 17:15:25 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1349 bytes result sent to driver
16/03/16 17:15:25 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 200 ms on localhost (2/2)
16/03/16 17:15:25 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 17:15:25 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.202 s
16/03/16 17:15:25 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.210278 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 17:15:25 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 17:15:25 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 17:15:25 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 17:15:25 INFO MemoryStore: MemoryStore cleared
16/03/16 17:15:25 INFO BlockManager: BlockManager stopped
16/03/16 17:15:25 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 17:15:25 INFO SparkContext: Successfully stopped SparkContext
16/03/16 17:15:25 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 17:15:25 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 17:15:25 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'giant']
16/03/16 17:15:26 INFO SparkContext: Running Spark version 1.5.2
16/03/16 17:15:26 INFO SecurityManager: Changing view acls to: root
16/03/16 17:15:26 INFO SecurityManager: Changing modify acls to: root
16/03/16 17:15:26 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 17:15:26 INFO Slf4jLogger: Slf4jLogger started
16/03/16 17:15:26 INFO Remoting: Starting remoting
16/03/16 17:15:26 INFO Utils: Successfully started service 'sparkDriver' on port 39373.
16/03/16 17:15:26 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:39373]
16/03/16 17:15:26 INFO SparkEnv: Registering MapOutputTracker
16/03/16 17:15:26 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 17:15:26 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a4027343-3d55-4a11-a714-8d7d4c8b0b32
16/03/16 17:15:26 INFO MemoryStore: MemoryStore started with capacity 524.3 MB
16/03/16 17:15:26 INFO HttpFileServer: HTTP File server directory is /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/httpd-55c6c737-3bf2-4882-9c96-39b88c0b5416
16/03/16 17:15:26 INFO HttpServer: Starting HTTP Server
16/03/16 17:15:26 INFO Utils: Successfully started service 'HTTP file server' on port 55512.
16/03/16 17:15:26 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 17:15:26 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 17:15:26 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 17:15:26 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-c7baec52-29ac-45bc-a549-56037d9fb1ca/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 17:15:26 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128726887
16/03/16 17:15:26 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 17:15:26 INFO Executor: Starting executor ID driver on host localhost
16/03/16 17:15:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43481.
16/03/16 17:15:26 INFO NettyBlockTransferService: Server created on 43481
16/03/16 17:15:26 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 17:15:26 INFO BlockManagerMasterEndpoint: Registering block manager localhost:43481 with 524.3 MB RAM, BlockManagerId(driver, localhost, 43481)
16/03/16 17:15:27 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): reputation
16/03/16 17:15:27 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:15:27 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:15:27 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:15:27 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:15:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 17:15:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 17:15:27 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:15:27 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=549810339
16/03/16 17:15:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 524.3 MB)
16/03/16 17:15:27 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=549810339
16/03/16 17:15:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 524.3 MB)
16/03/16 17:15:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:43481 (size: 4.1 KB, free: 524.3 MB)
16/03/16 17:15:27 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 17:15:27 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:15:27 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 17:15:27 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/16 17:15:27 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/16 17:15:27 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 17:15:27 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128726887
16/03/16 17:15:27 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 17:15:27 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-c7baec52-29ac-45bc-a549-56037d9fb1ca/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: set
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: issue
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: planning
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: permission
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: economy
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: composition
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: agency
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 17:15:37 INFO PythonRunner: Times: total = 9984, boot = 635, init = 552, finish = 8797
16/03/16 17:15:37 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/16 17:15:37 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 10081 ms on localhost (1/2)
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: bend
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: giant
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): adding to parents: syn =  Synset('colossus.n.02') ; keyword:  reputation  in syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= [u'giant']
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: astatine
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: present
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: area
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
16/03/16 17:15:37 INFO PythonRunner: Times: total = 10476, boot = 627, init = 701, finish = 9148
16/03/16 17:15:37 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/16 17:15:37 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 10.576 s
16/03/16 17:15:37 INFO DAGScheduler: looking for newly runnable stages
16/03/16 17:15:37 INFO DAGScheduler: running: Set()
16/03/16 17:15:37 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 17:15:37 INFO DAGScheduler: failed: Set()
16/03/16 17:15:37 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 17:15:37 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 17:15:37 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=549810339
16/03/16 17:15:37 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 10573 ms on localhost (2/2)
16/03/16 17:15:37 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 17:15:37 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 524.3 MB)
16/03/16 17:15:37 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=549810339
16/03/16 17:15:37 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 524.3 MB)
16/03/16 17:15:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:43481 (size: 3.0 KB, free: 524.3 MB)
16/03/16 17:15:37 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 17:15:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:15:37 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 17:15:37 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:15:37 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:15:37 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 17:15:37 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 17:15:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:15:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 17:15:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:15:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
reduceFunction_Parents(): returns= ['None', 'None', u'giant']
16/03/16 17:15:37 INFO PythonRunner: Times: total = 40, boot = -291, init = 330, finish = 1
16/03/16 17:15:37 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1281 bytes result sent to driver
16/03/16 17:15:37 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 68 ms on localhost (1/2)
16/03/16 17:15:37 INFO PythonRunner: Times: total = 250, boot = 249, init = 0, finish = 1
16/03/16 17:15:37 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/16 17:15:38 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 529 ms on localhost (2/2)
16/03/16 17:15:38 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 17:15:38 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.515 s
16/03/16 17:15:38 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 11.132637 s
16/03/16 17:15:38 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:43481 in memory (size: 4.1 KB, free: 524.3 MB)
16/03/16 17:15:38 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:15:38 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:15:38 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:15:38 INFO DAGScheduler: Parents of final stage: List()
16/03/16 17:15:38 INFO DAGScheduler: Missing parents: List()
16/03/16 17:15:38 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:15:38 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=8040, maxMem=549810339
16/03/16 17:15:38 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 524.3 MB)
16/03/16 17:15:38 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=13856, maxMem=549810339
16/03/16 17:15:38 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 524.3 MB)
16/03/16 17:15:38 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:43481 (size: 3.3 KB, free: 524.3 MB)
16/03/16 17:15:38 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 17:15:38 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:15:38 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 17:15:38 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/16 17:15:38 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2362 bytes)
16/03/16 17:15:38 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 17:15:38 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 17:15:38 INFO PythonRunner: Times: total = 29, boot = -162, init = 191, finish = 0
16/03/16 17:15:38 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1349 bytes result sent to driver
16/03/16 17:15:38 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 49 ms on localhost (1/2)
16/03/16 17:15:38 INFO PythonRunner: Times: total = 59, boot = -367, init = 426, finish = 0
16/03/16 17:15:38 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/16 17:15:38 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 78 ms on localhost (2/2)
16/03/16 17:15:38 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 17:15:38 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.079 s
16/03/16 17:15:38 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.087147 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 17:15:38 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 17:15:38 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 17:15:38 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 17:15:38 INFO MemoryStore: MemoryStore cleared
16/03/16 17:15:38 INFO BlockManager: BlockManager stopped
16/03/16 17:15:38 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 17:15:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 17:15:38 INFO SparkContext: Successfully stopped SparkContext
16/03/16 17:15:38 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 17:15:38 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 17:15:38 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'giant']
16/03/16 17:15:39 INFO SparkContext: Running Spark version 1.5.2
16/03/16 17:15:39 INFO SecurityManager: Changing view acls to: root
16/03/16 17:15:39 INFO SecurityManager: Changing modify acls to: root
16/03/16 17:15:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 17:15:39 INFO Slf4jLogger: Slf4jLogger started
16/03/16 17:15:39 INFO Remoting: Starting remoting
16/03/16 17:15:39 INFO Utils: Successfully started service 'sparkDriver' on port 38763.
16/03/16 17:15:39 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:38763]
16/03/16 17:15:39 INFO SparkEnv: Registering MapOutputTracker
16/03/16 17:15:39 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 17:15:39 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-171c720d-4519-40f4-bb38-88fad8b68d93
16/03/16 17:15:39 INFO MemoryStore: MemoryStore started with capacity 526.6 MB
16/03/16 17:15:39 INFO HttpFileServer: HTTP File server directory is /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/httpd-5389d3d7-c015-48e5-8161-fb323bb0af10
16/03/16 17:15:39 INFO HttpServer: Starting HTTP Server
16/03/16 17:15:39 INFO Utils: Successfully started service 'HTTP file server' on port 55761.
16/03/16 17:15:39 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 17:15:39 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 17:15:39 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 17:15:39 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-b8d9f9c7-abbc-467d-859e-deb4d078d1b3/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 17:15:39 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128739684
16/03/16 17:15:39 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 17:15:39 INFO Executor: Starting executor ID driver on host localhost
16/03/16 17:15:39 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54077.
16/03/16 17:15:39 INFO NettyBlockTransferService: Server created on 54077
16/03/16 17:15:39 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 17:15:39 INFO BlockManagerMasterEndpoint: Registering block manager localhost:54077 with 526.6 MB RAM, BlockManagerId(driver, localhost, 54077)
16/03/16 17:15:39 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): time
16/03/16 17:15:39 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:15:39 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:15:39 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:15:39 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:15:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 17:15:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 17:15:39 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:15:39 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=552216821
16/03/16 17:15:39 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 526.6 MB)
16/03/16 17:15:39 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=552216821
16/03/16 17:15:39 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 526.6 MB)
16/03/16 17:15:39 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:54077 (size: 4.1 KB, free: 526.6 MB)
16/03/16 17:15:39 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 17:15:39 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:15:39 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 17:15:39 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/16 17:15:39 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/16 17:15:39 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 17:15:39 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128739684
16/03/16 17:15:39 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 17:15:39 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-b8d9f9c7-abbc-467d-859e-deb4d078d1b3/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: set
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: issue
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: planning
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: permission
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: economy
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: composition
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: bend
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines():asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: agency
 time
mapFunction_Parents(): keyword: time ; prevleveltokens: giant
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: astatine
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [16/03/16 17:15:49 INFO PythonRunner: Times: total = 9592, boot = 558, init = 419, finish = 8615
'None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: present
16/03/16 17:15:49 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  time  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present'16/03/16 17:15:49 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9707 ms on localhost (1/2)
]
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: area
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/16 17:15:49 INFO PythonRunner: Times: total = 9664, boot = 553, init = 587, finish = 8524
16/03/16 17:15:49 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/16 17:15:49 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9773 ms on localhost (2/2)
16/03/16 17:15:49 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 17:15:49 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.766 s
16/03/16 17:15:49 INFO DAGScheduler: looking for newly runnable stages
16/03/16 17:15:49 INFO DAGScheduler: running: Set()
16/03/16 17:15:49 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 17:15:49 INFO DAGScheduler: failed: Set()
16/03/16 17:15:49 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 17:15:49 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 17:15:49 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=552216821
16/03/16 17:15:49 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 526.6 MB)
16/03/16 17:15:49 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=552216821
16/03/16 17:15:49 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 526.6 MB)
16/03/16 17:15:49 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:54077 (size: 3.0 KB, free: 526.6 MB)
16/03/16 17:15:49 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 17:15:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:15:49 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 17:15:49 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:15:49 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:15:49 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 17:15:49 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 17:15:49 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:15:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 17:15:49 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:15:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', 'None', u'present']
16/03/16 17:15:49 INFO PythonRunner: Times: total = 199, boot = 197, init = 1, finish = 1
16/03/16 17:15:49 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/16 17:15:49 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 226 ms on localhost (1/2)
16/03/16 17:15:49 INFO PythonRunner: Times: total = 295, boot = 294, init = 0, finish = 1
16/03/16 17:15:49 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/16 17:15:49 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.290 s
16/03/16 17:15:49 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 306 ms on localhost (2/2)
16/03/16 17:15:49 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 10.133261 s
16/03/16 17:15:49 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 17:15:50 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:15:50 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:15:50 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:15:50 INFO DAGScheduler: Parents of final stage: List()
16/03/16 17:15:50 INFO DAGScheduler: Missing parents: List()
16/03/16 17:15:50 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:15:50 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=552216821
16/03/16 17:15:50 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 526.6 MB)
16/03/16 17:15:50 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=552216821
16/03/16 17:15:50 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 526.6 MB)
16/03/16 17:15:50 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:54077 (size: 3.3 KB, free: 526.6 MB)
16/03/16 17:15:50 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 17:15:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:15:50 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 17:15:50 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/16 17:15:50 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/16 17:15:50 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 17:15:50 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 17:15:50 INFO PythonRunner: Times: total = 20, boot = -67, init = 87, finish = 0
16/03/16 17:15:50 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/16 17:15:50 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 124 ms on localhost (1/2)
16/03/16 17:15:50 INFO PythonRunner: Times: total = 146, boot = 146, init = 0, finish = 0
16/03/16 17:15:50 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1351 bytes result sent to driver
16/03/16 17:15:50 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 157 ms on localhost (2/2)
16/03/16 17:15:50 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 17:15:50 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.161 s
16/03/16 17:15:50 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.183237 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 17:15:50 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 17:15:50 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 17:15:50 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 17:15:50 INFO MemoryStore: MemoryStore cleared
16/03/16 17:15:50 INFO BlockManager: BlockManager stopped
16/03/16 17:15:50 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 17:15:50 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 17:15:50 INFO SparkContext: Successfully stopped SparkContext
16/03/16 17:15:50 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 17:15:50 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'present']
16/03/16 17:15:51 INFO SparkContext: Running Spark version 1.5.2
16/03/16 17:15:51 INFO SecurityManager: Changing view acls to: root
16/03/16 17:15:51 INFO SecurityManager: Changing modify acls to: root
16/03/16 17:15:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 17:15:51 INFO Slf4jLogger: Slf4jLogger started
16/03/16 17:15:51 INFO Remoting: Starting remoting
16/03/16 17:15:51 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:59931]
16/03/16 17:15:51 INFO Utils: Successfully started service 'sparkDriver' on port 59931.
16/03/16 17:15:51 INFO SparkEnv: Registering MapOutputTracker
16/03/16 17:15:51 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 17:15:51 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-447df13f-cb76-4195-8262-a67534a0efd3
16/03/16 17:15:51 INFO MemoryStore: MemoryStore started with capacity 526.6 MB
16/03/16 17:15:51 INFO HttpFileServer: HTTP File server directory is /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/httpd-9f586c99-4d22-4c28-90d6-c54b64d0ffe7
16/03/16 17:15:51 INFO HttpServer: Starting HTTP Server
16/03/16 17:15:51 INFO Utils: Successfully started service 'HTTP file server' on port 47057.
16/03/16 17:15:51 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 17:15:51 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 17:15:51 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 17:15:51 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-a0b89a9e-1ba0-40d9-ad78-73ed75ab0b24/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 17:15:51 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128751678
16/03/16 17:15:51 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 17:15:51 INFO Executor: Starting executor ID driver on host localhost
16/03/16 17:15:51 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56446.
16/03/16 17:15:51 INFO NettyBlockTransferService: Server created on 56446
16/03/16 17:15:51 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 17:15:51 INFO BlockManagerMasterEndpoint: Registering block manager localhost:56446 with 526.6 MB RAM, BlockManagerId(driver, localhost, 56446)
16/03/16 17:15:51 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): position
16/03/16 17:15:51 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:15:51 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:15:51 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:15:51 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:15:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 17:15:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 17:15:51 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:15:51 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=552216821
16/03/16 17:15:51 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 526.6 MB)
16/03/16 17:15:51 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=552216821
16/03/16 17:15:51 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 526.6 MB)
16/03/16 17:15:51 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:56446 (size: 4.1 KB, free: 526.6 MB)
16/03/16 17:15:51 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 17:15:51 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:15:51 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 17:15:51 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/16 17:15:51 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/16 17:15:51 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 17:15:51 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128751678
16/03/16 17:15:51 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 17:15:51 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-a0b89a9e-1ba0-40d9-ad78-73ed75ab0b24/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: set
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: issue
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: planning
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: permission
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: economy
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: composition
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: agency
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 17:16:02 INFO PythonRunner: Times: total = 10486, boot = 485, init = 645, finish = 9356
16/03/16 17:16:02 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/16 17:16:02 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 10578 ms on localhost (1/2)
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: bend
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: giant
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: astatine
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: present
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  position  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: area
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
16/03/16 17:16:03 INFO PythonRunner: Times: total = 11082, boot = 478, init = 666, finish = 9938
16/03/16 17:16:03 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/16 17:16:03 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 11.160 s
16/03/16 17:16:03 INFO DAGScheduler: looking for newly runnable stages
16/03/16 17:16:03 INFO DAGScheduler: running: Set()
16/03/16 17:16:03 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 17:16:03 INFO DAGScheduler: failed: Set()
16/03/16 17:16:03 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 17:16:03 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 17:16:03 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=552216821
16/03/16 17:16:03 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 526.6 MB)
16/03/16 17:16:03 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 11164 ms on localhost (2/2)
16/03/16 17:16:03 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 17:16:03 INFO MemoryStore: ensureFreeSpace(3058) called with curMem=15700, maxMem=552216821
16/03/16 17:16:03 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 526.6 MB)
16/03/16 17:16:03 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:56446 (size: 3.0 KB, free: 526.6 MB)
16/03/16 17:16:03 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 17:16:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:16:03 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 17:16:03 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:16:03 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:16:03 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 17:16:03 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:16:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 17:16:03 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 17:16:03 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:16:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 17:16:03 INFO PythonRunner: Times: total = 53, boot = -411, init = 464, finish = 0
16/03/16 17:16:03 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/16 17:16:03 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 81 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'metropolitan']
16/03/16 17:16:03 INFO PythonRunner: Times: total = 199, boot = 198, init = 0, finish = 1
16/03/16 17:16:03 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1288 bytes result sent to driver
16/03/16 17:16:03 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.228 s
16/03/16 17:16:03 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 11.423939 s
16/03/16 17:16:03 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 225 ms on localhost (2/2)
16/03/16 17:16:03 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 17:16:03 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:16:03 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:16:03 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:16:03 INFO DAGScheduler: Parents of final stage: List()
16/03/16 17:16:03 INFO DAGScheduler: Missing parents: List()
16/03/16 17:16:03 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:16:03 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18758, maxMem=552216821
16/03/16 17:16:03 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 526.6 MB)
16/03/16 17:16:03 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24574, maxMem=552216821
16/03/16 17:16:03 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 526.6 MB)
16/03/16 17:16:03 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:56446 (size: 3.3 KB, free: 526.6 MB)
16/03/16 17:16:03 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 17:16:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:16:03 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 17:16:03 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/16 17:16:03 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2369 bytes)
16/03/16 17:16:03 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 17:16:03 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 17:16:03 INFO PythonRunner: Times: total = 107, boot = 107, init = 0, finish = 0
16/03/16 17:16:03 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/16 17:16:03 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 116 ms on localhost (1/2)
16/03/16 17:16:03 INFO PythonRunner: Times: total = 116, boot = 116, init = 0, finish = 0
16/03/16 17:16:03 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1356 bytes result sent to driver
16/03/16 17:16:03 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 123 ms on localhost (2/2)
16/03/16 17:16:03 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 17:16:03 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.122 s
16/03/16 17:16:03 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.148869 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 17:16:03 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 17:16:03 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 17:16:03 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 17:16:03 INFO MemoryStore: MemoryStore cleared
16/03/16 17:16:03 INFO BlockManager: BlockManager stopped
16/03/16 17:16:03 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 17:16:03 INFO SparkContext: Successfully stopped SparkContext
16/03/16 17:16:03 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 17:16:03 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 17:16:03 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 17:16:03 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'metropolitan']
16/03/16 17:16:04 INFO SparkContext: Running Spark version 1.5.2
16/03/16 17:16:04 INFO SecurityManager: Changing view acls to: root
16/03/16 17:16:04 INFO SecurityManager: Changing modify acls to: root
16/03/16 17:16:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 17:16:04 INFO Slf4jLogger: Slf4jLogger started
16/03/16 17:16:04 INFO Remoting: Starting remoting
16/03/16 17:16:04 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:42719]
16/03/16 17:16:04 INFO Utils: Successfully started service 'sparkDriver' on port 42719.
16/03/16 17:16:04 INFO SparkEnv: Registering MapOutputTracker
16/03/16 17:16:04 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 17:16:04 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2e966bf4-df24-450c-b806-8b7f02e3ede3
16/03/16 17:16:04 INFO MemoryStore: MemoryStore started with capacity 526.6 MB
16/03/16 17:16:04 INFO HttpFileServer: HTTP File server directory is /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/httpd-b8910b70-bc4b-4f9d-aa9f-e7591487b993
16/03/16 17:16:04 INFO HttpServer: Starting HTTP Server
16/03/16 17:16:04 INFO Utils: Successfully started service 'HTTP file server' on port 49801.
16/03/16 17:16:04 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 17:16:05 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 17:16:05 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 17:16:05 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-057fde2b-b772-4711-8fc3-31fa24c21a61/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 17:16:05 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128765084
16/03/16 17:16:05 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 17:16:05 INFO Executor: Starting executor ID driver on host localhost
16/03/16 17:16:05 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53306.
16/03/16 17:16:05 INFO NettyBlockTransferService: Server created on 53306
16/03/16 17:16:05 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 17:16:05 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53306 with 526.6 MB RAM, BlockManagerId(driver, localhost, 53306)
16/03/16 17:16:05 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): quantity
16/03/16 17:16:05 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:16:05 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:16:05 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:16:05 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:16:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 17:16:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 17:16:05 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:16:05 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=552216821
16/03/16 17:16:05 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 526.6 MB)
16/03/16 17:16:05 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=552216821
16/03/16 17:16:05 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 526.6 MB)
16/03/16 17:16:05 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53306 (size: 4.1 KB, free: 526.6 MB)
16/03/16 17:16:05 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 17:16:05 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:16:05 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 17:16:05 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/16 17:16:05 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/16 17:16:05 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 17:16:05 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128765084
16/03/16 17:16:05 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 17:16:05 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-057fde2b-b772-4711-8fc3-31fa24c21a61/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: area
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: issue
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: planning
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: permission
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: economy
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: composition
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: agency
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 17:16:13 INFO PythonRunner: Times: total = 8273, boot = 483, init = 391, finish = 7399
16/03/16 17:16:13 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/16 17:16:13 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8356 ms on localhost (1/2)
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: bend
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: giant
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: astatine
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: present
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: area
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 17:16:13 INFO PythonRunner: Times: total = 8493, boot = 471, init = 398, finish = 7624
16/03/16 17:16:13 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/16 17:16:13 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.582 s
16/03/16 17:16:13 INFO DAGScheduler: looking for newly runnable stages
16/03/16 17:16:13 INFO DAGScheduler: running: Set()
16/03/16 17:16:13 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 17:16:13 INFO DAGScheduler: failed: Set()
16/03/16 17:16:13 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 17:16:13 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 17:16:13 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=552216821
16/03/16 17:16:13 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 526.6 MB)
16/03/16 17:16:13 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=552216821
16/03/16 17:16:13 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 526.6 MB)
16/03/16 17:16:13 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8571 ms on localhost (2/2)
16/03/16 17:16:13 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 17:16:13 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53306 (size: 3.0 KB, free: 526.6 MB)
16/03/16 17:16:13 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 17:16:13 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:16:13 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 17:16:13 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:16:13 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:16:13 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 17:16:13 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 17:16:13 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:16:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/16 17:16:13 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:16:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/03/16 17:16:13 INFO PythonRunner: Times: total = 74, boot = 23, init = 51, finish = 0
16/03/16 17:16:13 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/16 17:16:13 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 101 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None']
16/03/16 17:16:14 INFO PythonRunner: Times: total = 279, boot = 278, init = 0, finish = 1
16/03/16 17:16:14 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1269 bytes result sent to driver
16/03/16 17:16:14 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.286 s
16/03/16 17:16:14 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.928749 s
16/03/16 17:16:14 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 303 ms on localhost (2/2)
16/03/16 17:16:14 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 17:16:14 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 17:16:14 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 17:16:14 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:16:14 INFO DAGScheduler: Parents of final stage: List()
16/03/16 17:16:14 INFO DAGScheduler: Missing parents: List()
16/03/16 17:16:14 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 17:16:14 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=552216821
16/03/16 17:16:14 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 526.6 MB)
16/03/16 17:16:14 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=552216821
16/03/16 17:16:14 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 526.6 MB)
16/03/16 17:16:14 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53306 (size: 3.3 KB, free: 526.6 MB)
16/03/16 17:16:14 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 17:16:14 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 17:16:14 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 17:16:14 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/16 17:16:14 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2350 bytes)
16/03/16 17:16:14 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 17:16:14 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 17:16:14 INFO PythonRunner: Times: total = 71, boot = -81, init = 152, finish = 0
16/03/16 17:16:14 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1337 bytes result sent to driver
16/03/16 17:16:14 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 86 ms on localhost (1/2)
16/03/16 17:16:14 INFO PythonRunner: Times: total = 225, boot = 225, init = 0, finish = 0
16/03/16 17:16:14 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/16 17:16:14 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 236 ms on localhost (2/2)
16/03/16 17:16:14 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 17:16:14 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.235 s
16/03/16 17:16:14 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.249851 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 17:16:14 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 17:16:14 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 17:16:14 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 17:16:14 INFO MemoryStore: MemoryStore cleared
16/03/16 17:16:14 INFO BlockManager: BlockManager stopped
16/03/16 17:16:14 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 17:16:14 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 17:16:14 INFO SparkContext: Successfully stopped SparkContext
16/03/16 17:16:14 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 17:16:14 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None']
InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:freqterms1= [u'serving', u'Madras', u'Bengal', u'course', u'relation', u'geography', u'group', u'decay', u'program', u'Tamil', u'exceptional', u'Bay', u'formulating', u'serves', u'item', u'miles', u'unstable', u'including', u'people', u'series', u'Christianity', u'culture', u'meters', u'special', u'0.621371', u'Orthodox', u'definite', u'boundary', u'business', u'importance', u'equivalent', u'thorium', u'approval', u'providing', u'region', u'title', u'equal', u'length', u'resulting', u'act', u'action', u'whole', u'businesses', u'1000', u'formerly', u'period', u'highly', u'production', u'indefinite', u'unit', u'city', u'use', u'consumption', u'Eastern', u'stretch', u'archbishop', u'system', u'halogen', u'continuous', u'western', u'particular', u'given', u'kind', u'official', u'patriarch', u'Church', u'distribution', u'property', u'distinguished', u'metric', u'heaviest', u'purposes', u'general', u'something', u'bishop', u'things', u'belong', u'uranium', u'arrangement', u'parts', u'speech', u'geographical', u'spatial', u'Nadu', u'circular', u'product', u'used', u'usually', u'moment', u'purpose', u'segment', u'radioactive', u'happening', u'curve', u'together', u'element', u'person', u'reputation', u'time', u'position', u'quantity']
16/03/16 17:16:15 INFO SparkContext: Running Spark version 1.5.2
16/03/16 17:16:15 INFO SecurityManager: Changing view acls to: root
16/03/16 17:16:15 INFO SecurityManager: Changing modify acls to: root
16/03/16 17:16:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 17:16:15 INFO Slf4jLogger: Slf4jLogger started
16/03/16 17:16:15 INFO Remoting: Starting remoting
16/03/16 17:16:15 INFO Utils: Successfully started service 'sparkDriver' on port 36292.
16/03/16 17:16:15 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:36292]
16/03/16 17:16:15 INFO SparkEnv: Registering MapOutputTracker
16/03/16 17:16:15 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 17:16:15 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1d9a8f01-f2b1-43d1-b8d4-1da4da34e828
16/03/16 17:16:15 INFO MemoryStore: MemoryStore started with capacity 526.0 MB
16/03/16 17:16:15 INFO HttpFileServer: HTTP File server directory is /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/httpd-f328a45d-d859-4425-b4d0-5f20672f3a28
16/03/16 17:16:15 INFO HttpServer: Starting HTTP Server
16/03/16 17:16:15 INFO Utils: Successfully started service 'HTTP file server' on port 46420.
16/03/16 17:16:15 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 17:16:15 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 17:16:15 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 17:16:15 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-9f8ca1a8-e6ba-47eb-b755-8d429e6bea55/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 17:16:15 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128775778
16/03/16 17:16:15 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 17:16:15 INFO Executor: Starting executor ID driver on host localhost
16/03/16 17:16:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45907.
16/03/16 17:16:15 INFO NettyBlockTransferService: Server created on 45907
16/03/16 17:16:15 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 17:16:15 INFO BlockManagerMasterEndpoint: Registering block manager localhost:45907 with 526.0 MB RAM, BlockManagerId(driver, localhost, 45907)
16/03/16 17:16:15 INFO BlockManagerMaster: Registered BlockManager
Spark_MapReduce(): wordsatthislevel: [u'serving', u'Madras', u'Bengal', u'course', u'relation', u'geography', u'group', u'decay', u'program', u'Tamil', u'exceptional', u'Bay', u'formulating', u'serves', u'item', u'miles', u'unstable', u'including', u'people', u'series', u'Christianity', u'culture', u'meters', u'special', u'0.621371', u'Orthodox', u'definite', u'boundary', u'business', u'importance', u'equivalent', u'thorium', u'approval', u'providing', u'region', u'title', u'equal', u'length', u'resulting', u'act', u'action', u'whole', u'businesses', u'1000', u'formerly', u'period', u'highly', u'production', u'indefinite', u'unit', u'city', u'use', u'consumption', u'Eastern', u'stretch', u'archbishop', u'system', u'halogen', u'continuous', u'western', u'particular', u'given', u'kind', u'official', u'patriarch', u'Church', u'distribution', u'property', u'distinguished', u'metric', u'heaviest', u'purposes', u'general', u'something', u'bishop', u'things', u'belong', u'uranium', u'arrangement', u'parts', u'speech', u'geographical', u'spatial', u'Nadu', u'circular', u'product', u'used', u'usually', u'moment', u'purpose', u'segment', u'radioactive', u'happening', u'curve', u'together', u'element', u'person', u'reputation', u'time', u'position', u'quantity']
16/03/16 17:16:15 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230
16/03/16 17:16:15 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/16 17:16:15 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) with 2 output partitions
16/03/16 17:16:15 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/16 17:16:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 17:16:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 17:16:15 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230), which has no missing parents
16/03/16 17:16:15 INFO MemoryStore: ensureFreeSpace(6552) called with curMem=0, maxMem=551509032
16/03/16 17:16:15 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 526.0 MB)
16/03/16 17:16:15 INFO MemoryStore: ensureFreeSpace(4139) called with curMem=6552, maxMem=551509032
16/03/16 17:16:15 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 525.9 MB)
16/03/16 17:16:15 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:45907 (size: 4.0 KB, free: 526.0 MB)
16/03/16 17:16:15 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 17:16:15 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/16 17:16:15 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 17:16:15 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 3016 bytes)
16/03/16 17:16:15 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 3065 bytes)
16/03/16 17:16:15 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 17:16:15 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458128775778
16/03/16 17:16:15 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 17:16:15 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-707079cf-27f2-4340-b556-84ec2a4b23cc/userFiles-9f8ca1a8-e6ba-47eb-b755-8d429e6bea55/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
mapFunction(): freqterms1: city
mapFunction(): freqterms1: serving
mapFunction(): freqterms1: use
mapFunction(): freqterms1: consumption
mapFunction(): freqterms1: Eastern
mapFunction(): freqterms1: stretch
mapFunction(): freqterms1: archbishop
mapFunction(): freqterms1: system
mapFunction(): freqterms1: halogen
mapFunction(): freqterms1: continuous
mapFunction(): freqterms1: western
mapFunction(): freqterms1: particular
mapFunction(): freqterms1: Madras
mapFunction(): freqterms1: Bengal
mapFunction(): freqterms1: course
mapFunction(): freqterms1: relation
mapFunction(): freqterms1: given
mapFunction(): freqterms1: geography
mapFunction(): freqterms1: group
mapFunction(): freqterms1: decay
mapFunction(): freqterms1: program
mapFunction(): freqterms1: Tamil
mapFunction(): freqterms1: exceptional
mapFunction(): freqterms1: Bay
mapFunction(): freqterms1: formulating
mapFunction(): freqterms1: serves
mapFunction(): freqterms1: kind
mapFunction(): freqterms1: item
mapFunction(): freqterms1: miles
mapFunction(): freqterms1: official
mapFunction(): freqterms1: unstable
mapFunction(): freqterms1: patriarchmapFunction(): freqterms1: including

mapFunction(): freqterms1: mapFunction(): freqterms1: people
Church
mapFunction(): freqterms1: distribution
mapFunction(): freqterms1:mapFunction(): freqterms1: series
 property
mapFunction(): freqterms1: Christianity
mapFunction(): freqterms1: culture
mapFunction(): freqterms1: distinguished
mapFunction(): freqterms1: meters
mapFunction(): freqterms1: metric
mapFunction(): freqterms1: special
mapFunction(): freqterms1: heaviest
mapFunction(): freqterms1: 0.621371
mapFunction(): freqterms1: Orthodox
mapFunction(): freqterms1: definite
mapFunction(): freqterms1: boundary
mapFunction(): freqterms1: business
mapFunction(): freqterms1: importance
mapFunction(): freqterms1: equivalent
mapFunction(): freqterms1: purposes
mapFunction(): freqterms1: thorium
mapFunction(): freqterms1: approval
mapFunction(): freqterms1: providing
mapFunction(): freqterms1: region
mapFunction(): freqterms1: general
mapFunction(): freqterms1: title
mapFunction(): freqterms1: something
mapFunction(): freqterms1: bishop
mapFunction(): freqterms1: equal
mapFunction(): freqterms1: things
mapFunction(): freqterms1: length
mapFunction(): freqterms1: resulting
mapFunction(): freqterms1: act
mapFunction(): freqterms1: belong
mapFunction(): freqterms1: uranium
mapFunction(): freqterms1: arrangement
mapFunction(): freqterms1: action
mapFunction(): freqterms1: parts
mapFunction(): freqterms1: whole
mapFunction(): freqterms1: businesses
mapFunction(): freqterms1: 1000
mapFunction(): freqterms1: formerly
mapFunction(): freqterms1: period
mapFunction(): freqterms1: speech
mapFunction(): freqterms1: highly
mapFunction(): freqterms1:mapFunction(): freqterms1: production
 geographical
mapFunction(): freqterms1: indefinite
mapFunction(): freqterms1: unit
mapFunction(): freqterms1: spatial
mapFunction(): freqterms1: Nadu
mapFunction(): freqterms1: circular
mapFunction(): freqterms1: product
mapFunction(): freqterms1: used
16/03/16 17:16:25 INFO PythonRunner: Times: total = 9009, boot = 476, init = 409, finish = 8124
16/03/16 17:16:25 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/03/16 17:16:25 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9092 ms on localhost (1/2)
mapFunction(): freqterms1: usually
mapFunction(): freqterms1: moment
mapFunction(): freqterms1: purpose
mapFunction(): freqterms1: segment
mapFunction(): freqterms1: radioactive
mapFunction(): freqterms1: happening
mapFunction(): freqterms1: curve
mapFunction(): freqterms1: together
mapFunction(): freqterms1: element
mapFunction(): freqterms1: person
mapFunction(): freqterms1: reputation
mapFunction(): freqterms1: time
mapFunction(): freqterms1: position
mapFunction(): freqterms1: quantity
16/03/16 17:16:25 INFO PythonRunner: Times: total = 9252, boot = 474, init = 406, finish = 8372
16/03/16 17:16:25 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/03/16 17:16:25 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9312 ms on localhost (2/2)
16/03/16 17:16:25 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 17:16:25 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) finished in 9.318 s
16/03/16 17:16:25 INFO DAGScheduler: looking for newly runnable stages
16/03/16 17:16:25 INFO DAGScheduler: running: Set()
16/03/16 17:16:25 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 17:16:25 INFO DAGScheduler: failed: Set()
16/03/16 17:16:25 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 17:16:25 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230), which is now runnable
16/03/16 17:16:25 INFO MemoryStore: ensureFreeSpace(4976) called with curMem=10691, maxMem=551509032
16/03/16 17:16:25 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 525.9 MB)
16/03/16 17:16:25 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15667, maxMem=551509032
16/03/16 17:16:25 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 525.9 MB)
16/03/16 17:16:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:45907 (size: 3.0 KB, free: 526.0 MB)
16/03/16 17:16:25 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 17:16:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/16 17:16:25 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 17:16:25 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:16:25 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 17:16:25 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 17:16:25 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:16:25 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 17:16:25 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 17:16:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/16 17:16:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
16/03/16 17:16:25 INFO PythonRunner: Times: total = 34, boot = -43, init = 74, finish = 3
16/03/16 17:16:25 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 11013 bytes result sent to driver
16/03/16 17:16:25 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 114 ms on localhost (1/2)
16/03/16 17:16:25 INFO PythonRunner: Times: total = 353, boot = 352, init = 1, finish = 0
16/03/16 17:16:25 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/16 17:16:25 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) finished in 0.352 s
16/03/16 17:16:25 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230, took 9.721135 s
16/03/16 17:16:25 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 368 ms on localhost (2/2)
16/03/16 17:16:25 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 17:16:25 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230
16/03/16 17:16:25 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) with 2 output partitions
16/03/16 17:16:25 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/16 17:16:25 INFO DAGScheduler: Parents of final stage: List()
16/03/16 17:16:25 INFO DAGScheduler: Missing parents: List()
16/03/16 17:16:25 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230), which has no missing parents
16/03/16 17:16:25 INFO MemoryStore: ensureFreeSpace(5872) called with curMem=18715, maxMem=551509032
16/03/16 17:16:25 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 525.9 MB)
16/03/16 17:16:25 INFO MemoryStore: ensureFreeSpace(3419) called with curMem=24587, maxMem=551509032
16/03/16 17:16:25 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 525.9 MB)
16/03/16 17:16:25 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:45907 (size: 3.3 KB, free: 525.9 MB)
16/03/16 17:16:25 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 17:16:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/16 17:16:25 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 17:16:25 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/16 17:16:25 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 11962 bytes)
16/03/16 17:16:25 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 17:16:25 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 17:16:25 INFO PythonRunner: Times: total = 92, boot = -179, init = 269, finish = 2
16/03/16 17:16:25 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 11320 bytes result sent to driver
16/03/16 17:16:25 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 130 ms on localhost (1/2)
16/03/16 17:16:25 INFO PythonRunner: Times: total = 137, boot = 137, init = 0, finish = 0
16/03/16 17:16:25 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/16 17:16:25 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 149 ms on localhost (2/2)
16/03/16 17:16:25 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 17:16:25 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) finished in 0.142 s
16/03/16 17:16:25 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230, took 0.163867 s
Spark_MapReduce() - SparkSQL DataFrame query results:
Row(tokensatthislevel=[u'individual', u'quantity', u'food', u'drink', u'taken', u'part', u'meal', u'state', u'southeastern', u'India', u'Bay', u'Bengal', u'south', u'Andhra', u'Pradesh', u'formerly', u'Madras', u'region', u'whose', u'eastern', u'part', u'Bangladesh', u'whose', u'western', u'part', u'included', u'India', u'education', u'imparted', u'series', u'lessons', u'meetings', u'act', u'sexual', u'procreation', u'man', u'woman', u'man', u'penis', u'inserted', u'woman', u'vagina', u'excited', u'orgasm', u'ejaculation', u'occur', u'study', u'earth', u'surface', u'includes', u'people', u'responses', u'topography', u'climate', u'soil', u'vegetation', u'number', u'entities', u'members', u'considered', u'unit', u'gradual', u'decrease', u'stored', u'charge', u'current', u'series', u'steps', u'carried', u'goals', u'accomplished', u'member', u'mixed', u'Dravidian', u'Caucasian', u'people', u'southern', u'India', u'Sri', u'Lanka', u'deviating', u'widely', u'norm', u'physical', u'mental', u'ability', u'used', u'especially', u'children', u'normal', u'intelligence', u'indentation', u'shoreline', u'larger', u'cove', u'smaller', u'gulf', u'come', u'idea', u'plan', u'explanation', u'theory', u'principle', u'mental', u'effort', u'sports', u'stroke', u'puts', u'ball', u'play', u'distinct', u'part', u'specified', u'separately', u'group', u'things', u'could', u'enumerated', u'list', u'unit', u'length', u'equal', u'1,760', u'yards', u'5,280', u'feet', u'exactly', u'1609.344', u'meters', u'lacking', u'stability', u'fixity', u'firmness', u'part', u'made', u'plural', u'group', u'human', u'beings', u'men', u'women', u'children', u'collectively', u'similar', u'things', u'placed', u'order', u'happening', u'one', u'another', u'monotheistic', u'system', u'beliefs', u'practices', u'based', u'Old', u'Testament', u'teachings', u'Jesus', u'embodied', u'New', u'Testament', u'emphasizing', u'role', u'Jesus', u'savior', u'particular', u'society', u'particular', u'time', u'place', u'basic', u'unit', u'length', u'adopted', u'Systeme', u'International', u"d'Unites", u'approximately', u'1.094', u'yards', u'special', u'offering', u'usually', u'temporary', u'reduced', u'price', u'featured', u'advertising', u'pertaining', u'characteristic', u'Judaism', u'precise', u'explicit', u'clearly', u'defined', u'line', u'determining', u'limits', u'area', u'commercial', u'industrial', u'enterprise', u'people', u'constitute', u'prominent', u'status', u'person', u'thing', u'equal', u'another', u'value', u'measure', u'force', u'effect', u'significance', u'etc', u'soft', u'silvery-white', u'tetravalent', u'radioactive', u'metallic', u'element', u'isotope', u'232', u'used', u'power', u'source', u'nuclear', u'reactors', u'occurs', u'thorite', u'monazite', u'sands', u'feeling', u'liking', u'something', u'someone', u'good', u'give', u'something', u'useful', u'necessary', u'extended', u'spatial', u'location', u'something', u'heading', u'names', u'statute', u'legislative', u'bill', u'give', u'brief', u'summary', u'matters', u'deals', u'person', u'equal', u'standing', u'another', u'group', u'linear', u'extent', u'space', u'one', u'end', u'longest', u'dimension', u'something', u'fixed', u'place', u'issue', u'terminate', u'specified', u'way', u'state', u'etc', u'end', u'legal', u'document', u'codifying', u'result', u'deliberations', u'committee', u'society', u'legislative', u'body', u'military', u'engagement', u'something', u'including', u'component', u'elements', u'parts', u'commercial', u'industrial', u'enterprise', u'people', u'constitute', u'cardinal', u'number', u'product', u'10', u'100', u'previous', u'time', u'amount', u'time', u'high', u'degree', u'extent', u'favorably', u'much', u'respect', u'act', u'process', u'producing', u'something', u'vague', u'clearly', u'defined', u'stated', u'division', u'quantity', u'accepted', u'standard', u'measurement', u'exchange', u'large', u'densely', u'populated', u'urban', u'area', u'include', u'several', u'independent', u'administrative', u'districts', u'act', u'using', u'process', u'taking', u'food', u'body', u'mouth', u'eating', u'lying', u'toward', u'situated', u'east', u'large', u'unbroken', u'expanse', u'distance', u'bishop', u'highest', u'rank', u'instrumentality', u'combines', u'interrelated', u'interacting', u'artifacts', u'designed', u'work', u'coherent', u'entity', u'five', u'related', u'nonmetallic', u'elements', u'fluorine', u'chlorine', u'bromine', u'iodine', u'astatine', u'monovalent', u'readily', u'form', u'negative', u'ions', u'continuing', u'time', u'space', u'without', u'interruption', u'film', u'life', u'western', u'United', u'States', u'period', u'exploration', u'development', u'fact', u'part', u'opposed', u'general', u'assumption', u'taken', u'granted', u'category', u'things', u'distinguished', u'common', u'characteristic', u'quality', u'worker', u'holds', u'invested', u'office', u'man', u'older', u'higher', u'rank', u'one', u'groups', u'Christians', u'beliefs', u'forms', u'worship', u'statistics', u'arrangement', u'values', u'variable', u'showing', u'observed', u'theoretical', u'frequency', u'occurrence', u'something', u'owned', u'tangible', u'intangible', u'possession', u'owned', u'someone', u'mark', u'different', u'function', u'topological', u'space', u'gives', u'two', u'points', u'space', u'value', u'equal', u'distance', u'usually', u'describes', u'large', u'person', u'fat', u'large', u'frame', u'carry', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions', u'general', u'officer', u'highest', u'rank', u'senior', u'member', u'Christian', u'clergy', u'spiritual', u'administrative', u'authority', u'appointed', u'Christian', u'churches', u'oversee', u'priests', u'ministers', u'considered', u'churches', u'successors', u'twelve', u'Apostles', u'Christ', u'movable', u'possession', u'especially', u'articles', u'clothing', u'owned', u'possession', u'heavy', u'toxic', u'silvery-white', u'radioactive', u'metallic', u'element', u'occurs', u'many', u'isotopes', u'used', u'nuclear', u'fuels', u'nuclear', u'weapons', u'orderly', u'grouping', u'things', u'persons', u'considered', u'unit', u'result', u'arranging', u'something', u'less', u'whole', u'human', u'artifact', u'act', u'delivering', u'formal', u'spoken', u'communication', u'audience', u'relating', u'science', u'geography', u'pertaining', u'involving', u'nature', u'space', u'advertisement', u'usually', u'printed', u'page', u'leaflet', u'intended', u'wide', u'distribution', u'commodities', u'offered', u'sale', u'put', u'service', u'make', u'work', u'employ', u'particular', u'purpose', u'inherent', u'natural', u'purpose', u'normal', u'conditions', u'particular', u'point', u'time', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions', u'one', u'several', u'parts', u'pieces', u'fit', u'others', u'constitute', u'whole', u'object', u'exhibiting', u'caused', u'radioactivity', u'event', u'happens', u'trace', u'point', u'whose', u'direction', u'motion', u'changes', u'mentally', u'emotionally', u'stable', u'abstract', u'part', u'something', u'human', u'general', u'estimation', u'public', u'person', u'instance', u'single', u'occasion', u'event', u'particular', u'portion', u'space', u'occupied', u'something', u'concept', u'something', u'magnitude', u'represented', u'mathematical', u'expressions', u'constant', u'variable'])
16/03/16 17:16:26 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 17:16:26 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 17:16:26 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 17:16:26 INFO MemoryStore: MemoryStore cleared
16/03/16 17:16:26 INFO BlockManager: BlockManager stopped
16/03/16 17:16:26 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 17:16:26 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 17:16:26 INFO SparkContext: Successfully stopped SparkContext
16/03/16 17:16:26 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 17:16:26 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 17:16:26 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:tokensofthislevel: [u'individual', u'quantity', u'food', u'drink', u'taken', u'part', u'meal', u'state', u'southeastern', u'India', u'Bay', u'Bengal', u'south', u'Andhra', u'Pradesh', u'formerly', u'Madras', u'region', u'whose', u'eastern', u'part', u'Bangladesh', u'whose', u'western', u'part', u'included', u'India', u'education', u'imparted', u'series', u'lessons', u'meetings', u'act', u'sexual', u'procreation', u'man', u'woman', u'man', u'penis', u'inserted', u'woman', u'vagina', u'excited', u'orgasm', u'ejaculation', u'occur', u'study', u'earth', u'surface', u'includes', u'people', u'responses', u'topography', u'climate', u'soil', u'vegetation', u'number', u'entities', u'members', u'considered', u'unit', u'gradual', u'decrease', u'stored', u'charge', u'current', u'series', u'steps', u'carried', u'goals', u'accomplished', u'member', u'mixed', u'Dravidian', u'Caucasian', u'people', u'southern', u'India', u'Sri', u'Lanka', u'deviating', u'widely', u'norm', u'physical', u'mental', u'ability', u'used', u'especially', u'children', u'normal', u'intelligence', u'indentation', u'shoreline', u'larger', u'cove', u'smaller', u'gulf', u'come', u'idea', u'plan', u'explanation', u'theory', u'principle', u'mental', u'effort', u'sports', u'stroke', u'puts', u'ball', u'play', u'distinct', u'part', u'specified', u'separately', u'group', u'things', u'could', u'enumerated', u'list', u'unit', u'length', u'equal', u'1,760', u'yards', u'5,280', u'feet', u'exactly', u'1609.344', u'meters', u'lacking', u'stability', u'fixity', u'firmness', u'part', u'made', u'plural', u'group', u'human', u'beings', u'men', u'women', u'children', u'collectively', u'similar', u'things', u'placed', u'order', u'happening', u'one', u'another', u'monotheistic', u'system', u'beliefs', u'practices', u'based', u'Old', u'Testament', u'teachings', u'Jesus', u'embodied', u'New', u'Testament', u'emphasizing', u'role', u'Jesus', u'savior', u'particular', u'society', u'particular', u'time', u'place', u'basic', u'unit', u'length', u'adopted', u'Systeme', u'International', u"d'Unites", u'approximately', u'1.094', u'yards', u'special', u'offering', u'usually', u'temporary', u'reduced', u'price', u'featured', u'advertising', u'pertaining', u'characteristic', u'Judaism', u'precise', u'explicit', u'clearly', u'defined', u'line', u'determining', u'limits', u'area', u'commercial', u'industrial', u'enterprise', u'people', u'constitute', u'prominent', u'status', u'person', u'thing', u'equal', u'another', u'value', u'measure', u'force', u'effect', u'significance', u'etc', u'soft', u'silvery-white', u'tetravalent', u'radioactive', u'metallic', u'element', u'isotope', u'232', u'used', u'power', u'source', u'nuclear', u'reactors', u'occurs', u'thorite', u'monazite', u'sands', u'feeling', u'liking', u'something', u'someone', u'good', u'give', u'something', u'useful', u'necessary', u'extended', u'spatial', u'location', u'something', u'heading', u'names', u'statute', u'legislative', u'bill', u'give', u'brief', u'summary', u'matters', u'deals', u'person', u'equal', u'standing', u'another', u'group', u'linear', u'extent', u'space', u'one', u'end', u'longest', u'dimension', u'something', u'fixed', u'place', u'issue', u'terminate', u'specified', u'way', u'state', u'etc', u'end', u'legal', u'document', u'codifying', u'result', u'deliberations', u'committee', u'society', u'legislative', u'body', u'military', u'engagement', u'something', u'including', u'component', u'elements', u'parts', u'commercial', u'industrial', u'enterprise', u'people', u'constitute', u'cardinal', u'number', u'product', u'10', u'100', u'previous', u'time', u'amount', u'time', u'high', u'degree', u'extent', u'favorably', u'much', u'respect', u'act', u'process', u'producing', u'something', u'vague', u'clearly', u'defined', u'stated', u'division', u'quantity', u'accepted', u'standard', u'measurement', u'exchange', u'large', u'densely', u'populated', u'urban', u'area', u'include', u'several', u'independent', u'administrative', u'districts', u'act', u'using', u'process', u'taking', u'food', u'body', u'mouth', u'eating', u'lying', u'toward', u'situated', u'east', u'large', u'unbroken', u'expanse', u'distance', u'bishop', u'highest', u'rank', u'instrumentality', u'combines', u'interrelated', u'interacting', u'artifacts', u'designed', u'work', u'coherent', u'entity', u'five', u'related', u'nonmetallic', u'elements', u'fluorine', u'chlorine', u'bromine', u'iodine', u'astatine', u'monovalent', u'readily', u'form', u'negative', u'ions', u'continuing', u'time', u'space', u'without', u'interruption', u'film', u'life', u'western', u'United', u'States', u'period', u'exploration', u'development', u'fact', u'part', u'opposed', u'general', u'assumption', u'taken', u'granted', u'category', u'things', u'distinguished', u'common', u'characteristic', u'quality', u'worker', u'holds', u'invested', u'office', u'man', u'older', u'higher', u'rank', u'one', u'groups', u'Christians', u'beliefs', u'forms', u'worship', u'statistics', u'arrangement', u'values', u'variable', u'showing', u'observed', u'theoretical', u'frequency', u'occurrence', u'something', u'owned', u'tangible', u'intangible', u'possession', u'owned', u'someone', u'mark', u'different', u'function', u'topological', u'space', u'gives', u'two', u'points', u'space', u'value', u'equal', u'distance', u'usually', u'describes', u'large', u'person', u'fat', u'large', u'frame', u'carry', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions', u'general', u'officer', u'highest', u'rank', u'senior', u'member', u'Christian', u'clergy', u'spiritual', u'administrative', u'authority', u'appointed', u'Christian', u'churches', u'oversee', u'priests', u'ministers', u'considered', u'churches', u'successors', u'twelve', u'Apostles', u'Christ', u'movable', u'possession', u'especially', u'articles', u'clothing', u'owned', u'possession', u'heavy', u'toxic', u'silvery-white', u'radioactive', u'metallic', u'element', u'occurs', u'many', u'isotopes', u'used', u'nuclear', u'fuels', u'nuclear', u'weapons', u'orderly', u'grouping', u'things', u'persons', u'considered', u'unit', u'result', u'arranging', u'something', u'less', u'whole', u'human', u'artifact', u'act', u'delivering', u'formal', u'spoken', u'communication', u'audience', u'relating', u'science', u'geography', u'pertaining', u'involving', u'nature', u'space', u'advertisement', u'usually', u'printed', u'page', u'leaflet', u'intended', u'wide', u'distribution', u'commodities', u'offered', u'sale', u'put', u'service', u'make', u'work', u'employ', u'particular', u'purpose', u'inherent', u'natural', u'purpose', u'normal', u'conditions', u'particular', u'point', u'time', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions', u'one', u'several', u'parts', u'pieces', u'fit', u'others', u'constitute', u'whole', u'object', u'exhibiting', u'caused', u'radioactivity', u'event', u'happens', u'trace', u'point', u'whose', u'direction', u'motion', u'changes', u'mentally', u'emotionally', u'stable', u'abstract', u'part', u'something', u'human', u'general', u'estimation', u'public', u'person', u'instance', u'single', u'occasion', u'event', u'particular', u'portion', u'space', u'occupied', u'something', u'concept', u'something', u'magnitude', u'represented', u'mathematical', u'expressions', u'constant', u'variable']
prevlevelsynsets: [Synset('city.n.01'), Synset('use.n.01'), Synset('consumption.n.01'), Synset('eastern.s.01'), Synset('stretch.n.01'), Synset('archbishop.n.01'), Synset('system.n.01'), Synset('halogen.n.01'), Synset('continuous.a.01'), Synset('western.n.01'), Synset('helping.n.01'), Synset('tamil_nadu.n.01'), Synset('bengal.n.01'), Synset('course.n.01'), Synset('particular.n.01'), Synset('sexual_intercourse.n.01'), Synset('geography.n.01'), Synset('group.n.01'), Synset('decay.n.01'), Synset('plan.n.01'), Synset('tamil.n.01'), Synset('exceeding.s.01'), Synset('bay.n.01'), Synset('invent.v.01'), Synset('given.n.01'), Synset('serve.n.01'), Synset('item.n.01'), Synset('kind.n.01'), Synset('mile.n.01'), Synset('official.n.01'), Synset('unstable.a.01'), Synset('patriarch.n.01'), Synset('include.v.01'), Synset('church.n.01'), Synset('distribution.n.01'), Synset('people.n.01'), Synset('series.n.01'), Synset('christianity.n.01'), Synset('property.n.01'), Synset('culture.n.01'), Synset('distinguish.v.01'), Synset('meter.n.01'), Synset('metric_function.n.01'), Synset('special.n.01'), Synset('orthodox.a.01'), Synset('definite.a.01'), Synset('boundary.n.01'), Synset('business.n.01'), Synset('importance.n.01'), Synset('fleshy.s.01'), Synset('equivalent.n.01'), Synset('thorium.n.01'), Synset('blessing.n.01'), Synset('supply.n.01'), Synset('purpose.n.01'), Synset('region.n.01'), Synset('general.n.01'), Synset('title.n.01'), Synset('bishop.n.01'), Synset('peer.n.01'), Synset('length.n.01'), Synset('consequence.n.01'), Synset('things.n.01'), Synset('belong.v.01'), Synset('uranium.n.01'), Synset('act.n.01'), Synset('agreement.n.04'), Synset('military_action.n.01'), Synset('whole.n.01'), Synset('business.n.01'), Synset('thousand.n.01'), Synset('once.r.01'), Synset('part.n.01'), Synset('time_period.n.01'), Synset('highly.r.01'), Synset('address.n.01'), Synset('production.n.01'), Synset('indefinite.a.01'), Synset('geographic.a.01'), Synset('spatial.a.01'), Synset('unit_of_measurement.n.01'), Synset('circular.n.01'), Synset('merchandise.n.01'), Synset('use.n.01'), Synset('normally.r.01'), Synset('moment.n.01'), Synset('purpose.n.01'), Synset('section.n.01'), Synset('radioactive.a.01'), Synset('happening.n.01'), Synset('curve.n.01'), Synset('together.s.01'), Synset('component.n.01'), Synset('person.n.01'), Synset('repute.n.01'), Synset('time.n.01'), Synset('position.n.01'), Synset('measure.n.02')]
defaultdict(<type 'list'>, {u'serving': [u'area', u'None', u'area'], u'Madras': [u'None', u'Chennai', u'None', u'Chennai'], u'Bengal': [u'None', u'Chennai', u'None', u'Chennai'], u'course': [u'None', u'planning', u'None'], u'relation': [u'None', u'composition', u'None'], u'geography': [u'area', u'None', u'area'], u'group': [u'None', u'set'], u'decay': [u'None', u'None', u'astatine'], u'halogen': [u'None', u'None', u'astatine'], u'Tamil': [u'None', u'Chennai', u'None', u'Chennai'], u'exceptional': [u'None', u'None', u'giant'], u'Bay': [u'None', u'Chennai', u'None', u'Chennai'], u'formulating': [u'None', u'planning', u'None'], u'serves': [u'None', u'agency', u'None'], u'item': [u'None', u'None'], u'miles': [u'None', u'kilometer', u'None', u'kilometer'], u'unstable': [u'None', u'None', u'astatine'], u'including': [u'None', u'None', u'present'], u'people': [u'area', u'None', u'area'], u'series': [u'None', u'None', u'astatine'], u'Christianity': [u'None', u'None', u'metropolitan'], u'culture': [u'area', u'None', u'area'], u'meters': [u'None', u'kilometer', u'None', u'kilometer'], u'special': [u'area', u'None', u'area'], u'0.621371': [u'None', u'kilometer', u'None', u'kilometer'], u'Orthodox': [u'None', u'None', u'metropolitan'], u'definite': [u'None', u'planning', u'None'], u'boundary': [u'area', u'None', u'area'], u'business': [u'None', u'agency', u'None'], u'importance': [u'None', u'None', u'giant'], u'equivalent': [u'None', u'None', u'metropolitan'], u'thorium': [u'None', u'None', u'astatine'], u'approval': [u'None', u'permission', u'None'], u'providing': [u'None', u'None'], u'region': [u'area', u'None', u'area'], u'title': [u'None', u'None', u'metropolitan'], u'equal': [u'None', u'kilometer', u'None', u'kilometer'], u'length': [u'None', u'kilometer', u'None', u'kilometer'], u'resulting': [u'None', u'composition', u'None'], u'act': [u'None', u'planning', u'None'], u'action': [u'None', u'planning', u'None'], u'whole': [u'None', u'composition', u'None'], u'businesses': [u'None', u'agency', u'None'], u'1000': [u'None', u'kilometer', u'None', u'kilometer'], u'formerly': [u'None', u'Chennai', u'None', u'Chennai'], u'period': [u'None', u'None', u'present'], u'highly': [u'None', u'None', u'astatine'], u'production': [u'None', u'economy', u'None'], u'indefinite': [u'area', u'None', u'area'], u'unit': [u'None', u'kilometer', u'None', u'kilometer'], u'city': [u'None', u'Chennai', u'None', u'Chennai'], u'use': [u'None', u'None'], u'consumption': [u'None', u'economy', u'None'], u'Eastern': [u'None', u'None', u'metropolitan'], u'stretch': [u'None', u'None', u'present'], u'archbishop': [u'None', u'None', u'metropolitan'], u'system': [u'None', u'economy', u'None'], u'program': [u'None', u'planning', u'None'], u'continuous': [u'None', u'None', u'present'], u'western': [u'None', u'None', u'metropolitan'], u'particular': [u'area', u'None', u'area'], u'given': [u'None', u'None', u'metropolitan'], u'kind': [u'None', u'set'], u'official': [u'None', u'None'], u'patriarch': [u'None', u'None', u'metropolitan'], u'Church': [u'None', u'None', u'metropolitan'], u'distribution': [u'None', u'economy', u'None'], u'property': [u'None', u'composition', u'None'], u'distinguished': [u'area', u'None', u'area'], u'metric': [u'None', u'kilometer', u'None', u'kilometer'], u'heaviest': [u'None', u'None', u'astatine'], u'purposes': [u'None', u'None'], u'general': [u'None', u'None'], u'something': [u'None', u'permission', u'None'], u'bishop': [u'None', u'None', u'metropolitan'], u'things': [u'None', u'set'], u'belong': [u'None', u'set'], u'uranium': [u'None', u'None', u'astatine'], u'arrangement': [u'None', u'composition', u'None'], u'parts': [u'None', u'composition', u'None'], u'speech': [u'None', u'None', u'present'], u'geographical': [u'area', u'None', u'area'], u'spatial': [u'None', u'composition', u'None'], u'Nadu': [u'None', u'Chennai', u'None', u'Chennai'], u'circular': [u'None', u'bend'], u'product': [u'None', u'None', u'astatine'], u'used': [u'None', u'set'], u'usually': [u'area', u'None', u'area'], u'moment': [u'None', u'None', u'present'], u'purpose': [u'area', u'None', u'area'], u'segment': [u'None', u'bend'], u'radioactive': [u'None', u'None', u'astatine'], u'happening': [u'None', u'None', u'present'], u'curve': [u'None', u'bend'], u'together': [u'None', u'set'], u'element': [u'None', u'None', u'astatine'], u'person': [u'None', u'None', u'giant'], u'reputation': [u'None', u'None', u'giant'], u'time': [u'None', u'None', u'present'], u'position': [u'None', u'None', u'metropolitan'], u'quantity': [u'None', u'None']})
ksynset= Synset('helping.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('helping.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('helping.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('course.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('course.n.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('course.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('relation.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('relation.n.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('relation.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('group.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('group.n.01')
lsynset= Synset('set.n.01')
ksynset= Synset('decay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('decay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('decay.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('halogen.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('halogen.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('halogen.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('exceeding.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('exceeding.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('exceeding.s.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('explicate.v.02')
lsynset= Synset('none.n.01')
ksynset= Synset('explicate.v.02')
lsynset= Synset('planning.n.01')
ksynset= Synset('explicate.v.02')
lsynset= Synset('none.n.01')
ksynset= Synset('serve.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('serve.n.01')
lsynset= Synset('agency.n.01')
ksynset= Synset('serve.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('item.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('item.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('unstable.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unstable.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unstable.a.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('include.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('include.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('include.v.01')
lsynset= Synset('present.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('series.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('series.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('series.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('definite.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('definite.a.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('definite.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('agency.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('importance.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('importance.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('importance.n.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('thorium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thorium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thorium.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('blessing.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('blessing.n.01')
lsynset= Synset('permission.n.01')
ksynset= Synset('blessing.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('supply.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('supply.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('result.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('result.v.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('result.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('act.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('act.n.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('act.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('action.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('action.n.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('action.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('whole.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('whole.n.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('whole.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('agency.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('none.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('chennai.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('none.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('chennai.n.01')
ksynset= Synset('time_period.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time_period.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time_period.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('highly.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('highly.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('highly.r.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('production.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('production.n.01')
lsynset= Synset('economy.n.01')
ksynset= Synset('production.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('use.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('use.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('consumption.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('consumption.n.01')
lsynset= Synset('economy.n.01')
ksynset= Synset('consumption.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('stretch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('stretch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('stretch.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('system.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('system.n.01')
lsynset= Synset('economy.n.01')
ksynset= Synset('system.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('plan.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('plan.n.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('plan.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('continuous.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('continuous.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('continuous.a.01')
lsynset= Synset('present.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('kind.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('kind.n.01')
lsynset= Synset('set.n.01')
ksynset= Synset('official.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('official.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('distribution.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distribution.n.01')
lsynset= Synset('economy.n.01')
ksynset= Synset('distribution.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('property.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('property.n.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('property.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('area.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('area.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('heavy.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('heavy.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('heavy.a.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('general.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('general.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('things.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('things.n.01')
lsynset= Synset('set.n.01')
ksynset= Synset('belong.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('belong.v.01')
lsynset= Synset('set.n.01')
ksynset= Synset('uranium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('uranium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('uranium.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('agreement.n.04')
lsynset= Synset('none.n.01')
ksynset= Synset('agreement.n.04')
lsynset= Synset('composition.n.01')
ksynset= Synset('agreement.n.04')
lsynset= Synset('none.n.01')
ksynset= Synset('parts.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('parts.n.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('parts.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('address.n.03')
lsynset= Synset('none.n.01')
ksynset= Synset('address.n.03')
lsynset= Synset('none.n.01')
ksynset= Synset('address.n.03')
lsynset= Synset('present.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('spatial.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('spatial.a.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('spatial.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('circular.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('circular.n.01')
lsynset= Synset('bend.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('use.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('use.v.01')
lsynset= Synset('set.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('area.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('area.n.01')
ksynset= Synset('moment.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('moment.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('moment.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('section.n.04')
lsynset= Synset('none.n.01')
ksynset= Synset('section.n.04')
lsynset= Synset('bend.n.01')
ksynset= Synset('radioactive.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('radioactive.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('radioactive.a.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('happening.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('happening.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('happening.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('curve.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('curve.n.01')
lsynset= Synset('bend.n.01')
ksynset= Synset('together.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('together.s.01')
lsynset= Synset('set.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('repute.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('repute.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('repute.n.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('time.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('measure.n.02')
lsynset= Synset('none.n.01')
ksynset= Synset('measure.n.02')
lsynset= Synset('none.n.01')
Core number (sorted) : [(u'area', 13), (u'metropolitan', 12), (u'astatine', 11), (u'kilometer', 8), (u'present', 8), (u'Chennai', 7), (u'composition', 7), (u'planning', 6), (u'set', 6), (u'giant', 4), (u'economy', 4), (u'bend', 3), (u'agency', 3), (u'serving', 2), (u'Madras', 2), (u'Bengal', 2), (u'course', 2), (u'relation', 2), (u'geography', 2), (u'group', 2), (u'title', 2), (u'halogen', 2), (u'Tamil', 2), (u'permission', 2), (u'Bay', 2), (u'formulating', 2), (u'serves', 2), (u'miles', 2), (u'unstable', 2), (u'including', 2), (u'people', 2), (u'series', 2), (u'Christianity', 2), (u'culture', 2), (u'meters', 2), (u'special', 2), (u'0.621371', 2), (u'Orthodox', 2), (u'definite', 2), (u'boundary', 2), (u'business', 2), (u'importance', 2), (u'equivalent', 2), (u'thorium', 2), (u'approval', 2), (u'region', 2), (u'decay', 2), (u'equal', 2), (u'length', 2), (u'resulting', 2), (u'act', 2), (u'action', 2), (u'whole', 2), (u'businesses', 2), (u'1000', 2), (u'formerly', 2), (u'period', 2), (u'highly', 2), (u'production', 2), (u'indefinite', 2), (u'unit', 2), (u'city', 2), (u'given', 2), (u'consumption', 2), (u'stretch', 2), (u'archbishop', 2), (u'system', 2), (u'program', 2), (u'exceptional', 2), (u'continuous', 2), (u'western', 2), (u'particular', 2), (u'kind', 2), (u'patriarch', 2), (u'Eastern', 2), (u'Church', 2), (u'distribution', 2), (u'property', 2), (u'distinguished', 2), (u'something', 2), (u'metric', 2), (u'heaviest', 2), (u'bishop', 2), (u'things', 2), (u'belong', 2), (u'uranium', 2), (u'arrangement', 2), (u'parts', 2), (u'speech', 2), (u'geographical', 2), (u'spatial', 2), (u'Nadu', 2), (u'circular', 2), (u'product', 2), (u'used', 2), (u'usually', 2), (u'moment', 2), (u'purpose', 2), (u'segment', 2), (u'radioactive', 2), (u'happening', 2), (u'curve', 2), (u'together', 2), (u'element', 2), (u'person', 2), (u'reputation', 2), (u'time', 2), (u'position', 2), (u'item', 0), (u'None', 0), (u'use', 0), (u'providing', 0), (u'official', 0), (u'purposes', 0), (u'general', 0), (u'quantity', 0)]
=============================================================================================================
Unsupervised Classification based on top percentile Core numbers of the definition graph(subgraph of WordNet)
=============================================================================================================
This document belongs to class: area ,core number= 13
This document belongs to class: metropolitan ,core number= 12
This document belongs to class: astatine ,core number= 11
This document belongs to class: kilometer ,core number= 8
This document belongs to class: present ,core number= 8
This document belongs to class: Chennai ,core number= 7
This document belongs to class: composition ,core number= 7
This document belongs to class: planning ,core number= 6
This document belongs to class: set ,core number= 6
This document belongs to class: giant ,core number= 4
This document belongs to class: economy ,core number= 4
This document belongs to class: bend ,core number= 3
This document belongs to class: agency ,core number= 3
max_core_number 13
===================================================================
Page Rank of the vertices of RGO Definition Graph
===================================================================
[(u'area', 0.05964397617197671), (u'metropolitan', 0.05543677058743772), (u'astatine', 0.051229565002898755), (u'kilometer', 0.03860794824928188), (u'present', 0.03860794824928188), (u'Chennai', 0.034400742664742925), (u'composition', 0.034400742664742925), (u'planning', 0.030193537080203968), (u'set', 0.030193537080203968), (u'giant', 0.021779125911126046), (u'economy', 0.02177912591112604), (u'agency', 0.01757192032658708), (u'bend', 0.017571920326587075), (u'permission', 0.013364714742048119), (u'approval', 0.0070539063652396775), (u'something', 0.0070539063652396775), (u'serves', 0.006352705434483184), (u'business', 0.006352705434483184), (u'businesses', 0.006352705434483184), (u'circular', 0.006352705434483183), (u'segment', 0.006352705434483183), (u'curve', 0.006352705434483183), (u'importance', 0.006002104969104938), (u'production', 0.006002104969104938), (u'consumption', 0.006002104969104938), (u'system', 0.006002104969104938), (u'distribution', 0.006002104969104938), (u'exceptional', 0.006002104969104938), (u'person', 0.006002104969104938), (u'reputation', 0.006002104969104938), (u'course', 0.0056515045037266905), (u'group', 0.0056515045037266905), (u'program', 0.0056515045037266905), (u'formulating', 0.0056515045037266905), (u'definite', 0.0056515045037266905), (u'act', 0.0056515045037266905), (u'action', 0.0056515045037266905), (u'belong', 0.0056515045037266905), (u'kind', 0.0056515045037266905), (u'things', 0.0056515045037266905), (u'used', 0.0056515045037266905), (u'together', 0.0056515045037266905), (u'Madras', 0.005551332942190048), (u'Bengal', 0.005551332942190048), (u'relation', 0.005551332942190048), (u'Tamil', 0.005551332942190048), (u'Bay', 0.005551332942190048), (u'resulting', 0.005551332942190048), (u'whole', 0.005551332942190048), (u'formerly', 0.005551332942190048), (u'city', 0.005551332942190048), (u'property', 0.005551332942190048), (u'arrangement', 0.005551332942190048), (u'parts', 0.005551332942190048), (u'spatial', 0.005551332942190048), (u'Nadu', 0.005551332942190048), (u'miles', 0.0054762042710375675), (u'including', 0.0054762042710375675), (u'meters', 0.0054762042710375675), (u'0.621371', 0.0054762042710375675), (u'equal', 0.0054762042710375675), (u'length', 0.0054762042710375675), (u'1000', 0.0054762042710375675), (u'period', 0.0054762042710375675), (u'unit', 0.0054762042710375675), (u'stretch', 0.0054762042710375675), (u'continuous', 0.0054762042710375675), (u'metric', 0.0054762042710375675), (u'speech', 0.0054762042710375675), (u'moment', 0.0054762042710375675), (u'happening', 0.0054762042710375675), (u'time', 0.0054762042710375675), (u'unstable', 0.005332776807928284), (u'series', 0.005332776807928284), (u'thorium', 0.005332776807928284), (u'decay', 0.005332776807928284), (u'highly', 0.005332776807928284), (u'halogen', 0.005332776807928284), (u'heaviest', 0.005332776807928284), (u'uranium', 0.005332776807928284), (u'product', 0.005332776807928284), (u'radioactive', 0.005332776807928284), (u'element', 0.005332776807928284), (u'title', 0.005300904038348444), (u'Christianity', 0.005300904038348444), (u'Orthodox', 0.005300904038348444), (u'equivalent', 0.005300904038348444), (u'given', 0.005300904038348444), (u'archbishop', 0.005300904038348444), (u'western', 0.005300904038348444), (u'patriarch', 0.005300904038348444), (u'Eastern', 0.005300904038348444), (u'Church', 0.005300904038348444), (u'bishop', 0.005300904038348444), (u'position', 0.005300904038348444), (u'serving', 0.005273934771780889), (u'geography', 0.005273934771780889), (u'people', 0.005273934771780889), (u'culture', 0.005273934771780889), (u'special', 0.005273934771780889), (u'boundary', 0.005273934771780889), (u'region', 0.005273934771780889), (u'indefinite', 0.005273934771780889), (u'particular', 0.005273934771780889), (u'distinguished', 0.005273934771780889), (u'geographical', 0.005273934771780889), (u'usually', 0.005273934771780889), (u'purpose', 0.005273934771780889), (u'item', 0.001373626373626374), (u'None', 0.001373626373626374), (u'use', 0.001373626373626374), (u'providing', 0.001373626373626374), (u'official', 0.001373626373626374), (u'purposes', 0.001373626373626374), (u'general', 0.001373626373626374), (u'quantity', 0.001373626373626374)]
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - connectivity of RGO Definition Graph - Mengers Theorem
==========================================================================================================
0
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - Maxflow-Mincut of RGO Definition Graph - Minimum Edge Cut
==========================================================================================================
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - Maxflow-Mincut of RGO Definition Graph - Stoer-Wagner
==========================================================================================================

