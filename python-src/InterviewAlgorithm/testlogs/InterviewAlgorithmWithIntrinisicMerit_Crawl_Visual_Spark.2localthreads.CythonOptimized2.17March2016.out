Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
16/03/17 15:37:45 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:37:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/03/17 15:37:46 WARN Utils: Your hostname, shrinivaasanka-Inspiron-1545 resolves to a loopback address: 127.0.1.1, but we couldn't find any external IP address!
16/03/17 15:37:46 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
16/03/17 15:37:46 INFO SecurityManager: Changing view acls to: root
16/03/17 15:37:46 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:37:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:37:48 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:37:48 INFO Remoting: Starting remoting
16/03/17 15:37:48 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@127.0.1.1:44907]
16/03/17 15:37:48 INFO Utils: Successfully started service 'sparkDriver' on port 44907.
16/03/17 15:37:48 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:37:48 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:37:48 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-71e02b49-b8f3-4dd8-9eac-70e9a3d5fa1c
16/03/17 15:37:49 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
16/03/17 15:37:49 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-a41836ab-bc3d-450b-bd44-4056c89a7b8f
16/03/17 15:37:49 INFO HttpServer: Starting HTTP Server
16/03/17 15:37:49 INFO Utils: Successfully started service 'HTTP file server' on port 59897.
16/03/17 15:37:49 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:37:49 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:37:49 INFO SparkUI: Started SparkUI at http://127.0.1.1:4040
16/03/17 15:37:49 WARN : Your hostname, shrinivaasanka-Inspiron-1545 resolves to a loopback/non-reachable address: 127.0.0.1, but we couldn't find any external IP address!
16/03/17 15:37:49 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-e7c5ef1a-9711-4b5a-8d64-67c59d2a954d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:37:49 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209269883
16/03/17 15:37:50 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:37:50 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:37:50 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51501.
16/03/17 15:37:50 INFO NettyBlockTransferService: Server created on 51501
16/03/17 15:37:50 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:37:50 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51501 with 530.0 MB RAM, BlockManagerId(driver, localhost, 51501)
16/03/17 15:37:50 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:37:52 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230
16/03/17 15:37:52 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/17 15:37:52 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) with 2 output partitions
16/03/17 15:37:52 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/17 15:37:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:37:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:37:52 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230), which has no missing parents
16/03/17 15:37:52 WARN SizeEstimator: Failed to check whether UseCompressedOops is set; assuming yes
16/03/17 15:37:52 INFO MemoryStore: ensureFreeSpace(6560) called with curMem=0, maxMem=555755765
16/03/17 15:37:52 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)
16/03/17 15:37:52 INFO MemoryStore: ensureFreeSpace(4147) called with curMem=6560, maxMem=555755765
16/03/17 15:37:52 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 530.0 MB)
16/03/17 15:37:52 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51501 (size: 4.0 KB, free: 530.0 MB)
16/03/17 15:37:52 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:37:52 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/17 15:37:52 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:37:52 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2503 bytes)
16/03/17 15:37:52 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2508 bytes)
16/03/17 15:37:52 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:37:52 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:37:52 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209269883
16/03/17 15:37:52 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-e7c5ef1a-9711-4b5a-8d64-67c59d2a954d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:37:53 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:37:53 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:37:53 INFO MemoryStore: ensureFreeSpace(240) called with curMem=10707, maxMem=555755765
16/03/17 15:37:53 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 240.0 B, free 530.0 MB)
16/03/17 15:37:53 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:51501 (size: 240.0 B, free: 530.0 MB)
16/03/17 15:37:53 INFO MemoryStore: ensureFreeSpace(248) called with curMem=10947, maxMem=555755765
16/03/17 15:37:53 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 248.0 B, free 530.0 MB)
16/03/17 15:37:53 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:51501 (size: 248.0 B, free: 530.0 MB)
mapFunction(): freqterms1: Area
mapFunction(): freqterms1: Set
mapFunction(): freqterms1: Turn
mapFunction(): freqterms1: Giant
mapFunction(): freqterms1: Megapolis
mapFunction(): freqterms1: At
mapFunction(): freqterms1: present
mapFunction(): freqterms1: Chennai
mapFunction(): freqterms1: Metropolitan
mapFunction(): freqterms1: Area
mapFunction(): freqterms1: issuance
mapFunction(): freqterms1: planning
mapFunction(): freqterms1: 1,189
mapFunction(): freqterms1: sq
mapFunction(): freqterms1: km
mapFunction(): freqterms1: 7,700
mapFunction(): freqterms1: sq
mapFunction(): freqterms1: ...mapFunction(): freqterms1: permission

mapFunction(): freqterms1: ...
mapFunction(): freqterms1: Economy
mapFunction(): freqterms1: Composition
16/03/17 15:38:01 INFO PythonRunner: Times: total = 8372, boot = 490, init = 432, finish = 7450
mapFunction(): freqterms1: Nodal
mapFunction(): freqterms1: agencies
mapFunction(): freqterms1: ProfileWith
mapFunction(): freqterms1: 8,878
mapFunction(): freqterms1: sq
mapFunction(): freqterms1: km
mapFunction(): freqterms1: Chennai
16/03/17 15:38:01 INFO PythonRunner: Times: total = 8423, boot = 490, init = 414, finish = 7519
16/03/17 15:38:01 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:38:01 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:38:01 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8751 ms on localhost (1/2)
16/03/17 15:38:01 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8853 ms on localhost (2/2)
16/03/17 15:38:01 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:38:01 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) finished in 8.892 s
16/03/17 15:38:01 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:38:01 INFO DAGScheduler: running: Set()
16/03/17 15:38:01 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:38:01 INFO DAGScheduler: failed: Set()
16/03/17 15:38:01 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:38:01 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230), which is now runnable
16/03/17 15:38:01 INFO MemoryStore: ensureFreeSpace(4976) called with curMem=11195, maxMem=555755765
16/03/17 15:38:01 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.0 MB)
16/03/17 15:38:01 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16171, maxMem=555755765
16/03/17 15:38:01 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.0 MB)
16/03/17 15:38:01 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51501 (size: 3.0 KB, free: 530.0 MB)
16/03/17 15:38:01 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:38:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/17 15:38:02 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:38:02 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:38:02 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:38:02 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:38:02 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:38:02 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:38:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
16/03/17 15:38:02 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:38:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 25 ms
16/03/17 15:38:02 INFO PythonRunner: Times: total = 29, boot = -204, init = 231, finish = 2
16/03/17 15:38:02 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 3190 bytes result sent to driver
16/03/17 15:38:02 INFO PythonRunner: Times: total = 49, boot = -277, init = 325, finish = 1
16/03/17 15:38:02 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:38:02 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 186 ms on localhost (1/2)
16/03/17 15:38:02 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 204 ms on localhost (2/2)
16/03/17 15:38:02 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) finished in 0.213 s
16/03/17 15:38:02 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:38:02 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230, took 10.061170 s
16/03/17 15:38:05 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230
16/03/17 15:38:05 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) with 2 output partitions
16/03/17 15:38:05 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/17 15:38:05 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:38:05 INFO DAGScheduler: Missing parents: List()
16/03/17 15:38:05 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230), which has no missing parents
16/03/17 15:38:05 INFO MemoryStore: ensureFreeSpace(5872) called with curMem=19218, maxMem=555755765
16/03/17 15:38:05 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.0 MB)
16/03/17 15:38:05 INFO MemoryStore: ensureFreeSpace(3417) called with curMem=25090, maxMem=555755765
16/03/17 15:38:05 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
16/03/17 15:38:05 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:51501 (size: 3.3 KB, free: 530.0 MB)
16/03/17 15:38:05 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:38:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/17 15:38:05 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:38:05 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:38:05 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 4191 bytes)
16/03/17 15:38:05 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:38:05 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:38:05 INFO PythonRunner: Times: total = 44, boot = -3168, init = 3212, finish = 0
16/03/17 15:38:05 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:38:05 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 121 ms on localhost (1/2)
16/03/17 15:38:05 INFO PythonRunner: Times: total = 45, boot = -3188, init = 3232, finish = 1
16/03/17 15:38:06 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 3497 bytes result sent to driver
16/03/17 15:38:06 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 247 ms on localhost (2/2)
16/03/17 15:38:06 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:38:06 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) finished in 0.247 s
16/03/17 15:38:06 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230, took 0.284605 s
16/03/17 15:38:06 INFO SparkUI: Stopped Spark web UI at http://127.0.1.1:4040
16/03/17 15:38:06 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:38:06 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:38:06 INFO MemoryStore: MemoryStore cleared
16/03/17 15:38:06 INFO BlockManager: BlockManager stopped
16/03/17 15:38:06 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:38:06 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:38:06 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:38:06 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:38:06 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:38:06 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:38:13 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:38:13 INFO SecurityManager: Changing view acls to: root
16/03/17 15:38:13 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:38:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:38:14 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:38:14 INFO Remoting: Starting remoting
16/03/17 15:38:14 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:42586]
16/03/17 15:38:14 INFO Utils: Successfully started service 'sparkDriver' on port 42586.
16/03/17 15:38:14 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:38:14 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:38:14 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e665ef30-9dc6-47a3-8a06-823e716f0101
16/03/17 15:38:14 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
16/03/17 15:38:14 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-9772d4b8-5cd4-4b13-ad44-2b330dc147ec
16/03/17 15:38:14 INFO HttpServer: Starting HTTP Server
16/03/17 15:38:14 INFO Utils: Successfully started service 'HTTP file server' on port 60104.
16/03/17 15:38:14 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:38:14 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:38:14 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:38:14 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-35c0f0c7-439b-43c5-893e-4c870f9c5960/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:38:14 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209294504
16/03/17 15:38:14 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:38:14 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:38:14 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33550.
16/03/17 15:38:14 INFO NettyBlockTransferService: Server created on 33550
16/03/17 15:38:14 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:38:14 INFO BlockManagerMasterEndpoint: Registering block manager localhost:33550 with 530.0 MB RAM, BlockManagerId(driver, localhost, 33550)
16/03/17 15:38:14 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:38:14 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:38:14 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:38:14 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:38:14 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:38:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:38:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:38:14 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:38:14 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555755765
16/03/17 15:38:14 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)
16/03/17 15:38:14 INFO MemoryStore: ensureFreeSpace(4155) called with curMem=6576, maxMem=555755765
16/03/17 15:38:14 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)
16/03/17 15:38:14 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:33550 (size: 4.1 KB, free: 530.0 MB)
16/03/17 15:38:14 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:38:14 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:38:14 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:38:14 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:38:14 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:38:14 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:38:14 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209294504
16/03/17 15:38:14 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:38:14 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-35c0f0c7-439b-43c5-893e-4c870f9c5960/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:38:14 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:38:14 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10731, maxMem=555755765
16/03/17 15:38:14 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 530.0 MB)
16/03/17 15:38:14 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:33550 (size: 179.0 B, free: 530.0 MB)
16/03/17 15:38:14 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:38:14 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10910, maxMem=555755765
16/03/17 15:38:14 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 530.0 MB)
16/03/17 15:38:14 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:33550 (size: 173.0 B, free: 530.0 MB)
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: area
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: bend
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: giant
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: astatine
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: present
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: area
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  serving  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: issue
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/17 15:38:23 INFO PythonRunner: Times: total = 8551, boot = 459, init = 364, finish = 7728
16/03/17 15:38:23 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:38:23 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8690 ms on localhost (1/2)
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  serving  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: planning
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: permission
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: economy
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: composition
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: agency
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): serving
mapFunction_Parents(): keyword: serving ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= serving ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/17 15:38:23 INFO PythonRunner: Times: total = 8980, boot = 462, init = 442, finish = 8076
16/03/17 15:38:23 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:38:23 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.096 s
16/03/17 15:38:23 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:38:23 INFO DAGScheduler: running: Set()
16/03/17 15:38:23 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:38:23 INFO DAGScheduler: failed: Set()
16/03/17 15:38:23 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:38:23 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:38:23 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11083, maxMem=555755765
16/03/17 15:38:23 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.0 MB)
16/03/17 15:38:23 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9099 ms on localhost (2/2)
16/03/17 15:38:23 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:38:23 INFO MemoryStore: ensureFreeSpace(3054) called with curMem=16067, maxMem=555755765
16/03/17 15:38:23 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.0 MB)
16/03/17 15:38:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:33550 (size: 3.0 KB, free: 530.0 MB)
16/03/17 15:38:23 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:38:23 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:38:23 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:38:23 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:38:23 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:38:23 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:38:23 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:38:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:38:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:38:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:38:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
reduceFunction_Parents(): returns= ['None', u'area', u'area']
16/03/17 15:38:23 INFO PythonRunner: Times: total = 15, boot = -270, init = 284, finish = 1
16/03/17 15:38:23 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/17 15:38:23 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 67 ms on localhost (1/2)
16/03/17 15:38:24 INFO PythonRunner: Times: total = 231, boot = 230, init = 1, finish = 0
16/03/17 15:38:24 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:38:24 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 258 ms on localhost (2/2)
16/03/17 15:38:24 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:38:24 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.250 s
16/03/17 15:38:24 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.423240 s
16/03/17 15:38:24 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:38:24 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:38:24 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:38:24 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:38:24 INFO DAGScheduler: Missing parents: List()
16/03/17 15:38:24 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:38:24 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19121, maxMem=555755765
16/03/17 15:38:24 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.0 MB)
16/03/17 15:38:24 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24937, maxMem=555755765
16/03/17 15:38:24 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
16/03/17 15:38:24 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:33550 (size: 3.3 KB, free: 530.0 MB)
16/03/17 15:38:24 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:38:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:38:24 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:38:24 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:38:24 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/17 15:38:24 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:38:24 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:38:24 INFO PythonRunner: Times: total = 18, boot = 18, init = 0, finish = 0
16/03/17 15:38:24 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:38:24 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 48 ms on localhost (1/2)
16/03/17 15:38:24 INFO PythonRunner: Times: total = 58, boot = -307, init = 365, finish = 0
16/03/17 15:38:24 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/03/17 15:38:24 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 78 ms on localhost (2/2)
16/03/17 15:38:24 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:38:24 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.065 s
16/03/17 15:38:24 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.120846 s
16/03/17 15:38:24 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:38:24 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:38:24 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:38:24 INFO MemoryStore: MemoryStore cleared
16/03/17 15:38:24 INFO BlockManager: BlockManager stopped
16/03/17 15:38:24 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:38:24 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:38:24 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:38:24 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:38:24 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:38:24 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:38:25 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:38:25 INFO SecurityManager: Changing view acls to: root
16/03/17 15:38:25 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:38:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:38:25 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:38:25 INFO Remoting: Starting remoting
16/03/17 15:38:25 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:56201]
16/03/17 15:38:25 INFO Utils: Successfully started service 'sparkDriver' on port 56201.
16/03/17 15:38:25 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:38:25 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:38:25 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-266258c4-ad75-46f7-a49f-54f2cb02a24f
16/03/17 15:38:25 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
16/03/17 15:38:25 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-802cc44f-691d-419f-b45a-a6f174491ac3
16/03/17 15:38:25 INFO HttpServer: Starting HTTP Server
16/03/17 15:38:25 INFO Utils: Successfully started service 'HTTP file server' on port 42053.
16/03/17 15:38:25 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:38:25 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:38:25 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:38:25 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-a0f9bd63-fc26-4140-821e-093c01f46365/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:38:25 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209305728
16/03/17 15:38:25 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:38:25 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:38:25 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59608.
16/03/17 15:38:25 INFO NettyBlockTransferService: Server created on 59608
16/03/17 15:38:25 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:38:25 INFO BlockManagerMasterEndpoint: Registering block manager localhost:59608 with 530.0 MB RAM, BlockManagerId(driver, localhost, 59608)
16/03/17 15:38:25 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:38:25 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:38:25 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:38:25 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:38:25 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:38:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:38:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:38:25 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:38:25 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555755765
16/03/17 15:38:25 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)
16/03/17 15:38:25 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555755765
16/03/17 15:38:25 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)
16/03/17 15:38:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:59608 (size: 4.1 KB, free: 530.0 MB)
16/03/17 15:38:25 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:38:25 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:38:25 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:38:25 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:38:25 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:38:25 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:38:25 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209305728
16/03/17 15:38:25 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:38:26 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-a0f9bd63-fc26-4140-821e-093c01f46365/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:38:26 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:38:26 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=555755765
16/03/17 15:38:26 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 530.0 MB)
16/03/17 15:38:26 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:38:26 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:59608 (size: 179.0 B, free: 530.0 MB)
16/03/17 15:38:26 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=555755765
16/03/17 15:38:26 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 530.0 MB)
16/03/17 15:38:26 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:59608 (size: 173.0 B, free: 530.0 MB)
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: set
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: bend
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: giant
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: astatine
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: present
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Madras  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: area
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: issue
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/17 15:38:34 INFO PythonRunner: Times: total = 8142, boot = 464, init = 407, finish = 7271
16/03/17 15:38:34 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:38:34 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8281 ms on localhost (1/2)
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: planning
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: permission
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: economy
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: composition
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: agency
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Madras
mapFunction_Parents(): keyword: Madras ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Madras ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Madras  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/17 15:38:34 INFO PythonRunner: Times: total = 8354, boot = 455, init = 420, finish = 7479
16/03/17 15:38:34 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:38:34 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8477 ms on localhost (2/2)
16/03/17 15:38:34 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:38:34 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.489 s
16/03/17 15:38:34 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:38:34 INFO DAGScheduler: running: Set()
16/03/17 15:38:34 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:38:34 INFO DAGScheduler: failed: Set()
16/03/17 15:38:34 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:38:34 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:38:34 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=555755765
16/03/17 15:38:34 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.0 MB)
16/03/17 15:38:34 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=555755765
16/03/17 15:38:34 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.0 MB)
16/03/17 15:38:34 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:59608 (size: 3.0 KB, free: 530.0 MB)
16/03/17 15:38:34 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:38:34 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:38:34 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:38:34 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:38:34 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:38:34 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:38:34 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:38:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:38:34 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:38:34 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:38:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:38:34 INFO PythonRunner: Times: total = 20, boot = -61, init = 81, finish = 0
16/03/17 15:38:34 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:38:34 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 62 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'Chennai', 'None', u'Chennai']
16/03/17 15:38:34 INFO PythonRunner: Times: total = 212, boot = 211, init = 0, finish = 1
16/03/17 15:38:34 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1297 bytes result sent to driver
16/03/17 15:38:34 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 239 ms on localhost (2/2)
16/03/17 15:38:34 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.240 s
16/03/17 15:38:34 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.793613 s
16/03/17 15:38:34 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:38:35 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:38:35 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:38:35 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:38:35 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:38:35 INFO DAGScheduler: Missing parents: List()
16/03/17 15:38:35 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:38:35 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=555755765
16/03/17 15:38:35 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.0 MB)
16/03/17 15:38:35 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=555755765
16/03/17 15:38:35 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
16/03/17 15:38:35 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:59608 (size: 3.3 KB, free: 530.0 MB)
16/03/17 15:38:35 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:38:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:38:35 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:38:35 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:38:35 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2378 bytes)
16/03/17 15:38:35 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:38:35 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:38:35 INFO PythonRunner: Times: total = 50, boot = -304, init = 354, finish = 0
16/03/17 15:38:35 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:38:35 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 62 ms on localhost (1/2)
16/03/17 15:38:35 INFO PythonRunner: Times: total = 150, boot = 149, init = 1, finish = 0
16/03/17 15:38:35 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1365 bytes result sent to driver
16/03/17 15:38:35 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 167 ms on localhost (2/2)
16/03/17 15:38:35 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:38:35 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.161 s
16/03/17 15:38:35 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.250719 s
16/03/17 15:38:35 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:38:35 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:38:35 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:38:35 INFO MemoryStore: MemoryStore cleared
16/03/17 15:38:35 INFO BlockManager: BlockManager stopped
16/03/17 15:38:35 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:38:35 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:38:35 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:38:35 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:38:35 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:38:35 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:38:36 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:38:36 INFO SecurityManager: Changing view acls to: root
16/03/17 15:38:36 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:38:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:38:36 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:38:36 INFO Remoting: Starting remoting
16/03/17 15:38:36 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:33836]
16/03/17 15:38:36 INFO Utils: Successfully started service 'sparkDriver' on port 33836.
16/03/17 15:38:36 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:38:36 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:38:36 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c0b308e7-86dc-45df-b967-b59dfcf38d2c
16/03/17 15:38:36 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
16/03/17 15:38:36 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-2f6c559e-2709-4d60-b2cd-b9621b96d5e9
16/03/17 15:38:36 INFO HttpServer: Starting HTTP Server
16/03/17 15:38:36 INFO Utils: Successfully started service 'HTTP file server' on port 60706.
16/03/17 15:38:36 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:38:36 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:38:36 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:38:36 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-f00c4239-fa98-4b38-afd1-9ff774830015/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:38:36 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209316515
16/03/17 15:38:36 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:38:36 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:38:36 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33146.
16/03/17 15:38:36 INFO NettyBlockTransferService: Server created on 33146
16/03/17 15:38:36 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:38:36 INFO BlockManagerMasterEndpoint: Registering block manager localhost:33146 with 530.0 MB RAM, BlockManagerId(driver, localhost, 33146)
16/03/17 15:38:36 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:38:36 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:38:36 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:38:36 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:38:36 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:38:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:38:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:38:36 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:38:36 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555755765
16/03/17 15:38:36 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)
16/03/17 15:38:36 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555755765
16/03/17 15:38:36 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)
16/03/17 15:38:36 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:33146 (size: 4.1 KB, free: 530.0 MB)
16/03/17 15:38:36 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:38:36 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:38:36 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:38:36 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:38:36 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:38:36 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:38:36 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209316515
16/03/17 15:38:36 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:38:36 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-f00c4239-fa98-4b38-afd1-9ff774830015/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:38:36 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:38:36 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=555755765
16/03/17 15:38:36 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 530.0 MB)
16/03/17 15:38:36 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:33146 (size: 179.0 B, free: 530.0 MB)
16/03/17 15:38:36 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:38:36 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=555755765
16/03/17 15:38:36 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 530.0 MB)
16/03/17 15:38:36 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:33146 (size: 173.0 B, free: 530.0 MB)
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: set
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: planning
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: permission
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: economy
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: composition
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: agency
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Bengal  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/17 15:38:45 INFO PythonRunner: Times: total = 8178, boot = 483, init = 367, finish = 7328
16/03/17 15:38:45 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:38:45 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8302 ms on localhost (1/2)
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: bend
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: giant
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: astatine
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: present
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Bengal  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: area
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: issue
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/17 15:38:45 INFO PythonRunner: Times: total = 8462, boot = 485, init = 389, finish = 7588
16/03/17 15:38:45 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:38:45 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8580 ms on localhost (2/2)
16/03/17 15:38:45 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:38:45 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.572 s
16/03/17 15:38:45 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:38:45 INFO DAGScheduler: running: Set()
16/03/17 15:38:45 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:38:45 INFO DAGScheduler: failed: Set()
16/03/17 15:38:45 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:38:45 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:38:45 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=555755765
16/03/17 15:38:45 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.0 MB)
16/03/17 15:38:45 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=555755765
16/03/17 15:38:45 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.0 MB)
16/03/17 15:38:45 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:33146 (size: 3.0 KB, free: 530.0 MB)
16/03/17 15:38:45 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:38:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:38:45 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:38:45 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:38:45 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:38:45 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:38:45 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:38:45 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:38:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:38:45 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:38:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:38:45 INFO PythonRunner: Times: total = 24, boot = -193, init = 217, finish = 0
16/03/17 15:38:45 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:38:45 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 56 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'Chennai', 'None', u'Chennai']
16/03/17 15:38:45 INFO PythonRunner: Times: total = 143, boot = 141, init = 1, finish = 1
16/03/17 15:38:45 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1297 bytes result sent to driver
16/03/17 15:38:45 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.172 s
16/03/17 15:38:45 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 182 ms on localhost (2/2)
16/03/17 15:38:45 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.904341 s
16/03/17 15:38:45 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:38:45 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:38:45 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:38:45 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:38:45 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:38:45 INFO DAGScheduler: Missing parents: List()
16/03/17 15:38:45 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:38:45 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=555755765
16/03/17 15:38:45 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.0 MB)
16/03/17 15:38:45 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=555755765
16/03/17 15:38:45 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
16/03/17 15:38:45 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:33146 (size: 3.3 KB, free: 530.0 MB)
16/03/17 15:38:45 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:38:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:38:45 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:38:45 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:38:45 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2378 bytes)
16/03/17 15:38:45 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:38:45 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:38:46 INFO PythonRunner: Times: total = 52, boot = -111, init = 163, finish = 0
16/03/17 15:38:46 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:38:46 INFO PythonRunner: Times: total = 21, boot = -100, init = 121, finish = 0
16/03/17 15:38:46 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1365 bytes result sent to driver
16/03/17 15:38:46 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 228 ms on localhost (1/2)
16/03/17 15:38:46 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 232 ms on localhost (2/2)
16/03/17 15:38:46 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:38:46 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.230 s
16/03/17 15:38:46 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.294639 s
16/03/17 15:38:46 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:33146 in memory (size: 3.0 KB, free: 530.0 MB)
16/03/17 15:38:46 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:38:46 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:38:46 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:38:46 INFO MemoryStore: MemoryStore cleared
16/03/17 15:38:46 INFO BlockManager: BlockManager stopped
16/03/17 15:38:46 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:38:46 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:38:46 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:38:46 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:38:46 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:38:46 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:38:47 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:38:47 INFO SecurityManager: Changing view acls to: root
16/03/17 15:38:47 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:38:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:38:47 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:38:47 INFO Remoting: Starting remoting
16/03/17 15:38:47 INFO Utils: Successfully started service 'sparkDriver' on port 57033.
16/03/17 15:38:47 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:38:47 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:38:47 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:57033]
16/03/17 15:38:47 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3f1b8764-220b-4714-8b9a-2a05d13dfdc8
16/03/17 15:38:47 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
16/03/17 15:38:47 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-f84b03a4-429e-4b7c-8a58-cc767292c90a
16/03/17 15:38:47 INFO HttpServer: Starting HTTP Server
16/03/17 15:38:47 INFO Utils: Successfully started service 'HTTP file server' on port 51142.
16/03/17 15:38:47 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:38:47 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:38:47 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:38:47 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-c20453f5-368e-4491-b5b5-4af94478d814/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:38:47 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209327393
16/03/17 15:38:47 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:38:47 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:38:47 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54649.
16/03/17 15:38:47 INFO NettyBlockTransferService: Server created on 54649
16/03/17 15:38:47 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:38:47 INFO BlockManagerMasterEndpoint: Registering block manager localhost:54649 with 530.0 MB RAM, BlockManagerId(driver, localhost, 54649)
16/03/17 15:38:47 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:38:47 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:38:47 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:38:47 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:38:47 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:38:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:38:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:38:47 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:38:47 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555755765
16/03/17 15:38:47 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)
16/03/17 15:38:47 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555755765
16/03/17 15:38:47 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)
16/03/17 15:38:47 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:54649 (size: 4.1 KB, free: 530.0 MB)
16/03/17 15:38:47 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:38:47 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:38:47 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:38:47 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:38:47 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:38:47 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:38:47 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209327393
16/03/17 15:38:47 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:38:47 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-c20453f5-368e-4491-b5b5-4af94478d814/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:38:47 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:38:47 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10732, maxMem=555755765
16/03/17 15:38:47 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 530.0 MB)
16/03/17 15:38:47 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:54649 (size: 173.0 B, free: 530.0 MB)
16/03/17 15:38:47 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:38:47 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10905, maxMem=555755765
16/03/17 15:38:47 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 530.0 MB)
16/03/17 15:38:47 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:54649 (size: 179.0 B, free: 530.0 MB)
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: set
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: planning
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): adding to parents: syn =  Synset('planning.n.01') ; keyword:  course  in syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= [u'planning']
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: permission
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: economy
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: composition
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: agency
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
16/03/17 15:38:56 INFO PythonRunner: Times: total = 9142, boot = 469, init = 636, finish = 8037
16/03/17 15:38:56 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:38:56 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9274 ms on localhost (1/2)
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: bend
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: giant
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: astatine
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: present
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: area
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): course
mapFunction_Parents(): keyword: course ; prevleveltokens: issue
mapFunction_Parents(): keyword= course ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:38:57 INFO PythonRunner: Times: total = 9438, boot = 469, init = 656, finish = 8313
16/03/17 15:38:57 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:38:57 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9555 ms on localhost (2/2)
16/03/17 15:38:57 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.562 s
16/03/17 15:38:57 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:38:57 INFO DAGScheduler: running: Set()
16/03/17 15:38:57 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:38:57 INFO DAGScheduler: failed: Set()
16/03/17 15:38:57 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:38:57 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:38:57 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=555755765
16/03/17 15:38:57 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.0 MB)
16/03/17 15:38:57 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=555755765
16/03/17 15:38:57 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.0 MB)
16/03/17 15:38:57 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:38:57 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:54649 (size: 3.0 KB, free: 530.0 MB)
16/03/17 15:38:57 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:38:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:38:57 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:38:57 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:38:57 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:38:57 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:38:57 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:38:57 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:38:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:38:57 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:38:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
reduceFunction_Parents(): returns= ['None', 'None', u'planning']
16/03/17 15:38:57 INFO PythonRunner: Times: total = 62, boot = 60, init = 1, finish = 1
16/03/17 15:38:57 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/03/17 15:38:57 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 81 ms on localhost (1/2)
16/03/17 15:38:57 INFO PythonRunner: Times: total = 183, boot = 182, init = 1, finish = 0
16/03/17 15:38:57 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:38:57 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.203 s
16/03/17 15:38:57 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.810362 s
16/03/17 15:38:57 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 206 ms on localhost (2/2)
16/03/17 15:38:57 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:38:57 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:38:57 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:38:57 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:38:57 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:38:57 INFO DAGScheduler: Missing parents: List()
16/03/17 15:38:57 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:38:57 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=555755765
16/03/17 15:38:57 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.0 MB)
16/03/17 15:38:57 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=555755765
16/03/17 15:38:57 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
16/03/17 15:38:57 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:54649 (size: 3.3 KB, free: 530.0 MB)
16/03/17 15:38:57 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:38:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:38:57 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:38:57 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:38:57 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/03/17 15:38:57 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:38:57 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:38:57 INFO PythonRunner: Times: total = 50, boot = -36, init = 86, finish = 0
16/03/17 15:38:57 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:38:57 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 66 ms on localhost (1/2)
16/03/17 15:38:57 INFO PythonRunner: Times: total = 74, boot = 74, init = 0, finish = 0
16/03/17 15:38:57 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/03/17 15:38:57 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 89 ms on localhost (2/2)
16/03/17 15:38:57 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:38:57 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.081 s
16/03/17 15:38:57 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.117431 s
16/03/17 15:38:57 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:38:57 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:38:57 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:38:57 INFO MemoryStore: MemoryStore cleared
16/03/17 15:38:57 INFO BlockManager: BlockManager stopped
16/03/17 15:38:57 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:38:57 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:38:57 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:38:57 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:38:57 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:38:57 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:38:58 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:38:58 INFO SecurityManager: Changing view acls to: root
16/03/17 15:38:58 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:38:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:38:58 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:38:58 INFO Remoting: Starting remoting
16/03/17 15:38:58 INFO Utils: Successfully started service 'sparkDriver' on port 36779.
16/03/17 15:38:58 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:36779]
16/03/17 15:38:58 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:38:58 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:38:58 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8abe1480-95b5-4917-9b3d-bba9e0b479a5
16/03/17 15:38:58 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
16/03/17 15:38:58 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-2c28bdbf-37e5-4749-8bf5-f231f8dab5a2
16/03/17 15:38:58 INFO HttpServer: Starting HTTP Server
16/03/17 15:38:58 INFO Utils: Successfully started service 'HTTP file server' on port 57861.
16/03/17 15:38:58 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:38:58 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:38:58 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:38:58 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-4bc7ebb1-9b7c-4e14-99ab-aef83a1d104e/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:38:58 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209338963
16/03/17 15:38:58 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:38:58 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:38:59 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40517.
16/03/17 15:38:59 INFO NettyBlockTransferService: Server created on 40517
16/03/17 15:38:59 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:38:59 INFO BlockManagerMasterEndpoint: Registering block manager localhost:40517 with 530.0 MB RAM, BlockManagerId(driver, localhost, 40517)
16/03/17 15:38:59 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:38:59 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:38:59 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:38:59 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:38:59 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:38:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:38:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:38:59 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:38:59 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555755765
16/03/17 15:38:59 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)
16/03/17 15:38:59 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555755765
16/03/17 15:38:59 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)
16/03/17 15:38:59 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:40517 (size: 4.1 KB, free: 530.0 MB)
16/03/17 15:38:59 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:38:59 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:38:59 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:38:59 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:38:59 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:38:59 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:38:59 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:38:59 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209338963
16/03/17 15:38:59 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-4bc7ebb1-9b7c-4e14-99ab-aef83a1d104e/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:38:59 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:38:59 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=555755765
16/03/17 15:38:59 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 530.0 MB)
16/03/17 15:38:59 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:38:59 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:40517 (size: 179.0 B, free: 530.0 MB)
16/03/17 15:38:59 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=555755765
16/03/17 15:38:59 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 530.0 MB)
16/03/17 15:38:59 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:40517 (size: 173.0 B, free: 530.0 MB)
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: area
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: planning
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: permission
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: economy
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: composition
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  relation  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: agency
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: bend
16/03/17 15:39:08 INFO PythonRunner: Times: total = 8869, boot = 501, init = 627, finish = 7741
16/03/17 15:39:08 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:39:08 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8949 ms on localhost (1/2)
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: giant
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: astatine
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: present
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: area
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): relation
mapFunction_Parents(): keyword: relation ; prevleveltokens: issue
mapFunction_Parents(): keyword= relation ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:39:08 INFO PythonRunner: Times: total = 9021, boot = 500, init = 492, finish = 8029
16/03/17 15:39:08 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:39:08 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9101 ms on localhost (2/2)
16/03/17 15:39:08 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:39:08 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.099 s
16/03/17 15:39:08 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:39:08 INFO DAGScheduler: running: Set()
16/03/17 15:39:08 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:39:08 INFO DAGScheduler: failed: Set()
16/03/17 15:39:08 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:39:08 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:39:08 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=555755765
16/03/17 15:39:08 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.0 MB)
16/03/17 15:39:08 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=555755765
16/03/17 15:39:08 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.0 MB)
16/03/17 15:39:08 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:40517 (size: 3.0 KB, free: 530.0 MB)
16/03/17 15:39:08 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:39:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:39:08 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:39:08 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:39:08 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:39:08 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:39:08 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:39:08 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:39:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:39:08 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:39:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', 'None', u'composition']
16/03/17 15:39:08 INFO PythonRunner: Times: total = 39, boot = 37, init = 0, finish = 2
16/03/17 15:39:08 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1287 bytes result sent to driver
16/03/17 15:39:08 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 55 ms on localhost (1/2)
16/03/17 15:39:08 INFO PythonRunner: Times: total = 293, boot = 292, init = 0, finish = 1
16/03/17 15:39:08 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:39:08 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 312 ms on localhost (2/2)
16/03/17 15:39:08 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:39:08 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.313 s
16/03/17 15:39:08 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.467334 s
16/03/17 15:39:08 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:39:08 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:39:08 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:39:08 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:39:08 INFO DAGScheduler: Missing parents: List()
16/03/17 15:39:08 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:39:08 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=555755765
16/03/17 15:39:08 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.0 MB)
16/03/17 15:39:08 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=555755765
16/03/17 15:39:08 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
16/03/17 15:39:08 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:40517 (size: 3.3 KB, free: 530.0 MB)
16/03/17 15:39:08 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:39:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:39:08 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:39:08 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:39:08 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2368 bytes)
16/03/17 15:39:08 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:39:08 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:39:08 INFO PythonRunner: Times: total = 4, boot = -58, init = 62, finish = 0
16/03/17 15:39:08 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:39:08 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 34 ms on localhost (1/2)
16/03/17 15:39:08 INFO PythonRunner: Times: total = 39, boot = -313, init = 352, finish = 0
16/03/17 15:39:08 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1355 bytes result sent to driver
16/03/17 15:39:08 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 61 ms on localhost (2/2)
16/03/17 15:39:08 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:39:08 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.051 s
16/03/17 15:39:08 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.076225 s
16/03/17 15:39:08 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:39:08 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:39:09 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:39:09 INFO MemoryStore: MemoryStore cleared
16/03/17 15:39:09 INFO BlockManager: BlockManager stopped
16/03/17 15:39:09 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:39:09 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:39:09 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:39:09 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:39:09 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:39:09 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:39:09 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:39:09 INFO SecurityManager: Changing view acls to: root
16/03/17 15:39:09 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:39:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:39:09 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:39:09 INFO Remoting: Starting remoting
16/03/17 15:39:10 INFO Utils: Successfully started service 'sparkDriver' on port 58857.
16/03/17 15:39:10 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:58857]
16/03/17 15:39:10 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:39:10 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:39:10 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0916f6e2-895c-4876-86db-205940ca59cb
16/03/17 15:39:10 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
16/03/17 15:39:10 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-c610f8b8-b722-4178-813c-4448972ed077
16/03/17 15:39:10 INFO HttpServer: Starting HTTP Server
16/03/17 15:39:10 INFO Utils: Successfully started service 'HTTP file server' on port 55481.
16/03/17 15:39:10 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:39:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:39:10 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:39:10 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-0b53dd50-ea10-4b82-bbbb-a317a341f390/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:39:10 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209350090
16/03/17 15:39:10 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:39:10 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:39:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55623.
16/03/17 15:39:10 INFO NettyBlockTransferService: Server created on 55623
16/03/17 15:39:10 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:39:10 INFO BlockManagerMasterEndpoint: Registering block manager localhost:55623 with 530.0 MB RAM, BlockManagerId(driver, localhost, 55623)
16/03/17 15:39:10 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:39:10 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:39:10 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:39:10 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:39:10 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:39:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:39:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:39:10 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:39:10 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555755765
16/03/17 15:39:10 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)
16/03/17 15:39:10 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555755765
16/03/17 15:39:10 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)
16/03/17 15:39:10 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:55623 (size: 4.1 KB, free: 530.0 MB)
16/03/17 15:39:10 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:39:10 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:39:10 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:39:10 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:39:10 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:39:10 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:39:10 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209350090
16/03/17 15:39:10 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:39:10 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-0b53dd50-ea10-4b82-bbbb-a317a341f390/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:39:10 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:39:10 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10732, maxMem=555755765
16/03/17 15:39:10 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 530.0 MB)
16/03/17 15:39:10 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:55623 (size: 173.0 B, free: 530.0 MB)
16/03/17 15:39:10 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:39:10 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10905, maxMem=555755765
16/03/17 15:39:10 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 530.0 MB)
16/03/17 15:39:10 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:55623 (size: 179.0 B, free: 530.0 MB)
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: area
mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  geography  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: planning
mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: permission
mapFunction_Parents(): keyword=mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
 geographyasfer_pickle_string_load(): picklef.readlines(): geography
 mapFunction_Parents(): keyword: geography ; prevleveltokens: bend
; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: economy
mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: composition
mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: agency
mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: giant
mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: astatine
mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'('mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: present
, u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [16/03/17 15:39:18 INFO PythonRunner: Times: total = 8383, boot = 466, init = 417, finish = 7500
'None']
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: area
16/03/17 15:39:18 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  geography  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): geography
mapFunction_Parents(): keyword: geography ; prevleveltokens: issue
16/03/17 15:39:18 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8475 ms on localhost (1/2)
mapFunction_Parents(): keyword= geography ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/17 15:39:18 INFO PythonRunner: Times: total = 8451, boot = 462, init = 379, finish = 7610
16/03/17 15:39:18 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:39:18 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8532 ms on localhost (2/2)
16/03/17 15:39:18 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:39:18 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.534 s
16/03/17 15:39:18 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:39:18 INFO DAGScheduler: running: Set()
16/03/17 15:39:18 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:39:18 INFO DAGScheduler: failed: Set()
16/03/17 15:39:18 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:39:18 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:39:18 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=555755765
16/03/17 15:39:18 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.0 MB)
16/03/17 15:39:18 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=555755765
16/03/17 15:39:18 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.0 MB)
16/03/17 15:39:18 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:55623 (size: 3.0 KB, free: 530.0 MB)
16/03/17 15:39:18 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:39:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:39:18 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:39:18 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:39:18 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:39:18 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:39:18 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:39:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:39:18 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:39:18 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:39:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'area', u'area']
16/03/17 15:39:19 INFO PythonRunner: Times: total = 160, boot = 159, init = 0, finish = 1
16/03/17 15:39:19 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/17 15:39:19 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 190 ms on localhost (1/2)
16/03/17 15:39:19 INFO PythonRunner: Times: total = 267, boot = 267, init = 0, finish = 0
16/03/17 15:39:19 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:39:19 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.289 s
16/03/17 15:39:19 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.879179 s
16/03/17 15:39:19 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 296 ms on localhost (2/2)
16/03/17 15:39:19 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:39:19 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:39:19 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:39:19 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:39:19 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:39:19 INFO DAGScheduler: Missing parents: List()
16/03/17 15:39:19 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:39:19 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=555755765
16/03/17 15:39:19 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.0 MB)
16/03/17 15:39:19 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=555755765
16/03/17 15:39:19 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
16/03/17 15:39:19 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:55623 (size: 3.3 KB, free: 530.0 MB)
16/03/17 15:39:19 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:39:19 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:39:19 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:39:19 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:39:19 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/17 15:39:19 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:39:19 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:39:19 INFO PythonRunner: Times: total = 6, boot = -38, init = 43, finish = 1
16/03/17 15:39:19 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:39:19 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 62 ms on localhost (1/2)
16/03/17 15:39:19 INFO PythonRunner: Times: total = 171, boot = 171, init = 0, finish = 0
16/03/17 15:39:19 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/03/17 15:39:19 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 191 ms on localhost (2/2)
16/03/17 15:39:19 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:39:19 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.193 s
16/03/17 15:39:19 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.218254 s
16/03/17 15:39:19 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:39:19 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:39:19 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:39:19 INFO MemoryStore: MemoryStore cleared
16/03/17 15:39:19 INFO BlockManager: BlockManager stopped
16/03/17 15:39:19 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:39:19 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:39:19 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:39:19 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:39:19 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:39:19 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:39:20 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:39:20 INFO SecurityManager: Changing view acls to: root
16/03/17 15:39:20 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:39:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:39:20 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:39:20 INFO Remoting: Starting remoting
16/03/17 15:39:20 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:56683]
16/03/17 15:39:20 INFO Utils: Successfully started service 'sparkDriver' on port 56683.
16/03/17 15:39:20 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:39:20 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:39:20 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-18109013-c73b-4c77-a35e-bfff2dc3e606
16/03/17 15:39:20 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
16/03/17 15:39:20 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-3d64426a-6056-4fd0-8b1f-2c69ea50e3d8
16/03/17 15:39:20 INFO HttpServer: Starting HTTP Server
16/03/17 15:39:20 INFO Utils: Successfully started service 'HTTP file server' on port 58558.
16/03/17 15:39:20 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:39:20 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:39:20 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:39:20 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-0aeffc2c-3958-4e11-bc9f-75c362d6f9d2/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:39:20 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209360750
16/03/17 15:39:20 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:39:20 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:39:20 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40795.
16/03/17 15:39:20 INFO NettyBlockTransferService: Server created on 40795
16/03/17 15:39:20 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:39:20 INFO BlockManagerMasterEndpoint: Registering block manager localhost:40795 with 530.0 MB RAM, BlockManagerId(driver, localhost, 40795)
16/03/17 15:39:20 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:39:20 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:39:20 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:39:20 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:39:20 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:39:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:39:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:39:20 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:39:20 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555755765
16/03/17 15:39:20 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)
16/03/17 15:39:20 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555755765
16/03/17 15:39:20 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)
16/03/17 15:39:20 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:40795 (size: 4.1 KB, free: 530.0 MB)
16/03/17 15:39:20 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:39:20 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:39:20 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:39:20 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:39:20 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:39:20 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:39:20 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209360750
16/03/17 15:39:20 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:39:20 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-0aeffc2c-3958-4e11-bc9f-75c362d6f9d2/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:39:20 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:39:20 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=555755765
16/03/17 15:39:20 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 530.0 MB)
16/03/17 15:39:20 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:40795 (size: 179.0 B, free: 530.0 MB)
16/03/17 15:39:20 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:39:20 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=555755765
16/03/17 15:39:20 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 530.0 MB)
16/03/17 15:39:20 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:40795 (size: 173.0 B, free: 530.0 MB)
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: set
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: planning
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: permission
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: economy
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: composition
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: agency
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:39:29 INFO PythonRunner: Times: total = 8102, boot = 457, init = 383, finish = 7262
16/03/17 15:39:29 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:39:29 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8167 ms on localhost (1/2)
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  Synset('set.n.01') ; keyword:  group  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: bend
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: giant
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: astatine
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: present
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: area
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): group
mapFunction_Parents(): keyword: group ; prevleveltokens: issue
mapFunction_Parents(): keyword= group ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
16/03/17 15:39:29 INFO PythonRunner: Times: total = 8449, boot = 458, init = 384, finish = 7607
16/03/17 15:39:29 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:39:29 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8525 ms on localhost (2/2)
16/03/17 15:39:29 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.528 s
16/03/17 15:39:29 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:39:29 INFO DAGScheduler: running: Set()
16/03/17 15:39:29 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:39:29 INFO DAGScheduler: failed: Set()
16/03/17 15:39:29 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:39:29 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:39:29 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=555755765
16/03/17 15:39:29 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.0 MB)
16/03/17 15:39:29 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:39:29 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=555755765
16/03/17 15:39:29 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.0 MB)
16/03/17 15:39:29 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:40795 (size: 3.0 KB, free: 530.0 MB)
16/03/17 15:39:29 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:39:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:39:29 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:39:29 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:39:29 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:39:29 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:39:29 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:39:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:39:29 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:39:29 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:39:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= [u'set', 'None']
16/03/17 15:39:29 INFO PythonRunner: Times: total = 24, boot = -209, init = 233, finish = 0
16/03/17 15:39:29 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1271 bytes result sent to driver
16/03/17 15:39:29 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 70 ms on localhost (1/2)
16/03/17 15:39:29 INFO PythonRunner: Times: total = 295, boot = 294, init = 1, finish = 0
16/03/17 15:39:29 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:39:29 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.301 s
16/03/17 15:39:29 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.880994 s
16/03/17 15:39:29 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 309 ms on localhost (2/2)
16/03/17 15:39:29 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:39:29 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:39:29 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:39:29 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:39:29 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:39:29 INFO DAGScheduler: Missing parents: List()
16/03/17 15:39:29 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:39:29 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=555755765
16/03/17 15:39:29 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.0 MB)
16/03/17 15:39:29 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=555755765
16/03/17 15:39:29 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
16/03/17 15:39:29 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:40795 (size: 3.3 KB, free: 530.0 MB)
16/03/17 15:39:29 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:39:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:39:29 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:39:29 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:39:29 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/17 15:39:29 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:39:29 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:39:30 INFO PythonRunner: Times: total = 41, boot = -177, init = 218, finish = 0
16/03/17 15:39:30 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:39:30 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 58 ms on localhost (1/2)
16/03/17 15:39:30 INFO PythonRunner: Times: total = 66, boot = 65, init = 1, finish = 0
16/03/17 15:39:30 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1336 bytes result sent to driver
16/03/17 15:39:30 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 85 ms on localhost (2/2)
16/03/17 15:39:30 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:39:30 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.058 s
16/03/17 15:39:30 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.113667 s
16/03/17 15:39:30 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:39:30 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:39:30 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:39:30 INFO MemoryStore: MemoryStore cleared
16/03/17 15:39:30 INFO BlockManager: BlockManager stopped
16/03/17 15:39:30 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:39:30 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:39:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:39:30 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:39:30 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:39:30 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:39:31 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:39:31 INFO SecurityManager: Changing view acls to: root
16/03/17 15:39:31 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:39:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:39:31 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:39:31 INFO Remoting: Starting remoting
16/03/17 15:39:31 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:39200]
16/03/17 15:39:31 INFO Utils: Successfully started service 'sparkDriver' on port 39200.
16/03/17 15:39:31 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:39:31 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:39:31 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c2643f28-eb5f-42b1-838b-e9b1a4a5126c
16/03/17 15:39:31 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
16/03/17 15:39:31 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-2be7657d-06da-4438-a2e5-bb5b5d758240
16/03/17 15:39:31 INFO HttpServer: Starting HTTP Server
16/03/17 15:39:31 INFO Utils: Successfully started service 'HTTP file server' on port 43291.
16/03/17 15:39:31 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:39:31 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:39:31 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:39:31 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-8257c8bb-4336-42c1-b4bd-995281b3483c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:39:31 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209371244
16/03/17 15:39:31 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:39:31 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:39:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50092.
16/03/17 15:39:31 INFO NettyBlockTransferService: Server created on 50092
16/03/17 15:39:31 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:39:31 INFO BlockManagerMasterEndpoint: Registering block manager localhost:50092 with 530.0 MB RAM, BlockManagerId(driver, localhost, 50092)
16/03/17 15:39:31 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:39:31 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:39:31 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:39:31 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:39:31 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:39:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:39:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:39:31 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:39:31 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555755765
16/03/17 15:39:31 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)
16/03/17 15:39:31 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555755765
16/03/17 15:39:31 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)
16/03/17 15:39:31 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:50092 (size: 4.1 KB, free: 530.0 MB)
16/03/17 15:39:31 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:39:31 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:39:31 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:39:31 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:39:31 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:39:31 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:39:31 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209371244
16/03/17 15:39:31 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:39:31 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-8257c8bb-4336-42c1-b4bd-995281b3483c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:39:31 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:39:31 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10732, maxMem=555755765
16/03/17 15:39:31 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 530.0 MB)
16/03/17 15:39:31 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:39:31 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:50092 (size: 173.0 B, free: 530.0 MB)
16/03/17 15:39:31 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10905, maxMem=555755765
16/03/17 15:39:31 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 530.0 MB)
16/03/17 15:39:31 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:50092 (size: 179.0 B, free: 530.0 MB)
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: set
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: bend
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: giant
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: astatine
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  decay  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: present
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: area
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: issue
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/17 15:39:39 INFO PythonRunner: Times: total = 8291, boot = 458, init = 385, finish = 7448
16/03/17 15:39:39 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:39:39 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8365 ms on localhost (1/2)
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: planning
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: permission
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: economy
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: composition
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: agency
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): decay
mapFunction_Parents(): keyword: decay ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= decay ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:39:39 INFO PythonRunner: Times: total = 8536, boot = 461, init = 379, finish = 7696
16/03/17 15:39:39 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:39:40 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8600 ms on localhost (2/2)
16/03/17 15:39:40 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:39:40 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.608 s
16/03/17 15:39:40 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:39:40 INFO DAGScheduler: running: Set()
16/03/17 15:39:40 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:39:40 INFO DAGScheduler: failed: Set()
16/03/17 15:39:40 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:39:40 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:39:40 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=555755765
16/03/17 15:39:40 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.0 MB)
16/03/17 15:39:40 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=555755765
16/03/17 15:39:40 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.0 MB)
16/03/17 15:39:40 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:50092 (size: 3.0 KB, free: 530.0 MB)
16/03/17 15:39:40 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:39:40 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:39:40 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:39:40 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:39:40 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:39:40 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:39:40 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:39:40 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:39:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:39:40 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:39:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'astatine', 'None']
16/03/17 15:39:40 INFO PythonRunner: Times: total = 17, boot = -79, init = 96, finish = 0
16/03/17 15:39:40 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/03/17 15:39:40 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 35 ms on localhost (1/2)
16/03/17 15:39:40 INFO PythonRunner: Times: total = 201, boot = 200, init = 1, finish = 0
16/03/17 15:39:40 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:39:40 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.211 s
16/03/17 15:39:40 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.855113 s
16/03/17 15:39:40 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 220 ms on localhost (2/2)
16/03/17 15:39:40 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:39:40 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:39:40 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:39:40 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:39:40 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:39:40 INFO DAGScheduler: Missing parents: List()
16/03/17 15:39:40 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:39:40 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=555755765
16/03/17 15:39:40 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.0 MB)
16/03/17 15:39:40 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=555755765
16/03/17 15:39:40 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
16/03/17 15:39:40 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:50092 (size: 3.3 KB, free: 530.0 MB)
16/03/17 15:39:40 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:39:40 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:39:40 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:39:40 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:39:40 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/03/17 15:39:40 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:39:40 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:39:40 INFO PythonRunner: Times: total = 4, boot = -22, init = 26, finish = 0
16/03/17 15:39:40 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/03/17 15:39:40 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 36 ms on localhost (1/2)
16/03/17 15:39:40 INFO PythonRunner: Times: total = 41, boot = -180, init = 221, finish = 0
16/03/17 15:39:40 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:39:40 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 51 ms on localhost (2/2)
16/03/17 15:39:40 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:39:40 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.052 s
16/03/17 15:39:40 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.076243 s
16/03/17 15:39:40 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:39:40 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:39:40 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:39:40 INFO MemoryStore: MemoryStore cleared
16/03/17 15:39:40 INFO BlockManager: BlockManager stopped
16/03/17 15:39:40 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:39:40 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:39:40 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:39:40 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:39:40 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:39:40 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:39:41 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:39:41 INFO SecurityManager: Changing view acls to: root
16/03/17 15:39:41 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:39:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:39:41 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:39:41 INFO Remoting: Starting remoting
16/03/17 15:39:41 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:55789]
16/03/17 15:39:41 INFO Utils: Successfully started service 'sparkDriver' on port 55789.
16/03/17 15:39:41 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:39:41 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:39:41 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-276c0e6c-0342-4c74-990c-fad51f99c86a
16/03/17 15:39:41 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
16/03/17 15:39:41 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-9045c3c9-2962-44e4-89c5-06c183008ccf
16/03/17 15:39:41 INFO HttpServer: Starting HTTP Server
16/03/17 15:39:41 INFO Utils: Successfully started service 'HTTP file server' on port 34754.
16/03/17 15:39:41 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:39:41 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:39:41 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:39:41 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-938ecdcf-c34b-46c0-a9c5-e84447a9c0cc/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:39:41 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209381718
16/03/17 15:39:41 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:39:41 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:39:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55585.
16/03/17 15:39:41 INFO NettyBlockTransferService: Server created on 55585
16/03/17 15:39:41 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:39:41 INFO BlockManagerMasterEndpoint: Registering block manager localhost:55585 with 530.0 MB RAM, BlockManagerId(driver, localhost, 55585)
16/03/17 15:39:41 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:39:41 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:39:41 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:39:41 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:39:41 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:39:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:39:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:39:41 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:39:41 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555755765
16/03/17 15:39:41 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)
16/03/17 15:39:41 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555755765
16/03/17 15:39:41 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)
16/03/17 15:39:41 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:55585 (size: 4.1 KB, free: 530.0 MB)
16/03/17 15:39:41 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:39:41 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:39:41 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:39:41 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:39:41 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:39:41 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:39:41 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209381718
16/03/17 15:39:41 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:39:41 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-938ecdcf-c34b-46c0-a9c5-e84447a9c0cc/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:39:41 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:39:41 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=555755765
16/03/17 15:39:41 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 530.0 MB)
16/03/17 15:39:41 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:55585 (size: 179.0 B, free: 530.0 MB)
16/03/17 15:39:41 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:39:41 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=555755765
16/03/17 15:39:41 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 530.0 MB)
16/03/17 15:39:41 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:55585 (size: 173.0 B, free: 530.0 MB)
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: area
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: planning
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): adding to parents: syn =  Synset('planning.n.01') ; keyword:  program  in syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= [u'planning']
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: permission
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: economy
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: composition
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: agency
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
16/03/17 15:39:52 INFO PythonRunner: Times: total = 10670, boot = 459, init = 715, finish = 9496
16/03/17 15:39:52 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:39:52 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 10756 ms on localhost (1/2)
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: bend
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: giant
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: astatine
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: present
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: area
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): program
mapFunction_Parents(): keyword: program ; prevleveltokens: issue
mapFunction_Parents(): keyword= program ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:39:52 INFO PythonRunner: Times: total = 10929, boot = 525, init = 407, finish = 9997
16/03/17 15:39:52 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:39:52 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 11021 ms on localhost (2/2)
16/03/17 15:39:52 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:39:52 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 11.023 s
16/03/17 15:39:52 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:39:52 INFO DAGScheduler: running: Set()
16/03/17 15:39:52 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:39:52 INFO DAGScheduler: failed: Set()
16/03/17 15:39:52 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:39:52 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:39:52 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=555755765
16/03/17 15:39:52 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.0 MB)
16/03/17 15:39:52 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=555755765
16/03/17 15:39:52 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.0 MB)
16/03/17 15:39:52 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:55585 (size: 3.0 KB, free: 530.0 MB)
16/03/17 15:39:52 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:39:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:39:52 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:39:52 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:39:52 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:39:52 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:39:52 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:39:52 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:39:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
16/03/17 15:39:52 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:39:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
reduceFunction_Parents(): returns= ['None', 'None', u'planning']
16/03/17 15:39:52 INFO PythonRunner: Times: total = 12, boot = -58, init = 70, finish = 0
16/03/17 15:39:52 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/03/17 15:39:53 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 58 ms on localhost (1/2)
16/03/17 15:39:53 INFO PythonRunner: Times: total = 281, boot = 280, init = 1, finish = 0
16/03/17 15:39:53 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:39:53 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.286 s
16/03/17 15:39:53 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 11.363909 s
16/03/17 15:39:53 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 293 ms on localhost (2/2)
16/03/17 15:39:53 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:39:53 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:39:53 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:39:53 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:39:53 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:39:53 INFO DAGScheduler: Missing parents: List()
16/03/17 15:39:53 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:39:53 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=555755765
16/03/17 15:39:53 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.0 MB)
16/03/17 15:39:53 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=555755765
16/03/17 15:39:53 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
16/03/17 15:39:53 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:55585 (size: 3.3 KB, free: 530.0 MB)
16/03/17 15:39:53 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:39:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:39:53 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:39:53 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:39:53 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/03/17 15:39:53 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:39:53 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:39:53 INFO PythonRunner: Times: total = 43, boot = -175, init = 218, finish = 0
16/03/17 15:39:53 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:39:53 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 55 ms on localhost (1/2)
16/03/17 15:39:53 INFO PythonRunner: Times: total = 127, boot = 127, init = 0, finish = 0
16/03/17 15:39:53 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/03/17 15:39:53 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 137 ms on localhost (2/2)
16/03/17 15:39:53 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:39:53 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.137 s
16/03/17 15:39:53 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.162790 s
16/03/17 15:39:53 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:39:53 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:39:53 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:39:53 INFO MemoryStore: MemoryStore cleared
16/03/17 15:39:53 INFO BlockManager: BlockManager stopped
16/03/17 15:39:53 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:39:53 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:39:53 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:39:53 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:39:53 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:39:53 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:39:54 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:39:54 INFO SecurityManager: Changing view acls to: root
16/03/17 15:39:54 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:39:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:39:54 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:39:54 INFO Remoting: Starting remoting
16/03/17 15:39:54 INFO Utils: Successfully started service 'sparkDriver' on port 40991.
16/03/17 15:39:54 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:40991]
16/03/17 15:39:54 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:39:54 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:39:54 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-951e0434-4d41-4ff0-b999-3a534d99b2fc
16/03/17 15:39:54 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
16/03/17 15:39:54 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-2c21dce9-95f6-41fe-8bc6-6da48c766e4c
16/03/17 15:39:54 INFO HttpServer: Starting HTTP Server
16/03/17 15:39:54 INFO Utils: Successfully started service 'HTTP file server' on port 57785.
16/03/17 15:39:54 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:39:54 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:39:54 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:39:54 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-2ca1252f-82d6-465c-8b08-8b58b27ba326/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:39:54 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209394734
16/03/17 15:39:54 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:39:54 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:39:54 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59528.
16/03/17 15:39:54 INFO NettyBlockTransferService: Server created on 59528
16/03/17 15:39:54 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:39:54 INFO BlockManagerMasterEndpoint: Registering block manager localhost:59528 with 530.0 MB RAM, BlockManagerId(driver, localhost, 59528)
16/03/17 15:39:54 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:39:54 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:39:54 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:39:54 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:39:54 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:39:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:39:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:39:54 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:39:54 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555755765
16/03/17 15:39:54 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)
16/03/17 15:39:54 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555755765
16/03/17 15:39:54 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)
16/03/17 15:39:54 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:59528 (size: 4.1 KB, free: 530.0 MB)
16/03/17 15:39:54 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:39:54 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:39:54 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:39:54 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:39:54 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:39:54 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:39:54 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209394734
16/03/17 15:39:54 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:39:54 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-2ca1252f-82d6-465c-8b08-8b58b27ba326/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:39:54 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:39:54 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10732, maxMem=555755765
16/03/17 15:39:54 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 530.0 MB)
16/03/17 15:39:54 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:59528 (size: 173.0 B, free: 530.0 MB)
16/03/17 15:39:54 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:39:54 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10905, maxMem=555755765
16/03/17 15:39:54 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 530.0 MB)
16/03/17 15:39:54 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:59528 (size: 179.0 B, free: 530.0 MB)
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: area
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: bend
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: giant
mapFunction_Parents(): keyword= mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
Tamil asfer_pickle_string_load(): picklef.readlines(): Tamil
; syndef_tokens=mapFunction_Parents(): keyword: Tamil ; prevleveltokens: kilometer
 set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: astatine
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: planning
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: present
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: permission
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: economy
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: composition
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Tamil  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): TamilmapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']

asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: agency
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): TamilmapFunction_Parents(): keyword=
 Tamil ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Tamil  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: issue
16/03/17 15:40:03 INFO PythonRunner: Times: total = 8784, boot = 477, init = 725, finish = 7582
16/03/17 15:40:03 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:40:03 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8888 ms on localhost (1/2)
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/17 15:40:03 INFO PythonRunner: Times: total = 8845, boot = 482, init = 728, finish = 7635
16/03/17 15:40:03 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:40:03 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.947 s
16/03/17 15:40:03 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8944 ms on localhost (2/2)
16/03/17 15:40:03 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:40:03 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:40:03 INFO DAGScheduler: running: Set()
16/03/17 15:40:03 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:40:03 INFO DAGScheduler: failed: Set()
16/03/17 15:40:03 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:40:03 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:40:03 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=555755765
16/03/17 15:40:03 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.0 MB)
16/03/17 15:40:03 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=555755765
16/03/17 15:40:03 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.0 MB)
16/03/17 15:40:03 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:59528 (size: 3.0 KB, free: 530.0 MB)
16/03/17 15:40:03 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:40:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:40:03 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:40:03 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:40:03 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:40:03 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:40:03 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:40:03 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:40:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:40:03 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:40:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
16/03/17 15:40:04 INFO PythonRunner: Times: total = 174, boot = 173, init = 0, finish = 1
16/03/17 15:40:04 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:40:04 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 193 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'Chennai', 'None', u'Chennai']
16/03/17 15:40:04 INFO PythonRunner: Times: total = 227, boot = 225, init = 0, finish = 2
16/03/17 15:40:04 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1297 bytes result sent to driver
16/03/17 15:40:04 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.257 s
16/03/17 15:40:04 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.243525 s
16/03/17 15:40:04 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 255 ms on localhost (2/2)
16/03/17 15:40:04 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:40:04 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:40:04 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:40:04 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:40:04 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:40:04 INFO DAGScheduler: Missing parents: List()
16/03/17 15:40:04 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:40:04 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=555755765
16/03/17 15:40:04 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.0 MB)
16/03/17 15:40:04 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=555755765
16/03/17 15:40:04 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
16/03/17 15:40:04 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:59528 (size: 3.3 KB, free: 530.0 MB)
16/03/17 15:40:04 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:40:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:40:04 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:40:04 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:40:04 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2378 bytes)
16/03/17 15:40:04 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:40:04 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:40:04 INFO PythonRunner: Times: total = 71, boot = 71, init = 0, finish = 0
16/03/17 15:40:04 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1365 bytes result sent to driver
16/03/17 15:40:04 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 80 ms on localhost (1/2)
16/03/17 15:40:04 INFO PythonRunner: Times: total = 244, boot = 244, init = 0, finish = 0
16/03/17 15:40:04 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:40:04 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 259 ms on localhost (2/2)
16/03/17 15:40:04 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:40:04 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.257 s
16/03/17 15:40:04 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.282664 s
16/03/17 15:40:04 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:40:04 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:40:04 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:40:04 INFO MemoryStore: MemoryStore cleared
16/03/17 15:40:04 INFO BlockManager: BlockManager stopped
16/03/17 15:40:04 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:40:04 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:40:04 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:40:05 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:40:05 INFO SecurityManager: Changing view acls to: root
16/03/17 15:40:05 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:40:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:40:05 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:40:05 INFO Remoting: Starting remoting
16/03/17 15:40:05 INFO Utils: Successfully started service 'sparkDriver' on port 37962.
16/03/17 15:40:05 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:37962]
16/03/17 15:40:05 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:40:05 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:40:05 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d9fa33b1-079c-4037-b187-cc47781e0a0d
16/03/17 15:40:05 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
16/03/17 15:40:05 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-ce2965fd-1492-43a3-8f9f-93f6f0252429
16/03/17 15:40:05 INFO HttpServer: Starting HTTP Server
16/03/17 15:40:05 INFO Utils: Successfully started service 'HTTP file server' on port 34648.
16/03/17 15:40:05 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:40:05 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:40:05 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:40:05 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-3903cae1-35ac-4406-8d2f-2c1838473edf/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:40:05 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209405765
16/03/17 15:40:05 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:40:05 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:40:05 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49919.
16/03/17 15:40:05 INFO NettyBlockTransferService: Server created on 49919
16/03/17 15:40:05 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:40:05 INFO BlockManagerMasterEndpoint: Registering block manager localhost:49919 with 530.0 MB RAM, BlockManagerId(driver, localhost, 49919)
16/03/17 15:40:05 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:40:05 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:40:05 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:40:05 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:40:05 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:40:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:40:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:40:05 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:40:05 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555755765
16/03/17 15:40:05 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)
16/03/17 15:40:05 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555755765
16/03/17 15:40:05 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)
16/03/17 15:40:05 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:49919 (size: 4.1 KB, free: 530.0 MB)
16/03/17 15:40:05 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:40:05 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:40:05 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:40:05 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:40:05 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:40:05 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:40:05 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209405765
16/03/17 15:40:05 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:40:05 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-3903cae1-35ac-4406-8d2f-2c1838473edf/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:40:05 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:40:05 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=555755765
16/03/17 15:40:05 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 530.0 MB)
16/03/17 15:40:05 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:40:05 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:49919 (size: 179.0 B, free: 530.0 MB)
16/03/17 15:40:05 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=555755765
16/03/17 15:40:05 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 530.0 MB)
16/03/17 15:40:05 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:49919 (size: 173.0 B, free: 530.0 MB)
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: area
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: planning
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: permission
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: economy
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: composition
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: agency
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:40:14 INFO PythonRunner: Times: total = 8707, boot = 510, init = 547, finish = 7650
16/03/17 15:40:14 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: bend
16/03/17 15:40:14 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8772 ms on localhost (1/2)
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: giant
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): adding to parents: syn =  Synset('colossus.n.02') ; keyword:  exceptional  in syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= [u'giant']
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: astatine
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: present
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: area
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): exceptional
mapFunction_Parents(): keyword: exceptional ; prevleveltokens: issue
mapFunction_Parents(): keyword= exceptional ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
16/03/17 15:40:14 INFO PythonRunner: Times: total = 8846, boot = 510, init = 527, finish = 7809
16/03/17 15:40:14 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:40:14 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.918 s
16/03/17 15:40:14 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:40:14 INFO DAGScheduler: running: Set()
16/03/17 15:40:14 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:40:14 INFO DAGScheduler: failed: Set()
16/03/17 15:40:14 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:40:14 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:40:14 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=555755765
16/03/17 15:40:14 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.0 MB)
16/03/17 15:40:14 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8916 ms on localhost (2/2)
16/03/17 15:40:14 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:40:14 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=555755765
16/03/17 15:40:14 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.0 MB)
16/03/17 15:40:14 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:49919 (size: 3.0 KB, free: 530.0 MB)
16/03/17 15:40:14 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:40:14 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:40:14 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:40:14 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:40:14 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:40:14 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:40:14 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:40:14 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:40:14 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:40:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:40:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
reduceFunction_Parents(): returns= ['None', u'giant', 'None']
16/03/17 15:40:14 INFO PythonRunner: Times: total = 104, boot = 103, init = 0, finish = 1
16/03/17 15:40:14 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1281 bytes result sent to driver
16/03/17 15:40:15 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 119 ms on localhost (1/2)
16/03/17 15:40:15 INFO PythonRunner: Times: total = 237, boot = 236, init = 1, finish = 0
16/03/17 15:40:15 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:40:15 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.250 s
16/03/17 15:40:15 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.219424 s
16/03/17 15:40:15 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 252 ms on localhost (2/2)
16/03/17 15:40:15 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:40:15 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:40:15 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:40:15 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:40:15 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:40:15 INFO DAGScheduler: Missing parents: List()
16/03/17 15:40:15 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:40:15 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=555755765
16/03/17 15:40:15 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.0 MB)
16/03/17 15:40:15 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=555755765
16/03/17 15:40:15 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
16/03/17 15:40:15 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:49919 (size: 3.3 KB, free: 530.0 MB)
16/03/17 15:40:15 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:40:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:40:15 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:40:15 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:40:15 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2362 bytes)
16/03/17 15:40:15 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:40:15 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:40:15 INFO PythonRunner: Times: total = 48, boot = 47, init = 0, finish = 1
16/03/17 15:40:15 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1349 bytes result sent to driver
16/03/17 15:40:15 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 56 ms on localhost (1/2)
16/03/17 15:40:15 INFO PythonRunner: Times: total = 159, boot = 159, init = 0, finish = 0
16/03/17 15:40:15 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:40:15 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 166 ms on localhost (2/2)
16/03/17 15:40:15 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:40:15 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.172 s
16/03/17 15:40:15 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.191004 s
16/03/17 15:40:15 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:40:15 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:40:15 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:40:15 INFO MemoryStore: MemoryStore cleared
16/03/17 15:40:15 INFO BlockManager: BlockManager stopped
16/03/17 15:40:15 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:40:15 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:40:15 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:40:15 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:40:15 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:40:15 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:40:16 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:40:16 INFO SecurityManager: Changing view acls to: root
16/03/17 15:40:16 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:40:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:40:16 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:40:16 INFO Remoting: Starting remoting
16/03/17 15:40:16 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:57883]
16/03/17 15:40:16 INFO Utils: Successfully started service 'sparkDriver' on port 57883.
16/03/17 15:40:16 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:40:16 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:40:16 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2726c148-f5a2-424e-85c0-e232defec4c6
16/03/17 15:40:16 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
16/03/17 15:40:16 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-652798c8-9297-4599-b777-d75f5dd6efee
16/03/17 15:40:16 INFO HttpServer: Starting HTTP Server
16/03/17 15:40:16 INFO Utils: Successfully started service 'HTTP file server' on port 48237.
16/03/17 15:40:16 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:40:16 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:40:16 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:40:16 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-a0b1019d-c8f9-47eb-88e2-7fc526eb972b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:40:16 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209416700
16/03/17 15:40:16 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:40:16 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:40:16 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37904.
16/03/17 15:40:16 INFO NettyBlockTransferService: Server created on 37904
16/03/17 15:40:16 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:40:16 INFO BlockManagerMasterEndpoint: Registering block manager localhost:37904 with 530.0 MB RAM, BlockManagerId(driver, localhost, 37904)
16/03/17 15:40:16 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:40:16 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:40:16 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:40:16 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:40:16 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:40:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:40:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:40:16 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:40:16 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555755765
16/03/17 15:40:16 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)
16/03/17 15:40:16 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555755765
16/03/17 15:40:16 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)
16/03/17 15:40:16 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:37904 (size: 4.1 KB, free: 530.0 MB)
16/03/17 15:40:16 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:40:16 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:40:16 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:40:16 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:40:16 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:40:16 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:40:16 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209416700
16/03/17 15:40:16 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:40:16 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-a0b1019d-c8f9-47eb-88e2-7fc526eb972b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:40:17 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:40:17 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=555755765
16/03/17 15:40:17 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 530.0 MB)
16/03/17 15:40:17 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:40:17 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:37904 (size: 179.0 B, free: 530.0 MB)
16/03/17 15:40:17 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=555755765
16/03/17 15:40:17 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 530.0 MB)
16/03/17 15:40:17 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:37904 (size: 173.0 B, free: 530.0 MB)
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: set
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: bend
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: giant
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: astatine
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: present
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Bay  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: area
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: issue
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: planning
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: permission
16/03/17 15:40:25 INFO PythonRunner: Times: total = 8839, boot = 496, init = 646, finish = 7697
16/03/17 15:40:25 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: economy
16/03/17 15:40:25 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8934 ms on localhost (1/2)
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: composition
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: agency
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Bay  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/17 15:40:25 INFO PythonRunner: Times: total = 8918, boot = 500, init = 414, finish = 8004
16/03/17 15:40:25 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:40:25 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9018 ms on localhost (2/2)
16/03/17 15:40:25 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:40:25 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.025 s
16/03/17 15:40:25 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:40:25 INFO DAGScheduler: running: Set()
16/03/17 15:40:25 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:40:25 INFO DAGScheduler: failed: Set()
16/03/17 15:40:25 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:40:25 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:40:25 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=555755765
16/03/17 15:40:25 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.0 MB)
16/03/17 15:40:25 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=555755765
16/03/17 15:40:25 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.0 MB)
16/03/17 15:40:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:37904 (size: 3.0 KB, free: 530.0 MB)
16/03/17 15:40:25 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:40:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:40:25 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:40:25 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:40:25 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:40:25 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:40:25 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:40:25 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:40:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:40:25 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:40:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
reduceFunction_Parents(): returns= ['None', u'Chennai', 'None', u'Chennai']
16/03/17 15:40:26 INFO PythonRunner: Times: total = 129, boot = 128, init = 1, finish = 0
16/03/17 15:40:26 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1297 bytes result sent to driver
16/03/17 15:40:26 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 144 ms on localhost (1/2)
16/03/17 15:40:26 INFO PythonRunner: Times: total = 207, boot = 206, init = 0, finish = 1
16/03/17 15:40:26 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:40:26 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.219 s
16/03/17 15:40:26 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.299921 s
16/03/17 15:40:26 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 224 ms on localhost (2/2)
16/03/17 15:40:26 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:40:26 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:40:26 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:40:26 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:40:26 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:40:26 INFO DAGScheduler: Missing parents: List()
16/03/17 15:40:26 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:40:26 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=555755765
16/03/17 15:40:26 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.0 MB)
16/03/17 15:40:26 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=555755765
16/03/17 15:40:26 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
16/03/17 15:40:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:37904 (size: 3.3 KB, free: 530.0 MB)
16/03/17 15:40:26 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:40:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:40:26 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:40:26 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:40:26 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2378 bytes)
16/03/17 15:40:26 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:40:26 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:40:26 INFO PythonRunner: Times: total = 103, boot = 103, init = 0, finish = 0
16/03/17 15:40:26 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1365 bytes result sent to driver
16/03/17 15:40:26 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 117 ms on localhost (1/2)
16/03/17 15:40:26 INFO PythonRunner: Times: total = 112, boot = 111, init = 0, finish = 1
16/03/17 15:40:26 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:40:26 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 130 ms on localhost (2/2)
16/03/17 15:40:26 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:40:26 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.113 s
16/03/17 15:40:26 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.150410 s
16/03/17 15:40:26 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:40:26 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:40:26 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:40:26 INFO MemoryStore: MemoryStore cleared
16/03/17 15:40:26 INFO BlockManager: BlockManager stopped
16/03/17 15:40:26 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:40:26 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:40:26 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:40:26 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:40:26 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:40:27 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:40:27 INFO SecurityManager: Changing view acls to: root
16/03/17 15:40:27 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:40:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:40:27 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:40:27 INFO Remoting: Starting remoting
16/03/17 15:40:27 INFO Utils: Successfully started service 'sparkDriver' on port 37931.
16/03/17 15:40:27 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:37931]
16/03/17 15:40:27 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:40:27 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:40:27 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8e202f55-003c-4032-b330-aa1d2143532f
16/03/17 15:40:27 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
16/03/17 15:40:27 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-b78dabe4-cb87-47d1-b051-550150922947
16/03/17 15:40:27 INFO HttpServer: Starting HTTP Server
16/03/17 15:40:27 INFO Utils: Successfully started service 'HTTP file server' on port 49109.
16/03/17 15:40:27 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:40:27 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:40:27 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:40:27 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-ca40f8c3-4e79-4c6b-a307-436c18caf7f4/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:40:27 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209427674
16/03/17 15:40:27 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:40:27 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:40:27 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60953.
16/03/17 15:40:27 INFO NettyBlockTransferService: Server created on 60953
16/03/17 15:40:27 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:40:27 INFO BlockManagerMasterEndpoint: Registering block manager localhost:60953 with 530.0 MB RAM, BlockManagerId(driver, localhost, 60953)
16/03/17 15:40:27 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:40:27 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:40:27 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:40:27 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:40:27 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:40:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:40:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:40:27 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:40:27 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555755765
16/03/17 15:40:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)
16/03/17 15:40:27 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555755765
16/03/17 15:40:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)
16/03/17 15:40:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:60953 (size: 4.1 KB, free: 530.0 MB)
16/03/17 15:40:27 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:40:27 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:40:27 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:40:27 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:40:27 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:40:27 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:40:27 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209427674
16/03/17 15:40:27 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:40:27 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-ca40f8c3-4e79-4c6b-a307-436c18caf7f4/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:40:27 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:40:27 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:40:27 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10732, maxMem=555755765
16/03/17 15:40:27 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 530.0 MB)
16/03/17 15:40:27 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10905, maxMem=555755765
16/03/17 15:40:27 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:60953 (size: 173.0 B, free: 530.0 MB)
16/03/17 15:40:27 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 530.0 MB)
16/03/17 15:40:27 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:60953 (size: 179.0 B, free: 530.0 MB)
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: set
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: planning
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): adding to parents: syn =  Synset('planning.n.01') ; keyword:  formulating  in syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= [u'planning']
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: permission
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: economy
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: composition
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: agency
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
16/03/17 15:40:36 INFO PythonRunner: Times: total = 8902, boot = 518, init = 631, finish = 7753
16/03/17 15:40:36 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:40:36 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8972 ms on localhost (1/2)
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: bend
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: giant
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: astatine
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: present
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: area
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): formulating
mapFunction_Parents(): keyword: formulating ; prevleveltokens: issue
mapFunction_Parents(): keyword= formulating ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:40:37 INFO PythonRunner: Times: total = 9300, boot = 514, init = 810, finish = 7976
16/03/17 15:40:37 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:40:37 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9362 ms on localhost (2/2)
16/03/17 15:40:37 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:40:37 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.363 s
16/03/17 15:40:37 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:40:37 INFO DAGScheduler: running: Set()
16/03/17 15:40:37 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:40:37 INFO DAGScheduler: failed: Set()
16/03/17 15:40:37 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:40:37 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:40:37 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=555755765
16/03/17 15:40:37 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.0 MB)
16/03/17 15:40:37 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=555755765
16/03/17 15:40:37 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.0 MB)
16/03/17 15:40:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:60953 (size: 3.0 KB, free: 530.0 MB)
16/03/17 15:40:37 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:40:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:40:37 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:40:37 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:40:37 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:40:37 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:40:37 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:40:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:40:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:40:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:40:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', 'None', u'planning']
16/03/17 15:40:37 INFO PythonRunner: Times: total = 23, boot = -234, init = 256, finish = 1
16/03/17 15:40:37 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/03/17 15:40:37 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 47 ms on localhost (1/2)
16/03/17 15:40:37 INFO PythonRunner: Times: total = 217, boot = 216, init = 0, finish = 1
16/03/17 15:40:37 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:40:37 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 233 ms on localhost (2/2)
16/03/17 15:40:37 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:40:37 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.230 s
16/03/17 15:40:37 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.636333 s
16/03/17 15:40:37 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:40:37 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:40:37 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:40:37 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:40:37 INFO DAGScheduler: Missing parents: List()
16/03/17 15:40:37 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:40:37 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=555755765
16/03/17 15:40:37 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.0 MB)
16/03/17 15:40:37 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=555755765
16/03/17 15:40:37 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
16/03/17 15:40:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:60953 (size: 3.3 KB, free: 530.0 MB)
16/03/17 15:40:37 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:40:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:40:37 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:40:37 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:40:37 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/03/17 15:40:37 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:40:37 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:40:37 INFO PythonRunner: Times: total = 46, boot = -134, init = 180, finish = 0
16/03/17 15:40:37 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:40:37 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 59 ms on localhost (1/2)
16/03/17 15:40:37 INFO PythonRunner: Times: total = 108, boot = 108, init = 0, finish = 0
16/03/17 15:40:37 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/03/17 15:40:37 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 116 ms on localhost (2/2)
16/03/17 15:40:37 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:40:37 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.116 s
16/03/17 15:40:37 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.136038 s
16/03/17 15:40:37 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:40:37 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:40:37 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:40:37 INFO MemoryStore: MemoryStore cleared
16/03/17 15:40:37 INFO BlockManager: BlockManager stopped
16/03/17 15:40:37 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:40:37 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:40:37 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:40:37 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:40:37 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:40:38 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:40:38 INFO SecurityManager: Changing view acls to: root
16/03/17 15:40:38 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:40:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:40:38 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:40:38 INFO Remoting: Starting remoting
16/03/17 15:40:38 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:54281]
16/03/17 15:40:38 INFO Utils: Successfully started service 'sparkDriver' on port 54281.
16/03/17 15:40:38 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:40:38 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:40:38 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5c55637d-b935-4406-b7bf-bcec1ed80188
16/03/17 15:40:38 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
16/03/17 15:40:38 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-550c4b4f-db79-4736-a324-b64198d7c767
16/03/17 15:40:38 INFO HttpServer: Starting HTTP Server
16/03/17 15:40:38 INFO Utils: Successfully started service 'HTTP file server' on port 60518.
16/03/17 15:40:38 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:40:38 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:40:38 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:40:38 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-8ef92b89-ff8f-4643-9f8a-7ea35a7bf9d9/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:40:38 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209438909
16/03/17 15:40:38 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:40:38 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:40:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41570.
16/03/17 15:40:38 INFO NettyBlockTransferService: Server created on 41570
16/03/17 15:40:38 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:40:38 INFO BlockManagerMasterEndpoint: Registering block manager localhost:41570 with 530.0 MB RAM, BlockManagerId(driver, localhost, 41570)
16/03/17 15:40:38 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:40:39 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:40:39 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:40:39 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:40:39 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:40:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:40:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:40:39 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:40:39 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555755765
16/03/17 15:40:39 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)
16/03/17 15:40:39 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555755765
16/03/17 15:40:39 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)
16/03/17 15:40:39 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:41570 (size: 4.1 KB, free: 530.0 MB)
16/03/17 15:40:39 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:40:39 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:40:39 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:40:39 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:40:39 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:40:39 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:40:39 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209438909
16/03/17 15:40:39 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:40:39 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-8ef92b89-ff8f-4643-9f8a-7ea35a7bf9d9/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:40:39 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:40:39 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=555755765
16/03/17 15:40:39 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 530.0 MB)
16/03/17 15:40:39 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:40:39 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:41570 (size: 179.0 B, free: 530.0 MB)
16/03/17 15:40:39 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=555755765
16/03/17 15:40:39 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 530.0 MB)
16/03/17 15:40:39 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:41570 (size: 173.0 B, free: 530.0 MB)
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: set
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: planning
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: permission
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: economy
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: bend
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: composition
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: agency
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): adding to parents: syn =  Synset('agency.n.02') ; keyword:  serves  in syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= [u'agency']
reduceFunction_Parents(): returns= ['None', u'agency']
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'a', mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'agency']
u'of'asfer_pickle_string_load(): picklef.readlines(): serves
, u'segment'mapFunction_Parents(): keyword:,  serves ; prevleveltokens: Chennai
u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: giant
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'agency']
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: astatine
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: present
16/03/17 15:40:47 INFO PythonRunner: Times: total = 8790, boot = 466, init = 390, finish = 7934
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [16/03/17 15:40:47 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
'None']
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: area
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): serves
mapFunction_Parents(): keyword: serves ; prevleveltokens: issue
16/03/17 15:40:47 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8881 ms on localhost (1/2)
mapFunction_Parents(): keyword= serves ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:40:47 INFO PythonRunner: Times: total = 8877, boot = 470, init = 401, finish = 8006
16/03/17 15:40:47 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:40:47 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.954 s
16/03/17 15:40:47 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:40:47 INFO DAGScheduler: running: Set()
16/03/17 15:40:47 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:40:47 INFO DAGScheduler: failed: Set()
16/03/17 15:40:47 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:40:47 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:40:47 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=555755765
16/03/17 15:40:47 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.0 MB)
16/03/17 15:40:47 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=555755765
16/03/17 15:40:47 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.0 MB)
16/03/17 15:40:47 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8953 ms on localhost (2/2)
16/03/17 15:40:47 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:40:47 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:41570 (size: 3.0 KB, free: 530.0 MB)
16/03/17 15:40:48 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:40:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:40:48 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:40:48 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:40:48 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:40:48 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:40:48 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:40:48 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:40:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:40:48 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:40:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:40:48 INFO PythonRunner: Times: total = 187, boot = 186, init = 1, finish = 0
16/03/17 15:40:48 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:40:48 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 196 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'agency']
16/03/17 15:40:48 INFO PythonRunner: Times: total = 253, boot = 251, init = 1, finish = 1
16/03/17 15:40:48 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1282 bytes result sent to driver
16/03/17 15:40:48 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.266 s
16/03/17 15:40:48 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.258665 s
16/03/17 15:40:48 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 271 ms on localhost (2/2)
16/03/17 15:40:48 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:40:48 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:40:48 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:40:48 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:40:48 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:40:48 INFO DAGScheduler: Missing parents: List()
16/03/17 15:40:48 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:40:48 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=555755765
16/03/17 15:40:48 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.0 MB)
16/03/17 15:40:48 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=555755765
16/03/17 15:40:48 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
16/03/17 15:40:48 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:41570 (size: 3.3 KB, free: 530.0 MB)
16/03/17 15:40:48 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:40:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:40:48 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:40:48 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:40:48 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2363 bytes)
16/03/17 15:40:48 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:40:48 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:40:48 INFO PythonRunner: Times: total = 28, boot = 18, init = 10, finish = 0
16/03/17 15:40:48 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:40:48 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 55 ms on localhost (1/2)
16/03/17 15:40:48 INFO PythonRunner: Times: total = 88, boot = 87, init = 1, finish = 0
16/03/17 15:40:48 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1350 bytes result sent to driver
16/03/17 15:40:48 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 103 ms on localhost (2/2)
16/03/17 15:40:48 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:40:48 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.102 s
16/03/17 15:40:48 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.126066 s
16/03/17 15:40:48 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:40:48 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:40:48 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:40:48 INFO MemoryStore: MemoryStore cleared
16/03/17 15:40:48 INFO BlockManager: BlockManager stopped
16/03/17 15:40:48 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:40:48 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:40:48 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:40:48 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:40:48 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:40:49 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:40:49 INFO SecurityManager: Changing view acls to: root
16/03/17 15:40:49 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:40:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:40:49 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:40:49 INFO Remoting: Starting remoting
16/03/17 15:40:49 INFO Utils: Successfully started service 'sparkDriver' on port 38241.
16/03/17 15:40:49 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:38241]
16/03/17 15:40:49 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:40:49 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:40:49 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-376fb893-3ca7-40d3-b3d9-2bd14108b127
16/03/17 15:40:49 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
16/03/17 15:40:49 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-d8405457-0fb3-46b2-b357-24d041de7524
16/03/17 15:40:49 INFO HttpServer: Starting HTTP Server
16/03/17 15:40:49 INFO Utils: Successfully started service 'HTTP file server' on port 42340.
16/03/17 15:40:49 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:40:49 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:40:49 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:40:49 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-dfee4061-c5f8-457f-8310-0c9b39e1430d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:40:49 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209449941
16/03/17 15:40:49 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:40:49 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:40:49 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42786.
16/03/17 15:40:49 INFO NettyBlockTransferService: Server created on 42786
16/03/17 15:40:49 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:40:49 INFO BlockManagerMasterEndpoint: Registering block manager localhost:42786 with 530.0 MB RAM, BlockManagerId(driver, localhost, 42786)
16/03/17 15:40:49 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:40:50 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:40:50 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:40:50 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:40:50 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:40:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:40:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:40:50 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:40:50 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555755765
16/03/17 15:40:50 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)
16/03/17 15:40:50 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555755765
16/03/17 15:40:50 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)
16/03/17 15:40:50 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:42786 (size: 4.1 KB, free: 530.0 MB)
16/03/17 15:40:50 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:40:50 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:40:50 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:40:50 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:40:50 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:40:50 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:40:50 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209449941
16/03/17 15:40:50 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:40:50 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-dfee4061-c5f8-457f-8310-0c9b39e1430d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:40:50 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:40:50 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=555755765
16/03/17 15:40:50 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 530.0 MB)
16/03/17 15:40:50 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:40:50 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=555755765
16/03/17 15:40:50 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 530.0 MB)
16/03/17 15:40:50 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:42786 (size: 179.0 B, free: 530.0 MB)
16/03/17 15:40:50 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:42786 (size: 173.0 B, free: 530.0 MB)
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: area
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: planning
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: permission
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: economy
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: composition
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: agency
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:40:58 INFO PythonRunner: Times: total = 8390, boot = 466, init = 425, finish = 7499
16/03/17 15:40:58 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:40:58 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8472 ms on localhost (1/2)
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: bend
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: giant
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: astatine
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: present
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: area
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): item
mapFunction_Parents(): keyword: item ; prevleveltokens: issue
mapFunction_Parents(): keyword= item ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:40:58 INFO PythonRunner: Times: total = 8727, boot = 467, init = 411, finish = 7849
16/03/17 15:40:58 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:40:58 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8803 ms on localhost (2/2)
16/03/17 15:40:58 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:40:58 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.798 s
16/03/17 15:40:58 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:40:58 INFO DAGScheduler: running: Set()
16/03/17 15:40:58 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:40:58 INFO DAGScheduler: failed: Set()
16/03/17 15:40:58 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:40:58 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:40:58 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=555755765
16/03/17 15:40:58 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.0 MB)
16/03/17 15:40:58 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=555755765
16/03/17 15:40:58 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.0 MB)
16/03/17 15:40:58 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:42786 (size: 3.0 KB, free: 530.0 MB)
16/03/17 15:40:58 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:40:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:40:58 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:40:58 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:40:58 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:40:58 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:40:58 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:40:58 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:40:58 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:40:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:40:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
reduceFunction_Parents(): returns= ['None', 'None']
16/03/17 15:40:58 INFO PythonRunner: Times: total = 25, boot = -135, init = 159, finish = 1
16/03/17 15:40:58 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1269 bytes result sent to driver
16/03/17 15:40:59 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 73 ms on localhost (1/2)
16/03/17 15:40:59 INFO PythonRunner: Times: total = 217, boot = 216, init = 0, finish = 1
16/03/17 15:40:59 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:40:59 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.221 s
16/03/17 15:40:59 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.067161 s
16/03/17 15:40:59 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 236 ms on localhost (2/2)
16/03/17 15:40:59 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:40:59 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:40:59 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:40:59 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:40:59 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:40:59 INFO DAGScheduler: Missing parents: List()
16/03/17 15:40:59 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:40:59 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=555755765
16/03/17 15:40:59 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.0 MB)
16/03/17 15:40:59 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=555755765
16/03/17 15:40:59 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
16/03/17 15:40:59 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:42786 (size: 3.3 KB, free: 530.0 MB)
16/03/17 15:40:59 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:40:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:40:59 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:40:59 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:40:59 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2350 bytes)
16/03/17 15:40:59 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:40:59 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:40:59 INFO PythonRunner: Times: total = 53, boot = 53, init = 0, finish = 0
16/03/17 15:40:59 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:40:59 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 61 ms on localhost (1/2)
16/03/17 15:40:59 INFO PythonRunner: Times: total = 55, boot = -163, init = 218, finish = 0
16/03/17 15:40:59 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1337 bytes result sent to driver
16/03/17 15:40:59 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 69 ms on localhost (2/2)
16/03/17 15:40:59 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:40:59 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.073 s
16/03/17 15:40:59 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.093010 s
16/03/17 15:40:59 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:40:59 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:40:59 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:40:59 INFO MemoryStore: MemoryStore cleared
16/03/17 15:40:59 INFO BlockManager: BlockManager stopped
16/03/17 15:40:59 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:40:59 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:40:59 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:40:59 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:40:59 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:40:59 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:41:00 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:41:00 INFO SecurityManager: Changing view acls to: root
16/03/17 15:41:00 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:41:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:41:00 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:41:00 INFO Remoting: Starting remoting
16/03/17 15:41:00 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:38442]
16/03/17 15:41:00 INFO Utils: Successfully started service 'sparkDriver' on port 38442.
16/03/17 15:41:00 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:41:00 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:41:00 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a4aac75a-0622-42bc-bc8d-e2caac9c4448
16/03/17 15:41:00 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
16/03/17 15:41:00 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-5081a03d-acec-4018-91e9-0a7c8ea1d9c8
16/03/17 15:41:00 INFO HttpServer: Starting HTTP Server
16/03/17 15:41:00 INFO Utils: Successfully started service 'HTTP file server' on port 44984.
16/03/17 15:41:00 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:41:00 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:41:00 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:41:00 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-110d3387-0ced-4e7f-b879-fefa7f33e1cf/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:41:00 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209460618
16/03/17 15:41:00 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:41:00 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:41:00 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39095.
16/03/17 15:41:00 INFO NettyBlockTransferService: Server created on 39095
16/03/17 15:41:00 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:41:00 INFO BlockManagerMasterEndpoint: Registering block manager localhost:39095 with 530.0 MB RAM, BlockManagerId(driver, localhost, 39095)
16/03/17 15:41:00 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:41:00 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:41:00 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:41:00 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:41:00 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:41:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:41:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:41:00 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:41:00 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555755765
16/03/17 15:41:00 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)
16/03/17 15:41:00 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555755765
16/03/17 15:41:00 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)
16/03/17 15:41:00 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:39095 (size: 4.1 KB, free: 530.0 MB)
16/03/17 15:41:00 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:41:00 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:41:00 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:41:00 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:41:00 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:41:00 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:41:00 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209460618
16/03/17 15:41:00 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:41:00 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-110d3387-0ced-4e7f-b879-fefa7f33e1cf/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:41:00 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:41:00 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:41:00 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=555755765
16/03/17 15:41:00 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 530.0 MB)
16/03/17 15:41:00 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:39095 (size: 179.0 B, free: 530.0 MB)
16/03/17 15:41:00 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=555755765
16/03/17 15:41:00 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 530.0 MB)
16/03/17 15:41:00 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:39095 (size: 173.0 B, free: 530.0 MB)
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: set
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): adding to parents: syn =  Synset('kilometer.n.01') ; keyword:  miles  in syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= [u'kilometer']
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: planning
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: permission
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: economy
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: composition
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: agency
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): adding to parents: syn =  Synset('kilometer.n.01') ; keyword:  miles  in syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= [u'kilometer']
reduceFunction_Parents(): returns= [u'kilometer', u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer', u'kilometer']
16/03/17 15:41:09 INFO PythonRunner: Times: total = 8269, boot = 456, init = 378, finish = 7435
16/03/17 15:41:09 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:41:09 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8333 ms on localhost (1/2)
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: bend
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: giant
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: astatine
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: present
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: area
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): miles
mapFunction_Parents(): keyword: miles ; prevleveltokens: issue
mapFunction_Parents(): keyword= miles ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:41:09 INFO PythonRunner: Times: total = 8678, boot = 456, init = 395, finish = 7827
16/03/17 15:41:09 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:41:09 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8734 ms on localhost (2/2)
16/03/17 15:41:09 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:41:09 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.733 s
16/03/17 15:41:09 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:41:09 INFO DAGScheduler: running: Set()
16/03/17 15:41:09 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:41:09 INFO DAGScheduler: failed: Set()
16/03/17 15:41:09 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:41:09 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:41:09 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=555755765
16/03/17 15:41:09 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.0 MB)
16/03/17 15:41:09 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=555755765
16/03/17 15:41:09 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.0 MB)
16/03/17 15:41:09 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:39095 (size: 3.0 KB, free: 530.0 MB)
16/03/17 15:41:09 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:41:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:41:09 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:41:09 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:41:09 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:41:09 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:41:09 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:41:09 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:41:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:41:09 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:41:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'kilometer', u'kilometer']
16/03/17 15:41:09 INFO PythonRunner: Times: total = 19, boot = -177, init = 195, finish = 1
16/03/17 15:41:09 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1279 bytes result sent to driver
16/03/17 15:41:09 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 40 ms on localhost (1/2)
16/03/17 15:41:09 INFO PythonRunner: Times: total = 232, boot = 231, init = 0, finish = 1
16/03/17 15:41:09 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:41:09 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.240 s
16/03/17 15:41:09 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.002563 s
16/03/17 15:41:09 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 241 ms on localhost (2/2)
16/03/17 15:41:09 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:41:09 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:41:09 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:41:09 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:41:09 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:41:09 INFO DAGScheduler: Missing parents: List()
16/03/17 15:41:09 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:41:09 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=555755765
16/03/17 15:41:09 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.0 MB)
16/03/17 15:41:09 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=555755765
16/03/17 15:41:09 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
16/03/17 15:41:09 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:39095 (size: 3.3 KB, free: 530.0 MB)
16/03/17 15:41:09 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:41:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:41:09 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:41:09 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:41:09 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2360 bytes)
16/03/17 15:41:09 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:41:09 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:41:10 INFO PythonRunner: Times: total = 56, boot = -230, init = 286, finish = 0
16/03/17 15:41:10 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:41:10 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 67 ms on localhost (1/2)
16/03/17 15:41:10 INFO PythonRunner: Times: total = 127, boot = 127, init = 0, finish = 0
16/03/17 15:41:10 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1358 bytes result sent to driver
16/03/17 15:41:10 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 141 ms on localhost (2/2)
16/03/17 15:41:10 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:41:10 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.139 s
16/03/17 15:41:10 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.170460 s
16/03/17 15:41:10 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:41:10 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:41:10 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:41:10 INFO MemoryStore: MemoryStore cleared
16/03/17 15:41:10 INFO BlockManager: BlockManager stopped
16/03/17 15:41:10 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:41:10 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:41:10 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:41:10 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:41:10 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:41:10 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:41:11 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:41:11 INFO SecurityManager: Changing view acls to: root
16/03/17 15:41:11 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:41:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:41:11 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:41:11 INFO Remoting: Starting remoting
16/03/17 15:41:11 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:45191]
16/03/17 15:41:11 INFO Utils: Successfully started service 'sparkDriver' on port 45191.
16/03/17 15:41:11 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:41:11 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:41:11 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a0194a1a-05ba-4fcb-8a71-f6e8cd99b2bf
16/03/17 15:41:11 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
16/03/17 15:41:11 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-b546bddf-7f75-4157-8a01-ff4e9c794f50
16/03/17 15:41:11 INFO HttpServer: Starting HTTP Server
16/03/17 15:41:11 INFO Utils: Successfully started service 'HTTP file server' on port 43384.
16/03/17 15:41:11 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:41:11 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:41:11 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:41:11 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-116adb65-6e08-4587-bf3d-5bfe231a3891/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:41:11 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209471313
16/03/17 15:41:11 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:41:11 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:41:11 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53546.
16/03/17 15:41:11 INFO NettyBlockTransferService: Server created on 53546
16/03/17 15:41:11 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:41:11 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53546 with 530.0 MB RAM, BlockManagerId(driver, localhost, 53546)
16/03/17 15:41:11 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:41:11 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:41:11 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:41:11 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:41:11 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:41:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:41:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:41:11 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:41:11 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555755765
16/03/17 15:41:11 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)
16/03/17 15:41:11 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555755765
16/03/17 15:41:11 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)
16/03/17 15:41:11 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53546 (size: 4.1 KB, free: 530.0 MB)
16/03/17 15:41:11 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:41:11 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:41:11 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:41:11 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:41:11 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:41:11 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:41:11 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209471313
16/03/17 15:41:11 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:41:11 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-116adb65-6e08-4587-bf3d-5bfe231a3891/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:41:11 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:41:11 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:41:11 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=555755765
16/03/17 15:41:11 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 530.0 MB)
16/03/17 15:41:11 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:53546 (size: 179.0 B, free: 530.0 MB)
16/03/17 15:41:11 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=555755765
16/03/17 15:41:11 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 530.0 MB)
16/03/17 15:41:11 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:53546 (size: 173.0 B, free: 530.0 MB)
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: area
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: bend
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: giant
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: astatine
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  unstable  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: present
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: area
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: issue
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/17 15:41:19 INFO PythonRunner: Times: total = 8165, boot = 452, init = 379, finish = 7334
16/03/17 15:41:19 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:41:19 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8233 ms on localhost (1/2)
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: planning
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: permission
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: economy
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: composition
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: agency
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): unstable
mapFunction_Parents(): keyword: unstable ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= unstable ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:41:20 INFO PythonRunner: Times: total = 8766, boot = 449, init = 433, finish = 7884
16/03/17 15:41:20 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:41:20 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8817 ms on localhost (2/2)
16/03/17 15:41:20 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.810 s
16/03/17 15:41:20 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:41:20 INFO DAGScheduler: running: Set()
16/03/17 15:41:20 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:41:20 INFO DAGScheduler: failed: Set()
16/03/17 15:41:20 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:41:20 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:41:20 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=555755765
16/03/17 15:41:20 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.0 MB)
16/03/17 15:41:20 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:41:20 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=555755765
16/03/17 15:41:20 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.0 MB)
16/03/17 15:41:20 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53546 (size: 3.0 KB, free: 530.0 MB)
16/03/17 15:41:20 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:41:20 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:41:20 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:41:20 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:41:20 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:41:20 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:41:20 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:41:20 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:41:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:41:20 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:41:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'astatine', 'None']
16/03/17 15:41:20 INFO PythonRunner: Times: total = 15, boot = -432, init = 447, finish = 0
16/03/17 15:41:20 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/03/17 15:41:20 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 50 ms on localhost (1/2)
16/03/17 15:41:20 INFO PythonRunner: Times: total = 196, boot = 195, init = 0, finish = 1
16/03/17 15:41:20 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:41:20 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.209 s
16/03/17 15:41:20 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.083804 s
16/03/17 15:41:20 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 210 ms on localhost (2/2)
16/03/17 15:41:20 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:41:20 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:41:20 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:41:20 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:41:20 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:41:20 INFO DAGScheduler: Missing parents: List()
16/03/17 15:41:20 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:41:20 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=555755765
16/03/17 15:41:20 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.0 MB)
16/03/17 15:41:20 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=555755765
16/03/17 15:41:20 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
16/03/17 15:41:20 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53546 (size: 3.3 KB, free: 530.0 MB)
16/03/17 15:41:20 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:41:20 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:41:20 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:41:20 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:41:20 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/03/17 15:41:20 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:41:20 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:41:20 INFO PythonRunner: Times: total = 5, boot = -3, init = 8, finish = 0
16/03/17 15:41:20 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/03/17 15:41:20 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 35 ms on localhost (1/2)
16/03/17 15:41:20 INFO PythonRunner: Times: total = 44, boot = -49, init = 93, finish = 0
16/03/17 15:41:20 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:41:20 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 58 ms on localhost (2/2)
16/03/17 15:41:20 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:41:20 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.059 s
16/03/17 15:41:20 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.072112 s
16/03/17 15:41:20 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:41:20 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:41:20 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:41:20 INFO MemoryStore: MemoryStore cleared
16/03/17 15:41:20 INFO BlockManager: BlockManager stopped
16/03/17 15:41:20 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:41:20 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:41:20 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:41:20 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:41:20 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:41:20 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:41:21 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:41:21 INFO SecurityManager: Changing view acls to: root
16/03/17 15:41:21 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:41:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:41:21 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:41:21 INFO Remoting: Starting remoting
16/03/17 15:41:21 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:47786]
16/03/17 15:41:21 INFO Utils: Successfully started service 'sparkDriver' on port 47786.
16/03/17 15:41:21 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:41:21 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:41:21 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9783aca8-de84-40f7-a8ee-dff050e23feb
16/03/17 15:41:21 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
16/03/17 15:41:21 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-9850b150-db33-440f-b3f6-3537ac947733
16/03/17 15:41:21 INFO HttpServer: Starting HTTP Server
16/03/17 15:41:21 INFO Utils: Successfully started service 'HTTP file server' on port 50243.
16/03/17 15:41:21 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:41:21 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:41:21 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:41:21 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-289ab358-9930-4be0-8a27-790cfc9d0a4a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:41:21 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209481956
16/03/17 15:41:21 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:41:21 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:41:22 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50568.
16/03/17 15:41:22 INFO NettyBlockTransferService: Server created on 50568
16/03/17 15:41:22 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:41:22 INFO BlockManagerMasterEndpoint: Registering block manager localhost:50568 with 530.0 MB RAM, BlockManagerId(driver, localhost, 50568)
16/03/17 15:41:22 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:41:22 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:41:22 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:41:22 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:41:22 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:41:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:41:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:41:22 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:41:22 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555755765
16/03/17 15:41:22 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)
16/03/17 15:41:22 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555755765
16/03/17 15:41:22 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)
16/03/17 15:41:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:50568 (size: 4.1 KB, free: 530.0 MB)
16/03/17 15:41:22 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:41:22 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:41:22 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:41:22 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:41:22 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:41:22 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:41:22 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209481956
16/03/17 15:41:22 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:41:22 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-289ab358-9930-4be0-8a27-790cfc9d0a4a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:41:22 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:41:22 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10732, maxMem=555755765
16/03/17 15:41:22 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 530.0 MB)
16/03/17 15:41:22 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:50568 (size: 173.0 B, free: 530.0 MB)
16/03/17 15:41:22 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:41:22 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10905, maxMem=555755765
16/03/17 15:41:22 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 530.0 MB)
16/03/17 15:41:22 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:50568 (size: 179.0 B, free: 530.0 MB)
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: area
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: bend
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: giant
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: astatine
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: present
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  including  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: area
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: issue
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/17 15:41:30 INFO PythonRunner: Times: total = 8373, boot = 454, init = 394, finish = 7525
16/03/17 15:41:30 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:41:30 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8434 ms on localhost (1/2)
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: planning
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: permission
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: economy
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: composition
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: agency
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): including
mapFunction_Parents(): keyword: including ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= including ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:41:30 INFO PythonRunner: Times: total = 8567, boot = 469, init = 401, finish = 7697
16/03/17 15:41:30 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:41:30 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.623 s
16/03/17 15:41:30 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:41:30 INFO DAGScheduler: running: Set()
16/03/17 15:41:30 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:41:30 INFO DAGScheduler: failed: Set()
16/03/17 15:41:30 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:41:30 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:41:30 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=555755765
16/03/17 15:41:30 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.0 MB)
16/03/17 15:41:30 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=555755765
16/03/17 15:41:30 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8626 ms on localhost (2/2)
16/03/17 15:41:30 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:41:30 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.0 MB)
16/03/17 15:41:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:50568 (size: 3.0 KB, free: 530.0 MB)
16/03/17 15:41:30 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:41:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:41:30 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:41:30 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:41:30 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:41:30 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:41:30 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:41:30 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:41:30 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'present', 'None']
16/03/17 15:41:30 INFO PythonRunner: Times: total = 22, boot = -27, init = 48, finish = 1
16/03/17 15:41:30 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/17 15:41:30 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 39 ms on localhost (1/2)
16/03/17 15:41:31 INFO PythonRunner: Times: total = 199, boot = 198, init = 0, finish = 1
16/03/17 15:41:31 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:41:31 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 217 ms on localhost (2/2)
16/03/17 15:41:31 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.218 s
16/03/17 15:41:31 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:41:31 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.877051 s
16/03/17 15:41:31 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:41:31 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:41:31 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:41:31 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:41:31 INFO DAGScheduler: Missing parents: List()
16/03/17 15:41:31 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:41:31 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=555755765
16/03/17 15:41:31 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.0 MB)
16/03/17 15:41:31 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=555755765
16/03/17 15:41:31 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
16/03/17 15:41:31 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:50568 (size: 3.3 KB, free: 530.0 MB)
16/03/17 15:41:31 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:41:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:41:31 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:41:31 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:41:31 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/17 15:41:31 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:41:31 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:41:31 INFO PythonRunner: Times: total = 54, boot = -5, init = 59, finish = 0
16/03/17 15:41:31 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:41:31 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 62 ms on localhost (1/2)
16/03/17 15:41:31 INFO PythonRunner: Times: total = 104, boot = 104, init = 0, finish = 0
16/03/17 15:41:31 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1351 bytes result sent to driver
16/03/17 15:41:31 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 114 ms on localhost (2/2)
16/03/17 15:41:31 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:41:31 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.116 s
16/03/17 15:41:31 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.141576 s
16/03/17 15:41:31 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:41:31 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:41:31 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:41:31 INFO MemoryStore: MemoryStore cleared
16/03/17 15:41:31 INFO BlockManager: BlockManager stopped
16/03/17 15:41:31 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:41:31 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:41:31 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:41:31 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:41:31 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:41:31 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:41:32 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:41:32 INFO SecurityManager: Changing view acls to: root
16/03/17 15:41:32 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:41:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:41:32 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:41:32 INFO Remoting: Starting remoting
16/03/17 15:41:32 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:35016]
16/03/17 15:41:32 INFO Utils: Successfully started service 'sparkDriver' on port 35016.
16/03/17 15:41:32 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:41:32 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:41:32 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-249592b6-64dc-4fc8-bb3b-6b4594bc787f
16/03/17 15:41:32 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
16/03/17 15:41:32 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-09242df0-cf95-45d6-a0af-9dfa070d9fa8
16/03/17 15:41:32 INFO HttpServer: Starting HTTP Server
16/03/17 15:41:32 INFO Utils: Successfully started service 'HTTP file server' on port 60632.
16/03/17 15:41:32 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:41:32 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:41:32 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:41:32 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-39e24e63-2d78-4b44-bce0-7a9ba1f18954/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:41:32 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209492537
16/03/17 15:41:32 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:41:32 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:41:32 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60561.
16/03/17 15:41:32 INFO NettyBlockTransferService: Server created on 60561
16/03/17 15:41:32 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:41:32 INFO BlockManagerMasterEndpoint: Registering block manager localhost:60561 with 530.0 MB RAM, BlockManagerId(driver, localhost, 60561)
16/03/17 15:41:32 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:41:32 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:41:32 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:41:32 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:41:32 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:41:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:41:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:41:32 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:41:32 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555755765
16/03/17 15:41:32 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)
16/03/17 15:41:32 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555755765
16/03/17 15:41:32 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)
16/03/17 15:41:32 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:60561 (size: 4.1 KB, free: 530.0 MB)
16/03/17 15:41:32 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:41:32 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:41:32 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:41:32 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:41:32 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:41:32 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:41:32 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209492537
16/03/17 15:41:32 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:41:32 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-39e24e63-2d78-4b44-bce0-7a9ba1f18954/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:41:32 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:41:32 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10732, maxMem=555755765
16/03/17 15:41:32 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 530.0 MB)
16/03/17 15:41:32 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:41:32 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10905, maxMem=555755765
16/03/17 15:41:32 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 530.0 MB)
16/03/17 15:41:32 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:60561 (size: 173.0 B, free: 530.0 MB)
16/03/17 15:41:32 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:60561 (size: 179.0 B, free: 530.0 MB)
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: area
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: bend
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: giant
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: astatine
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: present
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: area
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  people  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: issue
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/17 15:41:41 INFO PythonRunner: Times: total = 8385, boot = 453, init = 362, finish = 7570
16/03/17 15:41:41 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:41:41 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8482 ms on localhost (1/2)
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  people  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: planning
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: permission
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: economy
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: composition
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: agency
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): people
mapFunction_Parents(): keyword: people ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= people ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/17 15:41:41 INFO PythonRunner: Times: total = 8751, boot = 463, init = 413, finish = 7875
16/03/17 15:41:41 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:41:41 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.865 s
16/03/17 15:41:41 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:41:41 INFO DAGScheduler: running: Set()
16/03/17 15:41:41 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:41:41 INFO DAGScheduler: failed: Set()
16/03/17 15:41:41 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:41:41 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:41:41 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=555755765
16/03/17 15:41:41 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.0 MB)
16/03/17 15:41:41 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=555755765
16/03/17 15:41:41 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.0 MB)
16/03/17 15:41:41 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8860 ms on localhost (2/2)
16/03/17 15:41:41 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:41:41 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:60561 (size: 3.0 KB, free: 530.0 MB)
16/03/17 15:41:41 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:41:41 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:41:41 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:41:41 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:41:41 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:41:41 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:41:41 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:41:41 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:41:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:41:41 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:41:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'area', u'area']
16/03/17 15:41:41 INFO PythonRunner: Times: total = 16, boot = -218, init = 233, finish = 1
16/03/17 15:41:41 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/17 15:41:41 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 77 ms on localhost (1/2)
16/03/17 15:41:41 INFO PythonRunner: Times: total = 319, boot = 318, init = 0, finish = 1
16/03/17 15:41:41 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:41:41 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.346 s
16/03/17 15:41:41 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.246973 s
16/03/17 15:41:41 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 345 ms on localhost (2/2)
16/03/17 15:41:41 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:41:42 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:41:42 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:41:42 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:41:42 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:41:42 INFO DAGScheduler: Missing parents: List()
16/03/17 15:41:42 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:41:42 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=555755765
16/03/17 15:41:42 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.0 MB)
16/03/17 15:41:42 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=555755765
16/03/17 15:41:42 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
16/03/17 15:41:42 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:60561 (size: 3.3 KB, free: 530.0 MB)
16/03/17 15:41:42 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:41:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:41:42 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:41:42 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:41:42 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/17 15:41:42 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:41:42 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:41:42 INFO PythonRunner: Times: total = 47, boot = -44, init = 91, finish = 0
16/03/17 15:41:42 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:41:42 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 53 ms on localhost (1/2)
16/03/17 15:41:42 INFO PythonRunner: Times: total = 258, boot = 257, init = 0, finish = 1
16/03/17 15:41:42 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/03/17 15:41:42 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.262 s
16/03/17 15:41:42 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.283260 s
16/03/17 15:41:42 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 270 ms on localhost (2/2)
16/03/17 15:41:42 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:41:42 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:41:42 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:41:42 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:41:42 INFO MemoryStore: MemoryStore cleared
16/03/17 15:41:42 INFO BlockManager: BlockManager stopped
16/03/17 15:41:42 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:41:42 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:41:42 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:41:42 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:41:42 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:41:42 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:41:43 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:41:43 INFO SecurityManager: Changing view acls to: root
16/03/17 15:41:43 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:41:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:41:43 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:41:43 INFO Remoting: Starting remoting
16/03/17 15:41:43 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:43235]
16/03/17 15:41:43 INFO Utils: Successfully started service 'sparkDriver' on port 43235.
16/03/17 15:41:43 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:41:43 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:41:43 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-35cff0bf-f348-49db-aa98-a48ab58f12ed
16/03/17 15:41:43 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
16/03/17 15:41:43 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-e919fda5-e4f1-4c38-816e-c7a060226075
16/03/17 15:41:43 INFO HttpServer: Starting HTTP Server
16/03/17 15:41:43 INFO Utils: Successfully started service 'HTTP file server' on port 37143.
16/03/17 15:41:43 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:41:43 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:41:43 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:41:43 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-ae5d2b42-37ef-47db-98a3-6c69e7ba3111/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:41:43 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209503501
16/03/17 15:41:43 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:41:43 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:41:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45494.
16/03/17 15:41:43 INFO NettyBlockTransferService: Server created on 45494
16/03/17 15:41:43 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:41:43 INFO BlockManagerMasterEndpoint: Registering block manager localhost:45494 with 530.0 MB RAM, BlockManagerId(driver, localhost, 45494)
16/03/17 15:41:43 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:41:43 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:41:43 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:41:43 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:41:43 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:41:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:41:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:41:43 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:41:43 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555755765
16/03/17 15:41:43 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)
16/03/17 15:41:43 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555755765
16/03/17 15:41:43 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)
16/03/17 15:41:43 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:45494 (size: 4.1 KB, free: 530.0 MB)
16/03/17 15:41:43 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:41:43 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:41:43 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:41:43 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:41:43 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:41:43 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:41:43 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209503501
16/03/17 15:41:43 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:41:43 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-ae5d2b42-37ef-47db-98a3-6c69e7ba3111/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:41:43 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:41:43 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=555755765
16/03/17 15:41:43 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 530.0 MB)
16/03/17 15:41:43 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:41:43 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:45494 (size: 179.0 B, free: 530.0 MB)
16/03/17 15:41:43 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=555755765
16/03/17 15:41:43 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 530.0 MB)
16/03/17 15:41:43 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:45494 (size: 173.0 B, free: 530.0 MB)
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: set
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: bend
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: giant
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: astatine
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  series  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: present
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: area
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: planning
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: issue
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: permission
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: economy
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: composition
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: agency
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): series
mapFunction_Parents(): keyword: series ; prevleveltokens: Chennai
16/03/17 15:41:52 INFO PythonRunner: Times: total = 8836, boot = 464, init = 567, finish = 7805
mapFunction_Parents(): keyword= series ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:41:52 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:41:52 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8917 ms on localhost (1/2)
16/03/17 15:41:52 INFO PythonRunner: Times: total = 8864, boot = 463, init = 528, finish = 7873
16/03/17 15:41:52 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:41:52 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.959 s
16/03/17 15:41:52 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:41:52 INFO DAGScheduler: running: Set()
16/03/17 15:41:52 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:41:52 INFO DAGScheduler: failed: Set()
16/03/17 15:41:52 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:41:52 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:41:52 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=555755765
16/03/17 15:41:52 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.0 MB)
16/03/17 15:41:52 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8955 ms on localhost (2/2)
16/03/17 15:41:52 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:41:52 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=555755765
16/03/17 15:41:52 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.0 MB)
16/03/17 15:41:52 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:45494 (size: 3.0 KB, free: 530.0 MB)
16/03/17 15:41:52 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:41:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:41:52 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:41:52 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:41:52 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:41:52 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:41:52 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:41:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:41:52 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:41:52 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:41:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'astatine', 'None']
16/03/17 15:41:52 INFO PythonRunner: Times: total = 136, boot = 134, init = 1, finish = 1
16/03/17 15:41:52 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/03/17 15:41:52 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 156 ms on localhost (1/2)
16/03/17 15:41:52 INFO PythonRunner: Times: total = 298, boot = 297, init = 1, finish = 0
16/03/17 15:41:52 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:41:52 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 319 ms on localhost (2/2)
16/03/17 15:41:52 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:41:52 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.293 s
16/03/17 15:41:52 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.325633 s
16/03/17 15:41:53 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:41:53 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:41:53 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:41:53 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:41:53 INFO DAGScheduler: Missing parents: List()
16/03/17 15:41:53 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:41:53 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=555755765
16/03/17 15:41:53 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.0 MB)
16/03/17 15:41:53 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=555755765
16/03/17 15:41:53 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
16/03/17 15:41:53 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:45494 (size: 3.3 KB, free: 530.0 MB)
16/03/17 15:41:53 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:41:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:41:53 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:41:53 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:41:53 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/03/17 15:41:53 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:41:53 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:41:53 INFO PythonRunner: Times: total = 29, boot = -62, init = 91, finish = 0
16/03/17 15:41:53 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:41:53 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 57 ms on localhost (1/2)
16/03/17 15:41:53 INFO PythonRunner: Times: total = 146, boot = 146, init = 0, finish = 0
16/03/17 15:41:53 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/03/17 15:41:53 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 164 ms on localhost (2/2)
16/03/17 15:41:53 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:41:53 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.135 s
16/03/17 15:41:53 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.176069 s
16/03/17 15:41:53 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:41:53 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:41:53 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:41:53 INFO MemoryStore: MemoryStore cleared
16/03/17 15:41:53 INFO BlockManager: BlockManager stopped
16/03/17 15:41:53 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:41:53 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:41:53 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:41:53 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:41:53 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:41:53 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:41:54 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:41:54 INFO SecurityManager: Changing view acls to: root
16/03/17 15:41:54 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:41:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:41:54 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:41:54 INFO Remoting: Starting remoting
16/03/17 15:41:54 INFO Utils: Successfully started service 'sparkDriver' on port 42507.
16/03/17 15:41:54 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:42507]
16/03/17 15:41:54 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:41:54 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:41:54 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-235bba15-41b8-475d-8a10-6cf869995d68
16/03/17 15:41:54 INFO MemoryStore: MemoryStore started with capacity 539.9 MB
16/03/17 15:41:54 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-3235b481-d380-497e-8e83-7e7ac86274a6
16/03/17 15:41:54 INFO HttpServer: Starting HTTP Server
16/03/17 15:41:54 INFO Utils: Successfully started service 'HTTP file server' on port 59234.
16/03/17 15:41:54 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:41:54 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:41:54 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:41:54 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-300cfe69-f45e-4133-ace3-e32c58fb42ee/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:41:54 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209514456
16/03/17 15:41:54 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:41:54 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:41:54 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46415.
16/03/17 15:41:54 INFO NettyBlockTransferService: Server created on 46415
16/03/17 15:41:54 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:41:54 INFO BlockManagerMasterEndpoint: Registering block manager localhost:46415 with 539.9 MB RAM, BlockManagerId(driver, localhost, 46415)
16/03/17 15:41:54 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:41:54 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:41:54 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:41:54 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:41:54 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:41:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:41:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:41:54 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:41:54 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=566089482
16/03/17 15:41:54 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 539.9 MB)
16/03/17 15:41:54 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=566089482
16/03/17 15:41:54 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 539.9 MB)
16/03/17 15:41:54 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:46415 (size: 4.1 KB, free: 539.9 MB)
16/03/17 15:41:54 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:41:54 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:41:54 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:41:54 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:41:54 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:41:54 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:41:54 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209514456
16/03/17 15:41:54 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:41:54 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-300cfe69-f45e-4133-ace3-e32c58fb42ee/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:41:54 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:41:54 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=566089482
16/03/17 15:41:54 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 539.9 MB)
16/03/17 15:41:54 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:46415 (size: 179.0 B, free: 539.9 MB)
16/03/17 15:41:54 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:41:54 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=566089482
16/03/17 15:41:54 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 539.9 MB)
16/03/17 15:41:54 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:46415 (size: 173.0 B, free: 539.9 MB)
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: set
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: planning
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: permission
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: economy
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: composition
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: agency
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:42:03 INFO PythonRunner: Times: total = 8451, boot = 495, init = 382, finish = 7574
16/03/17 15:42:03 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:42:03 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8528 ms on localhost (1/2)
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: bend
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: giant
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: astatine
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: present
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  Christianity  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: area
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Christianity
mapFunction_Parents(): keyword: Christianity ; prevleveltokens: issue
mapFunction_Parents(): keyword= Christianity ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
16/03/17 15:42:03 INFO PythonRunner: Times: total = 8655, boot = 493, init = 404, finish = 7758
16/03/17 15:42:03 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:42:03 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.727 s
16/03/17 15:42:03 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:42:03 INFO DAGScheduler: running: Set()
16/03/17 15:42:03 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:42:03 INFO DAGScheduler: failed: Set()
16/03/17 15:42:03 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:42:03 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:42:03 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8736 ms on localhost (2/2)
16/03/17 15:42:03 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:42:03 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=566089482
16/03/17 15:42:03 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 539.8 MB)
16/03/17 15:42:03 INFO MemoryStore: ensureFreeSpace(3054) called with curMem=16068, maxMem=566089482
16/03/17 15:42:03 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 539.8 MB)
16/03/17 15:42:03 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:46415 (size: 3.0 KB, free: 539.9 MB)
16/03/17 15:42:03 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:42:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:42:03 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:42:03 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:42:03 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:42:03 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:42:03 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:42:03 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:42:03 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:42:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:42:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:42:03 INFO PythonRunner: Times: total = 22, boot = 11, init = 10, finish = 1
16/03/17 15:42:03 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:42:03 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 41 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'metropolitan', 'None']
16/03/17 15:42:03 INFO PythonRunner: Times: total = 229, boot = 228, init = 0, finish = 1
16/03/17 15:42:03 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1288 bytes result sent to driver
16/03/17 15:42:03 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 236 ms on localhost (2/2)
16/03/17 15:42:03 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:42:03 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.231 s
16/03/17 15:42:03 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.009651 s
16/03/17 15:42:03 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:42:03 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:42:03 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:42:03 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:42:03 INFO DAGScheduler: Missing parents: List()
16/03/17 15:42:03 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:42:03 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19122, maxMem=566089482
16/03/17 15:42:03 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 539.8 MB)
16/03/17 15:42:03 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24938, maxMem=566089482
16/03/17 15:42:03 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 539.8 MB)
16/03/17 15:42:03 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:46415 (size: 3.3 KB, free: 539.9 MB)
16/03/17 15:42:03 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:42:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:42:03 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:42:03 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:42:03 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2369 bytes)
16/03/17 15:42:03 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:42:03 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:42:03 INFO PythonRunner: Times: total = 45, boot = -116, init = 161, finish = 0
16/03/17 15:42:03 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1356 bytes result sent to driver
16/03/17 15:42:03 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 62 ms on localhost (1/2)
16/03/17 15:42:03 INFO PythonRunner: Times: total = 106, boot = 106, init = 0, finish = 0
16/03/17 15:42:03 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:42:03 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 119 ms on localhost (2/2)
16/03/17 15:42:03 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.120 s
16/03/17 15:42:03 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.130320 s
16/03/17 15:42:03 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:42:03 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:42:03 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:42:03 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:42:03 INFO MemoryStore: MemoryStore cleared
16/03/17 15:42:03 INFO BlockManager: BlockManager stopped
16/03/17 15:42:04 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:42:04 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:42:04 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:42:04 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:42:04 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:42:04 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:42:04 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:42:04 INFO SecurityManager: Changing view acls to: root
16/03/17 15:42:04 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:42:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:42:04 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:42:04 INFO Remoting: Starting remoting
16/03/17 15:42:04 INFO Utils: Successfully started service 'sparkDriver' on port 53318.
16/03/17 15:42:04 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:53318]
16/03/17 15:42:04 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:42:04 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:42:04 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c3407709-7535-4072-b195-9f6ad7dd6ef4
16/03/17 15:42:04 INFO MemoryStore: MemoryStore started with capacity 539.9 MB
16/03/17 15:42:04 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-7068f238-abc2-406c-a19b-95aa28952628
16/03/17 15:42:04 INFO HttpServer: Starting HTTP Server
16/03/17 15:42:04 INFO Utils: Successfully started service 'HTTP file server' on port 58090.
16/03/17 15:42:04 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:42:05 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:42:05 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:42:05 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-26742c88-b0f3-4bf8-aab1-2f3cb18951cd/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:42:05 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209525026
16/03/17 15:42:05 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:42:05 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:42:05 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58764.
16/03/17 15:42:05 INFO NettyBlockTransferService: Server created on 58764
16/03/17 15:42:05 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:42:05 INFO BlockManagerMasterEndpoint: Registering block manager localhost:58764 with 539.9 MB RAM, BlockManagerId(driver, localhost, 58764)
16/03/17 15:42:05 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:42:05 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:42:05 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:42:05 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:42:05 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:42:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:42:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:42:05 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:42:05 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=566089482
16/03/17 15:42:05 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 539.9 MB)
16/03/17 15:42:05 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=566089482
16/03/17 15:42:05 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 539.9 MB)
16/03/17 15:42:05 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:58764 (size: 4.1 KB, free: 539.9 MB)
16/03/17 15:42:05 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:42:05 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:42:05 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:42:05 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:42:05 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:42:05 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:42:05 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209525026
16/03/17 15:42:05 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:42:05 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-26742c88-b0f3-4bf8-aab1-2f3cb18951cd/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:42:05 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:42:05 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=566089482
16/03/17 15:42:05 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 539.9 MB)
16/03/17 15:42:05 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:58764 (size: 179.0 B, free: 539.9 MB)
16/03/17 15:42:05 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:42:05 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=566089482
16/03/17 15:42:05 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 539.9 MB)
16/03/17 15:42:05 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:58764 (size: 173.0 B, free: 539.9 MB)
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: set
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  culture  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: planning
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: permission
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: economy
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: composition
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: agency
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/17 15:42:13 INFO PythonRunner: Times: total = 8683, boot = 461, init = 384, finish = 7838
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: bend
16/03/17 15:42:13 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: giant
16/03/17 15:42:13 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8759 ms on localhost (1/2)
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: astatine
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: present
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: area
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  culture  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): culture
mapFunction_Parents(): keyword: culture ; prevleveltokens: issue
mapFunction_Parents(): keyword= culture ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/17 15:42:14 INFO PythonRunner: Times: total = 8778, boot = 454, init = 420, finish = 7904
16/03/17 15:42:14 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:42:14 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8869 ms on localhost (2/2)
16/03/17 15:42:14 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:42:14 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.866 s
16/03/17 15:42:14 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:42:14 INFO DAGScheduler: running: Set()
16/03/17 15:42:14 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:42:14 INFO DAGScheduler: failed: Set()
16/03/17 15:42:14 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:42:14 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:42:14 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=566089482
16/03/17 15:42:14 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 539.8 MB)
16/03/17 15:42:14 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=566089482
16/03/17 15:42:14 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 539.8 MB)
16/03/17 15:42:14 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:58764 (size: 3.0 KB, free: 539.9 MB)
16/03/17 15:42:14 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:42:14 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:42:14 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:42:14 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:42:14 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:42:14 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:42:14 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:42:14 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:42:14 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:42:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:42:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:42:14 INFO PythonRunner: Times: total = 114, boot = 113, init = 0, finish = 1
16/03/17 15:42:14 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:42:14 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 127 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'area', u'area']
16/03/17 15:42:14 INFO PythonRunner: Times: total = 204, boot = 203, init = 0, finish = 1
16/03/17 15:42:14 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/17 15:42:14 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 217 ms on localhost (2/2)
16/03/17 15:42:14 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:42:14 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.219 s
16/03/17 15:42:14 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.119770 s
16/03/17 15:42:14 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:42:14 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:42:14 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:42:14 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:42:14 INFO DAGScheduler: Missing parents: List()
16/03/17 15:42:14 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:42:14 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=566089482
16/03/17 15:42:14 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 539.8 MB)
16/03/17 15:42:14 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=566089482
16/03/17 15:42:14 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 539.8 MB)
16/03/17 15:42:14 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:58764 (size: 3.3 KB, free: 539.9 MB)
16/03/17 15:42:14 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:42:14 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:42:14 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:42:14 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:42:14 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/17 15:42:14 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:42:14 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:42:14 INFO PythonRunner: Times: total = 37, boot = 34, init = 2, finish = 1
16/03/17 15:42:14 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:42:14 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 51 ms on localhost (1/2)
16/03/17 15:42:14 INFO PythonRunner: Times: total = 153, boot = 152, init = 1, finish = 0
16/03/17 15:42:14 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/03/17 15:42:14 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 162 ms on localhost (2/2)
16/03/17 15:42:14 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:42:14 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.163 s
16/03/17 15:42:14 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.184726 s
16/03/17 15:42:14 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:42:14 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:42:14 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:42:14 INFO MemoryStore: MemoryStore cleared
16/03/17 15:42:14 INFO BlockManager: BlockManager stopped
16/03/17 15:42:14 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:42:14 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:42:14 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:42:14 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:42:14 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:42:14 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:42:15 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:42:15 INFO SecurityManager: Changing view acls to: root
16/03/17 15:42:15 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:42:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:42:15 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:42:15 INFO Remoting: Starting remoting
16/03/17 15:42:15 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:46866]
16/03/17 15:42:15 INFO Utils: Successfully started service 'sparkDriver' on port 46866.
16/03/17 15:42:15 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:42:15 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:42:15 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-6c6fe55d-ef2d-43f2-80b2-82dfcab1059c
16/03/17 15:42:15 INFO MemoryStore: MemoryStore started with capacity 539.9 MB
16/03/17 15:42:15 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-47cc219a-a7d1-44aa-ad0a-8d512a68d6c7
16/03/17 15:42:15 INFO HttpServer: Starting HTTP Server
16/03/17 15:42:15 INFO Utils: Successfully started service 'HTTP file server' on port 54401.
16/03/17 15:42:15 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:42:15 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:42:15 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:42:15 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-190b0504-84c1-4f57-a1db-72278fca50bb/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:42:15 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209535780
16/03/17 15:42:15 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:42:15 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:42:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39093.
16/03/17 15:42:15 INFO NettyBlockTransferService: Server created on 39093
16/03/17 15:42:15 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:42:15 INFO BlockManagerMasterEndpoint: Registering block manager localhost:39093 with 539.9 MB RAM, BlockManagerId(driver, localhost, 39093)
16/03/17 15:42:15 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:42:15 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:42:15 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:42:15 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:42:15 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:42:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:42:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:42:15 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:42:15 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=566089482
16/03/17 15:42:15 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 539.9 MB)
16/03/17 15:42:15 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=566089482
16/03/17 15:42:15 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 539.9 MB)
16/03/17 15:42:16 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:39093 (size: 4.1 KB, free: 539.9 MB)
16/03/17 15:42:16 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:42:16 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:42:16 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:42:16 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:42:16 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:42:16 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:42:16 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209535780
16/03/17 15:42:16 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:42:16 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-190b0504-84c1-4f57-a1db-72278fca50bb/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:42:16 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:42:16 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=566089482
16/03/17 15:42:16 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 539.9 MB)
16/03/17 15:42:16 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:39093 (size: 179.0 B, free: 539.9 MB)
16/03/17 15:42:16 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:42:16 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=566089482
16/03/17 15:42:16 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 539.9 MB)
16/03/17 15:42:16 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:39093 (size: 173.0 B, free: 539.9 MB)
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: set
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): adding to parents: syn =  Synset('kilometer.n.01') ; keyword:  meters  in syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= [u'kilometer']
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: planning
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: permission
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: economy
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: composition
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: agency
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): adding to parents: syn =  Synset('kilometer.n.01') ; keyword:  meters  in syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= [u'kilometer']
reduceFunction_Parents(): returns= [u'kilometer', u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer', u'kilometer']
16/03/17 15:42:24 INFO PythonRunner: Times: total = 8596, boot = 492, init = 431, finish = 7673
16/03/17 15:42:24 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:42:24 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8692 ms on localhost (1/2)
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: bend
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: giant
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: astatine
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: present
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: area
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): meters
mapFunction_Parents(): keyword: meters ; prevleveltokens: issue
mapFunction_Parents(): keyword= meters ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:42:25 INFO PythonRunner: Times: total = 8954, boot = 506, init = 636, finish = 7812
16/03/17 15:42:25 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:42:25 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.056 s
16/03/17 15:42:25 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:42:25 INFO DAGScheduler: running: Set()
16/03/17 15:42:25 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:42:25 INFO DAGScheduler: failed: Set()
16/03/17 15:42:25 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:42:25 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:42:25 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=566089482
16/03/17 15:42:25 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 539.8 MB)
16/03/17 15:42:25 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=566089482
16/03/17 15:42:25 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 539.8 MB)
16/03/17 15:42:25 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9055 ms on localhost (2/2)
16/03/17 15:42:25 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:42:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:39093 (size: 3.0 KB, free: 539.9 MB)
16/03/17 15:42:25 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:42:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:42:25 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:42:25 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:42:25 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:42:25 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:42:25 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:42:25 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:42:25 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:42:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:42:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
reduceFunction_Parents(): returns= ['None', u'kilometer', u'kilometer']
16/03/17 15:42:25 INFO PythonRunner: Times: total = 28, boot = -182, init = 209, finish = 1
16/03/17 15:42:25 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1279 bytes result sent to driver
16/03/17 15:42:25 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 50 ms on localhost (1/2)
16/03/17 15:42:25 INFO PythonRunner: Times: total = 204, boot = 203, init = 0, finish = 1
16/03/17 15:42:25 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:42:25 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.211 s
16/03/17 15:42:25 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.306595 s
16/03/17 15:42:25 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 215 ms on localhost (2/2)
16/03/17 15:42:25 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:42:25 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:42:25 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:42:25 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:42:25 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:42:25 INFO DAGScheduler: Missing parents: List()
16/03/17 15:42:25 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:42:25 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=566089482
16/03/17 15:42:25 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 539.8 MB)
16/03/17 15:42:25 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=566089482
16/03/17 15:42:25 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 539.8 MB)
16/03/17 15:42:25 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:39093 (size: 3.3 KB, free: 539.9 MB)
16/03/17 15:42:25 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:42:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:42:25 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:42:25 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:42:25 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2360 bytes)
16/03/17 15:42:25 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:42:25 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:42:25 INFO PythonRunner: Times: total = 82, boot = 81, init = 1, finish = 0
16/03/17 15:42:25 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:42:25 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 90 ms on localhost (1/2)
16/03/17 15:42:25 INFO PythonRunner: Times: total = 166, boot = 165, init = 1, finish = 0
16/03/17 15:42:25 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1358 bytes result sent to driver
16/03/17 15:42:25 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 176 ms on localhost (2/2)
16/03/17 15:42:25 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:42:25 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.169 s
16/03/17 15:42:25 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.195607 s
16/03/17 15:42:25 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:42:25 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:42:25 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:42:25 INFO MemoryStore: MemoryStore cleared
16/03/17 15:42:25 INFO BlockManager: BlockManager stopped
16/03/17 15:42:25 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:42:25 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:42:25 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:42:25 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:42:25 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:42:25 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:42:26 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:42:26 INFO SecurityManager: Changing view acls to: root
16/03/17 15:42:26 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:42:26 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:42:26 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:42:26 INFO Remoting: Starting remoting
16/03/17 15:42:26 INFO Utils: Successfully started service 'sparkDriver' on port 32994.
16/03/17 15:42:26 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:32994]
16/03/17 15:42:26 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:42:26 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:42:26 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ec6c53f5-547f-4659-9b28-65b3f6b508cc
16/03/17 15:42:26 INFO MemoryStore: MemoryStore started with capacity 539.9 MB
16/03/17 15:42:26 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-9b91f97e-2000-4e4e-87e6-ba39824658c9
16/03/17 15:42:26 INFO HttpServer: Starting HTTP Server
16/03/17 15:42:26 INFO Utils: Successfully started service 'HTTP file server' on port 39607.
16/03/17 15:42:26 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:42:26 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:42:26 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:42:26 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-b0bb3f7a-6df6-44fd-8ee0-0fb44aa8a28f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:42:26 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209546756
16/03/17 15:42:26 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:42:26 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:42:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45894.
16/03/17 15:42:26 INFO NettyBlockTransferService: Server created on 45894
16/03/17 15:42:26 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:42:26 INFO BlockManagerMasterEndpoint: Registering block manager localhost:45894 with 539.9 MB RAM, BlockManagerId(driver, localhost, 45894)
16/03/17 15:42:26 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:42:26 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:42:26 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:42:26 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:42:26 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:42:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:42:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:42:26 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:42:26 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=566089482
16/03/17 15:42:26 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 539.9 MB)
16/03/17 15:42:26 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=566089482
16/03/17 15:42:26 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 539.9 MB)
16/03/17 15:42:26 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:45894 (size: 4.1 KB, free: 539.9 MB)
16/03/17 15:42:26 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:42:26 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:42:26 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:42:26 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:42:26 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:42:26 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:42:26 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209546756
16/03/17 15:42:26 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:42:26 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-b0bb3f7a-6df6-44fd-8ee0-0fb44aa8a28f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:42:26 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:42:26 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:42:26 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=566089482
16/03/17 15:42:26 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 539.9 MB)
16/03/17 15:42:26 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:45894 (size: 179.0 B, free: 539.9 MB)
16/03/17 15:42:26 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=566089482
16/03/17 15:42:26 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 539.9 MB)
16/03/17 15:42:26 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:45894 (size: 173.0 B, free: 539.9 MB)
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: set
mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: bend
mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  special  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: planning
mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: giant
mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: permission
mapFunction_Parents(): keyword= special ; syndef_tokens= mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
set([asfer_pickle_string_load(): picklef.readlines():u'a' special
mapFunction_Parents(): keyword:,  special ; prevleveltokens: economy
u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: astatine
mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium'mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
, u'thorium'asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword:,  special ; prevleveltokens: composition
u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: present
mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: agency
mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: area
16/03/17 15:42:35 INFO PythonRunner: Times: total = 8774, boot = 467, init = 387, finish = 7920
16/03/17 15:42:35 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  special  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'16/03/17 15:42:35 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8842 ms on localhost (1/2)
])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): special
mapFunction_Parents(): keyword: special ; prevleveltokens: issue
mapFunction_Parents(): keyword= special ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/17 15:42:35 INFO PythonRunner: Times: total = 8825, boot = 467, init = 392, finish = 7966
16/03/17 15:42:35 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:42:35 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8903 ms on localhost (2/2)
16/03/17 15:42:35 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:42:35 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.901 s
16/03/17 15:42:35 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:42:35 INFO DAGScheduler: running: Set()
16/03/17 15:42:35 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:42:35 INFO DAGScheduler: failed: Set()
16/03/17 15:42:35 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:42:35 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:42:35 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=566089482
16/03/17 15:42:35 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 539.8 MB)
16/03/17 15:42:35 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=566089482
16/03/17 15:42:35 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 539.8 MB)
16/03/17 15:42:35 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:45894 (size: 3.0 KB, free: 539.9 MB)
16/03/17 15:42:35 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:42:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:42:35 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:42:35 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:42:35 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:42:35 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:42:35 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:42:35 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:42:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:42:35 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:42:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:42:35 INFO PythonRunner: Times: total = 163, boot = 162, init = 1, finish = 0
16/03/17 15:42:35 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:42:36 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 177 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'area', u'area']
16/03/17 15:42:36 INFO PythonRunner: Times: total = 215, boot = 213, init = 1, finish = 1
16/03/17 15:42:36 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/17 15:42:36 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 235 ms on localhost (2/2)
16/03/17 15:42:36 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:42:36 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.237 s
16/03/17 15:42:36 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.170451 s
16/03/17 15:42:36 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:42:36 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:42:36 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:42:36 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:42:36 INFO DAGScheduler: Missing parents: List()
16/03/17 15:42:36 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:42:36 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=566089482
16/03/17 15:42:36 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 539.8 MB)
16/03/17 15:42:36 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=566089482
16/03/17 15:42:36 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 539.8 MB)
16/03/17 15:42:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:45894 (size: 3.3 KB, free: 539.9 MB)
16/03/17 15:42:36 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:42:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:42:36 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:42:36 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:42:36 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/17 15:42:36 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:42:36 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:42:36 INFO PythonRunner: Times: total = 6, boot = -129, init = 135, finish = 0
16/03/17 15:42:36 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/03/17 15:42:36 INFO PythonRunner: Times: total = 5, boot = -107, init = 112, finish = 0
16/03/17 15:42:36 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:42:36 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 47 ms on localhost (1/2)
16/03/17 15:42:36 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 47 ms on localhost (2/2)
16/03/17 15:42:36 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:42:36 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.040 s
16/03/17 15:42:36 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.066665 s
16/03/17 15:42:36 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:42:36 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:42:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:42:36 INFO MemoryStore: MemoryStore cleared
16/03/17 15:42:36 INFO BlockManager: BlockManager stopped
16/03/17 15:42:36 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:42:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:42:36 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:42:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:42:36 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:42:36 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:42:37 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:42:37 INFO SecurityManager: Changing view acls to: root
16/03/17 15:42:37 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:42:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:42:37 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:42:37 INFO Remoting: Starting remoting
16/03/17 15:42:37 INFO Utils: Successfully started service 'sparkDriver' on port 44480.
16/03/17 15:42:37 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:42:37 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:42:37 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9f61f83f-9f19-4c7a-b9ee-d19891754d98
16/03/17 15:42:37 INFO MemoryStore: MemoryStore started with capacity 539.9 MB
16/03/17 15:42:37 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:44480]
16/03/17 15:42:37 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-9e6ae4ca-fadf-4601-9503-343718f1f855
16/03/17 15:42:37 INFO HttpServer: Starting HTTP Server
16/03/17 15:42:37 INFO Utils: Successfully started service 'HTTP file server' on port 50177.
16/03/17 15:42:37 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:42:37 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:42:37 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:42:37 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-e130da92-f432-4f5e-80dc-0b854785dd21/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:42:37 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209557654
16/03/17 15:42:37 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:42:37 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:42:37 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34054.
16/03/17 15:42:37 INFO NettyBlockTransferService: Server created on 34054
16/03/17 15:42:37 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:42:37 INFO BlockManagerMasterEndpoint: Registering block manager localhost:34054 with 539.9 MB RAM, BlockManagerId(driver, localhost, 34054)
16/03/17 15:42:37 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:42:37 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:42:37 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:42:37 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:42:37 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:42:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:42:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:42:37 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:42:37 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=566089482
16/03/17 15:42:37 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 539.9 MB)
16/03/17 15:42:37 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=566089482
16/03/17 15:42:37 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 539.9 MB)
16/03/17 15:42:37 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:34054 (size: 4.1 KB, free: 539.9 MB)
16/03/17 15:42:37 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:42:37 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:42:37 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:42:37 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:42:37 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:42:37 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:42:37 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209557654
16/03/17 15:42:37 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:42:37 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-e130da92-f432-4f5e-80dc-0b854785dd21/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:42:37 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:42:37 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10732, maxMem=566089482
16/03/17 15:42:37 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 539.9 MB)
16/03/17 15:42:37 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:34054 (size: 173.0 B, free: 539.9 MB)
16/03/17 15:42:37 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:42:37 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10905, maxMem=566089482
16/03/17 15:42:37 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 539.9 MB)
16/03/17 15:42:37 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:34054 (size: 179.0 B, free: 539.9 MB)
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: set
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: bend
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: giant
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: astatine
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: present
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: area
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: issue
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:42:46 INFO PythonRunner: Times: total = 8657, boot = 479, init = 405, finish = 7773
16/03/17 15:42:46 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:42:46 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8731 ms on localhost (1/2)
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): adding to parents: syn =  Synset('kilometer.n.01') ; keyword:  0.621371  in syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= [u'kilometer']
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: planning
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: permission
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: economy
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: composition
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: agency
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): adding to parents: syn =  Synset('kilometer.n.01') ; keyword:  0.621371  in syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= [u'kilometer']
reduceFunction_Parents(): returns= [u'kilometer', u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): 0.621371
mapFunction_Parents(): keyword: 0.621371 ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= 0.621371 ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer', u'kilometer']
16/03/17 15:42:46 INFO PythonRunner: Times: total = 8969, boot = 475, init = 371, finish = 8123
16/03/17 15:42:46 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:42:46 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9044 ms on localhost (2/2)
16/03/17 15:42:46 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:42:46 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.045 s
16/03/17 15:42:46 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:42:46 INFO DAGScheduler: running: Set()
16/03/17 15:42:46 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:42:46 INFO DAGScheduler: failed: Set()
16/03/17 15:42:46 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:42:46 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:42:46 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=566089482
16/03/17 15:42:46 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 539.8 MB)
16/03/17 15:42:46 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=566089482
16/03/17 15:42:46 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 539.8 MB)
16/03/17 15:42:46 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:34054 (size: 3.0 KB, free: 539.9 MB)
16/03/17 15:42:46 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:42:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:42:46 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:42:46 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:42:46 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:42:46 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:42:46 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:42:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:42:46 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:42:46 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:42:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:42:46 INFO PythonRunner: Times: total = 51, boot = -146, init = 196, finish = 1
16/03/17 15:42:46 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:42:46 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 91 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'kilometer', u'kilometer']
16/03/17 15:42:47 INFO PythonRunner: Times: total = 225, boot = 223, init = 1, finish = 1
16/03/17 15:42:47 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1279 bytes result sent to driver
16/03/17 15:42:47 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.253 s
16/03/17 15:42:47 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.330099 s
16/03/17 15:42:47 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 245 ms on localhost (2/2)
16/03/17 15:42:47 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:42:47 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:42:47 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:42:47 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:42:47 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:42:47 INFO DAGScheduler: Missing parents: List()
16/03/17 15:42:47 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:42:47 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=566089482
16/03/17 15:42:47 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 539.8 MB)
16/03/17 15:42:47 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=566089482
16/03/17 15:42:47 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 539.8 MB)
16/03/17 15:42:47 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:34054 (size: 3.3 KB, free: 539.9 MB)
16/03/17 15:42:47 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:42:47 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:42:47 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:42:47 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:42:47 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2360 bytes)
16/03/17 15:42:47 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:42:47 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:42:47 INFO PythonRunner: Times: total = 43, boot = -80, init = 123, finish = 0
16/03/17 15:42:47 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:42:47 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 54 ms on localhost (1/2)
16/03/17 15:42:47 INFO PythonRunner: Times: total = 111, boot = 111, init = 0, finish = 0
16/03/17 15:42:47 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1358 bytes result sent to driver
16/03/17 15:42:47 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 118 ms on localhost (2/2)
16/03/17 15:42:47 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:42:47 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.115 s
16/03/17 15:42:47 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.134603 s
16/03/17 15:42:47 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:42:47 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:42:47 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:42:47 INFO MemoryStore: MemoryStore cleared
16/03/17 15:42:47 INFO BlockManager: BlockManager stopped
16/03/17 15:42:47 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:42:47 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:42:47 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:42:47 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:42:47 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:42:47 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:42:48 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:42:48 INFO SecurityManager: Changing view acls to: root
16/03/17 15:42:48 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:42:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:42:48 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:42:48 INFO Remoting: Starting remoting
16/03/17 15:42:48 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:48416]
16/03/17 15:42:48 INFO Utils: Successfully started service 'sparkDriver' on port 48416.
16/03/17 15:42:48 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:42:48 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:42:48 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-42ee42d8-f012-47de-8c06-d7d2691559b7
16/03/17 15:42:48 INFO MemoryStore: MemoryStore started with capacity 539.9 MB
16/03/17 15:42:48 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-e9db0a91-7545-43fb-9026-b03a2aa27d0c
16/03/17 15:42:48 INFO HttpServer: Starting HTTP Server
16/03/17 15:42:48 INFO Utils: Successfully started service 'HTTP file server' on port 51935.
16/03/17 15:42:48 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:42:48 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:42:48 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:42:48 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-0effcd24-cb31-4b86-9f75-a4d8bb579b83/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:42:48 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209568559
16/03/17 15:42:48 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:42:48 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:42:48 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46889.
16/03/17 15:42:48 INFO NettyBlockTransferService: Server created on 46889
16/03/17 15:42:48 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:42:48 INFO BlockManagerMasterEndpoint: Registering block manager localhost:46889 with 539.9 MB RAM, BlockManagerId(driver, localhost, 46889)
16/03/17 15:42:48 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:42:48 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:42:48 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:42:48 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:42:48 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:42:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:42:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:42:48 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:42:48 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=566089482
16/03/17 15:42:48 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 539.9 MB)
16/03/17 15:42:48 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=566089482
16/03/17 15:42:48 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 539.9 MB)
16/03/17 15:42:48 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:46889 (size: 4.1 KB, free: 539.9 MB)
16/03/17 15:42:48 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:42:48 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:42:48 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:42:48 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:42:48 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:42:48 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:42:48 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209568559
16/03/17 15:42:48 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:42:48 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-0effcd24-cb31-4b86-9f75-a4d8bb579b83/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:42:48 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:42:48 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=566089482
16/03/17 15:42:48 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:42:48 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 539.9 MB)
16/03/17 15:42:48 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:46889 (size: 179.0 B, free: 539.9 MB)
16/03/17 15:42:48 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=566089482
16/03/17 15:42:48 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 539.9 MB)
16/03/17 15:42:48 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:46889 (size: 173.0 B, free: 539.9 MB)
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: set
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: bend
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: giant
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: astatine
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: present
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  Orthodox  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: area
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: issue
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: planning
16/03/17 15:42:58 INFO PythonRunner: Times: total = 9268, boot = 506, init = 736, finish = 8026
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: permission
16/03/17 15:42:58 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: economy
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: composition
16/03/17 15:42:58 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9355 ms on localhost (1/2)
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: agency
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:42:58 INFO PythonRunner: Times: total = 9338, boot = 492, init = 651, finish = 8195
16/03/17 15:42:58 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:42:58 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.414 s
16/03/17 15:42:58 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:42:58 INFO DAGScheduler: running: Set()
16/03/17 15:42:58 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:42:58 INFO DAGScheduler: failed: Set()
16/03/17 15:42:58 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:42:58 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:42:58 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=566089482
16/03/17 15:42:58 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 539.8 MB)
16/03/17 15:42:58 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=566089482
16/03/17 15:42:58 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 539.8 MB)
16/03/17 15:42:58 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9425 ms on localhost (2/2)
16/03/17 15:42:58 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:42:58 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:46889 (size: 3.0 KB, free: 539.9 MB)
16/03/17 15:42:58 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:42:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:42:58 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:42:58 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:42:58 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:42:58 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:42:58 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:42:58 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:42:58 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:42:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:42:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:42:58 INFO PythonRunner: Times: total = 132, boot = 131, init = 1, finish = 0
16/03/17 15:42:58 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:42:58 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 150 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'metropolitan', 'None']
16/03/17 15:42:58 INFO PythonRunner: Times: total = 240, boot = 239, init = 0, finish = 1
16/03/17 15:42:58 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1288 bytes result sent to driver
16/03/17 15:42:58 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.252 s
16/03/17 15:42:58 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.702212 s
16/03/17 15:42:58 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 253 ms on localhost (2/2)
16/03/17 15:42:58 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:42:58 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:42:58 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:42:58 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:42:58 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:42:58 INFO DAGScheduler: Missing parents: List()
16/03/17 15:42:58 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:42:58 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=566089482
16/03/17 15:42:58 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 539.8 MB)
16/03/17 15:42:58 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=566089482
16/03/17 15:42:58 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 539.8 MB)
16/03/17 15:42:58 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:46889 (size: 3.3 KB, free: 539.9 MB)
16/03/17 15:42:58 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:42:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:42:58 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:42:58 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:42:58 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2369 bytes)
16/03/17 15:42:58 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:42:58 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:42:58 INFO PythonRunner: Times: total = 25, boot = -50, init = 75, finish = 0
16/03/17 15:42:58 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1356 bytes result sent to driver
16/03/17 15:42:58 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 42 ms on localhost (1/2)
16/03/17 15:42:58 INFO PythonRunner: Times: total = 135, boot = 135, init = 0, finish = 0
16/03/17 15:42:58 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:42:58 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 144 ms on localhost (2/2)
16/03/17 15:42:58 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:42:58 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.141 s
16/03/17 15:42:58 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.165343 s
16/03/17 15:42:58 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:42:58 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:42:59 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:42:59 INFO MemoryStore: MemoryStore cleared
16/03/17 15:42:59 INFO BlockManager: BlockManager stopped
16/03/17 15:42:59 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:42:59 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:42:59 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:42:59 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:42:59 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:42:59 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:42:59 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:42:59 INFO SecurityManager: Changing view acls to: root
16/03/17 15:42:59 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:42:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:42:59 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:42:59 INFO Remoting: Starting remoting
16/03/17 15:42:59 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:53063]
16/03/17 15:42:59 INFO Utils: Successfully started service 'sparkDriver' on port 53063.
16/03/17 15:42:59 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:42:59 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:42:59 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2409e656-0135-4cc4-a004-77e42060d426
16/03/17 15:42:59 INFO MemoryStore: MemoryStore started with capacity 538.2 MB
16/03/17 15:42:59 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-ff3d5362-ef2e-4b71-b6cb-6a1797635b21
16/03/17 15:42:59 INFO HttpServer: Starting HTTP Server
16/03/17 15:42:59 INFO Utils: Successfully started service 'HTTP file server' on port 49030.
16/03/17 15:43:00 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:43:00 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:43:00 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:43:00 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-8a11341f-2593-461e-8c31-d99760b7bb28/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:43:00 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209580046
16/03/17 15:43:00 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:43:00 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:43:00 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54074.
16/03/17 15:43:00 INFO NettyBlockTransferService: Server created on 54074
16/03/17 15:43:00 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:43:00 INFO BlockManagerMasterEndpoint: Registering block manager localhost:54074 with 538.2 MB RAM, BlockManagerId(driver, localhost, 54074)
16/03/17 15:43:00 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:43:00 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:43:00 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:43:00 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:43:00 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:43:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:43:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:43:00 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:43:00 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=564390789
16/03/17 15:43:00 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 538.2 MB)
16/03/17 15:43:00 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=564390789
16/03/17 15:43:00 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 538.2 MB)
16/03/17 15:43:00 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:54074 (size: 4.1 KB, free: 538.2 MB)
16/03/17 15:43:00 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:43:00 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:43:00 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:43:00 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:43:00 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:43:00 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:43:00 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209580046
16/03/17 15:43:00 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:43:00 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-8a11341f-2593-461e-8c31-d99760b7bb28/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:43:00 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:43:00 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:43:00 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=564390789
16/03/17 15:43:00 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 538.2 MB)
16/03/17 15:43:00 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=564390789
16/03/17 15:43:00 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 538.2 MB)
16/03/17 15:43:00 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:54074 (size: 179.0 B, free: 538.2 MB)
16/03/17 15:43:00 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:54074 (size: 173.0 B, free: 538.2 MB)
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: set
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: planning
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: bend
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): adding to parents: syn =  Synset('planning.n.01') ; keyword:  definite  in syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= [u'planning']
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: permission
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: economy
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: composition
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: giant
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: agency
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: Chennai
mapFunction_Parents(): keyword=mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
 definite ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: astatine
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: present
16/03/17 15:43:09 INFO PythonRunner: Times: total = 8750, boot = 499, init = 380, finish = 7871
16/03/17 15:43:09 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:43:09 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8861 ms on localhost (1/2)
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: area
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): definite
mapFunction_Parents(): keyword: definite ; prevleveltokens: issue
mapFunction_Parents(): keyword= definite ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:43:09 INFO PythonRunner: Times: total = 8884, boot = 494, init = 425, finish = 7965
16/03/17 15:43:09 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:43:09 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8997 ms on localhost (2/2)
16/03/17 15:43:09 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:43:09 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.014 s
16/03/17 15:43:09 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:43:09 INFO DAGScheduler: running: Set()
16/03/17 15:43:09 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:43:09 INFO DAGScheduler: failed: Set()
16/03/17 15:43:09 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:43:09 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:43:09 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=564390789
16/03/17 15:43:09 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 538.2 MB)
16/03/17 15:43:09 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=564390789
16/03/17 15:43:09 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 538.2 MB)
16/03/17 15:43:09 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:54074 (size: 3.0 KB, free: 538.2 MB)
16/03/17 15:43:09 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:43:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:43:09 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:43:09 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:43:09 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:43:09 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:43:09 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:43:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:43:09 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:43:09 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:43:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', 'None', u'planning']
16/03/17 15:43:09 INFO PythonRunner: Times: total = 170, boot = 169, init = 0, finish = 1
16/03/17 15:43:09 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/03/17 15:43:09 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 189 ms on localhost (1/2)
16/03/17 15:43:09 INFO PythonRunner: Times: total = 209, boot = 208, init = 1, finish = 0
16/03/17 15:43:09 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:43:09 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.229 s
16/03/17 15:43:09 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.276747 s
16/03/17 15:43:09 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 227 ms on localhost (2/2)
16/03/17 15:43:09 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:43:09 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:43:09 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:43:09 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:43:09 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:43:09 INFO DAGScheduler: Missing parents: List()
16/03/17 15:43:09 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:43:09 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=564390789
16/03/17 15:43:09 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 538.2 MB)
16/03/17 15:43:09 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=564390789
16/03/17 15:43:09 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 538.2 MB)
16/03/17 15:43:09 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:54074 (size: 3.3 KB, free: 538.2 MB)
16/03/17 15:43:09 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:43:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:43:09 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:43:09 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:43:09 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/03/17 15:43:09 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:43:09 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:43:09 INFO PythonRunner: Times: total = 54, boot = 54, init = 0, finish = 0
16/03/17 15:43:09 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/03/17 15:43:09 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 66 ms on localhost (1/2)
16/03/17 15:43:09 INFO PythonRunner: Times: total = 149, boot = 149, init = 0, finish = 0
16/03/17 15:43:09 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:43:09 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 162 ms on localhost (2/2)
16/03/17 15:43:09 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:43:09 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.149 s
16/03/17 15:43:09 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.175668 s
16/03/17 15:43:09 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:43:09 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:43:09 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:43:09 INFO MemoryStore: MemoryStore cleared
16/03/17 15:43:09 INFO BlockManager: BlockManager stopped
16/03/17 15:43:09 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:43:09 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:43:09 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:43:09 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:43:09 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:43:09 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:43:10 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:43:10 INFO SecurityManager: Changing view acls to: root
16/03/17 15:43:10 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:43:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:43:10 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:43:10 INFO Remoting: Starting remoting
16/03/17 15:43:10 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:51467]
16/03/17 15:43:10 INFO Utils: Successfully started service 'sparkDriver' on port 51467.
16/03/17 15:43:10 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:43:10 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:43:10 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-62be37f4-a56c-4f7c-b2ce-b8138415e60a
16/03/17 15:43:10 INFO MemoryStore: MemoryStore started with capacity 538.2 MB
16/03/17 15:43:10 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-5da0749a-2ff8-4a50-abf8-d922acec0347
16/03/17 15:43:10 INFO HttpServer: Starting HTTP Server
16/03/17 15:43:10 INFO Utils: Successfully started service 'HTTP file server' on port 50436.
16/03/17 15:43:10 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:43:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:43:10 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:43:10 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-e180fcf8-589b-4ec3-9ee5-6ca7f17fb94d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:43:10 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209590975
16/03/17 15:43:10 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:43:10 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:43:11 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34626.
16/03/17 15:43:11 INFO NettyBlockTransferService: Server created on 34626
16/03/17 15:43:11 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:43:11 INFO BlockManagerMasterEndpoint: Registering block manager localhost:34626 with 538.2 MB RAM, BlockManagerId(driver, localhost, 34626)
16/03/17 15:43:11 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:43:11 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:43:11 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:43:11 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:43:11 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:43:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:43:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:43:11 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:43:11 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=564390789
16/03/17 15:43:11 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 538.2 MB)
16/03/17 15:43:11 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=564390789
16/03/17 15:43:11 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 538.2 MB)
16/03/17 15:43:11 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:34626 (size: 4.1 KB, free: 538.2 MB)
16/03/17 15:43:11 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:43:11 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:43:11 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:43:11 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:43:11 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:43:11 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:43:11 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209590975
16/03/17 15:43:11 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:43:11 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-e180fcf8-589b-4ec3-9ee5-6ca7f17fb94d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:43:11 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:43:11 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=564390789
16/03/17 15:43:11 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 538.2 MB)
16/03/17 15:43:11 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:34626 (size: 179.0 B, free: 538.2 MB)
16/03/17 15:43:11 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:43:11 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=564390789
16/03/17 15:43:11 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 538.2 MB)
16/03/17 15:43:11 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:34626 (size: 173.0 B, free: 538.2 MB)
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: area
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  boundary  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: planning
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: permission
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: economy
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: composition
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: agency
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/17 15:43:19 INFO PythonRunner: Times: total = 8663, boot = 449, init = 500, finish = 7714
16/03/17 15:43:19 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:43:19 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8721 ms on localhost (1/2)
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: bend
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: giant
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: astatine
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: present
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: area
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  boundary  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: issue
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/17 15:43:20 INFO PythonRunner: Times: total = 8915, boot = 448, init = 475, finish = 7992
16/03/17 15:43:20 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:43:20 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8972 ms on localhost (2/2)
16/03/17 15:43:20 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:43:20 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.976 s
16/03/17 15:43:20 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:43:20 INFO DAGScheduler: running: Set()
16/03/17 15:43:20 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:43:20 INFO DAGScheduler: failed: Set()
16/03/17 15:43:20 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:43:20 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:43:20 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=564390789
16/03/17 15:43:20 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 538.2 MB)
16/03/17 15:43:20 INFO MemoryStore: ensureFreeSpace(3054) called with curMem=16068, maxMem=564390789
16/03/17 15:43:20 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 538.2 MB)
16/03/17 15:43:20 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:34626 (size: 3.0 KB, free: 538.2 MB)
16/03/17 15:43:20 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:43:20 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:43:20 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:43:20 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:43:20 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:43:20 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:43:20 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:43:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:43:20 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:43:20 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:43:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
reduceFunction_Parents(): returns= ['None', u'area', u'area']
16/03/17 15:43:20 INFO PythonRunner: Times: total = 21, boot = -62, init = 83, finish = 0
16/03/17 15:43:20 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/17 15:43:20 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 51 ms on localhost (1/2)
16/03/17 15:43:20 INFO PythonRunner: Times: total = 229, boot = 228, init = 1, finish = 0
16/03/17 15:43:20 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:43:20 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.241 s
16/03/17 15:43:20 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.237724 s
16/03/17 15:43:20 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 240 ms on localhost (2/2)
16/03/17 15:43:20 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:43:20 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:43:20 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:43:20 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:43:20 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:43:20 INFO DAGScheduler: Missing parents: List()
16/03/17 15:43:20 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:43:20 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19122, maxMem=564390789
16/03/17 15:43:20 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 538.2 MB)
16/03/17 15:43:20 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24938, maxMem=564390789
16/03/17 15:43:20 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 538.2 MB)
16/03/17 15:43:20 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:34626 (size: 3.3 KB, free: 538.2 MB)
16/03/17 15:43:20 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:43:20 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:43:20 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:43:20 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:43:20 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/17 15:43:20 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:43:20 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:43:20 INFO PythonRunner: Times: total = 49, boot = -109, init = 158, finish = 0
16/03/17 15:43:20 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/03/17 15:43:20 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 57 ms on localhost (1/2)
16/03/17 15:43:20 INFO PythonRunner: Times: total = 216, boot = 216, init = 0, finish = 0
16/03/17 15:43:20 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:43:20 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 223 ms on localhost (2/2)
16/03/17 15:43:20 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:43:20 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.225 s
16/03/17 15:43:20 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.234986 s
16/03/17 15:43:20 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:43:20 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:43:20 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:43:20 INFO MemoryStore: MemoryStore cleared
16/03/17 15:43:20 INFO BlockManager: BlockManager stopped
16/03/17 15:43:20 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:43:20 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:43:20 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:43:20 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:43:20 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:43:20 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:43:21 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:43:21 INFO SecurityManager: Changing view acls to: root
16/03/17 15:43:21 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:43:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:43:21 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:43:21 INFO Remoting: Starting remoting
16/03/17 15:43:21 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:46417]
16/03/17 15:43:21 INFO Utils: Successfully started service 'sparkDriver' on port 46417.
16/03/17 15:43:21 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:43:21 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:43:21 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ea2c864e-b086-4b3a-96da-c825ef33601e
16/03/17 15:43:21 INFO MemoryStore: MemoryStore started with capacity 538.2 MB
16/03/17 15:43:21 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-c727834b-e294-4801-bb01-d440eff6e2b2
16/03/17 15:43:21 INFO HttpServer: Starting HTTP Server
16/03/17 15:43:21 INFO Utils: Successfully started service 'HTTP file server' on port 42334.
16/03/17 15:43:21 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:43:21 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:43:21 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:43:21 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-4caafc28-e365-4da5-bb9b-83cc16f75791/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:43:21 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209601799
16/03/17 15:43:21 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:43:21 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:43:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39329.
16/03/17 15:43:21 INFO NettyBlockTransferService: Server created on 39329
16/03/17 15:43:21 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:43:21 INFO BlockManagerMasterEndpoint: Registering block manager localhost:39329 with 538.2 MB RAM, BlockManagerId(driver, localhost, 39329)
16/03/17 15:43:21 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:43:21 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:43:21 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:43:21 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:43:21 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:43:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:43:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:43:21 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:43:21 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=564390789
16/03/17 15:43:21 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 538.2 MB)
16/03/17 15:43:21 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=564390789
16/03/17 15:43:21 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 538.2 MB)
16/03/17 15:43:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:39329 (size: 4.1 KB, free: 538.2 MB)
16/03/17 15:43:21 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:43:21 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:43:21 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:43:21 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:43:21 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:43:21 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:43:21 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209601799
16/03/17 15:43:21 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:43:21 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-4caafc28-e365-4da5-bb9b-83cc16f75791/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:43:21 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:43:21 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=564390789
16/03/17 15:43:21 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 538.2 MB)
16/03/17 15:43:21 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:39329 (size: 179.0 B, free: 538.2 MB)
16/03/17 15:43:21 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:43:21 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=564390789
16/03/17 15:43:21 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 538.2 MB)
16/03/17 15:43:21 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:39329 (size: 173.0 B, free: 538.2 MB)
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: set
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: planning
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: permission
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: economy
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: composition
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: agency
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): adding to parents: syn =  Synset('agency.n.02') ; keyword:  business  in syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= [u'agency']
reduceFunction_Parents(): returns= ['None', u'agency']
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'agency']
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'agency']
16/03/17 15:43:30 INFO PythonRunner: Times: total = 8669, boot = 483, init = 418, finish = 7768
16/03/17 15:43:30 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:43:30 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8740 ms on localhost (1/2)
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: bend
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: giant
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: astatine
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: present
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: area
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): business
mapFunction_Parents(): keyword: business ; prevleveltokens: issue
mapFunction_Parents(): keyword= business ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:43:30 INFO PythonRunner: Times: total = 8878, boot = 480, init = 460, finish = 7938
16/03/17 15:43:30 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:43:30 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.942 s
16/03/17 15:43:30 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:43:30 INFO DAGScheduler: running: Set()
16/03/17 15:43:30 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:43:30 INFO DAGScheduler: failed: Set()
16/03/17 15:43:30 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:43:30 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:43:30 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8947 ms on localhost (2/2)
16/03/17 15:43:30 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:43:30 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=564390789
16/03/17 15:43:30 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 538.2 MB)
16/03/17 15:43:30 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=564390789
16/03/17 15:43:30 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 538.2 MB)
16/03/17 15:43:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:39329 (size: 3.0 KB, free: 538.2 MB)
16/03/17 15:43:30 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:43:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:43:30 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:43:30 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:43:30 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:43:30 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:43:30 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:43:30 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:43:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:43:30 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:43:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:43:30 INFO PythonRunner: Times: total = 22, boot = -68, init = 90, finish = 0
16/03/17 15:43:30 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:43:30 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 46 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'agency']
16/03/17 15:43:31 INFO PythonRunner: Times: total = 211, boot = 209, init = 0, finish = 2
16/03/17 15:43:31 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1282 bytes result sent to driver
16/03/17 15:43:31 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 226 ms on localhost (2/2)
16/03/17 15:43:31 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:43:31 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.230 s
16/03/17 15:43:31 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.220890 s
16/03/17 15:43:31 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:43:31 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:43:31 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:43:31 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:43:31 INFO DAGScheduler: Missing parents: List()
16/03/17 15:43:31 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:43:31 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=564390789
16/03/17 15:43:31 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 538.2 MB)
16/03/17 15:43:31 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=564390789
16/03/17 15:43:31 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 538.2 MB)
16/03/17 15:43:31 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:39329 (size: 3.3 KB, free: 538.2 MB)
16/03/17 15:43:31 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:43:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:43:31 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:43:31 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:43:31 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2363 bytes)
16/03/17 15:43:31 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:43:31 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:43:31 INFO PythonRunner: Times: total = 44, boot = -144, init = 188, finish = 0
16/03/17 15:43:31 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:43:31 INFO PythonRunner: Times: total = 46, boot = 46, init = 0, finish = 0
16/03/17 15:43:31 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1350 bytes result sent to driver
16/03/17 15:43:31 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 57 ms on localhost (1/2)
16/03/17 15:43:31 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 60 ms on localhost (2/2)
16/03/17 15:43:31 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:43:31 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.058 s
16/03/17 15:43:31 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.089225 s
16/03/17 15:43:31 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:43:31 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:43:31 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:43:31 INFO MemoryStore: MemoryStore cleared
16/03/17 15:43:31 INFO BlockManager: BlockManager stopped
16/03/17 15:43:31 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:43:31 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:43:31 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:43:31 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:43:31 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:43:31 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:43:32 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:43:32 INFO SecurityManager: Changing view acls to: root
16/03/17 15:43:32 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:43:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:43:32 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:43:32 INFO Remoting: Starting remoting
16/03/17 15:43:32 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:48855]
16/03/17 15:43:32 INFO Utils: Successfully started service 'sparkDriver' on port 48855.
16/03/17 15:43:32 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:43:32 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:43:32 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7993fb8c-98e7-4726-975d-00ff1bbe8189
16/03/17 15:43:32 INFO MemoryStore: MemoryStore started with capacity 538.2 MB
16/03/17 15:43:32 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-39ea9f93-ec63-457e-aaaf-b8b30330a57f
16/03/17 15:43:32 INFO HttpServer: Starting HTTP Server
16/03/17 15:43:32 INFO Utils: Successfully started service 'HTTP file server' on port 55977.
16/03/17 15:43:32 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:43:32 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:43:32 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:43:32 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-8ccbafb5-94fb-4c13-bc2a-e1974f97d2ee/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:43:32 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209612527
16/03/17 15:43:32 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:43:32 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:43:32 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42055.
16/03/17 15:43:32 INFO NettyBlockTransferService: Server created on 42055
16/03/17 15:43:32 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:43:32 INFO BlockManagerMasterEndpoint: Registering block manager localhost:42055 with 538.2 MB RAM, BlockManagerId(driver, localhost, 42055)
16/03/17 15:43:32 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:43:32 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:43:32 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:43:32 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:43:32 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:43:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:43:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:43:32 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:43:32 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=564390789
16/03/17 15:43:32 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 538.2 MB)
16/03/17 15:43:32 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=564390789
16/03/17 15:43:32 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 538.2 MB)
16/03/17 15:43:32 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:42055 (size: 4.1 KB, free: 538.2 MB)
16/03/17 15:43:32 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:43:32 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:43:32 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:43:32 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:43:32 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:43:32 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:43:32 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209612527
16/03/17 15:43:32 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:43:32 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-8ccbafb5-94fb-4c13-bc2a-e1974f97d2ee/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:43:32 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:43:32 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:43:32 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=564390789
16/03/17 15:43:32 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 538.2 MB)
16/03/17 15:43:32 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:42055 (size: 179.0 B, free: 538.2 MB)
16/03/17 15:43:32 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=564390789
16/03/17 15:43:32 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 538.2 MB)
16/03/17 15:43:32 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:42055 (size: 173.0 B, free: 538.2 MB)
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: area
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: bend
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: giant
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): adding to parents: syn =  Synset('colossus.n.02') ; keyword:  importance  in syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= [u'giant']
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: astatine
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: present
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: area
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: issue
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
16/03/17 15:43:41 INFO PythonRunner: Times: total = 8343, boot = 460, init = 384, finish = 7499
16/03/17 15:43:41 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:43:41 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8419 ms on localhost (1/2)
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: planning
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: permission
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: economy
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: composition
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: agency
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): importance
mapFunction_Parents(): keyword: importance ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= importance ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:43:41 INFO PythonRunner: Times: total = 8763, boot = 466, init = 399, finish = 7898
16/03/17 15:43:41 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:43:41 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8811 ms on localhost (2/2)
16/03/17 15:43:41 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:43:41 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.813 s
16/03/17 15:43:41 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:43:41 INFO DAGScheduler: running: Set()
16/03/17 15:43:41 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:43:41 INFO DAGScheduler: failed: Set()
16/03/17 15:43:41 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:43:41 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:43:41 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=564390789
16/03/17 15:43:41 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 538.2 MB)
16/03/17 15:43:41 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=564390789
16/03/17 15:43:41 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 538.2 MB)
16/03/17 15:43:41 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:42055 (size: 3.0 KB, free: 538.2 MB)
16/03/17 15:43:41 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:43:41 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:43:41 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:43:41 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:43:41 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:43:41 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:43:41 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:43:41 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:43:41 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:43:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:43:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:43:41 INFO PythonRunner: Times: total = 17, boot = -237, init = 253, finish = 1
16/03/17 15:43:41 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:43:41 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 42 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'giant', 'None']
16/03/17 15:43:41 INFO PythonRunner: Times: total = 215, boot = 212, init = 0, finish = 3
16/03/17 15:43:41 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1281 bytes result sent to driver
16/03/17 15:43:41 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.227 s
16/03/17 15:43:41 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.070618 s
16/03/17 15:43:41 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 229 ms on localhost (2/2)
16/03/17 15:43:41 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:43:41 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:43:41 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:43:41 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:43:41 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:43:41 INFO DAGScheduler: Missing parents: List()
16/03/17 15:43:41 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:43:41 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=564390789
16/03/17 15:43:41 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 538.2 MB)
16/03/17 15:43:41 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=564390789
16/03/17 15:43:41 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 538.2 MB)
16/03/17 15:43:41 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:42055 (size: 3.3 KB, free: 538.2 MB)
16/03/17 15:43:41 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:43:41 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:43:41 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:43:41 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:43:41 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2362 bytes)
16/03/17 15:43:41 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:43:41 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:43:41 INFO PythonRunner: Times: total = 50, boot = -113, init = 163, finish = 0
16/03/17 15:43:41 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1349 bytes result sent to driver
16/03/17 15:43:41 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 62 ms on localhost (1/2)
16/03/17 15:43:41 INFO PythonRunner: Times: total = 117, boot = 117, init = 0, finish = 0
16/03/17 15:43:41 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:43:41 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 130 ms on localhost (2/2)
16/03/17 15:43:41 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:43:41 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.128 s
16/03/17 15:43:41 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.147644 s
16/03/17 15:43:42 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:43:42 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:43:42 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:43:42 INFO MemoryStore: MemoryStore cleared
16/03/17 15:43:42 INFO BlockManager: BlockManager stopped
16/03/17 15:43:42 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:43:42 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:43:42 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:43:42 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:43:42 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:43:42 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:43:42 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:43:42 INFO SecurityManager: Changing view acls to: root
16/03/17 15:43:42 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:43:42 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:43:43 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:43:43 INFO Remoting: Starting remoting
16/03/17 15:43:43 INFO Utils: Successfully started service 'sparkDriver' on port 51948.
16/03/17 15:43:43 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:43:43 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:43:43 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-561bdef4-8d9f-4a95-a862-3d160612d512
16/03/17 15:43:43 INFO MemoryStore: MemoryStore started with capacity 538.2 MB
16/03/17 15:43:43 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:51948]
16/03/17 15:43:43 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-c3cfb68a-8f93-4fdf-9ce0-180be32efffd
16/03/17 15:43:43 INFO HttpServer: Starting HTTP Server
16/03/17 15:43:43 INFO Utils: Successfully started service 'HTTP file server' on port 38301.
16/03/17 15:43:43 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:43:43 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:43:43 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:43:43 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-dc427dea-15da-4990-9bf0-a49b2739995d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:43:43 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209623159
16/03/17 15:43:43 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:43:43 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:43:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 48608.
16/03/17 15:43:43 INFO NettyBlockTransferService: Server created on 48608
16/03/17 15:43:43 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:43:43 INFO BlockManagerMasterEndpoint: Registering block manager localhost:48608 with 538.2 MB RAM, BlockManagerId(driver, localhost, 48608)
16/03/17 15:43:43 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:43:43 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:43:43 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:43:43 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:43:43 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:43:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:43:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:43:43 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:43:43 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=564390789
16/03/17 15:43:43 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 538.2 MB)
16/03/17 15:43:43 INFO MemoryStore: ensureFreeSpace(4154) called with curMem=6576, maxMem=564390789
16/03/17 15:43:43 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 538.2 MB)
16/03/17 15:43:43 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:48608 (size: 4.1 KB, free: 538.2 MB)
16/03/17 15:43:43 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:43:43 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:43:43 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:43:43 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:43:43 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:43:43 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:43:43 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209623159
16/03/17 15:43:43 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:43:43 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-dc427dea-15da-4990-9bf0-a49b2739995d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:43:43 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:43:43 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10730, maxMem=564390789
16/03/17 15:43:43 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 538.2 MB)
16/03/17 15:43:43 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:43:43 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:48608 (size: 179.0 B, free: 538.2 MB)
16/03/17 15:43:43 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10909, maxMem=564390789
16/03/17 15:43:43 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 538.2 MB)
16/03/17 15:43:43 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:48608 (size: 173.0 B, free: 538.2 MB)
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: area
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: planning
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: permission
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: economy
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: composition
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: agency
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:43:51 INFO PythonRunner: Times: total = 8403, boot = 462, init = 450, finish = 7491
16/03/17 15:43:51 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:43:51 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8467 ms on localhost (1/2)
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: bend
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: giant
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: astatine
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: present
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  equivalent  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: area
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: issue
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
16/03/17 15:43:52 INFO PythonRunner: Times: total = 8678, boot = 463, init = 375, finish = 7840
16/03/17 15:43:52 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:43:52 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.736 s
16/03/17 15:43:52 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:43:52 INFO DAGScheduler: running: Set()
16/03/17 15:43:52 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:43:52 INFO DAGScheduler: failed: Set()
16/03/17 15:43:52 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:43:52 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:43:52 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8734 ms on localhost (2/2)
16/03/17 15:43:52 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:43:52 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11082, maxMem=564390789
16/03/17 15:43:52 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 538.2 MB)
16/03/17 15:43:52 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16066, maxMem=564390789
16/03/17 15:43:52 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 538.2 MB)
16/03/17 15:43:52 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:48608 (size: 3.0 KB, free: 538.2 MB)
16/03/17 15:43:52 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:43:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:43:52 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:43:52 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:43:52 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:43:52 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:43:52 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:43:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:43:52 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:43:52 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:43:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:43:52 INFO PythonRunner: Times: total = 28, boot = -83, init = 111, finish = 0
16/03/17 15:43:52 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:43:52 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 43 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'metropolitan', 'None']
16/03/17 15:43:52 INFO PythonRunner: Times: total = 214, boot = 212, init = 1, finish = 1
16/03/17 15:43:52 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1288 bytes result sent to driver
16/03/17 15:43:52 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 238 ms on localhost (2/2)
16/03/17 15:43:52 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:43:52 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.229 s
16/03/17 15:43:52 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.997229 s
16/03/17 15:43:52 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:43:52 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:43:52 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:43:52 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:43:52 INFO DAGScheduler: Missing parents: List()
16/03/17 15:43:52 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:43:52 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19121, maxMem=564390789
16/03/17 15:43:52 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 538.2 MB)
16/03/17 15:43:52 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24937, maxMem=564390789
16/03/17 15:43:52 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 538.2 MB)
16/03/17 15:43:52 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:48608 (size: 3.3 KB, free: 538.2 MB)
16/03/17 15:43:52 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:48608 in memory (size: 3.0 KB, free: 538.2 MB)
16/03/17 15:43:52 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:43:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:43:52 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:43:52 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:43:52 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2369 bytes)
16/03/17 15:43:52 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:43:52 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:43:52 INFO PythonRunner: Times: total = 11, boot = -114, init = 125, finish = 0
16/03/17 15:43:52 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1356 bytes result sent to driver
16/03/17 15:43:52 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 47 ms on localhost (1/2)
16/03/17 15:43:52 INFO ContextCleaner: Cleaned accumulator 127
16/03/17 15:43:52 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:48608 in memory (size: 4.1 KB, free: 538.2 MB)
16/03/17 15:43:52 INFO ContextCleaner: Cleaned accumulator 126
16/03/17 15:43:52 INFO PythonRunner: Times: total = 64, boot = -298, init = 362, finish = 0
16/03/17 15:43:52 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:43:52 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 79 ms on localhost (2/2)
16/03/17 15:43:52 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:43:52 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.080 s
16/03/17 15:43:52 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.091827 s
16/03/17 15:43:52 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:43:52 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:43:52 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:43:52 INFO MemoryStore: MemoryStore cleared
16/03/17 15:43:52 INFO BlockManager: BlockManager stopped
16/03/17 15:43:52 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:43:52 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:43:52 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:43:52 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:43:52 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:43:52 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:43:53 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:43:53 INFO SecurityManager: Changing view acls to: root
16/03/17 15:43:53 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:43:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:43:53 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:43:53 INFO Remoting: Starting remoting
16/03/17 15:43:53 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:41526]
16/03/17 15:43:53 INFO Utils: Successfully started service 'sparkDriver' on port 41526.
16/03/17 15:43:53 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:43:53 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:43:53 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-dac04be0-a470-4c8f-b8ce-ddc95a7bfb57
16/03/17 15:43:53 INFO MemoryStore: MemoryStore started with capacity 534.7 MB
16/03/17 15:43:53 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-dab1fd00-b8e0-427c-8654-036de534fafd
16/03/17 15:43:53 INFO HttpServer: Starting HTTP Server
16/03/17 15:43:53 INFO Utils: Successfully started service 'HTTP file server' on port 47149.
16/03/17 15:43:53 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:43:53 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:43:53 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:43:53 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-f8267ad7-fbd2-4e96-996b-0ea6a4619603/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:43:53 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209633832
16/03/17 15:43:53 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:43:53 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:43:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 48724.
16/03/17 15:43:53 INFO NettyBlockTransferService: Server created on 48724
16/03/17 15:43:53 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:43:53 INFO BlockManagerMasterEndpoint: Registering block manager localhost:48724 with 534.7 MB RAM, BlockManagerId(driver, localhost, 48724)
16/03/17 15:43:53 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:43:53 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:43:53 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:43:53 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:43:53 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:43:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:43:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:43:53 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:43:53 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=560710287
16/03/17 15:43:53 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 534.7 MB)
16/03/17 15:43:53 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=560710287
16/03/17 15:43:53 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 534.7 MB)
16/03/17 15:43:53 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:48724 (size: 4.1 KB, free: 534.7 MB)
16/03/17 15:43:53 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:43:53 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:43:53 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:43:53 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:43:53 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:43:53 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:43:53 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209633832
16/03/17 15:43:53 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:43:54 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-f8267ad7-fbd2-4e96-996b-0ea6a4619603/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:43:54 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:43:54 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10732, maxMem=560710287
16/03/17 15:43:54 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 534.7 MB)
16/03/17 15:43:54 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:48724 (size: 173.0 B, free: 534.7 MB)
16/03/17 15:43:54 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:43:54 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10905, maxMem=560710287
16/03/17 15:43:54 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 534.7 MB)
16/03/17 15:43:54 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:48724 (size: 179.0 B, free: 534.7 MB)
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: area
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: planning
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: permission
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: economy
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: composition
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: agency
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:44:02 INFO PythonRunner: Times: total = 8518, boot = 470, init = 413, finish = 7635
16/03/17 15:44:02 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:44:02 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8615 ms on localhost (1/2)
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: bend
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: giant
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: astatine
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  thorium  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: present
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: area
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): thorium
mapFunction_Parents(): keyword: thorium ; prevleveltokens: issue
mapFunction_Parents(): keyword= thorium ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/17 15:44:02 INFO PythonRunner: Times: total = 8758, boot = 482, init = 383, finish = 7893
16/03/17 15:44:02 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:44:02 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.819 s
16/03/17 15:44:02 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:44:02 INFO DAGScheduler: running: Set()
16/03/17 15:44:02 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:44:02 INFO DAGScheduler: failed: Set()
16/03/17 15:44:02 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:44:02 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:44:02 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=560710287
16/03/17 15:44:02 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 534.7 MB)
16/03/17 15:44:02 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=560710287
16/03/17 15:44:02 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 534.7 MB)
16/03/17 15:44:02 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8831 ms on localhost (2/2)
16/03/17 15:44:02 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:44:02 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:48724 (size: 3.0 KB, free: 534.7 MB)
16/03/17 15:44:02 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:44:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:02 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:44:02 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:44:02 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:44:02 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:44:02 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:44:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:44:02 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:44:02 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:44:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'astatine', 'None']
16/03/17 15:44:02 INFO PythonRunner: Times: total = 10, boot = -48, init = 57, finish = 1
16/03/17 15:44:02 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/03/17 15:44:02 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 46 ms on localhost (1/2)
16/03/17 15:44:03 INFO PythonRunner: Times: total = 206, boot = 205, init = 1, finish = 0
16/03/17 15:44:03 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:44:03 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.218 s
16/03/17 15:44:03 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 228 ms on localhost (2/2)
16/03/17 15:44:03 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.085840 s
16/03/17 15:44:03 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:44:03 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:44:03 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:44:03 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:03 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:44:03 INFO DAGScheduler: Missing parents: List()
16/03/17 15:44:03 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:44:03 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=560710287
16/03/17 15:44:03 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 534.7 MB)
16/03/17 15:44:03 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=560710287
16/03/17 15:44:03 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 534.7 MB)
16/03/17 15:44:03 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:48724 (size: 3.3 KB, free: 534.7 MB)
16/03/17 15:44:03 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:44:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:03 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:44:03 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:44:03 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/03/17 15:44:03 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:44:03 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:44:03 INFO PythonRunner: Times: total = 59, boot = -38, init = 97, finish = 0
16/03/17 15:44:03 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/03/17 15:44:03 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 71 ms on localhost (1/2)
16/03/17 15:44:03 INFO PythonRunner: Times: total = 84, boot = 84, init = 0, finish = 0
16/03/17 15:44:03 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:44:03 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 95 ms on localhost (2/2)
16/03/17 15:44:03 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:44:03 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.083 s
16/03/17 15:44:03 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.107008 s
16/03/17 15:44:03 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:44:03 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:44:03 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:44:03 INFO MemoryStore: MemoryStore cleared
16/03/17 15:44:03 INFO BlockManager: BlockManager stopped
16/03/17 15:44:03 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:44:03 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:44:03 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:44:03 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:44:03 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:44:03 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:44:04 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:44:04 INFO SecurityManager: Changing view acls to: root
16/03/17 15:44:04 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:44:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:44:04 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:44:04 INFO Remoting: Starting remoting
16/03/17 15:44:04 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:49541]
16/03/17 15:44:04 INFO Utils: Successfully started service 'sparkDriver' on port 49541.
16/03/17 15:44:04 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:44:04 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:44:04 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3e67508b-d2d5-4aca-b733-18cea768f07b
16/03/17 15:44:04 INFO MemoryStore: MemoryStore started with capacity 534.7 MB
16/03/17 15:44:04 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-4ac686d6-a6bd-4326-9f4b-52a5ca3dd184
16/03/17 15:44:04 INFO HttpServer: Starting HTTP Server
16/03/17 15:44:04 INFO Utils: Successfully started service 'HTTP file server' on port 59785.
16/03/17 15:44:04 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:44:04 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:44:04 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:44:04 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-24190790-e07a-40ae-974b-abab5f3d9004/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:44:04 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209644418
16/03/17 15:44:04 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:44:04 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:44:04 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53694.
16/03/17 15:44:04 INFO NettyBlockTransferService: Server created on 53694
16/03/17 15:44:04 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:44:04 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53694 with 534.7 MB RAM, BlockManagerId(driver, localhost, 53694)
16/03/17 15:44:04 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:44:04 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:44:04 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:04 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:44:04 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:44:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:44:04 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:44:04 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=560710287
16/03/17 15:44:04 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 534.7 MB)
16/03/17 15:44:04 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=560710287
16/03/17 15:44:04 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 534.7 MB)
16/03/17 15:44:04 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53694 (size: 4.1 KB, free: 534.7 MB)
16/03/17 15:44:04 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:44:04 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:04 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:44:04 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:44:04 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:44:04 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:44:04 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209644418
16/03/17 15:44:04 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:44:04 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-24190790-e07a-40ae-974b-abab5f3d9004/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:44:04 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:44:04 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:44:04 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10732, maxMem=560710287
16/03/17 15:44:04 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 534.7 MB)
16/03/17 15:44:04 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:53694 (size: 173.0 B, free: 534.7 MB)
16/03/17 15:44:04 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10905, maxMem=560710287
16/03/17 15:44:04 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 534.7 MB)
16/03/17 15:44:04 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:53694 (size: 179.0 B, free: 534.7 MB)
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: set
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: planning
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: permission
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): adding to parents: syn =  Synset('permission.n.01') ; keyword:  approval  in syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= [u'permission']
reduceFunction_Parents(): returns= ['None', u'permission']
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: economy
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'permission']
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: composition
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'permission']
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: agency
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'permission']
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'permission']
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'permission']
16/03/17 15:44:13 INFO PythonRunner: Times: total = 8842, boot = 473, init = 376, finish = 7993
16/03/17 15:44:13 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:44:13 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8931 ms on localhost (1/2)
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: bend
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: giant
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: astatine
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: present
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: area
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): approval
mapFunction_Parents(): keyword: approval ; prevleveltokens: issue
mapFunction_Parents(): keyword= approval ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:44:14 INFO PythonRunner: Times: total = 9426, boot = 470, init = 403, finish = 8553
16/03/17 15:44:14 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:44:14 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9491 ms on localhost (2/2)
16/03/17 15:44:14 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:44:14 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.497 s
16/03/17 15:44:14 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:44:14 INFO DAGScheduler: running: Set()
16/03/17 15:44:14 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:44:14 INFO DAGScheduler: failed: Set()
16/03/17 15:44:14 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:44:14 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:44:14 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=560710287
16/03/17 15:44:14 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 534.7 MB)
16/03/17 15:44:14 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=560710287
16/03/17 15:44:14 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 534.7 MB)
16/03/17 15:44:14 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53694 (size: 3.0 KB, free: 534.7 MB)
16/03/17 15:44:14 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:44:14 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:14 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:44:14 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:44:14 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:44:14 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:44:14 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:44:14 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:44:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:44:14 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:44:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
reduceFunction_Parents(): returns= ['None', 'None', u'permission']
16/03/17 15:44:14 INFO PythonRunner: Times: total = 15, boot = -286, init = 300, finish = 1
16/03/17 15:44:14 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1286 bytes result sent to driver
16/03/17 15:44:14 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 29 ms on localhost (1/2)
16/03/17 15:44:14 INFO PythonRunner: Times: total = 222, boot = 220, init = 1, finish = 1
16/03/17 15:44:14 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:44:14 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.224 s
16/03/17 15:44:14 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.750685 s
16/03/17 15:44:14 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 235 ms on localhost (2/2)
16/03/17 15:44:14 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:44:14 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:44:14 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:44:14 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:14 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:44:14 INFO DAGScheduler: Missing parents: List()
16/03/17 15:44:14 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:44:14 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=560710287
16/03/17 15:44:14 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 534.7 MB)
16/03/17 15:44:14 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=560710287
16/03/17 15:44:14 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 534.7 MB)
16/03/17 15:44:14 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53694 (size: 3.3 KB, free: 534.7 MB)
16/03/17 15:44:14 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:44:14 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:14 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:44:14 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:44:14 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2367 bytes)
16/03/17 15:44:14 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:44:14 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:44:14 INFO PythonRunner: Times: total = 7, boot = -8, init = 15, finish = 0
16/03/17 15:44:14 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1354 bytes result sent to driver
16/03/17 15:44:14 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 70 ms on localhost (1/2)
16/03/17 15:44:14 INFO PythonRunner: Times: total = 86, boot = -231, init = 317, finish = 0
16/03/17 15:44:14 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:44:14 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.086 s
16/03/17 15:44:14 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 94 ms on localhost (2/2)
16/03/17 15:44:14 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:44:14 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.112770 s
16/03/17 15:44:14 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:44:14 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:44:14 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:44:14 INFO MemoryStore: MemoryStore cleared
16/03/17 15:44:14 INFO BlockManager: BlockManager stopped
16/03/17 15:44:14 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:44:14 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:44:14 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:44:14 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:44:14 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:44:14 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:44:15 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:44:15 INFO SecurityManager: Changing view acls to: root
16/03/17 15:44:15 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:44:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:44:15 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:44:15 INFO Remoting: Starting remoting
16/03/17 15:44:15 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:41997]
16/03/17 15:44:15 INFO Utils: Successfully started service 'sparkDriver' on port 41997.
16/03/17 15:44:15 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:44:15 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:44:15 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7a4cfd02-8d98-4738-aede-fb024d364e1a
16/03/17 15:44:15 INFO MemoryStore: MemoryStore started with capacity 534.7 MB
16/03/17 15:44:15 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-1ab232d4-29fa-455b-9685-b14842c53086
16/03/17 15:44:15 INFO HttpServer: Starting HTTP Server
16/03/17 15:44:15 INFO Utils: Successfully started service 'HTTP file server' on port 51683.
16/03/17 15:44:15 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:44:15 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:44:15 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:44:15 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-9f9db492-22b3-400f-8f43-eaa404e30642/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:44:15 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209655882
16/03/17 15:44:15 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:44:15 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:44:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 47860.
16/03/17 15:44:15 INFO NettyBlockTransferService: Server created on 47860
16/03/17 15:44:15 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:44:15 INFO BlockManagerMasterEndpoint: Registering block manager localhost:47860 with 534.7 MB RAM, BlockManagerId(driver, localhost, 47860)
16/03/17 15:44:15 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:44:16 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:44:16 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:16 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:44:16 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:44:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:44:16 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:44:16 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=560710287
16/03/17 15:44:16 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 534.7 MB)
16/03/17 15:44:16 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=560710287
16/03/17 15:44:16 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 534.7 MB)
16/03/17 15:44:16 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:47860 (size: 4.1 KB, free: 534.7 MB)
16/03/17 15:44:16 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:44:16 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:16 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:44:16 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:44:16 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:44:16 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:44:16 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209655882
16/03/17 15:44:16 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:44:16 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-9f9db492-22b3-400f-8f43-eaa404e30642/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:44:16 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:44:16 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=560710287
16/03/17 15:44:16 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 534.7 MB)
16/03/17 15:44:16 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:47860 (size: 179.0 B, free: 534.7 MB)
16/03/17 15:44:16 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:44:16 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=560710287
16/03/17 15:44:16 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 534.7 MB)
16/03/17 15:44:16 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:47860 (size: 173.0 B, free: 534.7 MB)
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: set
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: planning
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: permission
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: economy
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: composition
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: agency
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:44:24 INFO PythonRunner: Times: total = 8419, boot = 532, init = 398, finish = 7489
16/03/17 15:44:24 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:44:24 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8574 ms on localhost (1/2)
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: bend
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: giant
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: astatine
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: present
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: area
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): providing
mapFunction_Parents(): keyword: providing ; prevleveltokens: issue
mapFunction_Parents(): keyword= providing ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:44:25 INFO PythonRunner: Times: total = 8983, boot = 538, init = 442, finish = 8003
16/03/17 15:44:25 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:44:25 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.118 s
16/03/17 15:44:25 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:44:25 INFO DAGScheduler: running: Set()
16/03/17 15:44:25 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:44:25 INFO DAGScheduler: failed: Set()
16/03/17 15:44:25 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:44:25 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:44:25 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=560710287
16/03/17 15:44:25 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 534.7 MB)
16/03/17 15:44:25 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=560710287
16/03/17 15:44:25 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 534.7 MB)
16/03/17 15:44:25 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9134 ms on localhost (2/2)
16/03/17 15:44:25 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:44:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:47860 (size: 3.0 KB, free: 534.7 MB)
16/03/17 15:44:25 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:44:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:25 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:44:25 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:44:25 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:44:25 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:44:25 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:44:25 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:44:25 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:44:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:44:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', 'None']
16/03/17 15:44:25 INFO PythonRunner: Times: total = 20, boot = -347, init = 367, finish = 0
16/03/17 15:44:25 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1269 bytes result sent to driver
16/03/17 15:44:25 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 39 ms on localhost (1/2)
16/03/17 15:44:25 INFO PythonRunner: Times: total = 222, boot = 221, init = 0, finish = 1
16/03/17 15:44:25 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:44:25 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 228 ms on localhost (2/2)
16/03/17 15:44:25 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.226 s
16/03/17 15:44:25 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:44:25 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.389925 s
16/03/17 15:44:25 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:44:25 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:44:25 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:25 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:44:25 INFO DAGScheduler: Missing parents: List()
16/03/17 15:44:25 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:44:25 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=560710287
16/03/17 15:44:25 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 534.7 MB)
16/03/17 15:44:25 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=560710287
16/03/17 15:44:25 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 534.7 MB)
16/03/17 15:44:25 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:47860 (size: 3.3 KB, free: 534.7 MB)
16/03/17 15:44:25 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:44:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:25 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:44:25 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:44:25 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2350 bytes)
16/03/17 15:44:25 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:44:25 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:44:25 INFO PythonRunner: Times: total = 54, boot = -109, init = 163, finish = 0
16/03/17 15:44:25 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:44:25 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 64 ms on localhost (1/2)
16/03/17 15:44:25 INFO PythonRunner: Times: total = 96, boot = 96, init = 0, finish = 0
16/03/17 15:44:25 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1337 bytes result sent to driver
16/03/17 15:44:25 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 108 ms on localhost (2/2)
16/03/17 15:44:25 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:44:25 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.105 s
16/03/17 15:44:25 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.136253 s
16/03/17 15:44:25 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:44:25 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:44:25 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:44:25 INFO MemoryStore: MemoryStore cleared
16/03/17 15:44:25 INFO BlockManager: BlockManager stopped
16/03/17 15:44:25 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:44:25 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:44:25 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:44:25 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:44:25 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:44:25 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:44:26 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:44:26 INFO SecurityManager: Changing view acls to: root
16/03/17 15:44:26 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:44:26 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:44:26 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:44:26 INFO Remoting: Starting remoting
16/03/17 15:44:26 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:58238]
16/03/17 15:44:26 INFO Utils: Successfully started service 'sparkDriver' on port 58238.
16/03/17 15:44:26 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:44:26 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:44:26 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d193786e-3493-477c-94d5-d9b2acbd4439
16/03/17 15:44:26 INFO MemoryStore: MemoryStore started with capacity 534.7 MB
16/03/17 15:44:26 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-64631187-ea19-4542-90e6-3c0c1b6f850e
16/03/17 15:44:26 INFO HttpServer: Starting HTTP Server
16/03/17 15:44:26 INFO Utils: Successfully started service 'HTTP file server' on port 38477.
16/03/17 15:44:26 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:44:26 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:44:26 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:44:26 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-cc109d0e-4c72-4d95-8f7b-c2a6c59e7036/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:44:26 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209666894
16/03/17 15:44:26 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:44:26 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:44:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57414.
16/03/17 15:44:26 INFO NettyBlockTransferService: Server created on 57414
16/03/17 15:44:26 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:44:26 INFO BlockManagerMasterEndpoint: Registering block manager localhost:57414 with 534.7 MB RAM, BlockManagerId(driver, localhost, 57414)
16/03/17 15:44:26 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:44:27 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:44:27 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:27 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:44:27 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:44:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:44:27 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:44:27 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=560710287
16/03/17 15:44:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 534.7 MB)
16/03/17 15:44:27 INFO MemoryStore: ensureFreeSpace(4155) called with curMem=6576, maxMem=560710287
16/03/17 15:44:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 534.7 MB)
16/03/17 15:44:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:57414 (size: 4.1 KB, free: 534.7 MB)
16/03/17 15:44:27 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:44:27 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:27 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:44:27 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:44:27 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:44:27 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:44:27 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209666894
16/03/17 15:44:27 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:44:27 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-cc109d0e-4c72-4d95-8f7b-c2a6c59e7036/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:44:27 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:44:27 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10731, maxMem=560710287
16/03/17 15:44:27 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 534.7 MB)
16/03/17 15:44:27 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:57414 (size: 179.0 B, free: 534.7 MB)
16/03/17 15:44:27 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:44:27 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10910, maxMem=560710287
16/03/17 15:44:27 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 534.7 MB)
16/03/17 15:44:27 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:57414 (size: 173.0 B, free: 534.7 MB)
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: set
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: bend
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: giant
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  region  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: planning
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: astatine
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
u'halogen', asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword:u'unstable' region ; prevleveltokens: permission
, u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: present
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: economy
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: composition
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: agency
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['NonmapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
e']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: area
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword: 16/03/17 15:44:35 INFO PythonRunner: Times: total = 8554, boot = 461, init = 395, finish = 7698
 region  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): region
16/03/17 15:44:35 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
mapFunction_Parents(): keyword: region ; prevleveltokens: issue
16/03/17 15:44:35 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8626 ms on localhost (1/2)
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/17 15:44:35 INFO PythonRunner: Times: total = 8602, boot = 463, init = 403, finish = 7736
16/03/17 15:44:35 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:44:35 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8675 ms on localhost (2/2)
16/03/17 15:44:35 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:44:35 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.682 s
16/03/17 15:44:35 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:44:35 INFO DAGScheduler: running: Set()
16/03/17 15:44:35 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:44:35 INFO DAGScheduler: failed: Set()
16/03/17 15:44:35 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:44:35 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:44:35 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11083, maxMem=560710287
16/03/17 15:44:35 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 534.7 MB)
16/03/17 15:44:35 INFO MemoryStore: ensureFreeSpace(3054) called with curMem=16067, maxMem=560710287
16/03/17 15:44:35 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 534.7 MB)
16/03/17 15:44:35 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:57414 (size: 3.0 KB, free: 534.7 MB)
16/03/17 15:44:35 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:44:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:35 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:44:35 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:44:35 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:44:35 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:44:35 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:44:35 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:44:35 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:44:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:44:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:44:35 INFO PythonRunner: Times: total = 244, boot = 243, init = 1, finish = 0
16/03/17 15:44:35 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:44:35 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 258 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'area', u'area']
16/03/17 15:44:35 INFO PythonRunner: Times: total = 264, boot = 263, init = 0, finish = 1
16/03/17 15:44:35 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/17 15:44:36 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 287 ms on localhost (2/2)
16/03/17 15:44:36 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:44:36 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.288 s
16/03/17 15:44:36 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.989295 s
16/03/17 15:44:36 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:44:36 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:44:36 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:36 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:44:36 INFO DAGScheduler: Missing parents: List()
16/03/17 15:44:36 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:44:36 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19121, maxMem=560710287
16/03/17 15:44:36 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 534.7 MB)
16/03/17 15:44:36 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24937, maxMem=560710287
16/03/17 15:44:36 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 534.7 MB)
16/03/17 15:44:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:57414 (size: 3.3 KB, free: 534.7 MB)
16/03/17 15:44:36 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:44:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:36 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:44:36 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:44:36 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/17 15:44:36 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:44:36 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:44:36 INFO PythonRunner: Times: total = 116, boot = 116, init = 0, finish = 0
16/03/17 15:44:36 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:44:36 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 124 ms on localhost (1/2)
16/03/17 15:44:36 INFO PythonRunner: Times: total = 130, boot = 129, init = 1, finish = 0
16/03/17 15:44:36 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/03/17 15:44:36 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 137 ms on localhost (2/2)
16/03/17 15:44:36 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:44:36 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.130 s
16/03/17 15:44:36 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.150898 s
16/03/17 15:44:36 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:44:36 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:44:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:44:36 INFO MemoryStore: MemoryStore cleared
16/03/17 15:44:36 INFO BlockManager: BlockManager stopped
16/03/17 15:44:36 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:44:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:44:36 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:44:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:44:36 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:44:36 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:44:37 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:44:37 INFO SecurityManager: Changing view acls to: root
16/03/17 15:44:37 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:44:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:44:37 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:44:37 INFO Remoting: Starting remoting
16/03/17 15:44:37 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:35820]
16/03/17 15:44:37 INFO Utils: Successfully started service 'sparkDriver' on port 35820.
16/03/17 15:44:37 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:44:37 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:44:37 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1493b49f-9a9b-4c61-a1a0-87fd38d24846
16/03/17 15:44:37 INFO MemoryStore: MemoryStore started with capacity 534.7 MB
16/03/17 15:44:37 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-13c4ac4d-eeca-46be-9d35-48708a2e9b1b
16/03/17 15:44:37 INFO HttpServer: Starting HTTP Server
16/03/17 15:44:37 INFO Utils: Successfully started service 'HTTP file server' on port 59659.
16/03/17 15:44:37 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:44:37 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:44:37 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:44:37 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-b335a9e4-438a-484d-9971-6123aee8f64e/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:44:37 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209677488
16/03/17 15:44:37 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:44:37 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:44:37 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46737.
16/03/17 15:44:37 INFO NettyBlockTransferService: Server created on 46737
16/03/17 15:44:37 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:44:37 INFO BlockManagerMasterEndpoint: Registering block manager localhost:46737 with 534.7 MB RAM, BlockManagerId(driver, localhost, 46737)
16/03/17 15:44:37 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:44:37 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:44:37 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:37 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:44:37 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:44:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:44:37 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:44:37 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=560710287
16/03/17 15:44:37 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 534.7 MB)
16/03/17 15:44:37 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=560710287
16/03/17 15:44:37 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 534.7 MB)
16/03/17 15:44:37 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:46737 (size: 4.1 KB, free: 534.7 MB)
16/03/17 15:44:37 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:44:37 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:37 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:44:37 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:44:37 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:44:37 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:44:37 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209677488
16/03/17 15:44:37 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:44:37 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-b335a9e4-438a-484d-9971-6123aee8f64e/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:44:37 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:44:37 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10732, maxMem=560710287
16/03/17 15:44:37 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 534.7 MB)
16/03/17 15:44:37 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:46737 (size: 173.0 B, free: 534.7 MB)
16/03/17 15:44:37 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:44:37 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10905, maxMem=560710287
16/03/17 15:44:37 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 534.7 MB)
16/03/17 15:44:37 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:46737 (size: 179.0 B, free: 534.7 MB)
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: set
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: planning
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: permission
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: economy
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: composition
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: agency
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:44:46 INFO PythonRunner: Times: total = 8367, boot = 463, init = 381, finish = 7523
16/03/17 15:44:46 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:44:46 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8441 ms on localhost (1/2)
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: bend
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: giant
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: astatine
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: present
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  title  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: area
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: issue
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
16/03/17 15:44:46 INFO PythonRunner: Times: total = 8707, boot = 454, init = 405, finish = 7848
16/03/17 15:44:46 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:44:46 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.769 s
16/03/17 15:44:46 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:44:46 INFO DAGScheduler: running: Set()
16/03/17 15:44:46 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:44:46 INFO DAGScheduler: failed: Set()
16/03/17 15:44:46 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:44:46 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:44:46 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=560710287
16/03/17 15:44:46 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 534.7 MB)
16/03/17 15:44:46 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8767 ms on localhost (2/2)
16/03/17 15:44:46 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:44:46 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=560710287
16/03/17 15:44:46 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 534.7 MB)
16/03/17 15:44:46 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:46737 (size: 3.0 KB, free: 534.7 MB)
16/03/17 15:44:46 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:44:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:46 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:44:46 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:44:46 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:44:46 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:44:46 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:44:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:44:46 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:44:46 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:44:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
reduceFunction_Parents(): returns= ['None', u'metropolitan', 'None']
16/03/17 15:44:46 INFO PythonRunner: Times: total = 13, boot = -166, init = 179, finish = 0
16/03/17 15:44:46 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1288 bytes result sent to driver
16/03/17 15:44:46 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 48 ms on localhost (1/2)
16/03/17 15:44:46 INFO PythonRunner: Times: total = 217, boot = 216, init = 0, finish = 1
16/03/17 15:44:46 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:44:46 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 230 ms on localhost (2/2)
16/03/17 15:44:46 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:44:46 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.230 s
16/03/17 15:44:46 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.023985 s
16/03/17 15:44:46 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:44:46 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:44:46 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:46 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:44:46 INFO DAGScheduler: Missing parents: List()
16/03/17 15:44:46 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:44:46 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=560710287
16/03/17 15:44:46 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 534.7 MB)
16/03/17 15:44:46 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=16900, maxMem=560710287
16/03/17 15:44:46 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:46737 in memory (size: 3.0 KB, free: 534.7 MB)
16/03/17 15:44:46 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 534.7 MB)
16/03/17 15:44:46 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:46737 (size: 3.3 KB, free: 534.7 MB)
16/03/17 15:44:46 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:44:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:46 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:44:46 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:44:46 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2369 bytes)
16/03/17 15:44:46 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:44:46 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:44:46 INFO PythonRunner: Times: total = 19, boot = -133, init = 152, finish = 0
16/03/17 15:44:46 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1356 bytes result sent to driver
16/03/17 15:44:47 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 47 ms on localhost (1/2)
16/03/17 15:44:47 INFO ContextCleaner: Cleaned accumulator 147
16/03/17 15:44:47 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:46737 in memory (size: 4.1 KB, free: 534.7 MB)
16/03/17 15:44:47 INFO ContextCleaner: Cleaned accumulator 146
16/03/17 15:44:47 INFO PythonRunner: Times: total = 55, boot = -348, init = 403, finish = 0
16/03/17 15:44:47 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:44:47 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 65 ms on localhost (2/2)
16/03/17 15:44:47 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:44:47 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.066 s
16/03/17 15:44:47 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.270194 s
16/03/17 15:44:47 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:44:47 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:44:47 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:44:47 INFO MemoryStore: MemoryStore cleared
16/03/17 15:44:47 INFO BlockManager: BlockManager stopped
16/03/17 15:44:47 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:44:47 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:44:47 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:44:47 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:44:47 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:44:47 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:44:48 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:44:48 INFO SecurityManager: Changing view acls to: root
16/03/17 15:44:48 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:44:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:44:48 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:44:48 INFO Remoting: Starting remoting
16/03/17 15:44:48 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:60362]
16/03/17 15:44:48 INFO Utils: Successfully started service 'sparkDriver' on port 60362.
16/03/17 15:44:48 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:44:48 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:44:48 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7f248972-4f13-4bb7-a39f-18ab14642011
16/03/17 15:44:48 INFO MemoryStore: MemoryStore started with capacity 535.4 MB
16/03/17 15:44:48 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-6737db8a-ff71-43c0-9533-416ec4c1307f
16/03/17 15:44:48 INFO HttpServer: Starting HTTP Server
16/03/17 15:44:48 INFO Utils: Successfully started service 'HTTP file server' on port 47895.
16/03/17 15:44:48 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:44:48 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:44:48 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:44:48 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-0899f43d-ef5f-4466-89d1-2d03a2a027f7/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:44:48 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209688197
16/03/17 15:44:48 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:44:48 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:44:48 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36159.
16/03/17 15:44:48 INFO NettyBlockTransferService: Server created on 36159
16/03/17 15:44:48 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:44:48 INFO BlockManagerMasterEndpoint: Registering block manager localhost:36159 with 535.4 MB RAM, BlockManagerId(driver, localhost, 36159)
16/03/17 15:44:48 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:44:48 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:44:48 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:48 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:44:48 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:44:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:44:48 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:44:48 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=561418076
16/03/17 15:44:48 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 535.4 MB)
16/03/17 15:44:48 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=561418076
16/03/17 15:44:48 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 535.4 MB)
16/03/17 15:44:48 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:36159 (size: 4.1 KB, free: 535.4 MB)
16/03/17 15:44:48 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:44:48 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:48 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:44:48 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:44:48 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:44:48 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:44:48 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209688197
16/03/17 15:44:48 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:44:48 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-0899f43d-ef5f-4466-89d1-2d03a2a027f7/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:44:48 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:44:48 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10732, maxMem=561418076
16/03/17 15:44:48 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 535.4 MB)
16/03/17 15:44:48 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:36159 (size: 173.0 B, free: 535.4 MB)
16/03/17 15:44:48 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:44:48 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10905, maxMem=561418076
16/03/17 15:44:48 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 535.4 MB)
16/03/17 15:44:48 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:36159 (size: 179.0 B, free: 535.4 MB)
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: set
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): adding to parents: syn =  Synset('kilometer.n.01') ; keyword:  equal  in syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= [u'kilometer']
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: planning
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: permission
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: economy
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: composition
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: agency
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): adding to parents: syn =  Synset('kilometer.n.01') ; keyword:  equal  in syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= [u'kilometer']
reduceFunction_Parents(): returns= [u'kilometer', u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer', u'kilometer']
16/03/17 15:44:56 INFO PythonRunner: Times: total = 8367, boot = 474, init = 375, finish = 7518
16/03/17 15:44:56 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:44:56 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8456 ms on localhost (1/2)
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: bend
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: giant
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: astatine
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: present
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: area
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equal
mapFunction_Parents(): keyword: equal ; prevleveltokens: issue
mapFunction_Parents(): keyword= equal ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:44:57 INFO PythonRunner: Times: total = 8799, boot = 485, init = 545, finish = 7769
16/03/17 15:44:57 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:44:57 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8889 ms on localhost (2/2)
16/03/17 15:44:57 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:44:57 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.891 s
16/03/17 15:44:57 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:44:57 INFO DAGScheduler: running: Set()
16/03/17 15:44:57 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:44:57 INFO DAGScheduler: failed: Set()
16/03/17 15:44:57 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:44:57 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:44:57 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=561418076
16/03/17 15:44:57 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 535.4 MB)
16/03/17 15:44:57 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=561418076
16/03/17 15:44:57 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 535.4 MB)
16/03/17 15:44:57 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:36159 (size: 3.0 KB, free: 535.4 MB)
16/03/17 15:44:57 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:44:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:57 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:44:57 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:44:57 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:44:57 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:44:57 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:44:57 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:44:57 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:44:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:44:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/17 15:44:57 INFO PythonRunner: Times: total = 15, boot = -262, init = 277, finish = 0
16/03/17 15:44:57 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:44:57 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 31 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'kilometer', u'kilometer']
16/03/17 15:44:57 INFO PythonRunner: Times: total = 190, boot = 189, init = 0, finish = 1
16/03/17 15:44:57 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1279 bytes result sent to driver
16/03/17 15:44:57 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 209 ms on localhost (2/2)
16/03/17 15:44:57 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.193 s
16/03/17 15:44:57 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:44:57 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.121547 s
16/03/17 15:44:57 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:44:57 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:44:57 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:57 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:44:57 INFO DAGScheduler: Missing parents: List()
16/03/17 15:44:57 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:44:57 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=561418076
16/03/17 15:44:57 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 535.4 MB)
16/03/17 15:44:57 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=561418076
16/03/17 15:44:57 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 535.4 MB)
16/03/17 15:44:57 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:36159 (size: 3.3 KB, free: 535.4 MB)
16/03/17 15:44:57 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:44:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:57 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:44:57 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:44:57 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2360 bytes)
16/03/17 15:44:57 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:44:57 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:44:57 INFO PythonRunner: Times: total = 47, boot = -85, init = 132, finish = 0
16/03/17 15:44:57 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1358 bytes result sent to driver
16/03/17 15:44:57 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 57 ms on localhost (1/2)
16/03/17 15:44:57 INFO PythonRunner: Times: total = 131, boot = 131, init = 0, finish = 0
16/03/17 15:44:57 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:44:57 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 143 ms on localhost (2/2)
16/03/17 15:44:57 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:44:57 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.145 s
16/03/17 15:44:57 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.156881 s
16/03/17 15:44:57 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:44:57 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:44:57 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:44:57 INFO MemoryStore: MemoryStore cleared
16/03/17 15:44:57 INFO BlockManager: BlockManager stopped
16/03/17 15:44:57 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:44:57 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:44:57 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:44:57 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:44:57 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:44:57 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:44:58 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:44:58 INFO SecurityManager: Changing view acls to: root
16/03/17 15:44:58 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:44:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:44:58 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:44:58 INFO Remoting: Starting remoting
16/03/17 15:44:58 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:49690]
16/03/17 15:44:58 INFO Utils: Successfully started service 'sparkDriver' on port 49690.
16/03/17 15:44:58 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:44:58 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:44:58 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b18d9654-e389-405b-9aad-3fe171ddb901
16/03/17 15:44:58 INFO MemoryStore: MemoryStore started with capacity 535.4 MB
16/03/17 15:44:58 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-252609cd-6ad5-48fb-ba83-643f4a5c04c4
16/03/17 15:44:58 INFO HttpServer: Starting HTTP Server
16/03/17 15:44:58 INFO Utils: Successfully started service 'HTTP file server' on port 41354.
16/03/17 15:44:58 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:44:58 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:44:58 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:44:58 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-69c3734a-7f8d-46e7-9d1b-c6aa746a3ece/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:44:58 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209698850
16/03/17 15:44:58 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:44:58 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:44:58 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49175.
16/03/17 15:44:58 INFO NettyBlockTransferService: Server created on 49175
16/03/17 15:44:58 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:44:58 INFO BlockManagerMasterEndpoint: Registering block manager localhost:49175 with 535.4 MB RAM, BlockManagerId(driver, localhost, 49175)
16/03/17 15:44:58 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:44:58 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:44:58 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:58 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:44:58 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:44:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:44:58 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:44:58 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=561418076
16/03/17 15:44:58 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 535.4 MB)
16/03/17 15:44:58 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=561418076
16/03/17 15:44:58 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 535.4 MB)
16/03/17 15:44:58 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:49175 (size: 4.1 KB, free: 535.4 MB)
16/03/17 15:44:58 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:44:58 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:44:58 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:44:58 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:44:58 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:44:58 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:44:58 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209698850
16/03/17 15:44:58 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:44:59 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-69c3734a-7f8d-46e7-9d1b-c6aa746a3ece/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:44:59 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:44:59 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:44:59 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=561418076
16/03/17 15:44:59 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 535.4 MB)
16/03/17 15:44:59 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:49175 (size: 179.0 B, free: 535.4 MB)
16/03/17 15:44:59 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=561418076
16/03/17 15:44:59 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 535.4 MB)
16/03/17 15:44:59 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:49175 (size: 173.0 B, free: 535.4 MB)
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: set
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: bend
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: giant
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: astatine
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: present
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: area
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: issue
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:45:07 INFO PythonRunner: Times: total = 8518, boot = 476, init = 413, finish = 7629
16/03/17 15:45:07 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:45:07 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8588 ms on localhost (1/2)
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): adding to parents: syn =  Synset('kilometer.n.01') ; keyword:  length  in syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= [u'kilometer']
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: planning
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: permission
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: economy
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: composition
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: agency
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): adding to parents: syn =  Synset('kilometer.n.01') ; keyword:  length  in syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= [u'kilometer']
reduceFunction_Parents(): returns= [u'kilometer', u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): length
mapFunction_Parents(): keyword: length ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= length ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer', u'kilometer']
16/03/17 15:45:08 INFO PythonRunner: Times: total = 9157, boot = 482, init = 395, finish = 8280
16/03/17 15:45:08 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:45:08 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.213 s
16/03/17 15:45:08 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:45:08 INFO DAGScheduler: running: Set()
16/03/17 15:45:08 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:45:08 INFO DAGScheduler: failed: Set()
16/03/17 15:45:08 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:45:08 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:45:08 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=561418076
16/03/17 15:45:08 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 535.4 MB)
16/03/17 15:45:08 INFO MemoryStore: ensureFreeSpace(3054) called with curMem=16068, maxMem=561418076
16/03/17 15:45:08 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 535.4 MB)
16/03/17 15:45:08 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9209 ms on localhost (2/2)
16/03/17 15:45:08 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:45:08 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:49175 (size: 3.0 KB, free: 535.4 MB)
16/03/17 15:45:08 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:45:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:45:08 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:45:08 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:45:08 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:45:08 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:45:08 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:45:08 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:45:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:45:08 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:45:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'kilometer', u'kilometer']
16/03/17 15:45:08 INFO PythonRunner: Times: total = 24, boot = -447, init = 471, finish = 0
16/03/17 15:45:08 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1279 bytes result sent to driver
16/03/17 15:45:08 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 43 ms on localhost (1/2)
16/03/17 15:45:08 INFO PythonRunner: Times: total = 213, boot = 212, init = 0, finish = 1
16/03/17 15:45:08 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:45:08 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 224 ms on localhost (2/2)
16/03/17 15:45:08 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:45:08 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.223 s
16/03/17 15:45:08 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.460990 s
16/03/17 15:45:08 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:45:08 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:45:08 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:45:08 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:45:08 INFO DAGScheduler: Missing parents: List()
16/03/17 15:45:08 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:45:08 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19122, maxMem=561418076
16/03/17 15:45:08 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 535.4 MB)
16/03/17 15:45:08 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24938, maxMem=561418076
16/03/17 15:45:08 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 535.4 MB)
16/03/17 15:45:08 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:49175 (size: 3.3 KB, free: 535.4 MB)
16/03/17 15:45:08 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:45:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:45:08 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:45:08 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:45:08 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2360 bytes)
16/03/17 15:45:08 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:45:08 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:45:08 INFO PythonRunner: Times: total = 53, boot = -120, init = 173, finish = 0
16/03/17 15:45:08 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:45:08 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 82 ms on localhost (1/2)
16/03/17 15:45:08 INFO PythonRunner: Times: total = 176, boot = 176, init = 0, finish = 0
16/03/17 15:45:08 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1358 bytes result sent to driver
16/03/17 15:45:08 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 192 ms on localhost (2/2)
16/03/17 15:45:08 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:45:08 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.192 s
16/03/17 15:45:08 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.214836 s
16/03/17 15:45:08 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:45:08 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:45:08 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:45:08 INFO MemoryStore: MemoryStore cleared
16/03/17 15:45:08 INFO BlockManager: BlockManager stopped
16/03/17 15:45:08 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:45:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:45:08 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:45:08 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:45:08 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:45:08 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:45:09 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:45:09 INFO SecurityManager: Changing view acls to: root
16/03/17 15:45:09 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:45:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:45:09 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:45:09 INFO Remoting: Starting remoting
16/03/17 15:45:09 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:56316]
16/03/17 15:45:09 INFO Utils: Successfully started service 'sparkDriver' on port 56316.
16/03/17 15:45:09 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:45:09 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:45:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-093377cd-3d8c-4a8c-8c2d-865f899e4223
16/03/17 15:45:09 INFO MemoryStore: MemoryStore started with capacity 535.4 MB
16/03/17 15:45:09 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-f2b55fb0-769f-4f3e-b66d-885364a3ca35
16/03/17 15:45:09 INFO HttpServer: Starting HTTP Server
16/03/17 15:45:09 INFO Utils: Successfully started service 'HTTP file server' on port 52005.
16/03/17 15:45:09 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:45:09 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:45:09 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:45:09 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-190b5f4d-72c1-4683-8873-b49f40062dec/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:45:09 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209709920
16/03/17 15:45:09 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:45:09 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:45:09 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55348.
16/03/17 15:45:09 INFO NettyBlockTransferService: Server created on 55348
16/03/17 15:45:09 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:45:09 INFO BlockManagerMasterEndpoint: Registering block manager localhost:55348 with 535.4 MB RAM, BlockManagerId(driver, localhost, 55348)
16/03/17 15:45:09 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:45:10 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:45:10 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:45:10 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:45:10 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:45:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:45:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:45:10 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:45:10 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=561418076
16/03/17 15:45:10 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 535.4 MB)
16/03/17 15:45:10 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=561418076
16/03/17 15:45:10 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 535.4 MB)
16/03/17 15:45:10 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:55348 (size: 4.1 KB, free: 535.4 MB)
16/03/17 15:45:10 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:45:10 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:45:10 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:45:10 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:45:10 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:45:10 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:45:10 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209709920
16/03/17 15:45:10 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:45:10 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-190b5f4d-72c1-4683-8873-b49f40062dec/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:45:10 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:45:10 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=561418076
16/03/17 15:45:10 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 535.4 MB)
16/03/17 15:45:10 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:55348 (size: 179.0 B, free: 535.4 MB)
16/03/17 15:45:10 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:45:10 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=561418076
16/03/17 15:45:10 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 535.4 MB)
16/03/17 15:45:10 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:55348 (size: 173.0 B, free: 535.4 MB)
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: set
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: bend
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: giant
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: astatine
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: present
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: area
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: issue
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:45:18 INFO PythonRunner: Times: total = 8733, boot = 470, init = 411, finish = 7852
16/03/17 15:45:18 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: planning
16/03/17 15:45:18 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8808 ms on localhost (1/2)
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: permission
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: economy
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: composition
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  resulting  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: agency
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): resulting
mapFunction_Parents(): keyword: resulting ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= resulting ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/17 15:45:18 INFO PythonRunner: Times: total = 8827, boot = 462, init = 386, finish = 7979
16/03/17 15:45:18 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:45:18 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.904 s
16/03/17 15:45:18 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:45:18 INFO DAGScheduler: running: Set()
16/03/17 15:45:18 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:45:18 INFO DAGScheduler: failed: Set()
16/03/17 15:45:18 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:45:18 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:45:18 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=561418076
16/03/17 15:45:18 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 535.4 MB)
16/03/17 15:45:18 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=561418076
16/03/17 15:45:18 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 535.4 MB)
16/03/17 15:45:18 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8901 ms on localhost (2/2)
16/03/17 15:45:18 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:45:18 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:55348 (size: 3.0 KB, free: 535.4 MB)
16/03/17 15:45:18 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:45:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:45:18 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:45:18 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:45:18 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:45:18 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:45:18 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:45:18 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:45:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:45:18 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:45:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:45:19 INFO PythonRunner: Times: total = 127, boot = 125, init = 1, finish = 1
16/03/17 15:45:19 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:45:19 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 143 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'composition']
16/03/17 15:45:19 INFO PythonRunner: Times: total = 233, boot = 232, init = 0, finish = 1
16/03/17 15:45:19 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1287 bytes result sent to driver
16/03/17 15:45:19 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.247 s
16/03/17 15:45:19 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.174195 s
16/03/17 15:45:19 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 248 ms on localhost (2/2)
16/03/17 15:45:19 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:45:19 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:45:19 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:45:19 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:45:19 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:45:19 INFO DAGScheduler: Missing parents: List()
16/03/17 15:45:19 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:45:19 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=561418076
16/03/17 15:45:19 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 535.4 MB)
16/03/17 15:45:19 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=561418076
16/03/17 15:45:19 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 535.4 MB)
16/03/17 15:45:19 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:55348 (size: 3.3 KB, free: 535.4 MB)
16/03/17 15:45:19 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:45:19 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:45:19 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:45:19 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:45:19 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2368 bytes)
16/03/17 15:45:19 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:45:19 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:45:19 INFO PythonRunner: Times: total = 28, boot = 27, init = 1, finish = 0
16/03/17 15:45:19 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:45:19 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 42 ms on localhost (1/2)
16/03/17 15:45:19 INFO PythonRunner: Times: total = 145, boot = 144, init = 0, finish = 1
16/03/17 15:45:19 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1355 bytes result sent to driver
16/03/17 15:45:19 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 156 ms on localhost (2/2)
16/03/17 15:45:19 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:45:19 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.158 s
16/03/17 15:45:19 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.168125 s
16/03/17 15:45:19 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:45:19 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:45:19 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:45:19 INFO MemoryStore: MemoryStore cleared
16/03/17 15:45:19 INFO BlockManager: BlockManager stopped
16/03/17 15:45:19 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:45:19 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:45:19 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:45:19 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:45:19 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:45:19 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:45:20 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:45:20 INFO SecurityManager: Changing view acls to: root
16/03/17 15:45:20 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:45:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:45:20 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:45:20 INFO Remoting: Starting remoting
16/03/17 15:45:20 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:44167]
16/03/17 15:45:20 INFO Utils: Successfully started service 'sparkDriver' on port 44167.
16/03/17 15:45:20 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:45:20 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:45:20 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-4ed2b953-5299-4d19-bcb4-cf0c72f91037
16/03/17 15:45:20 INFO MemoryStore: MemoryStore started with capacity 535.4 MB
16/03/17 15:45:20 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-e19fdd77-3e3f-45ea-b1f4-f3f9819008d3
16/03/17 15:45:20 INFO HttpServer: Starting HTTP Server
16/03/17 15:45:20 INFO Utils: Successfully started service 'HTTP file server' on port 36483.
16/03/17 15:45:20 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:45:20 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:45:20 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:45:20 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-9bb9ac1e-fd4b-4f0c-9955-faf812319638/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:45:20 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209720719
16/03/17 15:45:20 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:45:20 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:45:20 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57061.
16/03/17 15:45:20 INFO NettyBlockTransferService: Server created on 57061
16/03/17 15:45:20 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:45:20 INFO BlockManagerMasterEndpoint: Registering block manager localhost:57061 with 535.4 MB RAM, BlockManagerId(driver, localhost, 57061)
16/03/17 15:45:20 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:45:20 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:45:20 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:45:20 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:45:20 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:45:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:45:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:45:20 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:45:20 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=561418076
16/03/17 15:45:20 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 535.4 MB)
16/03/17 15:45:20 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=561418076
16/03/17 15:45:20 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 535.4 MB)
16/03/17 15:45:20 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:57061 (size: 4.1 KB, free: 535.4 MB)
16/03/17 15:45:20 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:45:20 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:45:20 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:45:20 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:45:20 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:45:20 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:45:20 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209720719
16/03/17 15:45:20 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:45:20 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-9bb9ac1e-fd4b-4f0c-9955-faf812319638/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:45:20 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:45:20 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:45:20 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=561418076
16/03/17 15:45:20 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 535.4 MB)
16/03/17 15:45:20 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:57061 (size: 179.0 B, free: 535.4 MB)
16/03/17 15:45:20 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=561418076
16/03/17 15:45:20 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 535.4 MB)
16/03/17 15:45:20 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:57061 (size: 173.0 B, free: 535.4 MB)
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: area
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: bend
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: giant
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: astatine
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: present
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: area
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: issue
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:45:29 INFO PythonRunner: Times: total = 8659, boot = 446, init = 383, finish = 7830
16/03/17 15:45:29 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:45:29 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8732 ms on localhost (1/2)
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: planning
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): adding to parents: syn =  Synset('planning.n.01') ; keyword:  act  in syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= [u'planning']
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: permission
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: economy
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: composition
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: agency
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): act
mapFunction_Parents(): keyword: act ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= act ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
16/03/17 15:45:29 INFO PythonRunner: Times: total = 8806, boot = 460, init = 409, finish = 7937
16/03/17 15:45:29 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:45:29 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.866 s
16/03/17 15:45:29 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:45:29 INFO DAGScheduler: running: Set()
16/03/17 15:45:29 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:45:29 INFO DAGScheduler: failed: Set()
16/03/17 15:45:29 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:45:29 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:45:29 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=561418076
16/03/17 15:45:29 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 535.4 MB)
16/03/17 15:45:29 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=561418076
16/03/17 15:45:29 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 535.4 MB)
16/03/17 15:45:29 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:57061 (size: 3.0 KB, free: 535.4 MB)
16/03/17 15:45:29 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:45:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:45:29 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:45:29 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8862 ms on localhost (2/2)
16/03/17 15:45:29 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:45:29 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:45:29 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:45:29 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:45:29 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:45:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:45:29 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:45:29 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:45:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:45:29 INFO PythonRunner: Times: total = 117, boot = 116, init = 0, finish = 1
16/03/17 15:45:29 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:45:29 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 130 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'planning']
16/03/17 15:45:29 INFO PythonRunner: Times: total = 234, boot = 234, init = 0, finish = 0
16/03/17 15:45:29 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/03/17 15:45:29 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.238 s
16/03/17 15:45:29 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.144256 s
16/03/17 15:45:29 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 249 ms on localhost (2/2)
16/03/17 15:45:29 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:45:30 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:45:30 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:45:30 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:45:30 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:45:30 INFO DAGScheduler: Missing parents: List()
16/03/17 15:45:30 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:45:30 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=561418076
16/03/17 15:45:30 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 535.4 MB)
16/03/17 15:45:30 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=561418076
16/03/17 15:45:30 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 535.4 MB)
16/03/17 15:45:30 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:57061 (size: 3.3 KB, free: 535.4 MB)
16/03/17 15:45:30 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:45:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:45:30 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:45:30 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:45:30 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/03/17 15:45:30 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:45:30 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:45:30 INFO PythonRunner: Times: total = 161, boot = 160, init = 1, finish = 0
16/03/17 15:45:30 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:45:30 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 170 ms on localhost (1/2)
16/03/17 15:45:30 INFO PythonRunner: Times: total = 168, boot = 167, init = 1, finish = 0
16/03/17 15:45:30 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/03/17 15:45:30 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 175 ms on localhost (2/2)
16/03/17 15:45:30 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:45:30 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.175 s
16/03/17 15:45:30 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.188963 s
16/03/17 15:45:30 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:45:30 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:45:30 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:45:30 INFO MemoryStore: MemoryStore cleared
16/03/17 15:45:30 INFO BlockManager: BlockManager stopped
16/03/17 15:45:30 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:45:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:45:30 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:45:30 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:45:30 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:45:30 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:45:31 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:45:31 INFO SecurityManager: Changing view acls to: root
16/03/17 15:45:31 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:45:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:45:31 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:45:31 INFO Remoting: Starting remoting
16/03/17 15:45:31 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:51567]
16/03/17 15:45:31 INFO Utils: Successfully started service 'sparkDriver' on port 51567.
16/03/17 15:45:31 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:45:31 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:45:31 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-073ed7f2-2a0d-40c8-b901-941b33fa6f9b
16/03/17 15:45:31 INFO MemoryStore: MemoryStore started with capacity 535.4 MB
16/03/17 15:45:31 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-146074dc-a306-4bf6-bc14-acc3e0a5c94b
16/03/17 15:45:31 INFO HttpServer: Starting HTTP Server
16/03/17 15:45:31 INFO Utils: Successfully started service 'HTTP file server' on port 44911.
16/03/17 15:45:31 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:45:31 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:45:31 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:45:31 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-425000ba-3433-4583-adcf-2b190169fe7a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:45:31 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209731457
16/03/17 15:45:31 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:45:31 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:45:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58297.
16/03/17 15:45:31 INFO NettyBlockTransferService: Server created on 58297
16/03/17 15:45:31 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:45:31 INFO BlockManagerMasterEndpoint: Registering block manager localhost:58297 with 535.4 MB RAM, BlockManagerId(driver, localhost, 58297)
16/03/17 15:45:31 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:45:31 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:45:31 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:45:31 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:45:31 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:45:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:45:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:45:31 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:45:31 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=561418076
16/03/17 15:45:31 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 535.4 MB)
16/03/17 15:45:31 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=561418076
16/03/17 15:45:31 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 535.4 MB)
16/03/17 15:45:31 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:58297 (size: 4.1 KB, free: 535.4 MB)
16/03/17 15:45:31 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:45:31 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:45:31 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:45:31 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:45:31 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:45:31 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:45:31 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209731457
16/03/17 15:45:31 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:45:31 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-425000ba-3433-4583-adcf-2b190169fe7a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:45:31 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:45:31 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=561418076
16/03/17 15:45:31 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 535.4 MB)
16/03/17 15:45:31 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:58297 (size: 179.0 B, free: 535.4 MB)
16/03/17 15:45:31 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:45:31 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=561418076
16/03/17 15:45:31 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 535.4 MB)
16/03/17 15:45:31 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:58297 (size: 173.0 B, free: 535.4 MB)
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: set
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: planning
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): adding to parents: syn =  Synset('planning.n.01') ; keyword:  action  in syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= [u'planning']
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: permission
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: economy
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: composition
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: agency
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'planning']
16/03/17 15:45:40 INFO PythonRunner: Times: total = 8221, boot = 468, init = 387, finish = 7366
16/03/17 15:45:40 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:45:40 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8438 ms on localhost (1/2)
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: bend
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: giant
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: astatine
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: present
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: area
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): action
mapFunction_Parents(): keyword: action ; prevleveltokens: issue
mapFunction_Parents(): keyword= action ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:45:40 INFO PythonRunner: Times: total = 9038, boot = 472, init = 399, finish = 8167
16/03/17 15:45:40 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:45:40 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.256 s
16/03/17 15:45:40 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:45:40 INFO DAGScheduler: running: Set()
16/03/17 15:45:40 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:45:40 INFO DAGScheduler: failed: Set()
16/03/17 15:45:40 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:45:40 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:45:40 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=561418076
16/03/17 15:45:40 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 535.4 MB)
16/03/17 15:45:40 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=561418076
16/03/17 15:45:40 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 535.4 MB)
16/03/17 15:45:40 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9251 ms on localhost (2/2)
16/03/17 15:45:40 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:45:40 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:58297 (size: 3.0 KB, free: 535.4 MB)
16/03/17 15:45:40 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:45:40 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:45:40 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:45:40 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:45:40 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:45:40 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:45:40 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:45:40 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:45:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:45:40 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:45:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
16/03/17 15:45:40 INFO PythonRunner: Times: total = 20, boot = -665, init = 685, finish = 0
16/03/17 15:45:40 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:45:40 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 75 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'planning']
16/03/17 15:45:41 INFO PythonRunner: Times: total = 178, boot = 177, init = 0, finish = 1
16/03/17 15:45:41 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/03/17 15:45:41 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 199 ms on localhost (2/2)
16/03/17 15:45:41 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:45:41 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.200 s
16/03/17 15:45:41 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.489648 s
16/03/17 15:45:41 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:45:41 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:45:41 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:45:41 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:45:41 INFO DAGScheduler: Missing parents: List()
16/03/17 15:45:41 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:45:41 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=561418076
16/03/17 15:45:41 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 535.4 MB)
16/03/17 15:45:41 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=561418076
16/03/17 15:45:41 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 535.4 MB)
16/03/17 15:45:41 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:58297 (size: 3.3 KB, free: 535.4 MB)
16/03/17 15:45:41 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:45:41 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:45:41 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:45:41 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:45:41 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/03/17 15:45:41 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:45:41 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:45:41 INFO PythonRunner: Times: total = 11, boot = 11, init = 0, finish = 0
16/03/17 15:45:41 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/03/17 15:45:41 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 31 ms on localhost (1/2)
16/03/17 15:45:41 INFO PythonRunner: Times: total = 56, boot = -4, init = 60, finish = 0
16/03/17 15:45:41 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:45:41 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 64 ms on localhost (2/2)
16/03/17 15:45:41 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:45:41 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.062 s
16/03/17 15:45:41 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.097167 s
16/03/17 15:45:41 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:45:41 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:45:41 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:45:41 INFO MemoryStore: MemoryStore cleared
16/03/17 15:45:41 INFO BlockManager: BlockManager stopped
16/03/17 15:45:41 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:45:41 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:45:41 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:45:41 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:45:41 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:45:42 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:45:42 INFO SecurityManager: Changing view acls to: root
16/03/17 15:45:42 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:45:42 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:45:42 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:45:42 INFO Remoting: Starting remoting
16/03/17 15:45:42 INFO Utils: Successfully started service 'sparkDriver' on port 50155.
16/03/17 15:45:42 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:50155]
16/03/17 15:45:42 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:45:42 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:45:42 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-bd2748b6-72bb-40dc-a2c3-917aad183f6c
16/03/17 15:45:42 INFO MemoryStore: MemoryStore started with capacity 532.0 MB
16/03/17 15:45:42 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-b333ff15-2406-4722-89ee-ce548f16a278
16/03/17 15:45:42 INFO HttpServer: Starting HTTP Server
16/03/17 15:45:42 INFO Utils: Successfully started service 'HTTP file server' on port 54267.
16/03/17 15:45:42 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:45:42 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:45:42 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:45:42 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-ccbdb8e1-94b3-43bc-9883-1a97c60195ad/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:45:42 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209742537
16/03/17 15:45:42 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:45:42 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:45:42 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34968.
16/03/17 15:45:42 INFO NettyBlockTransferService: Server created on 34968
16/03/17 15:45:42 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:45:42 INFO BlockManagerMasterEndpoint: Registering block manager localhost:34968 with 532.0 MB RAM, BlockManagerId(driver, localhost, 34968)
16/03/17 15:45:42 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:45:42 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:45:42 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:45:42 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:45:42 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:45:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:45:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:45:42 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:45:42 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=557879132
16/03/17 15:45:42 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 532.0 MB)
16/03/17 15:45:42 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=557879132
16/03/17 15:45:42 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 532.0 MB)
16/03/17 15:45:42 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:34968 (size: 4.1 KB, free: 532.0 MB)
16/03/17 15:45:42 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:45:42 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:45:42 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:45:42 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:45:42 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:45:42 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:45:42 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209742537
16/03/17 15:45:42 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:45:42 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-ccbdb8e1-94b3-43bc-9883-1a97c60195ad/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:45:42 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:45:42 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=557879132
16/03/17 15:45:42 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 532.0 MB)
16/03/17 15:45:42 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:45:42 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=557879132
16/03/17 15:45:42 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 532.0 MB)
16/03/17 15:45:42 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:34968 (size: 179.0 B, free: 532.0 MB)
16/03/17 15:45:42 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:34968 (size: 173.0 B, free: 532.0 MB)
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: area
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: bend
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: giant
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: astatine
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: present
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: area
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: issue
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:45:51 INFO PythonRunner: Times: total = 8891, boot = 487, init = 395, finish = 8009
16/03/17 15:45:51 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:45:51 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8956 ms on localhost (1/2)
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: planning
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: permission
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: economy
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: composition
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  whole  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: agency
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): whole
mapFunction_Parents(): keyword: whole ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= whole ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/17 15:45:51 INFO PythonRunner: Times: total = 9159, boot = 480, init = 424, finish = 8255
16/03/17 15:45:51 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:45:51 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9229 ms on localhost (2/2)
16/03/17 15:45:51 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:45:51 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.225 s
16/03/17 15:45:51 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:45:51 INFO DAGScheduler: running: Set()
16/03/17 15:45:51 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:45:51 INFO DAGScheduler: failed: Set()
16/03/17 15:45:51 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:45:51 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:45:51 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=557879132
16/03/17 15:45:51 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 532.0 MB)
16/03/17 15:45:51 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=557879132
16/03/17 15:45:51 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 532.0 MB)
16/03/17 15:45:51 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:34968 (size: 3.0 KB, free: 532.0 MB)
16/03/17 15:45:51 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:45:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:45:51 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:45:51 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:45:51 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:45:51 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:45:51 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:45:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:45:51 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:45:51 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:45:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:45:51 INFO PythonRunner: Times: total = 44, boot = -106, init = 150, finish = 0
16/03/17 15:45:51 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:45:52 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 72 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'composition']
16/03/17 15:45:52 INFO PythonRunner: Times: total = 256, boot = 252, init = 1, finish = 3
16/03/17 15:45:52 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1287 bytes result sent to driver
16/03/17 15:45:52 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 274 ms on localhost (2/2)
16/03/17 15:45:52 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:45:52 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.276 s
16/03/17 15:45:52 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.543164 s
16/03/17 15:45:52 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:45:52 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:45:52 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:45:52 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:45:52 INFO DAGScheduler: Missing parents: List()
16/03/17 15:45:52 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:45:52 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=557879132
16/03/17 15:45:52 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 532.0 MB)
16/03/17 15:45:52 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=557879132
16/03/17 15:45:52 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 532.0 MB)
16/03/17 15:45:52 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:34968 (size: 3.3 KB, free: 532.0 MB)
16/03/17 15:45:52 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:45:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:45:52 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:45:52 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:45:52 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2368 bytes)
16/03/17 15:45:52 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:45:52 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:45:52 INFO PythonRunner: Times: total = 48, boot = 40, init = 8, finish = 0
16/03/17 15:45:52 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:45:52 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 59 ms on localhost (1/2)
16/03/17 15:45:52 INFO PythonRunner: Times: total = 166, boot = 166, init = 0, finish = 0
16/03/17 15:45:52 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1355 bytes result sent to driver
16/03/17 15:45:52 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 180 ms on localhost (2/2)
16/03/17 15:45:52 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:45:52 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.181 s
16/03/17 15:45:52 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.194374 s
16/03/17 15:45:52 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:45:52 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:45:52 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:45:52 INFO MemoryStore: MemoryStore cleared
16/03/17 15:45:52 INFO BlockManager: BlockManager stopped
16/03/17 15:45:52 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:45:52 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:45:52 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:45:52 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:45:52 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:45:52 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:45:53 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:45:53 INFO SecurityManager: Changing view acls to: root
16/03/17 15:45:53 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:45:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:45:53 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:45:53 INFO Remoting: Starting remoting
16/03/17 15:45:53 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:49424]
16/03/17 15:45:53 INFO Utils: Successfully started service 'sparkDriver' on port 49424.
16/03/17 15:45:53 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:45:53 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:45:53 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5a2e7fed-6fec-4680-84aa-d2a21d7c11dd
16/03/17 15:45:53 INFO MemoryStore: MemoryStore started with capacity 532.0 MB
16/03/17 15:45:53 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-1beb2299-f97d-4a1b-a55f-a73b30432326
16/03/17 15:45:53 INFO HttpServer: Starting HTTP Server
16/03/17 15:45:53 INFO Utils: Successfully started service 'HTTP file server' on port 51777.
16/03/17 15:45:53 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:45:53 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:45:53 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:45:53 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-dd9d083f-cb2a-4727-89ac-e3b63713aaad/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:45:53 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209753712
16/03/17 15:45:53 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:45:53 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:45:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54186.
16/03/17 15:45:53 INFO NettyBlockTransferService: Server created on 54186
16/03/17 15:45:53 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:45:53 INFO BlockManagerMasterEndpoint: Registering block manager localhost:54186 with 532.0 MB RAM, BlockManagerId(driver, localhost, 54186)
16/03/17 15:45:53 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:45:53 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:45:53 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:45:53 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:45:53 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:45:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:45:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:45:53 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:45:53 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=557879132
16/03/17 15:45:53 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 532.0 MB)
16/03/17 15:45:53 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=557879132
16/03/17 15:45:53 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 532.0 MB)
16/03/17 15:45:53 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:54186 (size: 4.1 KB, free: 532.0 MB)
16/03/17 15:45:53 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:45:53 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:45:53 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:45:53 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:45:53 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:45:53 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:45:53 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:45:53 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209753712
16/03/17 15:45:53 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-dd9d083f-cb2a-4727-89ac-e3b63713aaad/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:45:53 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:45:53 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10732, maxMem=557879132
16/03/17 15:45:53 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 532.0 MB)
16/03/17 15:45:53 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:45:53 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:54186 (size: 173.0 B, free: 532.0 MB)
16/03/17 15:45:53 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10905, maxMem=557879132
16/03/17 15:45:53 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 532.0 MB)
16/03/17 15:45:53 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:54186 (size: 179.0 B, free: 532.0 MB)
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: set
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: bend
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: giant
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: astatine
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: present
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: area
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: issue
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: planning
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: permission
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: economy
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: composition
16/03/17 15:46:02 INFO PythonRunner: Times: total = 8733, boot = 463, init = 398, finish = 7872
16/03/17 15:46:02 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: agency
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): adding to parents: syn =  Synset('agency.n.02') ; keyword:  businesses  in syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= [u'agency']
reduceFunction_Parents(): returns= ['None', u'agency']
asfer_pickle_string_load(): picklef.readlines(): 16/03/17 15:46:02 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8793 ms on localhost (1/2)
businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'agency']
asfer_pickle_string_load(): picklef.readlines(): businesses
mapFunction_Parents(): keyword: businesses ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= businesses ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'agency']
16/03/17 15:46:02 INFO PythonRunner: Times: total = 8771, boot = 464, init = 390, finish = 7917
16/03/17 15:46:02 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:46:02 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8839 ms on localhost (2/2)
16/03/17 15:46:02 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:46:02 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.841 s
16/03/17 15:46:02 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:46:02 INFO DAGScheduler: running: Set()
16/03/17 15:46:02 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:46:02 INFO DAGScheduler: failed: Set()
16/03/17 15:46:02 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:46:02 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:46:02 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=557879132
16/03/17 15:46:02 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 532.0 MB)
16/03/17 15:46:02 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=557879132
16/03/17 15:46:02 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 532.0 MB)
16/03/17 15:46:02 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:54186 (size: 3.0 KB, free: 532.0 MB)
16/03/17 15:46:02 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:46:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:02 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:46:02 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:46:02 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:46:02 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:46:02 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:46:02 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:46:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:46:02 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:46:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', 'None', u'agency']
16/03/17 15:46:02 INFO PythonRunner: Times: total = 184, boot = 183, init = 0, finish = 1
16/03/17 15:46:02 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1282 bytes result sent to driver
16/03/17 15:46:02 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 198 ms on localhost (1/2)
16/03/17 15:46:02 INFO PythonRunner: Times: total = 209, boot = 208, init = 0, finish = 1
16/03/17 15:46:02 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:46:02 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.226 s
16/03/17 15:46:02 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.098164 s
16/03/17 15:46:02 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 224 ms on localhost (2/2)
16/03/17 15:46:02 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:46:03 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:46:03 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:46:03 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:03 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:46:03 INFO DAGScheduler: Missing parents: List()
16/03/17 15:46:03 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:46:03 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=557879132
16/03/17 15:46:03 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 532.0 MB)
16/03/17 15:46:03 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=557879132
16/03/17 15:46:03 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 532.0 MB)
16/03/17 15:46:03 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:54186 (size: 3.3 KB, free: 532.0 MB)
16/03/17 15:46:03 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:46:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:03 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:46:03 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:46:03 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2363 bytes)
16/03/17 15:46:03 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:46:03 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:46:03 INFO PythonRunner: Times: total = 118, boot = 118, init = 0, finish = 0
16/03/17 15:46:03 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:46:03 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 124 ms on localhost (1/2)
16/03/17 15:46:03 INFO PythonRunner: Times: total = 118, boot = 117, init = 1, finish = 0
16/03/17 15:46:03 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1350 bytes result sent to driver
16/03/17 15:46:03 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 129 ms on localhost (2/2)
16/03/17 15:46:03 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:46:03 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.129 s
16/03/17 15:46:03 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.145222 s
16/03/17 15:46:03 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:46:03 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:46:03 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:46:03 INFO MemoryStore: MemoryStore cleared
16/03/17 15:46:03 INFO BlockManager: BlockManager stopped
16/03/17 15:46:03 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:46:03 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:46:03 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:46:03 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:46:03 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:46:03 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:46:04 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:46:04 INFO SecurityManager: Changing view acls to: root
16/03/17 15:46:04 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:46:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:46:04 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:46:04 INFO Remoting: Starting remoting
16/03/17 15:46:04 INFO Utils: Successfully started service 'sparkDriver' on port 56249.
16/03/17 15:46:04 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:56249]
16/03/17 15:46:04 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:46:04 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:46:04 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2cd5b523-57db-4ef1-827f-bb5a3e6f0d40
16/03/17 15:46:04 INFO MemoryStore: MemoryStore started with capacity 532.0 MB
16/03/17 15:46:04 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-c5c9f74e-229b-405d-b979-bc7566f1c867
16/03/17 15:46:04 INFO HttpServer: Starting HTTP Server
16/03/17 15:46:04 INFO Utils: Successfully started service 'HTTP file server' on port 55675.
16/03/17 15:46:04 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:46:04 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:46:04 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:46:04 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-10711e12-6622-4781-80d1-866d2c5f61f8/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:46:04 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209764441
16/03/17 15:46:04 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:46:04 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:46:04 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46776.
16/03/17 15:46:04 INFO NettyBlockTransferService: Server created on 46776
16/03/17 15:46:04 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:46:04 INFO BlockManagerMasterEndpoint: Registering block manager localhost:46776 with 532.0 MB RAM, BlockManagerId(driver, localhost, 46776)
16/03/17 15:46:04 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:46:04 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:46:04 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:04 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:46:04 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:46:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:46:04 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:46:04 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=557879132
16/03/17 15:46:04 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 532.0 MB)
16/03/17 15:46:04 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=557879132
16/03/17 15:46:04 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 532.0 MB)
16/03/17 15:46:04 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:46776 (size: 4.1 KB, free: 532.0 MB)
16/03/17 15:46:04 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:46:04 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:04 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:46:04 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:46:04 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:46:04 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:46:04 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209764441
16/03/17 15:46:04 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:46:04 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-10711e12-6622-4781-80d1-866d2c5f61f8/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:46:04 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:46:04 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=557879132
16/03/17 15:46:04 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 532.0 MB)
16/03/17 15:46:04 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:46776 (size: 179.0 B, free: 532.0 MB)
16/03/17 15:46:04 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:46:04 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=557879132
16/03/17 15:46:04 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 532.0 MB)
16/03/17 15:46:04 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:46776 (size: 173.0 B, free: 532.0 MB)
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: area
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): adding to parents: syn =  Synset('kilometer.n.01') ; keyword:  1000  in syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= [u'kilometer']
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: planning
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: permission
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: economy
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: composition
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: agency
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): adding to parents: syn =  Synset('kilometer.n.01') ; keyword:  1000  in syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= [u'kilometer']
reduceFunction_Parents(): returns= [u'kilometer', u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer', u'kilometer']
16/03/17 15:46:13 INFO PythonRunner: Times: total = 8345, boot = 466, init = 409, finish = 7470
16/03/17 15:46:13 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:46:13 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8420 ms on localhost (1/2)
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: bend
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: giant
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: astatine
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: present
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: area
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): 1000
mapFunction_Parents(): keyword: 1000 ; prevleveltokens: issue
mapFunction_Parents(): keyword= 1000 ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:46:13 INFO PythonRunner: Times: total = 8919, boot = 467, init = 375, finish = 8077
16/03/17 15:46:13 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:46:13 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.982 s
16/03/17 15:46:13 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8996 ms on localhost (2/2)
16/03/17 15:46:13 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:46:13 INFO DAGScheduler: running: Set()
16/03/17 15:46:13 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:46:13 INFO DAGScheduler: failed: Set()
16/03/17 15:46:13 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:46:13 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:46:13 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:46:13 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=557879132
16/03/17 15:46:13 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 532.0 MB)
16/03/17 15:46:13 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=557879132
16/03/17 15:46:13 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 532.0 MB)
16/03/17 15:46:13 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:46776 (size: 3.0 KB, free: 532.0 MB)
16/03/17 15:46:13 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:46:13 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:13 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:46:13 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:46:13 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:46:13 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:46:13 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:46:13 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:46:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:46:13 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:46:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:46:13 INFO PythonRunner: Times: total = 20, boot = -395, init = 415, finish = 0
16/03/17 15:46:13 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:46:13 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 53 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'kilometer', u'kilometer']
16/03/17 15:46:13 INFO PythonRunner: Times: total = 223, boot = 223, init = 0, finish = 0
16/03/17 15:46:13 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1279 bytes result sent to driver
16/03/17 15:46:13 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.230 s
16/03/17 15:46:13 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.255256 s
16/03/17 15:46:13 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 238 ms on localhost (2/2)
16/03/17 15:46:13 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:46:13 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:46:13 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:46:13 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:13 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:46:13 INFO DAGScheduler: Missing parents: List()
16/03/17 15:46:13 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:46:13 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=557879132
16/03/17 15:46:13 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 532.0 MB)
16/03/17 15:46:13 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=557879132
16/03/17 15:46:13 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 532.0 MB)
16/03/17 15:46:13 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:46776 (size: 3.3 KB, free: 532.0 MB)
16/03/17 15:46:13 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:46:13 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:13 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:46:13 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:46:13 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2360 bytes)
16/03/17 15:46:13 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:46:13 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:46:13 INFO PythonRunner: Times: total = 45, boot = -119, init = 164, finish = 0
16/03/17 15:46:13 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:46:13 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 56 ms on localhost (1/2)
16/03/17 15:46:14 INFO PythonRunner: Times: total = 148, boot = 147, init = 1, finish = 0
16/03/17 15:46:14 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1358 bytes result sent to driver
16/03/17 15:46:14 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 162 ms on localhost (2/2)
16/03/17 15:46:14 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:46:14 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.152 s
16/03/17 15:46:14 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.173442 s
16/03/17 15:46:14 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:46:14 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:46:14 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:46:14 INFO MemoryStore: MemoryStore cleared
16/03/17 15:46:14 INFO BlockManager: BlockManager stopped
16/03/17 15:46:14 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:46:14 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:46:14 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:46:14 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:46:14 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:46:14 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:46:15 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:46:15 INFO SecurityManager: Changing view acls to: root
16/03/17 15:46:15 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:46:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:46:15 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:46:15 INFO Remoting: Starting remoting
16/03/17 15:46:15 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:51527]
16/03/17 15:46:15 INFO Utils: Successfully started service 'sparkDriver' on port 51527.
16/03/17 15:46:15 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:46:15 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:46:15 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7474d39a-b628-4ce2-88ae-816386a32a0b
16/03/17 15:46:15 INFO MemoryStore: MemoryStore started with capacity 532.0 MB
16/03/17 15:46:15 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-0ab9394e-05e5-4354-9093-90c31e53f667
16/03/17 15:46:15 INFO HttpServer: Starting HTTP Server
16/03/17 15:46:15 INFO Utils: Successfully started service 'HTTP file server' on port 51713.
16/03/17 15:46:15 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:46:15 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:46:15 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:46:15 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-cad46241-58ed-4ad5-8b17-7a04f0bed227/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:46:15 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209775284
16/03/17 15:46:15 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:46:15 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:46:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35317.
16/03/17 15:46:15 INFO NettyBlockTransferService: Server created on 35317
16/03/17 15:46:15 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:46:15 INFO BlockManagerMasterEndpoint: Registering block manager localhost:35317 with 532.0 MB RAM, BlockManagerId(driver, localhost, 35317)
16/03/17 15:46:15 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:46:15 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:46:15 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:15 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:46:15 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:46:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:46:15 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:46:15 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=557879132
16/03/17 15:46:15 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 532.0 MB)
16/03/17 15:46:15 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=557879132
16/03/17 15:46:15 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 532.0 MB)
16/03/17 15:46:15 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:35317 (size: 4.1 KB, free: 532.0 MB)
16/03/17 15:46:15 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:46:15 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:15 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:46:15 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:46:15 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:46:15 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:46:15 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209775284
16/03/17 15:46:15 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:46:15 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-cad46241-58ed-4ad5-8b17-7a04f0bed227/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:46:15 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:46:15 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=557879132
16/03/17 15:46:15 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 532.0 MB)
16/03/17 15:46:15 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:46:15 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:35317 (size: 179.0 B, free: 532.0 MB)
16/03/17 15:46:15 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=557879132
16/03/17 15:46:15 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 532.0 MB)
16/03/17 15:46:15 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:35317 (size: 173.0 B, free: 532.0 MB)
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: set
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: planning
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: permission
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: economy
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: composition
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: agency
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  formerly  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/17 15:46:23 INFO PythonRunner: Times: total = 8353, boot = 491, init = 397, finish = 7465
16/03/17 15:46:23 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:46:23 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8412 ms on localhost (1/2)
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: bend
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: giant
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: astatine
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: present
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  formerly  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: area
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): formerly
mapFunction_Parents(): keyword: formerly ; prevleveltokens: issue
mapFunction_Parents(): keyword= formerly ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/17 15:46:24 INFO PythonRunner: Times: total = 8860, boot = 500, init = 460, finish = 7900
16/03/17 15:46:24 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:46:24 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.920 s
16/03/17 15:46:24 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8918 ms on localhost (2/2)
16/03/17 15:46:24 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:46:24 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:46:24 INFO DAGScheduler: running: Set()
16/03/17 15:46:24 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:46:24 INFO DAGScheduler: failed: Set()
16/03/17 15:46:24 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:46:24 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:46:24 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=557879132
16/03/17 15:46:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 532.0 MB)
16/03/17 15:46:24 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=557879132
16/03/17 15:46:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 532.0 MB)
16/03/17 15:46:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:35317 (size: 3.0 KB, free: 532.0 MB)
16/03/17 15:46:24 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:46:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:24 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:46:24 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:46:24 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:46:24 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:46:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:46:24 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:46:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:46:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:46:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
reduceFunction_Parents(): returns= ['None', u'Chennai', 'None', u'Chennai']
16/03/17 15:46:24 INFO PythonRunner: Times: total = 24, boot = -339, init = 362, finish = 1
16/03/17 15:46:24 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1297 bytes result sent to driver
16/03/17 15:46:24 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 55 ms on localhost (1/2)
16/03/17 15:46:24 INFO PythonRunner: Times: total = 201, boot = 200, init = 1, finish = 0
16/03/17 15:46:24 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:46:24 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 228 ms on localhost (2/2)
16/03/17 15:46:24 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:46:24 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.212 s
16/03/17 15:46:24 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.165501 s
16/03/17 15:46:24 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:46:24 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:46:24 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:24 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:46:24 INFO DAGScheduler: Missing parents: List()
16/03/17 15:46:24 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:46:24 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=557879132
16/03/17 15:46:24 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 532.0 MB)
16/03/17 15:46:24 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=557879132
16/03/17 15:46:24 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 532.0 MB)
16/03/17 15:46:24 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:35317 (size: 3.3 KB, free: 532.0 MB)
16/03/17 15:46:24 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:46:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:24 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:46:24 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:46:24 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2378 bytes)
16/03/17 15:46:24 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:46:24 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:46:24 INFO PythonRunner: Times: total = 50, boot = -103, init = 153, finish = 0
16/03/17 15:46:24 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:46:24 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 60 ms on localhost (1/2)
16/03/17 15:46:24 INFO PythonRunner: Times: total = 87, boot = 87, init = 0, finish = 0
16/03/17 15:46:24 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1365 bytes result sent to driver
16/03/17 15:46:24 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 100 ms on localhost (2/2)
16/03/17 15:46:24 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:46:24 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.091 s
16/03/17 15:46:24 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.115773 s
16/03/17 15:46:24 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:46:24 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:46:24 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:46:24 INFO MemoryStore: MemoryStore cleared
16/03/17 15:46:24 INFO BlockManager: BlockManager stopped
16/03/17 15:46:24 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:46:24 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:46:24 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:46:24 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:46:24 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:46:25 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:46:25 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:46:25 INFO SecurityManager: Changing view acls to: root
16/03/17 15:46:25 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:46:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:46:25 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:46:25 INFO Remoting: Starting remoting
16/03/17 15:46:25 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:50873]
16/03/17 15:46:25 INFO Utils: Successfully started service 'sparkDriver' on port 50873.
16/03/17 15:46:25 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:46:25 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:46:25 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1225863b-334d-40bf-9f9c-d9609d3f3e22
16/03/17 15:46:25 INFO MemoryStore: MemoryStore started with capacity 534.9 MB
16/03/17 15:46:25 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-fd6f122b-6180-40b3-8894-3ed83336a1c1
16/03/17 15:46:25 INFO HttpServer: Starting HTTP Server
16/03/17 15:46:25 INFO Utils: Successfully started service 'HTTP file server' on port 35554.
16/03/17 15:46:25 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:46:25 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:46:25 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:46:25 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-f9bbee07-7caa-400a-bd29-528c34d7be77/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:46:25 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209785966
16/03/17 15:46:25 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:46:25 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:46:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38254.
16/03/17 15:46:26 INFO NettyBlockTransferService: Server created on 38254
16/03/17 15:46:26 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:46:26 INFO BlockManagerMasterEndpoint: Registering block manager localhost:38254 with 534.9 MB RAM, BlockManagerId(driver, localhost, 38254)
16/03/17 15:46:26 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:46:26 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:46:26 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:26 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:46:26 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:46:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:46:26 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:46:26 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=560851845
16/03/17 15:46:26 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 534.9 MB)
16/03/17 15:46:26 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=560851845
16/03/17 15:46:26 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 534.9 MB)
16/03/17 15:46:26 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:38254 (size: 4.1 KB, free: 534.9 MB)
16/03/17 15:46:26 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:46:26 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:26 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:46:26 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:46:26 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:46:26 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:46:26 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209785966
16/03/17 15:46:26 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:46:26 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-f9bbee07-7caa-400a-bd29-528c34d7be77/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:46:26 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:46:26 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:46:26 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10732, maxMem=560851845
16/03/17 15:46:26 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 534.9 MB)
16/03/17 15:46:26 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10905, maxMem=560851845
16/03/17 15:46:26 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 534.9 MB)
16/03/17 15:46:26 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:38254 (size: 173.0 B, free: 534.9 MB)
16/03/17 15:46:26 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:38254 (size: 179.0 B, free: 534.9 MB)
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: set
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: planning
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: permission
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: economy
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: composition
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: agency
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:46:34 INFO PythonRunner: Times: total = 8413, boot = 475, init = 430, finish = 7508
16/03/17 15:46:34 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:46:34 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8482 ms on localhost (1/2)
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: bend
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: giant
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: astatine
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: present
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  period  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: area
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): period
mapFunction_Parents(): keyword: period ; prevleveltokens: issue
mapFunction_Parents(): keyword= period ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/17 15:46:34 INFO PythonRunner: Times: total = 8679, boot = 496, init = 421, finish = 7762
16/03/17 15:46:34 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:46:34 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8737 ms on localhost (2/2)
16/03/17 15:46:34 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:46:34 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.744 s
16/03/17 15:46:34 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:46:34 INFO DAGScheduler: running: Set()
16/03/17 15:46:34 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:46:34 INFO DAGScheduler: failed: Set()
16/03/17 15:46:34 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:46:34 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:46:34 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=560851845
16/03/17 15:46:34 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 534.9 MB)
16/03/17 15:46:34 INFO MemoryStore: ensureFreeSpace(3054) called with curMem=16068, maxMem=560851845
16/03/17 15:46:34 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 534.9 MB)
16/03/17 15:46:34 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:38254 (size: 3.0 KB, free: 534.9 MB)
16/03/17 15:46:34 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:46:34 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:34 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:46:34 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:46:34 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:46:34 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:46:34 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:46:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:46:34 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:46:34 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:46:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'present', 'None']
16/03/17 15:46:34 INFO PythonRunner: Times: total = 46, boot = -94, init = 140, finish = 0
16/03/17 15:46:34 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/17 15:46:34 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 87 ms on localhost (1/2)
16/03/17 15:46:35 INFO PythonRunner: Times: total = 221, boot = 220, init = 0, finish = 1
16/03/17 15:46:35 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:46:35 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 245 ms on localhost (2/2)
16/03/17 15:46:35 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:46:35 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.223 s
16/03/17 15:46:35 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.012333 s
16/03/17 15:46:35 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:46:35 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:46:35 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:35 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:46:35 INFO DAGScheduler: Missing parents: List()
16/03/17 15:46:35 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:46:35 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19122, maxMem=560851845
16/03/17 15:46:35 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 534.8 MB)
16/03/17 15:46:35 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24938, maxMem=560851845
16/03/17 15:46:35 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 534.8 MB)
16/03/17 15:46:35 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:38254 (size: 3.3 KB, free: 534.9 MB)
16/03/17 15:46:35 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:46:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:35 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:46:35 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:46:35 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/17 15:46:35 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:46:35 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:46:35 INFO PythonRunner: Times: total = 52, boot = -79, init = 131, finish = 0
16/03/17 15:46:35 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:46:35 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 61 ms on localhost (1/2)
16/03/17 15:46:35 INFO PythonRunner: Times: total = 136, boot = 136, init = 0, finish = 0
16/03/17 15:46:35 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1351 bytes result sent to driver
16/03/17 15:46:35 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 149 ms on localhost (2/2)
16/03/17 15:46:35 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:46:35 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.139 s
16/03/17 15:46:35 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.168908 s
16/03/17 15:46:35 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:46:35 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:46:35 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:46:35 INFO MemoryStore: MemoryStore cleared
16/03/17 15:46:35 INFO BlockManager: BlockManager stopped
16/03/17 15:46:35 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:46:35 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:46:35 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:46:35 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:46:35 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:46:35 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:46:36 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:46:36 INFO SecurityManager: Changing view acls to: root
16/03/17 15:46:36 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:46:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:46:36 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:46:36 INFO Remoting: Starting remoting
16/03/17 15:46:36 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:50091]
16/03/17 15:46:36 INFO Utils: Successfully started service 'sparkDriver' on port 50091.
16/03/17 15:46:36 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:46:36 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:46:36 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-69ece593-998d-43e1-b42c-b6edd17d958d
16/03/17 15:46:36 INFO MemoryStore: MemoryStore started with capacity 534.9 MB
16/03/17 15:46:36 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-bf6aca20-df37-458f-a547-3866a7da3e87
16/03/17 15:46:36 INFO HttpServer: Starting HTTP Server
16/03/17 15:46:36 INFO Utils: Successfully started service 'HTTP file server' on port 53088.
16/03/17 15:46:36 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:46:36 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:46:36 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:46:36 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-e658dcd9-0cd6-4a5b-8bba-5ec3fc9c6289/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:46:36 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209796527
16/03/17 15:46:36 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:46:36 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:46:36 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50007.
16/03/17 15:46:36 INFO NettyBlockTransferService: Server created on 50007
16/03/17 15:46:36 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:46:36 INFO BlockManagerMasterEndpoint: Registering block manager localhost:50007 with 534.9 MB RAM, BlockManagerId(driver, localhost, 50007)
16/03/17 15:46:36 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:46:36 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:46:36 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:36 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:46:36 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:46:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:46:36 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:46:36 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=560851845
16/03/17 15:46:36 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 534.9 MB)
16/03/17 15:46:36 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=560851845
16/03/17 15:46:36 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 534.9 MB)
16/03/17 15:46:36 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:50007 (size: 4.1 KB, free: 534.9 MB)
16/03/17 15:46:36 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:46:36 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:36 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:46:36 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:46:36 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:46:36 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:46:36 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209796527
16/03/17 15:46:36 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:46:36 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-e658dcd9-0cd6-4a5b-8bba-5ec3fc9c6289/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:46:36 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:46:36 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=560851845
16/03/17 15:46:36 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 534.9 MB)
16/03/17 15:46:36 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:50007 (size: 179.0 B, free: 534.9 MB)
16/03/17 15:46:36 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:46:36 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=560851845
16/03/17 15:46:36 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 534.9 MB)
16/03/17 15:46:36 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:50007 (size: 173.0 B, free: 534.9 MB)
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: set
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: planning
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: permission
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: economy
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: composition
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: agency
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:46:45 INFO PythonRunner: Times: total = 8731, boot = 634, init = 482, finish = 7615
16/03/17 15:46:45 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:46:45 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8797 ms on localhost (1/2)
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: bend
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: giant
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: astatine
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  highly  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: present
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: area
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): highly
mapFunction_Parents(): keyword: highly ; prevleveltokens: issue
mapFunction_Parents(): keyword= highly ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/17 15:46:45 INFO PythonRunner: Times: total = 8977, boot = 651, init = 467, finish = 7859
16/03/17 15:46:45 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:46:45 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.053 s
16/03/17 15:46:45 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:46:45 INFO DAGScheduler: running: Set()
16/03/17 15:46:45 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:46:45 INFO DAGScheduler: failed: Set()
16/03/17 15:46:45 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:46:45 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:46:45 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=560851845
16/03/17 15:46:45 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 534.9 MB)
16/03/17 15:46:45 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9050 ms on localhost (2/2)
16/03/17 15:46:45 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:46:45 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=560851845
16/03/17 15:46:45 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 534.9 MB)
16/03/17 15:46:45 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:50007 (size: 3.0 KB, free: 534.9 MB)
16/03/17 15:46:45 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:46:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:45 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:46:45 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:46:45 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:46:45 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:46:45 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:46:45 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:46:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:46:45 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:46:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:46:45 INFO PythonRunner: Times: total = 38, boot = -93, init = 131, finish = 0
16/03/17 15:46:45 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:46:45 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 81 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'astatine', 'None']
16/03/17 15:46:46 INFO PythonRunner: Times: total = 266, boot = 265, init = 0, finish = 1
16/03/17 15:46:46 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/03/17 15:46:46 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 275 ms on localhost (2/2)
16/03/17 15:46:46 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:46:46 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.275 s
16/03/17 15:46:46 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.360666 s
16/03/17 15:46:46 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:46:46 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:46:46 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:46 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:46:46 INFO DAGScheduler: Missing parents: List()
16/03/17 15:46:46 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:46:46 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=560851845
16/03/17 15:46:46 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 534.8 MB)
16/03/17 15:46:46 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=560851845
16/03/17 15:46:46 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 534.8 MB)
16/03/17 15:46:46 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:50007 (size: 3.3 KB, free: 534.9 MB)
16/03/17 15:46:46 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:46:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:46 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:46:46 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:46:46 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/03/17 15:46:46 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:46:46 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:46:46 INFO PythonRunner: Times: total = 57, boot = -102, init = 159, finish = 0
16/03/17 15:46:46 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:46:46 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 69 ms on localhost (1/2)
16/03/17 15:46:46 INFO PythonRunner: Times: total = 177, boot = 177, init = 0, finish = 0
16/03/17 15:46:46 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/03/17 15:46:46 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 190 ms on localhost (2/2)
16/03/17 15:46:46 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:46:46 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.179 s
16/03/17 15:46:46 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.209381 s
16/03/17 15:46:46 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:46:46 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:46:46 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:46:46 INFO MemoryStore: MemoryStore cleared
16/03/17 15:46:46 INFO BlockManager: BlockManager stopped
16/03/17 15:46:46 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:46:46 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:46:46 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:46:46 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:46:46 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:46:46 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:46:47 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:46:47 INFO SecurityManager: Changing view acls to: root
16/03/17 15:46:47 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:46:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:46:47 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:46:47 INFO Remoting: Starting remoting
16/03/17 15:46:47 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:48030]
16/03/17 15:46:47 INFO Utils: Successfully started service 'sparkDriver' on port 48030.
16/03/17 15:46:47 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:46:47 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:46:47 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-40be3103-5f5c-4836-81cb-5f3fe909f942
16/03/17 15:46:47 INFO MemoryStore: MemoryStore started with capacity 534.9 MB
16/03/17 15:46:47 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-56257945-7a03-4d87-a06f-5f8b723d3885
16/03/17 15:46:47 INFO HttpServer: Starting HTTP Server
16/03/17 15:46:47 INFO Utils: Successfully started service 'HTTP file server' on port 57552.
16/03/17 15:46:47 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:46:47 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:46:47 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:46:47 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-73967787-d27e-4373-8803-33a5194eaded/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:46:47 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209807471
16/03/17 15:46:47 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:46:47 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:46:47 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53546.
16/03/17 15:46:47 INFO NettyBlockTransferService: Server created on 53546
16/03/17 15:46:47 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:46:47 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53546 with 534.9 MB RAM, BlockManagerId(driver, localhost, 53546)
16/03/17 15:46:47 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:46:47 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:46:47 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:47 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:46:47 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:46:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:46:47 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:46:47 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=560851845
16/03/17 15:46:47 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 534.9 MB)
16/03/17 15:46:47 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=560851845
16/03/17 15:46:47 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 534.9 MB)
16/03/17 15:46:47 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53546 (size: 4.1 KB, free: 534.9 MB)
16/03/17 15:46:47 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:46:47 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:47 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:46:47 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:46:47 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:46:47 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:46:47 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209807471
16/03/17 15:46:47 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:46:47 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-73967787-d27e-4373-8803-33a5194eaded/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:46:47 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:46:47 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:46:47 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=560851845
16/03/17 15:46:47 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 534.9 MB)
16/03/17 15:46:47 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=560851845
16/03/17 15:46:47 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:53546 (size: 179.0 B, free: 534.9 MB)
16/03/17 15:46:47 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 534.9 MB)
16/03/17 15:46:47 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:53546 (size: 173.0 B, free: 534.9 MB)
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: area
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: bend
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: giant
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: astatine
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: present
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: area
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: issue
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:46:56 INFO PythonRunner: Times: total = 8510, boot = 458, init = 442, finish = 7610
16/03/17 15:46:56 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:46:56 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8578 ms on localhost (1/2)
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: planning
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: permission
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: economy
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): adding to parents: syn =  Synset('economy.n.01') ; keyword:  production  in syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= [u'economy']
reduceFunction_Parents(): returns= ['None', u'economy']
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: composition
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'economy']
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: agency
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'economy']
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'economy']
asfer_pickle_string_load(): picklef.readlines(): production
mapFunction_Parents(): keyword: production ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= production ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'economy']
16/03/17 15:46:56 INFO PythonRunner: Times: total = 9139, boot = 460, init = 523, finish = 8156
16/03/17 15:46:56 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:46:56 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.199 s
16/03/17 15:46:56 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:46:56 INFO DAGScheduler: running: Set()
16/03/17 15:46:56 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:46:56 INFO DAGScheduler: failed: Set()
16/03/17 15:46:56 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:46:56 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:46:56 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=560851845
16/03/17 15:46:56 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 534.9 MB)
16/03/17 15:46:56 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=560851845
16/03/17 15:46:56 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 534.9 MB)
16/03/17 15:46:56 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9195 ms on localhost (2/2)
16/03/17 15:46:56 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53546 (size: 3.0 KB, free: 534.9 MB)
16/03/17 15:46:56 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:46:56 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:56 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:46:56 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:46:56 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:46:56 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:46:56 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:46:56 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:46:56 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:46:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:46:56 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:46:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:46:56 INFO PythonRunner: Times: total = 24, boot = -428, init = 452, finish = 0
16/03/17 15:46:56 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:46:56 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 62 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'economy']
16/03/17 15:46:57 INFO PythonRunner: Times: total = 230, boot = 229, init = 1, finish = 0
16/03/17 15:46:57 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/17 15:46:57 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.238 s
16/03/17 15:46:57 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.473488 s
16/03/17 15:46:57 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 249 ms on localhost (2/2)
16/03/17 15:46:57 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:46:57 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:46:57 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:46:57 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:57 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:46:57 INFO DAGScheduler: Missing parents: List()
16/03/17 15:46:57 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:46:57 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=560851845
16/03/17 15:46:57 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 534.8 MB)
16/03/17 15:46:57 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=560851845
16/03/17 15:46:57 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 534.8 MB)
16/03/17 15:46:57 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53546 (size: 3.3 KB, free: 534.9 MB)
16/03/17 15:46:57 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:46:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:57 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:46:57 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:46:57 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/17 15:46:57 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:46:57 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:46:57 INFO PythonRunner: Times: total = 46, boot = -77, init = 123, finish = 0
16/03/17 15:46:57 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1351 bytes result sent to driver
16/03/17 15:46:57 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 56 ms on localhost (1/2)
16/03/17 15:46:57 INFO PythonRunner: Times: total = 109, boot = 109, init = 0, finish = 0
16/03/17 15:46:57 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:46:57 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 115 ms on localhost (2/2)
16/03/17 15:46:57 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:46:57 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.118 s
16/03/17 15:46:57 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.127025 s
16/03/17 15:46:57 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:46:57 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:46:57 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:46:57 INFO MemoryStore: MemoryStore cleared
16/03/17 15:46:57 INFO BlockManager: BlockManager stopped
16/03/17 15:46:57 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:46:57 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:46:57 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:46:57 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:46:57 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:46:57 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:46:58 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:46:58 INFO SecurityManager: Changing view acls to: root
16/03/17 15:46:58 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:46:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:46:58 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:46:58 INFO Remoting: Starting remoting
16/03/17 15:46:58 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:41068]
16/03/17 15:46:58 INFO Utils: Successfully started service 'sparkDriver' on port 41068.
16/03/17 15:46:58 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:46:58 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:46:58 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e7f8f391-0ce8-4e3a-9257-a70bb2e0d7ce
16/03/17 15:46:58 INFO MemoryStore: MemoryStore started with capacity 534.9 MB
16/03/17 15:46:58 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-24a2a5ff-125c-48d8-a3e1-5191c157a2f3
16/03/17 15:46:58 INFO HttpServer: Starting HTTP Server
16/03/17 15:46:58 INFO Utils: Successfully started service 'HTTP file server' on port 57288.
16/03/17 15:46:58 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:46:58 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:46:58 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:46:58 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-ad4351a1-f6af-432d-9148-ef4d9a33a7fc/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:46:58 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209818477
16/03/17 15:46:58 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:46:58 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:46:58 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34981.
16/03/17 15:46:58 INFO NettyBlockTransferService: Server created on 34981
16/03/17 15:46:58 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:46:58 INFO BlockManagerMasterEndpoint: Registering block manager localhost:34981 with 534.9 MB RAM, BlockManagerId(driver, localhost, 34981)
16/03/17 15:46:58 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:46:58 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:46:58 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:58 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:46:58 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:46:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:46:58 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:46:58 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=560851845
16/03/17 15:46:58 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 534.9 MB)
16/03/17 15:46:58 INFO MemoryStore: ensureFreeSpace(4165) called with curMem=6576, maxMem=560851845
16/03/17 15:46:58 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 534.9 MB)
16/03/17 15:46:58 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:34981 (size: 4.1 KB, free: 534.9 MB)
16/03/17 15:46:58 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:46:58 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:46:58 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:46:58 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:46:58 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:46:58 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:46:58 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209818477
16/03/17 15:46:58 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:46:58 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-ad4351a1-f6af-432d-9148-ef4d9a33a7fc/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:46:58 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:46:58 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:46:58 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10741, maxMem=560851845
16/03/17 15:46:58 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 534.9 MB)
16/03/17 15:46:58 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:34981 (size: 173.0 B, free: 534.9 MB)
16/03/17 15:46:58 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10914, maxMem=560851845
16/03/17 15:46:58 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 534.9 MB)
16/03/17 15:46:58 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:34981 (size: 179.0 B, free: 534.9 MB)
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: set
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  indefinite  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: planning
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: permission
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: economy
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: composition
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: agency
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/17 15:47:07 INFO PythonRunner: Times: total = 8433, boot = 471, init = 371, finish = 7591
16/03/17 15:47:07 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:47:07 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8496 ms on localhost (1/2)
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: bend
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: giant
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: astatine
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: present
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: area
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  indefinite  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): indefinite
mapFunction_Parents(): keyword: indefinite ; prevleveltokens: issue
mapFunction_Parents(): keyword= indefinite ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/17 15:47:07 INFO PythonRunner: Times: total = 8871, boot = 464, init = 414, finish = 7993
16/03/17 15:47:07 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:47:07 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.927 s
16/03/17 15:47:07 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:47:07 INFO DAGScheduler: running: Set()
16/03/17 15:47:07 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:47:07 INFO DAGScheduler: failed: Set()
16/03/17 15:47:07 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:47:07 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:47:07 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11093, maxMem=560851845
16/03/17 15:47:07 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 534.9 MB)
16/03/17 15:47:07 INFO MemoryStore: ensureFreeSpace(3064) called with curMem=16077, maxMem=560851845
16/03/17 15:47:07 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 534.9 MB)
16/03/17 15:47:07 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8924 ms on localhost (2/2)
16/03/17 15:47:07 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:47:07 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:34981 (size: 3.0 KB, free: 534.9 MB)
16/03/17 15:47:07 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:47:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:47:07 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:47:07 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:47:07 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:47:07 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:47:07 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:47:07 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:47:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:47:07 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:47:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:47:07 INFO PythonRunner: Times: total = 28, boot = -258, init = 286, finish = 0
16/03/17 15:47:07 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:47:07 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 38 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'area', u'area']
16/03/17 15:47:07 INFO PythonRunner: Times: total = 208, boot = 207, init = 1, finish = 0
16/03/17 15:47:07 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/17 15:47:07 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.212 s
16/03/17 15:47:07 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.168109 s
16/03/17 15:47:07 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 222 ms on localhost (2/2)
16/03/17 15:47:07 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:47:07 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:47:07 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:47:07 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:47:07 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:47:07 INFO DAGScheduler: Missing parents: List()
16/03/17 15:47:07 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:47:07 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19141, maxMem=560851845
16/03/17 15:47:07 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 534.8 MB)
16/03/17 15:47:07 INFO MemoryStore: ensureFreeSpace(3379) called with curMem=24957, maxMem=560851845
16/03/17 15:47:07 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 534.8 MB)
16/03/17 15:47:07 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:34981 (size: 3.3 KB, free: 534.9 MB)
16/03/17 15:47:07 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:47:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:47:07 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:47:07 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:47:07 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/17 15:47:07 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:47:07 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:47:07 INFO PythonRunner: Times: total = 51, boot = -111, init = 162, finish = 0
16/03/17 15:47:07 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:47:07 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 58 ms on localhost (1/2)
16/03/17 15:47:07 INFO PythonRunner: Times: total = 106, boot = 106, init = 0, finish = 0
16/03/17 15:47:07 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/03/17 15:47:08 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 118 ms on localhost (2/2)
16/03/17 15:47:08 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:47:08 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.107 s
16/03/17 15:47:08 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.128705 s
16/03/17 15:47:08 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:47:08 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:47:08 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:47:08 INFO MemoryStore: MemoryStore cleared
16/03/17 15:47:08 INFO BlockManager: BlockManager stopped
16/03/17 15:47:08 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:47:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:47:08 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:47:08 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:47:08 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:47:08 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:47:09 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:47:09 INFO SecurityManager: Changing view acls to: root
16/03/17 15:47:09 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:47:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:47:09 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:47:09 INFO Remoting: Starting remoting
16/03/17 15:47:09 INFO Utils: Successfully started service 'sparkDriver' on port 44201.
16/03/17 15:47:09 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:44201]
16/03/17 15:47:09 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:47:09 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:47:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-987f4bf4-5ff9-407a-a223-13a0218d1202
16/03/17 15:47:09 INFO MemoryStore: MemoryStore started with capacity 534.9 MB
16/03/17 15:47:09 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-f261db7d-0a64-4e69-b0d3-b3dc4923d09d
16/03/17 15:47:09 INFO HttpServer: Starting HTTP Server
16/03/17 15:47:09 INFO Utils: Successfully started service 'HTTP file server' on port 35048.
16/03/17 15:47:09 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:47:09 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:47:09 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:47:09 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-27c9686b-c93c-4922-8199-e34ebebfd965/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:47:09 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209829324
16/03/17 15:47:09 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:47:09 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:47:09 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43769.
16/03/17 15:47:09 INFO NettyBlockTransferService: Server created on 43769
16/03/17 15:47:09 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:47:09 INFO BlockManagerMasterEndpoint: Registering block manager localhost:43769 with 534.9 MB RAM, BlockManagerId(driver, localhost, 43769)
16/03/17 15:47:09 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:47:09 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:47:09 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:47:09 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:47:09 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:47:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:47:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:47:09 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:47:09 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=560851845
16/03/17 15:47:09 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 534.9 MB)
16/03/17 15:47:09 INFO MemoryStore: ensureFreeSpace(4155) called with curMem=6576, maxMem=560851845
16/03/17 15:47:09 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 534.9 MB)
16/03/17 15:47:09 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:43769 (size: 4.1 KB, free: 534.9 MB)
16/03/17 15:47:09 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:47:09 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:47:09 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:47:09 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:47:09 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:47:09 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:47:09 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209829324
16/03/17 15:47:09 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:47:09 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-27c9686b-c93c-4922-8199-e34ebebfd965/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:47:09 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:47:09 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10731, maxMem=560851845
16/03/17 15:47:09 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 534.9 MB)
16/03/17 15:47:09 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:43769 (size: 179.0 B, free: 534.9 MB)
16/03/17 15:47:09 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:47:09 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10910, maxMem=560851845
16/03/17 15:47:09 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 534.9 MB)
16/03/17 15:47:09 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:43769 (size: 173.0 B, free: 534.9 MB)
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: area
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: bend
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: giant
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: astatine
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: present
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: area
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: issue
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:47:17 INFO PythonRunner: Times: total = 8464, boot = 465, init = 369, finish = 7630
16/03/17 15:47:17 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:47:17 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8532 ms on localhost (1/2)
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): adding to parents: syn =  Synset('kilometer.n.01') ; keyword:  unit  in syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= [u'kilometer']
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: planning
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: permission
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: economy
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: composition
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: agency
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): adding to parents: syn =  Synset('kilometer.n.01') ; keyword:  unit  in syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= [u'kilometer']
reduceFunction_Parents(): returns= [u'kilometer', u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): unit
mapFunction_Parents(): keyword: unit ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= unit ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer', u'kilometer']
16/03/17 15:47:18 INFO PythonRunner: Times: total = 8714, boot = 464, init = 418, finish = 7832
16/03/17 15:47:18 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:47:18 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8778 ms on localhost (2/2)
16/03/17 15:47:18 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.783 s
16/03/17 15:47:18 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:47:18 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:47:18 INFO DAGScheduler: running: Set()
16/03/17 15:47:18 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:47:18 INFO DAGScheduler: failed: Set()
16/03/17 15:47:18 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:47:18 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:47:18 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11083, maxMem=560851845
16/03/17 15:47:18 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 534.9 MB)
16/03/17 15:47:18 INFO MemoryStore: ensureFreeSpace(3054) called with curMem=16067, maxMem=560851845
16/03/17 15:47:18 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 534.9 MB)
16/03/17 15:47:18 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:43769 (size: 3.0 KB, free: 534.9 MB)
16/03/17 15:47:18 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:47:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:47:18 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:47:18 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:47:18 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:47:18 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:47:18 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:47:18 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:47:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:47:18 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:47:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'kilometer', u'kilometer']
16/03/17 15:47:18 INFO PythonRunner: Times: total = 30, boot = -95, init = 124, finish = 1
16/03/17 15:47:18 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1279 bytes result sent to driver
16/03/17 15:47:18 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 61 ms on localhost (1/2)
16/03/17 15:47:18 INFO PythonRunner: Times: total = 215, boot = 214, init = 0, finish = 1
16/03/17 15:47:18 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:47:18 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 233 ms on localhost (2/2)
16/03/17 15:47:18 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:47:18 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.223 s
16/03/17 15:47:18 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.041766 s
16/03/17 15:47:18 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:47:18 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:47:18 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:47:18 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:47:18 INFO DAGScheduler: Missing parents: List()
16/03/17 15:47:18 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:47:18 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19121, maxMem=560851845
16/03/17 15:47:18 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 534.8 MB)
16/03/17 15:47:18 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24937, maxMem=560851845
16/03/17 15:47:18 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 534.8 MB)
16/03/17 15:47:18 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:43769 (size: 3.3 KB, free: 534.9 MB)
16/03/17 15:47:18 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:47:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:47:18 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:47:18 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:47:18 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2360 bytes)
16/03/17 15:47:18 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:47:18 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:47:18 INFO PythonRunner: Times: total = 81, boot = 74, init = 7, finish = 0
16/03/17 15:47:18 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:47:18 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 90 ms on localhost (1/2)
16/03/17 15:47:18 INFO PythonRunner: Times: total = 211, boot = 210, init = 1, finish = 0
16/03/17 15:47:18 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1358 bytes result sent to driver
16/03/17 15:47:18 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 222 ms on localhost (2/2)
16/03/17 15:47:18 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:47:18 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.224 s
16/03/17 15:47:18 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.232566 s
16/03/17 15:47:18 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:47:18 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:47:18 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:47:18 INFO MemoryStore: MemoryStore cleared
16/03/17 15:47:18 INFO BlockManager: BlockManager stopped
16/03/17 15:47:18 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:47:18 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:47:18 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:47:19 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:47:19 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:47:19 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:47:19 INFO SecurityManager: Changing view acls to: root
16/03/17 15:47:19 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:47:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:47:19 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:47:19 INFO Remoting: Starting remoting
16/03/17 15:47:19 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:45286]
16/03/17 15:47:19 INFO Utils: Successfully started service 'sparkDriver' on port 45286.
16/03/17 15:47:19 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:47:19 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:47:19 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-81aa4cdd-1cd9-47d5-add7-9eba4525bf32
16/03/17 15:47:19 INFO MemoryStore: MemoryStore started with capacity 535.0 MB
16/03/17 15:47:19 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-f1c44aba-3720-4cb0-b89f-8da5278b68d9
16/03/17 15:47:19 INFO HttpServer: Starting HTTP Server
16/03/17 15:47:20 INFO Utils: Successfully started service 'HTTP file server' on port 36305.
16/03/17 15:47:20 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:47:20 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:47:20 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:47:20 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-2fefc30e-a02d-4c8f-84fe-8c576361c8df/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:47:20 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209840067
16/03/17 15:47:20 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:47:20 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:47:20 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43629.
16/03/17 15:47:20 INFO NettyBlockTransferService: Server created on 43629
16/03/17 15:47:20 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:47:20 INFO BlockManagerMasterEndpoint: Registering block manager localhost:43629 with 535.0 MB RAM, BlockManagerId(driver, localhost, 43629)
16/03/17 15:47:20 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:47:20 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:47:20 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:47:20 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:47:20 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:47:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:47:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:47:20 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:47:20 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=560993402
16/03/17 15:47:20 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 535.0 MB)
16/03/17 15:47:20 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=560993402
16/03/17 15:47:20 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 535.0 MB)
16/03/17 15:47:20 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:43629 (size: 4.1 KB, free: 535.0 MB)
16/03/17 15:47:20 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:47:20 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:47:20 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:47:20 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:47:20 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:47:20 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:47:20 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209840067
16/03/17 15:47:20 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:47:20 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-2fefc30e-a02d-4c8f-84fe-8c576361c8df/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:47:20 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:47:20 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=560993402
16/03/17 15:47:20 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 535.0 MB)
16/03/17 15:47:20 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:43629 (size: 179.0 B, free: 535.0 MB)
16/03/17 15:47:20 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:47:20 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=560993402
16/03/17 15:47:20 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 535.0 MB)
16/03/17 15:47:20 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:43629 (size: 173.0 B, free: 535.0 MB)
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: set
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: planning
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: permission
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: economy
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: composition
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: agency
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  city  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/17 15:47:28 INFO PythonRunner: Times: total = 8439, boot = 467, init = 390, finish = 7582
16/03/17 15:47:28 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:47:28 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8528 ms on localhost (1/2)
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: bend
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: giant
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: astatine
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: present
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  city  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: area
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): city
mapFunction_Parents(): keyword: city ; prevleveltokens: issue
mapFunction_Parents(): keyword= city ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/17 15:47:28 INFO PythonRunner: Times: total = 8636, boot = 459, init = 415, finish = 7762
16/03/17 15:47:28 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:47:28 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.722 s
16/03/17 15:47:28 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:47:28 INFO DAGScheduler: running: Set()
16/03/17 15:47:28 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:47:28 INFO DAGScheduler: failed: Set()
16/03/17 15:47:28 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:47:28 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:47:28 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=560993402
16/03/17 15:47:28 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 535.0 MB)
16/03/17 15:47:28 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=560993402
16/03/17 15:47:28 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 535.0 MB)
16/03/17 15:47:28 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8735 ms on localhost (2/2)
16/03/17 15:47:28 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:47:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:43629 (size: 3.0 KB, free: 535.0 MB)
16/03/17 15:47:28 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:47:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:47:28 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:47:28 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:47:28 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:47:28 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:47:28 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:47:28 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:47:28 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:47:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:47:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
reduceFunction_Parents(): returns= ['None', u'Chennai', 'None', u'Chennai']
16/03/17 15:47:28 INFO PythonRunner: Times: total = 17, boot = -21, init = 37, finish = 1
16/03/17 15:47:28 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1297 bytes result sent to driver
16/03/17 15:47:28 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 33 ms on localhost (1/2)
16/03/17 15:47:29 INFO PythonRunner: Times: total = 206, boot = 205, init = 1, finish = 0
16/03/17 15:47:29 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:47:29 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.229 s
16/03/17 15:47:29 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.987421 s
16/03/17 15:47:29 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 229 ms on localhost (2/2)
16/03/17 15:47:29 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:47:29 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:47:29 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:47:29 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:47:29 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:47:29 INFO DAGScheduler: Missing parents: List()
16/03/17 15:47:29 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:47:29 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=560993402
16/03/17 15:47:29 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 535.0 MB)
16/03/17 15:47:29 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=560993402
16/03/17 15:47:29 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 535.0 MB)
16/03/17 15:47:29 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:43629 (size: 3.3 KB, free: 535.0 MB)
16/03/17 15:47:29 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:47:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:47:29 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:47:29 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:47:29 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2378 bytes)
16/03/17 15:47:29 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:47:29 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:47:29 INFO PythonRunner: Times: total = 50, boot = -97, init = 147, finish = 0
16/03/17 15:47:29 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1365 bytes result sent to driver
16/03/17 15:47:29 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 61 ms on localhost (1/2)
16/03/17 15:47:29 INFO PythonRunner: Times: total = 95, boot = 95, init = 0, finish = 0
16/03/17 15:47:29 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:47:29 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 106 ms on localhost (2/2)
16/03/17 15:47:29 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:47:29 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.089 s
16/03/17 15:47:29 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.117819 s
16/03/17 15:47:29 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:47:29 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:47:29 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:47:29 INFO MemoryStore: MemoryStore cleared
16/03/17 15:47:29 INFO BlockManager: BlockManager stopped
16/03/17 15:47:29 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:47:29 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:47:29 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:47:29 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:47:29 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:47:29 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:47:30 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:47:30 INFO SecurityManager: Changing view acls to: root
16/03/17 15:47:30 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:47:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:47:30 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:47:30 INFO Remoting: Starting remoting
16/03/17 15:47:30 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:34931]
16/03/17 15:47:30 INFO Utils: Successfully started service 'sparkDriver' on port 34931.
16/03/17 15:47:30 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:47:30 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:47:30 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ed139c27-8620-43a2-a5b2-2b8fce9d9804
16/03/17 15:47:30 INFO MemoryStore: MemoryStore started with capacity 535.0 MB
16/03/17 15:47:30 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-2ac64cdb-8d70-4ba2-b5f7-a5430f925a98
16/03/17 15:47:30 INFO HttpServer: Starting HTTP Server
16/03/17 15:47:30 INFO Utils: Successfully started service 'HTTP file server' on port 38401.
16/03/17 15:47:30 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:47:30 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:47:30 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:47:30 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-63805076-bfd4-47fe-a2d4-71addabf4a8d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:47:30 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209850578
16/03/17 15:47:30 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:47:30 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:47:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51536.
16/03/17 15:47:30 INFO NettyBlockTransferService: Server created on 51536
16/03/17 15:47:30 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:47:30 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51536 with 535.0 MB RAM, BlockManagerId(driver, localhost, 51536)
16/03/17 15:47:30 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:47:30 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:47:30 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:47:30 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:47:30 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:47:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:47:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:47:30 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:47:30 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=560993402
16/03/17 15:47:30 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 535.0 MB)
16/03/17 15:47:30 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=560993402
16/03/17 15:47:30 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 535.0 MB)
16/03/17 15:47:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51536 (size: 4.1 KB, free: 535.0 MB)
16/03/17 15:47:30 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:47:30 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:47:30 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:47:30 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:47:30 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:47:30 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:47:30 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209850578
16/03/17 15:47:30 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:47:30 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-63805076-bfd4-47fe-a2d4-71addabf4a8d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:47:30 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:47:30 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=560993402
16/03/17 15:47:30 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 535.0 MB)
16/03/17 15:47:30 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:51536 (size: 179.0 B, free: 535.0 MB)
16/03/17 15:47:30 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:47:30 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=560993402
16/03/17 15:47:30 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 535.0 MB)
16/03/17 15:47:30 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:51536 (size: 173.0 B, free: 535.0 MB)
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: set
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: bend
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: giant
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: astatine
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: present
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: area
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: issue
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:47:39 INFO PythonRunner: Times: total = 8419, boot = 469, init = 394, finish = 7556
16/03/17 15:47:39 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:47:39 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8521 ms on localhost (1/2)
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: planning
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: permission
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: economy
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: composition
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: agency
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): use
mapFunction_Parents(): keyword: use ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= use ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:47:39 INFO PythonRunner: Times: total = 8747, boot = 471, init = 394, finish = 7882
16/03/17 15:47:39 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:47:39 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.823 s
16/03/17 15:47:39 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:47:39 INFO DAGScheduler: running: Set()
16/03/17 15:47:39 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:47:39 INFO DAGScheduler: failed: Set()
16/03/17 15:47:39 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:47:39 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:47:39 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=560993402
16/03/17 15:47:39 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 535.0 MB)
16/03/17 15:47:39 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=560993402
16/03/17 15:47:39 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 535.0 MB)
16/03/17 15:47:39 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8830 ms on localhost (2/2)
16/03/17 15:47:39 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:47:39 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51536 (size: 3.0 KB, free: 535.0 MB)
16/03/17 15:47:39 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:47:39 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:47:39 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:47:39 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:47:39 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:47:39 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:47:39 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:47:39 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:47:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:47:39 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:47:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
reduceFunction_Parents(): returns= ['None', 'None']
16/03/17 15:47:39 INFO PythonRunner: Times: total = 20, boot = -105, init = 125, finish = 0
16/03/17 15:47:39 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1269 bytes result sent to driver
16/03/17 15:47:39 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 56 ms on localhost (1/2)
16/03/17 15:47:39 INFO PythonRunner: Times: total = 223, boot = 222, init = 1, finish = 0
16/03/17 15:47:39 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:47:39 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.223 s
16/03/17 15:47:39 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.095117 s
16/03/17 15:47:39 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 237 ms on localhost (2/2)
16/03/17 15:47:39 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:47:39 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:47:39 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:47:39 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:47:39 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:47:39 INFO DAGScheduler: Missing parents: List()
16/03/17 15:47:39 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:47:39 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=560993402
16/03/17 15:47:39 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 535.0 MB)
16/03/17 15:47:39 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=560993402
16/03/17 15:47:39 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 535.0 MB)
16/03/17 15:47:39 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:51536 (size: 3.3 KB, free: 535.0 MB)
16/03/17 15:47:39 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:47:39 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:47:39 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:47:39 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:47:39 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2350 bytes)
16/03/17 15:47:39 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:47:39 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:47:39 INFO PythonRunner: Times: total = 61, boot = -111, init = 172, finish = 0
16/03/17 15:47:39 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1337 bytes result sent to driver
16/03/17 15:47:39 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 71 ms on localhost (1/2)
16/03/17 15:47:40 INFO PythonRunner: Times: total = 149, boot = 149, init = 0, finish = 0
16/03/17 15:47:40 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:47:40 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 169 ms on localhost (2/2)
16/03/17 15:47:40 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:47:40 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.153 s
16/03/17 15:47:40 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.183059 s
16/03/17 15:47:40 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:47:40 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:47:40 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:47:40 INFO MemoryStore: MemoryStore cleared
16/03/17 15:47:40 INFO BlockManager: BlockManager stopped
16/03/17 15:47:40 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:47:40 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:47:40 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:47:40 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:47:40 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:47:40 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:47:41 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:47:41 INFO SecurityManager: Changing view acls to: root
16/03/17 15:47:41 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:47:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:47:41 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:47:41 INFO Remoting: Starting remoting
16/03/17 15:47:41 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:35908]
16/03/17 15:47:41 INFO Utils: Successfully started service 'sparkDriver' on port 35908.
16/03/17 15:47:41 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:47:41 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:47:41 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-4bd50c39-0729-409c-8e23-1692c44ae0de
16/03/17 15:47:41 INFO MemoryStore: MemoryStore started with capacity 535.0 MB
16/03/17 15:47:41 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-ec4713aa-05d3-44a1-9f07-34c081edc5ef
16/03/17 15:47:41 INFO HttpServer: Starting HTTP Server
16/03/17 15:47:41 INFO Utils: Successfully started service 'HTTP file server' on port 55450.
16/03/17 15:47:41 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:47:41 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:47:41 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:47:41 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-07b9d608-01b8-4629-925d-d932d6abe286/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:47:41 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209861253
16/03/17 15:47:41 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:47:41 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:47:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40640.
16/03/17 15:47:41 INFO NettyBlockTransferService: Server created on 40640
16/03/17 15:47:41 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:47:41 INFO BlockManagerMasterEndpoint: Registering block manager localhost:40640 with 535.0 MB RAM, BlockManagerId(driver, localhost, 40640)
16/03/17 15:47:41 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:47:41 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:47:41 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:47:41 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:47:41 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:47:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:47:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:47:41 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:47:41 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=560993402
16/03/17 15:47:41 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 535.0 MB)
16/03/17 15:47:41 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=560993402
16/03/17 15:47:41 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 535.0 MB)
16/03/17 15:47:41 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:40640 (size: 4.1 KB, free: 535.0 MB)
16/03/17 15:47:41 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:47:41 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:47:41 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:47:41 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:47:41 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:47:41 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:47:41 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209861253
16/03/17 15:47:41 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:47:41 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-07b9d608-01b8-4629-925d-d932d6abe286/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:47:41 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:47:41 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:47:41 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10732, maxMem=560993402
16/03/17 15:47:41 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 535.0 MB)
16/03/17 15:47:41 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10905, maxMem=560993402
16/03/17 15:47:41 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:40640 (size: 173.0 B, free: 535.0 MB)
16/03/17 15:47:41 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 535.0 MB)
16/03/17 15:47:41 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:40640 (size: 179.0 B, free: 535.0 MB)
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: set
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: planning
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: permission
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: economy
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): adding to parents: syn =  Synset('economy.n.01') ; keyword:  consumption  in syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= [u'economy']
reduceFunction_Parents(): returns= ['None', u'economy']
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: composition
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'economy']
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: agency
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'economy']
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'economy']
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'economy']
16/03/17 15:47:50 INFO PythonRunner: Times: total = 8529, boot = 459, init = 393, finish = 7677
16/03/17 15:47:50 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:47:50 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8654 ms on localhost (1/2)
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: bend
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: giant
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: astatine
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: present
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: area
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): consumption
mapFunction_Parents(): keyword: consumption ; prevleveltokens: issue
mapFunction_Parents(): keyword= consumption ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:47:50 INFO PythonRunner: Times: total = 8975, boot = 458, init = 399, finish = 8118
16/03/17 15:47:50 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:47:50 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9090 ms on localhost (2/2)
16/03/17 15:47:50 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:47:50 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.086 s
16/03/17 15:47:50 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:47:50 INFO DAGScheduler: running: Set()
16/03/17 15:47:50 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:47:50 INFO DAGScheduler: failed: Set()
16/03/17 15:47:50 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:47:50 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:47:50 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=560993402
16/03/17 15:47:50 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 535.0 MB)
16/03/17 15:47:50 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=560993402
16/03/17 15:47:50 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 535.0 MB)
16/03/17 15:47:50 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:40640 (size: 3.0 KB, free: 535.0 MB)
16/03/17 15:47:50 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:47:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:47:50 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:47:50 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:47:50 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:47:50 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:47:50 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:47:50 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:47:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:47:50 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:47:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:47:50 INFO PythonRunner: Times: total = 29, boot = -265, init = 293, finish = 1
16/03/17 15:47:50 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
reduceFunction_Parents(): returns= ['None', 'None', u'economy']
16/03/17 15:47:50 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 53 ms on localhost (1/2)
16/03/17 15:47:50 INFO PythonRunner: Times: total = 229, boot = 229, init = 0, finish = 0
16/03/17 15:47:50 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:47:50 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 238 ms on localhost (2/2)
16/03/17 15:47:50 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:47:50 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.239 s
16/03/17 15:47:50 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.356035 s
16/03/17 15:47:50 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:47:50 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:47:50 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:47:50 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:47:50 INFO DAGScheduler: Missing parents: List()
16/03/17 15:47:50 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:47:50 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=560993402
16/03/17 15:47:50 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 535.0 MB)
16/03/17 15:47:50 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=560993402
16/03/17 15:47:50 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 535.0 MB)
16/03/17 15:47:50 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:40640 (size: 3.3 KB, free: 535.0 MB)
16/03/17 15:47:50 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:47:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:47:50 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:47:50 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:47:50 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/17 15:47:50 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:47:50 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:47:50 INFO PythonRunner: Times: total = 46, boot = -101, init = 147, finish = 0
16/03/17 15:47:50 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:47:50 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 55 ms on localhost (1/2)
16/03/17 15:47:50 INFO PythonRunner: Times: total = 159, boot = 158, init = 1, finish = 0
16/03/17 15:47:50 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1351 bytes result sent to driver
16/03/17 15:47:50 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 165 ms on localhost (2/2)
16/03/17 15:47:50 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:47:50 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.164 s
16/03/17 15:47:50 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.181028 s
16/03/17 15:47:51 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:47:51 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:47:51 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:47:51 INFO MemoryStore: MemoryStore cleared
16/03/17 15:47:51 INFO BlockManager: BlockManager stopped
16/03/17 15:47:51 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:47:51 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:47:51 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:47:51 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:47:51 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:47:51 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:47:51 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:47:52 INFO SecurityManager: Changing view acls to: root
16/03/17 15:47:52 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:47:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:47:52 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:47:52 INFO Remoting: Starting remoting
16/03/17 15:47:52 INFO Utils: Successfully started service 'sparkDriver' on port 50686.
16/03/17 15:47:52 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:50686]
16/03/17 15:47:52 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:47:52 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:47:52 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ddb818d6-b2af-4ab3-bc99-1cc322e12b7b
16/03/17 15:47:52 INFO MemoryStore: MemoryStore started with capacity 535.0 MB
16/03/17 15:47:52 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-7d8fb53f-4baa-4b4b-8e92-0906b2de2f46
16/03/17 15:47:52 INFO HttpServer: Starting HTTP Server
16/03/17 15:47:52 INFO Utils: Successfully started service 'HTTP file server' on port 40239.
16/03/17 15:47:52 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:47:52 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:47:52 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:47:52 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-0d81dab9-59b6-415e-a176-5ef3b8d91df7/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:47:52 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209872333
16/03/17 15:47:52 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:47:52 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:47:52 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36751.
16/03/17 15:47:52 INFO NettyBlockTransferService: Server created on 36751
16/03/17 15:47:52 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:47:52 INFO BlockManagerMasterEndpoint: Registering block manager localhost:36751 with 535.0 MB RAM, BlockManagerId(driver, localhost, 36751)
16/03/17 15:47:52 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:47:52 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:47:52 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:47:52 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:47:52 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:47:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:47:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:47:52 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:47:52 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=560993402
16/03/17 15:47:52 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 535.0 MB)
16/03/17 15:47:52 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=560993402
16/03/17 15:47:52 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 535.0 MB)
16/03/17 15:47:52 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:36751 (size: 4.1 KB, free: 535.0 MB)
16/03/17 15:47:52 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:47:52 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:47:52 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:47:52 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:47:52 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:47:52 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:47:52 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209872333
16/03/17 15:47:52 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:47:52 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-0d81dab9-59b6-415e-a176-5ef3b8d91df7/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:47:52 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:47:52 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=560993402
16/03/17 15:47:52 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 535.0 MB)
16/03/17 15:47:52 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:36751 (size: 179.0 B, free: 535.0 MB)
16/03/17 15:47:52 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:47:52 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=560993402
16/03/17 15:47:52 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 535.0 MB)
16/03/17 15:47:52 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:36751 (size: 173.0 B, free: 535.0 MB)
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: set
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: planning
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: permission
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: economy
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: composition
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: agency
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:48:00 INFO PythonRunner: Times: total = 8365, boot = 484, init = 387, finish = 7494
16/03/17 15:48:00 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:48:00 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8458 ms on localhost (1/2)
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: bend
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: giant
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: astatine
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: present
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  Eastern  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: area
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Eastern
mapFunction_Parents(): keyword: Eastern ; prevleveltokens: issue
mapFunction_Parents(): keyword= Eastern ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
16/03/17 15:48:01 INFO PythonRunner: Times: total = 8649, boot = 488, init = 409, finish = 7752
16/03/17 15:48:01 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:48:01 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8741 ms on localhost (2/2)
16/03/17 15:48:01 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.733 s
16/03/17 15:48:01 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:48:01 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:48:01 INFO DAGScheduler: running: Set()
16/03/17 15:48:01 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:48:01 INFO DAGScheduler: failed: Set()
16/03/17 15:48:01 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:48:01 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:48:01 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=560993402
16/03/17 15:48:01 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 535.0 MB)
16/03/17 15:48:01 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=560993402
16/03/17 15:48:01 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 535.0 MB)
16/03/17 15:48:01 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:36751 (size: 3.0 KB, free: 535.0 MB)
16/03/17 15:48:01 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:48:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:01 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:48:01 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:48:01 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:48:01 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:48:01 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:48:01 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:48:01 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
reduceFunction_Parents(): returns= ['None', u'metropolitan', 'None']
16/03/17 15:48:01 INFO PythonRunner: Times: total = 33, boot = -123, init = 155, finish = 1
16/03/17 15:48:01 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1288 bytes result sent to driver
16/03/17 15:48:01 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 56 ms on localhost (1/2)
16/03/17 15:48:01 INFO PythonRunner: Times: total = 186, boot = 185, init = 0, finish = 1
16/03/17 15:48:01 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:48:01 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.192 s
16/03/17 15:48:01 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.977221 s
16/03/17 15:48:01 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 208 ms on localhost (2/2)
16/03/17 15:48:01 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:48:01 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:48:01 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:48:01 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:01 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:48:01 INFO DAGScheduler: Missing parents: List()
16/03/17 15:48:01 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:48:01 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=560993402
16/03/17 15:48:01 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 535.0 MB)
16/03/17 15:48:01 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=560993402
16/03/17 15:48:01 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 535.0 MB)
16/03/17 15:48:01 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:36751 (size: 3.3 KB, free: 535.0 MB)
16/03/17 15:48:01 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:48:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:01 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:48:01 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:48:01 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2369 bytes)
16/03/17 15:48:01 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:48:01 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:48:01 INFO PythonRunner: Times: total = 48, boot = -97, init = 145, finish = 0
16/03/17 15:48:01 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:48:01 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 57 ms on localhost (1/2)
16/03/17 15:48:01 INFO PythonRunner: Times: total = 117, boot = 117, init = 0, finish = 0
16/03/17 15:48:01 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1356 bytes result sent to driver
16/03/17 15:48:01 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 123 ms on localhost (2/2)
16/03/17 15:48:01 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:48:01 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.121 s
16/03/17 15:48:01 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.134610 s
16/03/17 15:48:01 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:48:01 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:48:01 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:48:01 INFO MemoryStore: MemoryStore cleared
16/03/17 15:48:01 INFO BlockManager: BlockManager stopped
16/03/17 15:48:01 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:48:01 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:48:01 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:48:01 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:48:01 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:48:01 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:48:02 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:48:02 INFO SecurityManager: Changing view acls to: root
16/03/17 15:48:02 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:48:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:48:02 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:48:02 INFO Remoting: Starting remoting
16/03/17 15:48:02 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:39808]
16/03/17 15:48:02 INFO Utils: Successfully started service 'sparkDriver' on port 39808.
16/03/17 15:48:02 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:48:02 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:48:02 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-159f5b03-070a-4a81-99c8-fc9e5694030b
16/03/17 15:48:02 INFO MemoryStore: MemoryStore started with capacity 532.4 MB
16/03/17 15:48:02 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-5b1f2e91-3fbd-4d21-8874-91c67adb31e2
16/03/17 15:48:02 INFO HttpServer: Starting HTTP Server
16/03/17 15:48:02 INFO Utils: Successfully started service 'HTTP file server' on port 47751.
16/03/17 15:48:02 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:48:02 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:48:02 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:48:02 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-1a86c86a-7200-4c1a-a37e-ceab30ba4086/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:48:02 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209882913
16/03/17 15:48:02 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:48:02 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:48:02 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33162.
16/03/17 15:48:02 INFO NettyBlockTransferService: Server created on 33162
16/03/17 15:48:02 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:48:02 INFO BlockManagerMasterEndpoint: Registering block manager localhost:33162 with 532.4 MB RAM, BlockManagerId(driver, localhost, 33162)
16/03/17 15:48:02 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:48:03 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:48:03 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:03 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:48:03 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:48:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:48:03 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:48:03 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=558303805
16/03/17 15:48:03 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 532.4 MB)
16/03/17 15:48:03 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=558303805
16/03/17 15:48:03 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 532.4 MB)
16/03/17 15:48:03 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:33162 (size: 4.1 KB, free: 532.4 MB)
16/03/17 15:48:03 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:48:03 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:03 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:48:03 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:48:03 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:48:03 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:48:03 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209882913
16/03/17 15:48:03 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:48:03 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-1a86c86a-7200-4c1a-a37e-ceab30ba4086/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:48:03 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:48:03 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:48:03 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=558303805
16/03/17 15:48:03 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 532.4 MB)
16/03/17 15:48:03 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=558303805
16/03/17 15:48:03 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 532.4 MB)
16/03/17 15:48:03 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:33162 (size: 179.0 B, free: 532.4 MB)
16/03/17 15:48:03 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:33162 (size: 173.0 B, free: 532.4 MB)
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: set
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: planning
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: permission
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: economy
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: composition
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: agency
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:48:11 INFO PythonRunner: Times: total = 8285, boot = 494, init = 387, finish = 7404
16/03/17 15:48:11 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:48:11 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8345 ms on localhost (1/2)
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: bend
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: giant
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: astatine
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: present
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  stretch  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: area
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): stretch
mapFunction_Parents(): keyword: stretch ; prevleveltokens: issue
mapFunction_Parents(): keyword= stretch ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/17 15:48:11 INFO PythonRunner: Times: total = 8679, boot = 502, init = 418, finish = 7759
16/03/17 15:48:11 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:48:11 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8737 ms on localhost (2/2)
16/03/17 15:48:11 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:48:11 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.739 s
16/03/17 15:48:11 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:48:11 INFO DAGScheduler: running: Set()
16/03/17 15:48:11 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:48:11 INFO DAGScheduler: failed: Set()
16/03/17 15:48:11 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:48:11 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:48:11 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=558303805
16/03/17 15:48:11 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 532.4 MB)
16/03/17 15:48:11 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=558303805
16/03/17 15:48:11 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 532.4 MB)
16/03/17 15:48:11 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:33162 (size: 3.0 KB, free: 532.4 MB)
16/03/17 15:48:11 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:48:11 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:11 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:48:11 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:48:11 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:48:11 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:48:11 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:48:11 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:48:11 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
reduceFunction_Parents(): returns= ['None', u'present', 'None']
16/03/17 15:48:11 INFO PythonRunner: Times: total = 24, boot = -224, init = 248, finish = 0
16/03/17 15:48:11 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/17 15:48:11 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 74 ms on localhost (1/2)
16/03/17 15:48:11 INFO PythonRunner: Times: total = 188, boot = 187, init = 1, finish = 0
16/03/17 15:48:11 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:48:11 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 215 ms on localhost (2/2)
16/03/17 15:48:11 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:48:11 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.201 s
16/03/17 15:48:11 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.972897 s
16/03/17 15:48:12 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:48:12 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:48:12 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:12 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:48:12 INFO DAGScheduler: Missing parents: List()
16/03/17 15:48:12 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:48:12 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=558303805
16/03/17 15:48:12 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 532.4 MB)
16/03/17 15:48:12 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=558303805
16/03/17 15:48:12 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 532.4 MB)
16/03/17 15:48:12 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:33162 (size: 3.3 KB, free: 532.4 MB)
16/03/17 15:48:12 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:48:12 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:12 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:48:12 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:48:12 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/17 15:48:12 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:48:12 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:48:12 INFO PythonRunner: Times: total = 53, boot = -24, init = 77, finish = 0
16/03/17 15:48:12 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:48:12 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 60 ms on localhost (1/2)
16/03/17 15:48:12 INFO PythonRunner: Times: total = 124, boot = 123, init = 1, finish = 0
16/03/17 15:48:12 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1351 bytes result sent to driver
16/03/17 15:48:12 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 133 ms on localhost (2/2)
16/03/17 15:48:12 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:48:12 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.122 s
16/03/17 15:48:12 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.143938 s
16/03/17 15:48:12 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:48:12 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:48:12 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:48:12 INFO MemoryStore: MemoryStore cleared
16/03/17 15:48:12 INFO BlockManager: BlockManager stopped
16/03/17 15:48:12 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:48:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:48:12 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:48:12 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:48:12 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:48:12 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:48:13 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:48:13 INFO SecurityManager: Changing view acls to: root
16/03/17 15:48:13 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:48:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:48:13 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:48:13 INFO Remoting: Starting remoting
16/03/17 15:48:13 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:55415]
16/03/17 15:48:13 INFO Utils: Successfully started service 'sparkDriver' on port 55415.
16/03/17 15:48:13 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:48:13 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:48:13 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c177e851-1601-433a-9294-8832c849df3a
16/03/17 15:48:13 INFO MemoryStore: MemoryStore started with capacity 532.4 MB
16/03/17 15:48:13 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-288742cc-a033-4dd0-ad68-c140df1a54b7
16/03/17 15:48:13 INFO HttpServer: Starting HTTP Server
16/03/17 15:48:13 INFO Utils: Successfully started service 'HTTP file server' on port 46553.
16/03/17 15:48:13 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:48:13 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:48:13 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:48:13 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-aed31256-8c71-4db9-b0b6-bb87835392b1/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:48:13 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209893445
16/03/17 15:48:13 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:48:13 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:48:13 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57939.
16/03/17 15:48:13 INFO NettyBlockTransferService: Server created on 57939
16/03/17 15:48:13 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:48:13 INFO BlockManagerMasterEndpoint: Registering block manager localhost:57939 with 532.4 MB RAM, BlockManagerId(driver, localhost, 57939)
16/03/17 15:48:13 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:48:13 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:48:13 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:13 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:48:13 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:48:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:48:13 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:48:13 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=558303805
16/03/17 15:48:13 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 532.4 MB)
16/03/17 15:48:13 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=558303805
16/03/17 15:48:13 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 532.4 MB)
16/03/17 15:48:13 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:57939 (size: 4.1 KB, free: 532.4 MB)
16/03/17 15:48:13 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:48:13 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:13 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:48:13 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:48:13 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:48:13 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:48:13 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209893445
16/03/17 15:48:13 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:48:13 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-aed31256-8c71-4db9-b0b6-bb87835392b1/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:48:13 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:48:13 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=558303805
16/03/17 15:48:13 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 532.4 MB)
16/03/17 15:48:13 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:57939 (size: 179.0 B, free: 532.4 MB)
16/03/17 15:48:13 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:48:13 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=558303805
16/03/17 15:48:13 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 532.4 MB)
16/03/17 15:48:13 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:57939 (size: 173.0 B, free: 532.4 MB)
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: set
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: planning
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: permission
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: economy
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: composition
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: agency
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:48:22 INFO PythonRunner: Times: total = 8540, boot = 470, init = 381, finish = 7689
16/03/17 15:48:22 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:48:22 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8587 ms on localhost (1/2)
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: bend
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: giant
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: astatine
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: present
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  archbishop  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: area
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): archbishop
mapFunction_Parents(): keyword: archbishop ; prevleveltokens: issue
mapFunction_Parents(): keyword= archbishop ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
16/03/17 15:48:22 INFO PythonRunner: Times: total = 8763, boot = 478, init = 395, finish = 7890
16/03/17 15:48:22 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:48:22 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.811 s
16/03/17 15:48:22 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:48:22 INFO DAGScheduler: running: Set()
16/03/17 15:48:22 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:48:22 INFO DAGScheduler: failed: Set()
16/03/17 15:48:22 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:48:22 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:48:22 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=558303805
16/03/17 15:48:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 532.4 MB)
16/03/17 15:48:22 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=558303805
16/03/17 15:48:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 532.4 MB)
16/03/17 15:48:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:57939 (size: 3.0 KB, free: 532.4 MB)
16/03/17 15:48:22 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8809 ms on localhost (2/2)
16/03/17 15:48:22 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:48:22 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:48:22 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:22 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:48:22 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:48:22 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:48:22 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:48:22 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:48:22 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:48:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:48:22 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:48:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'metropolitan', 'None']
16/03/17 15:48:22 INFO PythonRunner: Times: total = 19, boot = -50, init = 69, finish = 0
16/03/17 15:48:22 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1288 bytes result sent to driver
16/03/17 15:48:22 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 51 ms on localhost (1/2)
16/03/17 15:48:22 INFO PythonRunner: Times: total = 206, boot = 205, init = 1, finish = 0
16/03/17 15:48:22 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:48:22 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 220 ms on localhost (2/2)
16/03/17 15:48:22 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:48:22 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.221 s
16/03/17 15:48:22 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.057034 s
16/03/17 15:48:22 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:48:22 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:48:22 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:22 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:48:22 INFO DAGScheduler: Missing parents: List()
16/03/17 15:48:22 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:48:22 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=558303805
16/03/17 15:48:22 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 532.4 MB)
16/03/17 15:48:22 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=558303805
16/03/17 15:48:22 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 532.4 MB)
16/03/17 15:48:22 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:57939 (size: 3.3 KB, free: 532.4 MB)
16/03/17 15:48:22 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:48:22 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:22 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:48:22 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:48:22 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2369 bytes)
16/03/17 15:48:22 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:48:22 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:48:22 INFO PythonRunner: Times: total = 58, boot = -74, init = 132, finish = 0
16/03/17 15:48:22 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:48:22 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 69 ms on localhost (1/2)
16/03/17 15:48:22 INFO PythonRunner: Times: total = 186, boot = 186, init = 0, finish = 0
16/03/17 15:48:22 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1356 bytes result sent to driver
16/03/17 15:48:22 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 197 ms on localhost (2/2)
16/03/17 15:48:22 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:48:22 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.184 s
16/03/17 15:48:22 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.207903 s
16/03/17 15:48:22 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:48:22 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:48:23 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:48:23 INFO MemoryStore: MemoryStore cleared
16/03/17 15:48:23 INFO BlockManager: BlockManager stopped
16/03/17 15:48:23 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:48:23 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:48:23 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:48:23 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:48:23 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:48:23 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:48:23 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:48:23 INFO SecurityManager: Changing view acls to: root
16/03/17 15:48:23 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:48:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:48:23 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:48:23 INFO Remoting: Starting remoting
16/03/17 15:48:24 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:58915]
16/03/17 15:48:24 INFO Utils: Successfully started service 'sparkDriver' on port 58915.
16/03/17 15:48:24 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:48:24 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:48:24 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e78a5aa7-70d0-43e1-b195-6f102fd32961
16/03/17 15:48:24 INFO MemoryStore: MemoryStore started with capacity 532.4 MB
16/03/17 15:48:24 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-e017350c-3e1c-4571-a6d3-6952344bfd46
16/03/17 15:48:24 INFO HttpServer: Starting HTTP Server
16/03/17 15:48:24 INFO Utils: Successfully started service 'HTTP file server' on port 35703.
16/03/17 15:48:24 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:48:24 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:48:24 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:48:24 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-9e3593cf-d645-4d71-a5ef-9acf20d0188c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:48:24 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209904108
16/03/17 15:48:24 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:48:24 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:48:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49455.
16/03/17 15:48:24 INFO NettyBlockTransferService: Server created on 49455
16/03/17 15:48:24 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:48:24 INFO BlockManagerMasterEndpoint: Registering block manager localhost:49455 with 532.4 MB RAM, BlockManagerId(driver, localhost, 49455)
16/03/17 15:48:24 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:48:24 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:48:24 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:24 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:48:24 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:48:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:48:24 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:48:24 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=558303805
16/03/17 15:48:24 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 532.4 MB)
16/03/17 15:48:24 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=558303805
16/03/17 15:48:24 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 532.4 MB)
16/03/17 15:48:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:49455 (size: 4.1 KB, free: 532.4 MB)
16/03/17 15:48:24 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:48:24 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:24 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:48:24 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:48:24 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:48:24 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:48:24 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209904108
16/03/17 15:48:24 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:48:24 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-9e3593cf-d645-4d71-a5ef-9acf20d0188c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:48:24 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:48:24 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10732, maxMem=558303805
16/03/17 15:48:24 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 532.4 MB)
16/03/17 15:48:24 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:49455 (size: 173.0 B, free: 532.4 MB)
16/03/17 15:48:24 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:48:24 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10905, maxMem=558303805
16/03/17 15:48:24 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 532.4 MB)
16/03/17 15:48:24 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:49455 (size: 179.0 B, free: 532.4 MB)
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: area
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: bend
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: giant
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: astatine
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: present
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: area
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: issue
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:48:32 INFO PythonRunner: Times: total = 8345, boot = 448, init = 389, finish = 7508
16/03/17 15:48:32 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:48:32 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8417 ms on localhost (1/2)
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: planning
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: permission
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: economy
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): adding to parents: syn =  Synset('economy.n.01') ; keyword:  system  in syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= [u'economy']
reduceFunction_Parents(): returns= ['None', u'economy']
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: composition
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'economy']
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: agency
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'economy']
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'economy']
asfer_pickle_string_load(): picklef.readlines(): system
mapFunction_Parents(): keyword: system ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= system ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'economy']
16/03/17 15:48:32 INFO PythonRunner: Times: total = 8666, boot = 450, init = 426, finish = 7790
16/03/17 15:48:32 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:48:32 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.725 s
16/03/17 15:48:32 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:48:32 INFO DAGScheduler: running: Set()
16/03/17 15:48:32 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:48:32 INFO DAGScheduler: failed: Set()
16/03/17 15:48:32 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:48:32 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:48:32 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=558303805
16/03/17 15:48:32 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 532.4 MB)
16/03/17 15:48:33 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=558303805
16/03/17 15:48:33 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 532.4 MB)
16/03/17 15:48:33 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8731 ms on localhost (2/2)
16/03/17 15:48:33 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:48:33 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:49455 (size: 3.0 KB, free: 532.4 MB)
16/03/17 15:48:33 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:48:33 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:33 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:48:33 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:48:33 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:48:33 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:48:33 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:48:33 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:48:33 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:48:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:48:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', 'None', u'economy']
16/03/17 15:48:33 INFO PythonRunner: Times: total = 24, boot = -149, init = 172, finish = 1
16/03/17 15:48:33 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/17 15:48:33 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 50 ms on localhost (1/2)
16/03/17 15:48:33 INFO PythonRunner: Times: total = 268, boot = 267, init = 0, finish = 1
16/03/17 15:48:33 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:48:33 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 282 ms on localhost (2/2)
16/03/17 15:48:33 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:48:33 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.280 s
16/03/17 15:48:33 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.045677 s
16/03/17 15:48:33 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:48:33 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:48:33 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:33 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:48:33 INFO DAGScheduler: Missing parents: List()
16/03/17 15:48:33 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:48:33 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=558303805
16/03/17 15:48:33 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 532.4 MB)
16/03/17 15:48:33 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=558303805
16/03/17 15:48:33 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 532.4 MB)
16/03/17 15:48:33 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:49455 (size: 3.3 KB, free: 532.4 MB)
16/03/17 15:48:33 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:48:33 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:33 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:48:33 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:48:33 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/17 15:48:33 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:48:33 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:48:33 INFO PythonRunner: Times: total = 50, boot = -121, init = 171, finish = 0
16/03/17 15:48:33 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1351 bytes result sent to driver
16/03/17 15:48:33 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 65 ms on localhost (1/2)
16/03/17 15:48:33 INFO PythonRunner: Times: total = 62, boot = 62, init = 0, finish = 0
16/03/17 15:48:33 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:48:33 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 73 ms on localhost (2/2)
16/03/17 15:48:33 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:48:33 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.060 s
16/03/17 15:48:33 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.084810 s
16/03/17 15:48:33 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:48:33 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:48:33 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:48:33 INFO MemoryStore: MemoryStore cleared
16/03/17 15:48:33 INFO BlockManager: BlockManager stopped
16/03/17 15:48:33 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:48:33 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:48:33 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:48:33 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:48:33 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:48:33 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:48:34 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:48:34 INFO SecurityManager: Changing view acls to: root
16/03/17 15:48:34 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:48:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:48:34 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:48:34 INFO Remoting: Starting remoting
16/03/17 15:48:34 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:36580]
16/03/17 15:48:34 INFO Utils: Successfully started service 'sparkDriver' on port 36580.
16/03/17 15:48:34 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:48:34 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:48:34 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-4a950f13-d1a0-4e0e-8a48-feefc5f99d50
16/03/17 15:48:34 INFO MemoryStore: MemoryStore started with capacity 532.7 MB
16/03/17 15:48:34 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-1aa14ea6-34ee-4ebf-b6c0-a0052036c734
16/03/17 15:48:34 INFO HttpServer: Starting HTTP Server
16/03/17 15:48:34 INFO Utils: Successfully started service 'HTTP file server' on port 59168.
16/03/17 15:48:34 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:48:34 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:48:34 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:48:34 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-1bea3f92-8002-48e3-85b3-e4b9562e3890/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:48:34 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209914812
16/03/17 15:48:34 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:48:34 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:48:34 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52301.
16/03/17 15:48:34 INFO NettyBlockTransferService: Server created on 52301
16/03/17 15:48:34 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:48:34 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52301 with 532.7 MB RAM, BlockManagerId(driver, localhost, 52301)
16/03/17 15:48:34 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:48:34 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:48:34 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:34 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:48:34 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:48:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:48:34 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:48:34 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=558586920
16/03/17 15:48:34 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 532.7 MB)
16/03/17 15:48:34 INFO MemoryStore: ensureFreeSpace(4159) called with curMem=6576, maxMem=558586920
16/03/17 15:48:34 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 532.7 MB)
16/03/17 15:48:34 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52301 (size: 4.1 KB, free: 532.7 MB)
16/03/17 15:48:34 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:48:34 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:34 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:48:34 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:48:34 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:48:34 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:48:34 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209914812
16/03/17 15:48:34 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:48:34 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-1bea3f92-8002-48e3-85b3-e4b9562e3890/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:48:35 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:48:35 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:48:35 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10735, maxMem=558586920
16/03/17 15:48:35 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 532.7 MB)
16/03/17 15:48:35 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10908, maxMem=558586920
16/03/17 15:48:35 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:52301 (size: 173.0 B, free: 532.7 MB)
16/03/17 15:48:35 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 532.7 MB)
16/03/17 15:48:35 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:52301 (size: 179.0 B, free: 532.7 MB)
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: set
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: planning
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: permission
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: economy
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: composition
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: agency
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:48:43 INFO PythonRunner: Times: total = 8606, boot = 464, init = 388, finish = 7754
16/03/17 15:48:43 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:48:43 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8673 ms on localhost (1/2)
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: bend
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: giant
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: astatine
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  halogen  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: present
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: area
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): halogen
mapFunction_Parents(): keyword: halogen ; prevleveltokens: issue
mapFunction_Parents(): keyword= halogen ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/17 15:48:43 INFO PythonRunner: Times: total = 8824, boot = 462, init = 429, finish = 7933
16/03/17 15:48:43 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:48:43 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.893 s
16/03/17 15:48:43 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:48:43 INFO DAGScheduler: running: Set()
16/03/17 15:48:43 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:48:43 INFO DAGScheduler: failed: Set()
16/03/17 15:48:43 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:48:43 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:48:43 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11087, maxMem=558586920
16/03/17 15:48:43 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 532.7 MB)
16/03/17 15:48:43 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16071, maxMem=558586920
16/03/17 15:48:43 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 532.7 MB)
16/03/17 15:48:43 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52301 (size: 3.0 KB, free: 532.7 MB)
16/03/17 15:48:43 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:48:43 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:43 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:48:43 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8891 ms on localhost (2/2)
16/03/17 15:48:43 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:48:43 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:48:43 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:48:43 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:48:43 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:48:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:48:43 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:48:43 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:48:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:48:43 INFO PythonRunner: Times: total = 18, boot = -34, init = 51, finish = 1
16/03/17 15:48:43 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:48:43 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 61 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'astatine', 'None']
16/03/17 15:48:44 INFO PythonRunner: Times: total = 227, boot = 225, init = 1, finish = 1
16/03/17 15:48:44 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/03/17 15:48:44 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 245 ms on localhost (2/2)
16/03/17 15:48:44 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:48:44 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.233 s
16/03/17 15:48:44 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.157923 s
16/03/17 15:48:44 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:48:44 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:48:44 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:44 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:48:44 INFO DAGScheduler: Missing parents: List()
16/03/17 15:48:44 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:48:44 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19126, maxMem=558586920
16/03/17 15:48:44 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 532.7 MB)
16/03/17 15:48:44 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24942, maxMem=558586920
16/03/17 15:48:44 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 532.7 MB)
16/03/17 15:48:44 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:52301 (size: 3.3 KB, free: 532.7 MB)
16/03/17 15:48:44 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:48:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:44 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:48:44 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:48:44 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/03/17 15:48:44 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:48:44 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:48:44 INFO PythonRunner: Times: total = 57, boot = 56, init = 1, finish = 0
16/03/17 15:48:44 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/03/17 15:48:44 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 68 ms on localhost (1/2)
16/03/17 15:48:44 INFO PythonRunner: Times: total = 84, boot = 83, init = 1, finish = 0
16/03/17 15:48:44 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:48:44 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 92 ms on localhost (2/2)
16/03/17 15:48:44 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:48:44 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.079 s
16/03/17 15:48:44 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.111324 s
16/03/17 15:48:44 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:48:44 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:48:44 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:48:44 INFO MemoryStore: MemoryStore cleared
16/03/17 15:48:44 INFO BlockManager: BlockManager stopped
16/03/17 15:48:44 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:48:44 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:48:44 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:48:44 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:48:44 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:48:44 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:48:45 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:48:45 INFO SecurityManager: Changing view acls to: root
16/03/17 15:48:45 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:48:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:48:45 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:48:45 INFO Remoting: Starting remoting
16/03/17 15:48:45 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:36150]
16/03/17 15:48:45 INFO Utils: Successfully started service 'sparkDriver' on port 36150.
16/03/17 15:48:45 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:48:45 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:48:45 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-6c29aabc-70ae-4f3b-8449-c408e43e27fb
16/03/17 15:48:45 INFO MemoryStore: MemoryStore started with capacity 532.7 MB
16/03/17 15:48:45 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-22dca9c6-5550-4ee9-b876-f142e5905272
16/03/17 15:48:45 INFO HttpServer: Starting HTTP Server
16/03/17 15:48:45 INFO Utils: Successfully started service 'HTTP file server' on port 41172.
16/03/17 15:48:45 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:48:45 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:48:45 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:48:45 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-03822e9e-56b6-403f-979a-20659ccde8b8/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:48:45 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209925555
16/03/17 15:48:45 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:48:45 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:48:45 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 47286.
16/03/17 15:48:45 INFO NettyBlockTransferService: Server created on 47286
16/03/17 15:48:45 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:48:45 INFO BlockManagerMasterEndpoint: Registering block manager localhost:47286 with 532.7 MB RAM, BlockManagerId(driver, localhost, 47286)
16/03/17 15:48:45 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:48:45 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:48:45 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:45 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:48:45 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:48:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:48:45 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:48:45 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=558586920
16/03/17 15:48:45 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 532.7 MB)
16/03/17 15:48:45 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=558586920
16/03/17 15:48:45 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 532.7 MB)
16/03/17 15:48:45 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:47286 (size: 4.1 KB, free: 532.7 MB)
16/03/17 15:48:45 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:48:45 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:45 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:48:45 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:48:45 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:48:45 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:48:45 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209925555
16/03/17 15:48:45 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:48:45 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-03822e9e-56b6-403f-979a-20659ccde8b8/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:48:45 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:48:45 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=558586920
16/03/17 15:48:45 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 532.7 MB)
16/03/17 15:48:45 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:48:45 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:47286 (size: 179.0 B, free: 532.7 MB)
16/03/17 15:48:45 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=558586920
16/03/17 15:48:45 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 532.7 MB)
16/03/17 15:48:45 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:47286 (size: 173.0 B, free: 532.7 MB)
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: set
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: planning
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: permission
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: economy
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: composition
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: agency
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:48:54 INFO PythonRunner: Times: total = 8638, boot = 464, init = 369, finish = 7805
16/03/17 15:48:54 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:48:54 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8714 ms on localhost (1/2)
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: bend
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: giant
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: astatine
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: present
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  continuous  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: area
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): continuous
mapFunction_Parents(): keyword: continuous ; prevleveltokens: issue
mapFunction_Parents(): keyword= continuous ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/17 15:48:54 INFO PythonRunner: Times: total = 9237, boot = 475, init = 418, finish = 8344
16/03/17 15:48:55 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:48:55 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.308 s
16/03/17 15:48:55 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:48:55 INFO DAGScheduler: running: Set()
16/03/17 15:48:55 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:48:55 INFO DAGScheduler: failed: Set()
16/03/17 15:48:55 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:48:55 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:48:55 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=558586920
16/03/17 15:48:55 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 532.7 MB)
16/03/17 15:48:55 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=558586920
16/03/17 15:48:55 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 532.7 MB)
16/03/17 15:48:55 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9303 ms on localhost (2/2)
16/03/17 15:48:55 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:48:55 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:47286 (size: 3.0 KB, free: 532.7 MB)
16/03/17 15:48:55 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:48:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:55 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:48:55 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:48:55 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:48:55 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:48:55 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:48:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:48:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:48:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:48:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'present', 'None']
16/03/17 15:48:55 INFO PythonRunner: Times: total = 39, boot = -405, init = 443, finish = 1
16/03/17 15:48:55 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/17 15:48:55 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 58 ms on localhost (1/2)
16/03/17 15:48:55 INFO PythonRunner: Times: total = 215, boot = 213, init = 1, finish = 1
16/03/17 15:48:55 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:48:55 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 234 ms on localhost (2/2)
16/03/17 15:48:55 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:48:55 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.213 s
16/03/17 15:48:55 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.566169 s
16/03/17 15:48:55 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:48:55 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:48:55 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:55 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:48:55 INFO DAGScheduler: Missing parents: List()
16/03/17 15:48:55 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:48:55 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=558586920
16/03/17 15:48:55 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 532.7 MB)
16/03/17 15:48:55 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=558586920
16/03/17 15:48:55 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 532.7 MB)
16/03/17 15:48:55 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:47286 (size: 3.3 KB, free: 532.7 MB)
16/03/17 15:48:55 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:48:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:55 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:48:55 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:48:55 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/17 15:48:55 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:48:55 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:48:55 INFO PythonRunner: Times: total = 44, boot = -49, init = 93, finish = 0
16/03/17 15:48:55 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1351 bytes result sent to driver
16/03/17 15:48:55 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 54 ms on localhost (1/2)
16/03/17 15:48:55 INFO PythonRunner: Times: total = 138, boot = 137, init = 1, finish = 0
16/03/17 15:48:55 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:48:55 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 144 ms on localhost (2/2)
16/03/17 15:48:55 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:48:55 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.137 s
16/03/17 15:48:55 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.154692 s
16/03/17 15:48:55 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:48:55 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:48:55 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:48:55 INFO MemoryStore: MemoryStore cleared
16/03/17 15:48:55 INFO BlockManager: BlockManager stopped
16/03/17 15:48:55 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:48:55 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:48:55 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:48:55 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:48:55 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:48:56 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:48:56 INFO SecurityManager: Changing view acls to: root
16/03/17 15:48:56 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:48:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:48:56 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:48:56 INFO Remoting: Starting remoting
16/03/17 15:48:56 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:39701]
16/03/17 15:48:56 INFO Utils: Successfully started service 'sparkDriver' on port 39701.
16/03/17 15:48:56 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:48:56 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:48:56 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-46c29ecb-83ae-4d4b-96e6-046796224ea7
16/03/17 15:48:56 INFO MemoryStore: MemoryStore started with capacity 532.7 MB
16/03/17 15:48:56 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-00782282-b15a-4375-8761-5f4380296226
16/03/17 15:48:56 INFO HttpServer: Starting HTTP Server
16/03/17 15:48:56 INFO Utils: Successfully started service 'HTTP file server' on port 53488.
16/03/17 15:48:56 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:48:56 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:48:56 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:48:56 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-7f771020-eb4f-4953-8a80-7338c53dfb7e/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:48:56 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209936666
16/03/17 15:48:56 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:48:56 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:48:56 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44842.
16/03/17 15:48:56 INFO NettyBlockTransferService: Server created on 44842
16/03/17 15:48:56 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:48:56 INFO BlockManagerMasterEndpoint: Registering block manager localhost:44842 with 532.7 MB RAM, BlockManagerId(driver, localhost, 44842)
16/03/17 15:48:56 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:48:56 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:48:56 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:56 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:48:56 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:48:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:48:56 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:48:56 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=558586920
16/03/17 15:48:56 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 532.7 MB)
16/03/17 15:48:56 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=558586920
16/03/17 15:48:56 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 532.7 MB)
16/03/17 15:48:56 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:44842 (size: 4.1 KB, free: 532.7 MB)
16/03/17 15:48:56 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:48:56 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:48:56 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:48:56 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:48:56 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:48:56 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:48:56 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209936666
16/03/17 15:48:56 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:48:56 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-7f771020-eb4f-4953-8a80-7338c53dfb7e/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:48:56 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:48:56 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=558586920
16/03/17 15:48:56 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 532.7 MB)
16/03/17 15:48:56 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:44842 (size: 179.0 B, free: 532.7 MB)
16/03/17 15:48:56 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:48:56 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=558586920
16/03/17 15:48:56 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 532.7 MB)
16/03/17 15:48:56 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:44842 (size: 173.0 B, free: 532.7 MB)
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: set
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: planning
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: permission
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: economy
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: composition
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: agency
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:49:05 INFO PythonRunner: Times: total = 8291, boot = 468, init = 389, finish = 7434
16/03/17 15:49:05 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:49:05 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8358 ms on localhost (1/2)
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: bend
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: giant
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: astatine
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: present
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  western  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: area
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: issue
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
16/03/17 15:49:05 INFO PythonRunner: Times: total = 8897, boot = 471, init = 410, finish = 8016
16/03/17 15:49:05 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:49:05 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.967 s
16/03/17 15:49:05 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:49:05 INFO DAGScheduler: running: Set()
16/03/17 15:49:05 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:49:05 INFO DAGScheduler: failed: Set()
16/03/17 15:49:05 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:49:05 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:49:05 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=558586920
16/03/17 15:49:05 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 532.7 MB)
16/03/17 15:49:05 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=558586920
16/03/17 15:49:05 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 532.7 MB)
16/03/17 15:49:05 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8962 ms on localhost (2/2)
16/03/17 15:49:05 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:49:05 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:44842 (size: 3.0 KB, free: 532.7 MB)
16/03/17 15:49:05 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:49:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:49:05 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:49:05 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:49:05 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:49:05 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:49:05 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:49:05 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:49:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:49:05 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:49:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
reduceFunction_Parents(): returns= ['None', u'metropolitan', 'None']
16/03/17 15:49:05 INFO PythonRunner: Times: total = 23, boot = -421, init = 443, finish = 1
16/03/17 15:49:05 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1288 bytes result sent to driver
16/03/17 15:49:05 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 43 ms on localhost (1/2)
16/03/17 15:49:05 INFO PythonRunner: Times: total = 201, boot = 200, init = 0, finish = 1
16/03/17 15:49:05 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:49:05 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 220 ms on localhost (2/2)
16/03/17 15:49:05 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.206 s
16/03/17 15:49:05 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:49:05 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.206406 s
16/03/17 15:49:06 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:49:06 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:49:06 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:49:06 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:49:06 INFO DAGScheduler: Missing parents: List()
16/03/17 15:49:06 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:49:06 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=558586920
16/03/17 15:49:06 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 532.7 MB)
16/03/17 15:49:06 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=558586920
16/03/17 15:49:06 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 532.7 MB)
16/03/17 15:49:06 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:44842 (size: 3.3 KB, free: 532.7 MB)
16/03/17 15:49:06 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:49:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:49:06 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:49:06 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:49:06 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2369 bytes)
16/03/17 15:49:06 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:49:06 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:49:06 INFO PythonRunner: Times: total = 43, boot = -63, init = 106, finish = 0
16/03/17 15:49:06 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:49:06 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 50 ms on localhost (1/2)
16/03/17 15:49:06 INFO PythonRunner: Times: total = 69, boot = 69, init = 0, finish = 0
16/03/17 15:49:06 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1356 bytes result sent to driver
16/03/17 15:49:06 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 77 ms on localhost (2/2)
16/03/17 15:49:06 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:49:06 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.078 s
16/03/17 15:49:06 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.094340 s
16/03/17 15:49:06 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:49:06 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:49:06 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:49:06 INFO MemoryStore: MemoryStore cleared
16/03/17 15:49:06 INFO BlockManager: BlockManager stopped
16/03/17 15:49:06 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:49:06 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:49:06 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:49:06 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:49:06 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:49:06 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:49:07 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:49:07 INFO SecurityManager: Changing view acls to: root
16/03/17 15:49:07 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:49:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:49:07 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:49:07 INFO Remoting: Starting remoting
16/03/17 15:49:07 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:33529]
16/03/17 15:49:07 INFO Utils: Successfully started service 'sparkDriver' on port 33529.
16/03/17 15:49:07 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:49:07 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:49:07 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-dccb8b15-7586-453f-ad4b-bf2712278cfe
16/03/17 15:49:07 INFO MemoryStore: MemoryStore started with capacity 532.7 MB
16/03/17 15:49:07 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-392969b2-0136-47ac-9d44-843a0ba1c155
16/03/17 15:49:07 INFO HttpServer: Starting HTTP Server
16/03/17 15:49:07 INFO Utils: Successfully started service 'HTTP file server' on port 35130.
16/03/17 15:49:07 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:49:07 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:49:07 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:49:07 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-894a3f6f-b504-4152-8a7e-db0ecd95e7c1/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:49:07 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209947403
16/03/17 15:49:07 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:49:07 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:49:07 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49337.
16/03/17 15:49:07 INFO NettyBlockTransferService: Server created on 49337
16/03/17 15:49:07 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:49:07 INFO BlockManagerMasterEndpoint: Registering block manager localhost:49337 with 532.7 MB RAM, BlockManagerId(driver, localhost, 49337)
16/03/17 15:49:07 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:49:07 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:49:07 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:49:07 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:49:07 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:49:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:49:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:49:07 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:49:07 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=558586920
16/03/17 15:49:07 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 532.7 MB)
16/03/17 15:49:07 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=558586920
16/03/17 15:49:07 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 532.7 MB)
16/03/17 15:49:07 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:49337 (size: 4.1 KB, free: 532.7 MB)
16/03/17 15:49:07 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:49:07 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:49:07 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:49:07 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:49:07 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:49:07 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:49:07 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209947403
16/03/17 15:49:07 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:49:07 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-894a3f6f-b504-4152-8a7e-db0ecd95e7c1/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:49:07 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:49:07 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=558586920
16/03/17 15:49:07 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 532.7 MB)
16/03/17 15:49:07 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:49337 (size: 179.0 B, free: 532.7 MB)
16/03/17 15:49:07 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:49:07 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=558586920
16/03/17 15:49:07 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 532.7 MB)
16/03/17 15:49:07 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:49337 (size: 173.0 B, free: 532.7 MB)
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: area
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  particular  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: planning
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: permission
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: economy
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: composition
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: agency
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/17 15:49:15 INFO PythonRunner: Times: total = 8311, boot = 466, init = 422, finish = 7423
16/03/17 15:49:15 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:49:15 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8368 ms on localhost (1/2)
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: bend
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: giant
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: astatine
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: present
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: area
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  particular  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: issue
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/17 15:49:16 INFO PythonRunner: Times: total = 8833, boot = 475, init = 395, finish = 7963
16/03/17 15:49:16 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:49:16 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8882 ms on localhost (2/2)
16/03/17 15:49:16 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:49:16 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.884 s
16/03/17 15:49:16 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:49:16 INFO DAGScheduler: running: Set()
16/03/17 15:49:16 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:49:16 INFO DAGScheduler: failed: Set()
16/03/17 15:49:16 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:49:16 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:49:16 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=558586920
16/03/17 15:49:16 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 532.7 MB)
16/03/17 15:49:16 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=558586920
16/03/17 15:49:16 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 532.7 MB)
16/03/17 15:49:16 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:49337 (size: 3.0 KB, free: 532.7 MB)
16/03/17 15:49:16 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:49:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:49:16 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:49:16 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:49:16 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:49:16 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:49:16 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:49:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:49:16 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:49:16 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:49:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'area', u'area']
16/03/17 15:49:16 INFO PythonRunner: Times: total = 274, boot = 193, init = 81, finish = 0
16/03/17 15:49:16 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/17 15:49:16 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:49337 in memory (size: 4.1 KB, free: 532.7 MB)
16/03/17 15:49:16 INFO PythonRunner: Times: total = 293, boot = -328, init = 620, finish = 1
16/03/17 15:49:16 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 303 ms on localhost (1/2)
16/03/17 15:49:16 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:49:16 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.320 s
16/03/17 15:49:16 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.233047 s
16/03/17 15:49:16 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 331 ms on localhost (2/2)
16/03/17 15:49:16 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:49:16 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:49:16 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:49:16 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:49:16 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:49:16 INFO DAGScheduler: Missing parents: List()
16/03/17 15:49:16 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:49:16 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=8391, maxMem=558586920
16/03/17 15:49:16 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 532.7 MB)
16/03/17 15:49:16 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=14207, maxMem=558586920
16/03/17 15:49:16 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 532.7 MB)
16/03/17 15:49:16 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:49337 (size: 3.3 KB, free: 532.7 MB)
16/03/17 15:49:16 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:49:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:49:16 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:49:16 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:49:16 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/17 15:49:16 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:49:16 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:49:16 INFO PythonRunner: Times: total = 73, boot = 72, init = 0, finish = 1
16/03/17 15:49:16 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:49:16 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 82 ms on localhost (1/2)
16/03/17 15:49:16 INFO PythonRunner: Times: total = 125, boot = 124, init = 1, finish = 0
16/03/17 15:49:17 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/03/17 15:49:17 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 137 ms on localhost (2/2)
16/03/17 15:49:17 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:49:17 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.132 s
16/03/17 15:49:17 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.154709 s
16/03/17 15:49:17 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:49:17 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:49:17 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:49:17 INFO MemoryStore: MemoryStore cleared
16/03/17 15:49:17 INFO BlockManager: BlockManager stopped
16/03/17 15:49:17 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:49:17 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:49:17 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:49:17 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:49:17 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:49:17 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:49:18 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:49:18 INFO SecurityManager: Changing view acls to: root
16/03/17 15:49:18 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:49:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:49:18 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:49:18 INFO Remoting: Starting remoting
16/03/17 15:49:18 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:35322]
16/03/17 15:49:18 INFO Utils: Successfully started service 'sparkDriver' on port 35322.
16/03/17 15:49:18 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:49:18 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:49:18 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8b5e3a64-8182-4407-8ce8-3f7f03a1a4f6
16/03/17 15:49:18 INFO MemoryStore: MemoryStore started with capacity 530.1 MB
16/03/17 15:49:18 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-4e2df9c3-455a-43cb-9826-a397544d056b
16/03/17 15:49:18 INFO HttpServer: Starting HTTP Server
16/03/17 15:49:18 INFO Utils: Successfully started service 'HTTP file server' on port 42895.
16/03/17 15:49:18 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:49:18 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:49:18 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:49:18 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-9c4c0f7f-a2f0-430b-af90-066e2808a309/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:49:18 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209958240
16/03/17 15:49:18 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:49:18 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:49:18 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 48671.
16/03/17 15:49:18 INFO NettyBlockTransferService: Server created on 48671
16/03/17 15:49:18 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:49:18 INFO BlockManagerMasterEndpoint: Registering block manager localhost:48671 with 530.1 MB RAM, BlockManagerId(driver, localhost, 48671)
16/03/17 15:49:18 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:49:18 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:49:18 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:49:18 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:49:18 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:49:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:49:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:49:18 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:49:18 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555897323
16/03/17 15:49:18 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.1 MB)
16/03/17 15:49:18 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555897323
16/03/17 15:49:18 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.1 MB)
16/03/17 15:49:18 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:48671 (size: 4.1 KB, free: 530.1 MB)
16/03/17 15:49:18 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:49:18 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:49:18 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:49:18 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:49:18 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:49:18 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:49:18 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209958240
16/03/17 15:49:18 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:49:18 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-9c4c0f7f-a2f0-430b-af90-066e2808a309/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:49:18 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:49:18 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:49:18 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=555897323
16/03/17 15:49:18 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 530.1 MB)
16/03/17 15:49:18 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=555897323
16/03/17 15:49:18 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 530.1 MB)
16/03/17 15:49:18 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:48671 (size: 179.0 B, free: 530.1 MB)
16/03/17 15:49:18 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:48671 (size: 173.0 B, free: 530.1 MB)
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: area
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: bend
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: giant
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: astatine
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: present
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  given  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: area
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: issue
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
16/03/17 15:49:27 INFO PythonRunner: Times: total = 8995, boot = 478, init = 413, finish = 8104
16/03/17 15:49:27 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: kilometer
16/03/17 15:49:27 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9077 ms on localhost (1/2)
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: planning
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: permission
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: economy
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: composition
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: agency
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): given
mapFunction_Parents(): keyword: given ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= given ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:49:27 INFO PythonRunner: Times: total = 9092, boot = 472, init = 440, finish = 8180
16/03/17 15:49:27 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:49:27 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9163 ms on localhost (2/2)
16/03/17 15:49:27 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:49:27 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.168 s
16/03/17 15:49:27 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:49:27 INFO DAGScheduler: running: Set()
16/03/17 15:49:27 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:49:27 INFO DAGScheduler: failed: Set()
16/03/17 15:49:27 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:49:27 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:49:27 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=555897323
16/03/17 15:49:27 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.1 MB)
16/03/17 15:49:27 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=555897323
16/03/17 15:49:27 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.1 MB)
16/03/17 15:49:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:48671 (size: 3.0 KB, free: 530.1 MB)
16/03/17 15:49:27 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:49:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:49:27 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:49:27 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:49:27 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:49:27 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:49:27 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:49:27 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:49:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:49:27 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:49:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'metropolitan', 'None']
16/03/17 15:49:27 INFO PythonRunner: Times: total = 99, boot = 98, init = 0, finish = 1
16/03/17 15:49:27 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1288 bytes result sent to driver
16/03/17 15:49:27 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 111 ms on localhost (1/2)
16/03/17 15:49:27 INFO PythonRunner: Times: total = 231, boot = 230, init = 0, finish = 1
16/03/17 15:49:27 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:49:27 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.252 s
16/03/17 15:49:27 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.444804 s
16/03/17 15:49:27 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 251 ms on localhost (2/2)
16/03/17 15:49:27 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:49:27 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:49:27 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:49:27 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:49:27 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:49:27 INFO DAGScheduler: Missing parents: List()
16/03/17 15:49:27 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:49:27 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=555897323
16/03/17 15:49:27 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.1 MB)
16/03/17 15:49:27 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=555897323
16/03/17 15:49:27 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.1 MB)
16/03/17 15:49:27 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:48671 (size: 3.3 KB, free: 530.1 MB)
16/03/17 15:49:27 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:49:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:49:27 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:49:27 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:49:27 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2369 bytes)
16/03/17 15:49:27 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:49:27 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:49:27 INFO PythonRunner: Times: total = 8, boot = -70, init = 78, finish = 0
16/03/17 15:49:27 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1356 bytes result sent to driver
16/03/17 15:49:27 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 51 ms on localhost (1/2)
16/03/17 15:49:28 INFO PythonRunner: Times: total = 250, boot = 249, init = 1, finish = 0
16/03/17 15:49:28 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:49:28 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 256 ms on localhost (2/2)
16/03/17 15:49:28 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:49:28 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.249 s
16/03/17 15:49:28 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.281303 s
16/03/17 15:49:28 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:49:28 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:49:28 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:49:28 INFO MemoryStore: MemoryStore cleared
16/03/17 15:49:28 INFO BlockManager: BlockManager stopped
16/03/17 15:49:28 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:49:28 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:49:28 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:49:28 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:49:28 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:49:28 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:49:29 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:49:29 INFO SecurityManager: Changing view acls to: root
16/03/17 15:49:29 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:49:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:49:29 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:49:29 INFO Remoting: Starting remoting
16/03/17 15:49:29 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:34849]
16/03/17 15:49:29 INFO Utils: Successfully started service 'sparkDriver' on port 34849.
16/03/17 15:49:29 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:49:29 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:49:29 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-530948f9-2a2d-46e6-af90-2eda9e560365
16/03/17 15:49:29 INFO MemoryStore: MemoryStore started with capacity 530.1 MB
16/03/17 15:49:29 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-8c5ef003-4f4b-418a-8089-ac793e834363
16/03/17 15:49:29 INFO HttpServer: Starting HTTP Server
16/03/17 15:49:29 INFO Utils: Successfully started service 'HTTP file server' on port 50790.
16/03/17 15:49:29 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:49:29 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:49:29 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:49:29 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-a288e7ae-0f5c-4889-8ac5-b98ede2e83c8/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:49:29 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209969435
16/03/17 15:49:29 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:49:29 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:49:29 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46932.
16/03/17 15:49:29 INFO NettyBlockTransferService: Server created on 46932
16/03/17 15:49:29 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:49:29 INFO BlockManagerMasterEndpoint: Registering block manager localhost:46932 with 530.1 MB RAM, BlockManagerId(driver, localhost, 46932)
16/03/17 15:49:29 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:49:29 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:49:29 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:49:29 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:49:29 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:49:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:49:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:49:29 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:49:29 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555897323
16/03/17 15:49:29 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.1 MB)
16/03/17 15:49:29 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555897323
16/03/17 15:49:29 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.1 MB)
16/03/17 15:49:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:46932 (size: 4.1 KB, free: 530.1 MB)
16/03/17 15:49:29 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:49:29 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:49:29 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:49:29 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:49:29 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:49:29 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:49:29 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209969435
16/03/17 15:49:29 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:49:29 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-a288e7ae-0f5c-4889-8ac5-b98ede2e83c8/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:49:29 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:49:29 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=555897323
16/03/17 15:49:29 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 530.1 MB)
16/03/17 15:49:29 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:46932 (size: 179.0 B, free: 530.1 MB)
16/03/17 15:49:29 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:49:29 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=555897323
16/03/17 15:49:29 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 530.1 MB)
16/03/17 15:49:29 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:46932 (size: 173.0 B, free: 530.1 MB)
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: area
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  Synset('set.n.01') ; keyword:  kind  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: bend
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: giant
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: astatine
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: present
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: planning
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'a', u'for', u'of', u'definite'mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
, u'an'asfer_pickle_string_load(): picklef.readlines(): kind
, mapFunction_Parents(): keyword: kind ; prevleveltokens: metropolitan
u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: permission
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines():mapFunction_Parents(): keyword= kind kind ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])

mapFunction_Parents(): returns=mapFunction_Parents(): keyword: kind ; prevleveltokens: area
 []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: economy
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: composition
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: issue
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: agency
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): kind
mapFunction_Parents(): keyword: kind ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
mapFunction_Parents(): keyword= kind ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:49:38 INFO PythonRunner: Times: total = 8659, boot = 457, init = 407, finish = 7795
16/03/17 15:49:38 INFO PythonRunner: Times: total = 8666, boot = 456, init = 431, finish = 7779
16/03/17 15:49:38 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:49:38 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:49:38 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8781 ms on localhost (1/2)
16/03/17 15:49:38 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8783 ms on localhost (2/2)
16/03/17 15:49:38 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:49:38 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.785 s
16/03/17 15:49:38 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:49:38 INFO DAGScheduler: running: Set()
16/03/17 15:49:38 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:49:38 INFO DAGScheduler: failed: Set()
16/03/17 15:49:38 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:49:38 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:49:38 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=555897323
16/03/17 15:49:38 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.1 MB)
16/03/17 15:49:38 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16068, maxMem=555897323
16/03/17 15:49:38 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.1 MB)
16/03/17 15:49:38 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:46932 (size: 3.0 KB, free: 530.1 MB)
16/03/17 15:49:38 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:49:38 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:49:38 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:49:38 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:49:38 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:49:38 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:49:38 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:49:38 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:49:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:49:38 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:49:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
reduceFunction_Parents(): returns= [u'set', 'None']
16/03/17 15:49:38 INFO PythonRunner: Times: total = 148, boot = 146, init = 1, finish = 1
16/03/17 15:49:38 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1271 bytes result sent to driver
16/03/17 15:49:38 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 165 ms on localhost (1/2)
16/03/17 15:49:38 INFO PythonRunner: Times: total = 237, boot = 236, init = 0, finish = 1
16/03/17 15:49:38 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:49:38 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 259 ms on localhost (2/2)
16/03/17 15:49:38 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:49:38 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.259 s
16/03/17 15:49:38 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.085398 s
16/03/17 15:49:38 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:49:38 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:49:38 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:49:38 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:49:38 INFO DAGScheduler: Missing parents: List()
16/03/17 15:49:38 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:49:38 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19123, maxMem=555897323
16/03/17 15:49:38 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.1 MB)
16/03/17 15:49:38 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24939, maxMem=555897323
16/03/17 15:49:38 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.1 MB)
16/03/17 15:49:38 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:46932 (size: 3.3 KB, free: 530.1 MB)
16/03/17 15:49:38 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:49:38 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:49:38 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:49:38 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:49:38 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/17 15:49:38 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:49:38 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:49:38 INFO PythonRunner: Times: total = 16, boot = -91, init = 107, finish = 0
16/03/17 15:49:38 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:49:38 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 46 ms on localhost (1/2)
16/03/17 15:49:39 INFO PythonRunner: Times: total = 168, boot = 167, init = 0, finish = 1
16/03/17 15:49:39 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1336 bytes result sent to driver
16/03/17 15:49:39 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 179 ms on localhost (2/2)
16/03/17 15:49:39 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:49:39 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.182 s
16/03/17 15:49:39 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.209212 s
16/03/17 15:49:39 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:49:39 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:49:39 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:49:39 INFO MemoryStore: MemoryStore cleared
16/03/17 15:49:39 INFO BlockManager: BlockManager stopped
16/03/17 15:49:39 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:49:39 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:49:39 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:49:39 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:49:39 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:49:39 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:49:40 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:49:40 INFO SecurityManager: Changing view acls to: root
16/03/17 15:49:40 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:49:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:49:40 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:49:40 INFO Remoting: Starting remoting
16/03/17 15:49:40 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:42800]
16/03/17 15:49:40 INFO Utils: Successfully started service 'sparkDriver' on port 42800.
16/03/17 15:49:40 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:49:40 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:49:40 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2daf9767-a6b1-4f42-90b7-2232a10195b4
16/03/17 15:49:40 INFO MemoryStore: MemoryStore started with capacity 530.1 MB
16/03/17 15:49:40 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-72aa8079-b5f0-4cd4-9091-846139ed5eac
16/03/17 15:49:40 INFO HttpServer: Starting HTTP Server
16/03/17 15:49:40 INFO Utils: Successfully started service 'HTTP file server' on port 39667.
16/03/17 15:49:40 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:49:40 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:49:40 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:49:40 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-88205375-aef5-4d7b-b906-544b903aab6d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:49:40 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209980211
16/03/17 15:49:40 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:49:40 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:49:40 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45056.
16/03/17 15:49:40 INFO NettyBlockTransferService: Server created on 45056
16/03/17 15:49:40 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:49:40 INFO BlockManagerMasterEndpoint: Registering block manager localhost:45056 with 530.1 MB RAM, BlockManagerId(driver, localhost, 45056)
16/03/17 15:49:40 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:49:40 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:49:40 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:49:40 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:49:40 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:49:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:49:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:49:40 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:49:40 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555897323
16/03/17 15:49:40 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.1 MB)
16/03/17 15:49:40 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555897323
16/03/17 15:49:40 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.1 MB)
16/03/17 15:49:40 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:45056 (size: 4.1 KB, free: 530.1 MB)
16/03/17 15:49:40 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:49:40 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:49:40 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:49:40 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:49:40 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:49:40 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:49:40 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209980211
16/03/17 15:49:40 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:49:40 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-88205375-aef5-4d7b-b906-544b903aab6d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:49:40 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:49:40 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:49:40 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10732, maxMem=555897323
16/03/17 15:49:40 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 530.1 MB)
16/03/17 15:49:40 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10905, maxMem=555897323
16/03/17 15:49:40 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:45056 (size: 173.0 B, free: 530.1 MB)
16/03/17 15:49:40 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 530.1 MB)
16/03/17 15:49:40 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:45056 (size: 179.0 B, free: 530.1 MB)
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: area
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: planning
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: permission
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: economy
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: composition
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: agency
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:49:48 INFO PythonRunner: Times: total = 8477, boot = 483, init = 400, finish = 7594
16/03/17 15:49:48 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: bend
16/03/17 15:49:48 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8572 ms on localhost (1/2)
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: giant
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: astatine
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: present
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: area
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): official
mapFunction_Parents(): keyword: official ; prevleveltokens: issue
mapFunction_Parents(): keyword= official ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:49:49 INFO PythonRunner: Times: total = 8609, boot = 472, init = 399, finish = 7738
16/03/17 15:49:49 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:49:49 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8692 ms on localhost (2/2)
16/03/17 15:49:49 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:49:49 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.693 s
16/03/17 15:49:49 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:49:49 INFO DAGScheduler: running: Set()
16/03/17 15:49:49 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:49:49 INFO DAGScheduler: failed: Set()
16/03/17 15:49:49 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:49:49 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:49:49 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=555897323
16/03/17 15:49:49 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.1 MB)
16/03/17 15:49:49 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=555897323
16/03/17 15:49:49 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.1 MB)
16/03/17 15:49:49 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:45056 (size: 3.0 KB, free: 530.1 MB)
16/03/17 15:49:49 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:49:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:49:49 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:49:49 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:49:49 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:49:49 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:49:49 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:49:49 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:49:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:49:49 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:49:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', 'None']
16/03/17 15:49:49 INFO PythonRunner: Times: total = 74, boot = 73, init = 0, finish = 1
16/03/17 15:49:49 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1269 bytes result sent to driver
16/03/17 15:49:49 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 86 ms on localhost (1/2)
16/03/17 15:49:49 INFO PythonRunner: Times: total = 225, boot = 224, init = 0, finish = 1
16/03/17 15:49:49 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:49:49 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 241 ms on localhost (2/2)
16/03/17 15:49:49 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:49:49 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.242 s
16/03/17 15:49:49 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.992745 s
16/03/17 15:49:49 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:49:49 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:49:49 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:49:49 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:49:49 INFO DAGScheduler: Missing parents: List()
16/03/17 15:49:49 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:49:49 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=555897323
16/03/17 15:49:49 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.1 MB)
16/03/17 15:49:49 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24940, maxMem=555897323
16/03/17 15:49:49 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.1 MB)
16/03/17 15:49:49 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:45056 (size: 3.3 KB, free: 530.1 MB)
16/03/17 15:49:49 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:49:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:49:49 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:49:49 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:49:49 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2350 bytes)
16/03/17 15:49:49 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:49:49 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:49:49 INFO PythonRunner: Times: total = 9, boot = -24, init = 33, finish = 0
16/03/17 15:49:49 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:49:49 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 50 ms on localhost (1/2)
16/03/17 15:49:49 INFO PythonRunner: Times: total = 104, boot = 103, init = 1, finish = 0
16/03/17 15:49:49 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1337 bytes result sent to driver
16/03/17 15:49:49 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 121 ms on localhost (2/2)
16/03/17 15:49:49 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:49:49 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.107 s
16/03/17 15:49:49 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.131041 s
16/03/17 15:49:49 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:49:49 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:49:49 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:49:49 INFO MemoryStore: MemoryStore cleared
16/03/17 15:49:49 INFO BlockManager: BlockManager stopped
16/03/17 15:49:49 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:49:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:49:49 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:49:49 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:49:49 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:49:49 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:49:50 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:49:50 INFO SecurityManager: Changing view acls to: root
16/03/17 15:49:50 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:49:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:49:50 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:49:50 INFO Remoting: Starting remoting
16/03/17 15:49:50 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:49227]
16/03/17 15:49:50 INFO Utils: Successfully started service 'sparkDriver' on port 49227.
16/03/17 15:49:50 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:49:50 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:49:50 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-4bfb0524-141e-4e85-bdc2-e047df0ef2f3
16/03/17 15:49:50 INFO MemoryStore: MemoryStore started with capacity 530.1 MB
16/03/17 15:49:50 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-5b1002b7-32fe-44de-aa59-8d6bfd03d2f9
16/03/17 15:49:50 INFO HttpServer: Starting HTTP Server
16/03/17 15:49:50 INFO Utils: Successfully started service 'HTTP file server' on port 43566.
16/03/17 15:49:50 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:49:50 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:49:50 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:49:50 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-9c101235-1a0c-42b5-9cea-f40fce4346cc/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:49:51 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209990987
16/03/17 15:49:51 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:49:51 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:49:51 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55483.
16/03/17 15:49:51 INFO NettyBlockTransferService: Server created on 55483
16/03/17 15:49:51 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:49:51 INFO BlockManagerMasterEndpoint: Registering block manager localhost:55483 with 530.1 MB RAM, BlockManagerId(driver, localhost, 55483)
16/03/17 15:49:51 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:49:51 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:49:51 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:49:51 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:49:51 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:49:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:49:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:49:51 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:49:51 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555897323
16/03/17 15:49:51 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.1 MB)
16/03/17 15:49:51 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555897323
16/03/17 15:49:51 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.1 MB)
16/03/17 15:49:51 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:55483 (size: 4.1 KB, free: 530.1 MB)
16/03/17 15:49:51 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:49:51 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:49:51 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:49:51 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:49:51 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:49:51 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:49:51 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458209990987
16/03/17 15:49:51 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:49:51 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-9c101235-1a0c-42b5-9cea-f40fce4346cc/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:49:51 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:49:51 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10732, maxMem=555897323
16/03/17 15:49:51 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 530.1 MB)
16/03/17 15:49:51 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:55483 (size: 173.0 B, free: 530.1 MB)
16/03/17 15:49:51 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:49:51 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10905, maxMem=555897323
16/03/17 15:49:51 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 530.1 MB)
16/03/17 15:49:51 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:55483 (size: 179.0 B, free: 530.1 MB)
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: area
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: planning
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: permission
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: economy
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: composition
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: agency
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:49:59 INFO PythonRunner: Times: total = 8412, boot = 462, init = 400, finish = 7550
16/03/17 15:49:59 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:49:59 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8481 ms on localhost (1/2)
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: bend
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: giant
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: astatine
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: present
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  patriarch  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: area
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: issue
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
16/03/17 15:49:59 INFO PythonRunner: Times: total = 8667, boot = 459, init = 407, finish = 7801
16/03/17 15:49:59 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:49:59 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8720 ms on localhost (2/2)
16/03/17 15:49:59 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:49:59 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.722 s
16/03/17 15:49:59 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:49:59 INFO DAGScheduler: running: Set()
16/03/17 15:49:59 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:49:59 INFO DAGScheduler: failed: Set()
16/03/17 15:49:59 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:49:59 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:49:59 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=555897323
16/03/17 15:49:59 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.1 MB)
16/03/17 15:49:59 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=555897323
16/03/17 15:49:59 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.1 MB)
16/03/17 15:49:59 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:55483 (size: 3.0 KB, free: 530.1 MB)
16/03/17 15:49:59 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:49:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:49:59 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:49:59 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:49:59 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:49:59 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:49:59 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:49:59 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:49:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:49:59 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:49:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:49:59 INFO PythonRunner: Times: total = 20, boot = -72, init = 92, finish = 0
16/03/17 15:49:59 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:49:59 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 41 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'metropolitan', 'None']
16/03/17 15:50:00 INFO PythonRunner: Times: total = 220, boot = 219, init = 0, finish = 1
16/03/17 15:50:00 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1288 bytes result sent to driver
16/03/17 15:50:00 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 240 ms on localhost (2/2)
16/03/17 15:50:00 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:50:00 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.228 s
16/03/17 15:50:00 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.983780 s
16/03/17 15:50:00 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:50:00 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:50:00 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:00 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:50:00 INFO DAGScheduler: Missing parents: List()
16/03/17 15:50:00 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:50:00 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=555897323
16/03/17 15:50:00 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.1 MB)
16/03/17 15:50:00 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24940, maxMem=555897323
16/03/17 15:50:00 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.1 MB)
16/03/17 15:50:00 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:55483 (size: 3.3 KB, free: 530.1 MB)
16/03/17 15:50:00 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:50:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:00 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:50:00 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:50:00 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2369 bytes)
16/03/17 15:50:00 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:50:00 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:50:00 INFO PythonRunner: Times: total = 54, boot = -91, init = 145, finish = 0
16/03/17 15:50:00 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:50:00 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 64 ms on localhost (1/2)
16/03/17 15:50:00 INFO PythonRunner: Times: total = 103, boot = 102, init = 1, finish = 0
16/03/17 15:50:00 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1356 bytes result sent to driver
16/03/17 15:50:00 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 110 ms on localhost (2/2)
16/03/17 15:50:00 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.112 s
16/03/17 15:50:00 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.122575 s
16/03/17 15:50:00 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:50:00 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:50:00 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:50:00 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:50:00 INFO MemoryStore: MemoryStore cleared
16/03/17 15:50:00 INFO BlockManager: BlockManager stopped
16/03/17 15:50:00 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:50:00 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:50:00 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:50:00 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:50:00 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:50:00 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:50:01 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:50:01 INFO SecurityManager: Changing view acls to: root
16/03/17 15:50:01 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:50:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:50:01 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:50:01 INFO Remoting: Starting remoting
16/03/17 15:50:01 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:46769]
16/03/17 15:50:01 INFO Utils: Successfully started service 'sparkDriver' on port 46769.
16/03/17 15:50:01 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:50:01 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:50:01 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-080e0d5b-75cb-42c5-8d4f-8cbcd9371657
16/03/17 15:50:01 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
16/03/17 15:50:01 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-81084935-750a-497a-bfbb-3fabedea437e
16/03/17 15:50:01 INFO HttpServer: Starting HTTP Server
16/03/17 15:50:01 INFO Utils: Successfully started service 'HTTP file server' on port 41814.
16/03/17 15:50:01 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:50:01 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:50:01 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:50:01 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-2215a635-7f30-49a1-8d84-15292aee9145/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:50:01 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210001503
16/03/17 15:50:01 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:50:01 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:50:01 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55056.
16/03/17 15:50:01 INFO NettyBlockTransferService: Server created on 55056
16/03/17 15:50:01 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:50:01 INFO BlockManagerMasterEndpoint: Registering block manager localhost:55056 with 530.0 MB RAM, BlockManagerId(driver, localhost, 55056)
16/03/17 15:50:01 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:50:01 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:50:01 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:01 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:50:01 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:50:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:50:01 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:50:01 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555755765
16/03/17 15:50:01 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)
16/03/17 15:50:01 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555755765
16/03/17 15:50:01 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)
16/03/17 15:50:01 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:55056 (size: 4.1 KB, free: 530.0 MB)
16/03/17 15:50:01 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:50:01 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:01 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:50:01 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:50:01 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:50:01 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:50:01 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210001503
16/03/17 15:50:01 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:50:01 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-2215a635-7f30-49a1-8d84-15292aee9145/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:50:01 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:50:01 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=555755765
16/03/17 15:50:01 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 530.0 MB)
16/03/17 15:50:01 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:55056 (size: 179.0 B, free: 530.0 MB)
16/03/17 15:50:01 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:50:01 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=555755765
16/03/17 15:50:01 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 530.0 MB)
16/03/17 15:50:01 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:55056 (size: 173.0 B, free: 530.0 MB)
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: set
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: planning
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: permission
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: economy
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: composition
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: agency
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:50:09 INFO PythonRunner: Times: total = 8211, boot = 471, init = 383, finish = 7357
16/03/17 15:50:09 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:50:09 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8283 ms on localhost (1/2)
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: bend
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: giant
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: astatine
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: present
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  Church  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: area
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: issue
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
16/03/17 15:50:10 INFO PythonRunner: Times: total = 8943, boot = 473, init = 407, finish = 8063
16/03/17 15:50:10 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:50:10 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9016 ms on localhost (2/2)
16/03/17 15:50:10 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:50:10 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.033 s
16/03/17 15:50:10 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:50:10 INFO DAGScheduler: running: Set()
16/03/17 15:50:10 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:50:10 INFO DAGScheduler: failed: Set()
16/03/17 15:50:10 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:50:10 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:50:10 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=555755765
16/03/17 15:50:10 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.0 MB)
16/03/17 15:50:10 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=555755765
16/03/17 15:50:10 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.0 MB)
16/03/17 15:50:10 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:55056 (size: 3.0 KB, free: 530.0 MB)
16/03/17 15:50:10 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:50:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:10 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:50:10 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:50:10 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:50:10 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:50:10 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:50:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:50:10 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:50:10 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:50:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:50:10 INFO PythonRunner: Times: total = 24, boot = -548, init = 571, finish = 1
16/03/17 15:50:10 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:50:10 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 43 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'metropolitan', 'None']
16/03/17 15:50:10 INFO PythonRunner: Times: total = 212, boot = 211, init = 0, finish = 1
16/03/17 15:50:10 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1288 bytes result sent to driver
16/03/17 15:50:10 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.214 s
16/03/17 15:50:10 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.279263 s
16/03/17 15:50:10 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 226 ms on localhost (2/2)
16/03/17 15:50:10 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:50:10 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:50:10 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:50:10 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:10 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:50:10 INFO DAGScheduler: Missing parents: List()
16/03/17 15:50:10 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:50:10 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=555755765
16/03/17 15:50:10 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.0 MB)
16/03/17 15:50:11 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24940, maxMem=555755765
16/03/17 15:50:11 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
16/03/17 15:50:11 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:55056 (size: 3.3 KB, free: 530.0 MB)
16/03/17 15:50:11 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:50:11 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:11 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:50:11 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:50:11 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2369 bytes)
16/03/17 15:50:11 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:50:11 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:50:11 INFO PythonRunner: Times: total = 73, boot = -124, init = 197, finish = 0
16/03/17 15:50:11 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:50:11 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 81 ms on localhost (1/2)
16/03/17 15:50:11 INFO PythonRunner: Times: total = 120, boot = 119, init = 1, finish = 0
16/03/17 15:50:11 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1356 bytes result sent to driver
16/03/17 15:50:11 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 128 ms on localhost (2/2)
16/03/17 15:50:11 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:50:11 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.107 s
16/03/17 15:50:11 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.139262 s
16/03/17 15:50:11 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:50:11 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:50:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:50:11 INFO MemoryStore: MemoryStore cleared
16/03/17 15:50:11 INFO BlockManager: BlockManager stopped
16/03/17 15:50:11 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:50:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:50:11 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:50:11 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:50:11 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:50:11 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:50:12 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:50:12 INFO SecurityManager: Changing view acls to: root
16/03/17 15:50:12 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:50:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:50:12 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:50:12 INFO Remoting: Starting remoting
16/03/17 15:50:12 INFO Utils: Successfully started service 'sparkDriver' on port 40354.
16/03/17 15:50:12 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:40354]
16/03/17 15:50:12 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:50:12 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:50:12 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1f6e1164-8de4-4769-ac40-47fb3f793073
16/03/17 15:50:12 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
16/03/17 15:50:12 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-e0c3b456-a0d2-42db-b3f7-440dbdfcddd3
16/03/17 15:50:12 INFO HttpServer: Starting HTTP Server
16/03/17 15:50:12 INFO Utils: Successfully started service 'HTTP file server' on port 33497.
16/03/17 15:50:12 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:50:12 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:50:12 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:50:12 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-83c02b9e-40c7-4826-9cca-47b8af549742/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:50:12 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210012385
16/03/17 15:50:12 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:50:12 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:50:12 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37002.
16/03/17 15:50:12 INFO NettyBlockTransferService: Server created on 37002
16/03/17 15:50:12 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:50:12 INFO BlockManagerMasterEndpoint: Registering block manager localhost:37002 with 530.0 MB RAM, BlockManagerId(driver, localhost, 37002)
16/03/17 15:50:12 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:50:12 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:50:12 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:12 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:50:12 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:50:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:50:12 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:50:12 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555755765
16/03/17 15:50:12 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)
16/03/17 15:50:12 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555755765
16/03/17 15:50:12 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)
16/03/17 15:50:12 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:37002 (size: 4.1 KB, free: 530.0 MB)
16/03/17 15:50:12 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:50:12 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:12 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:50:12 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:50:12 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:50:12 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:50:12 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210012385
16/03/17 15:50:12 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:50:12 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-83c02b9e-40c7-4826-9cca-47b8af549742/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:50:12 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:50:12 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=555755765
16/03/17 15:50:12 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 530.0 MB)
16/03/17 15:50:12 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:37002 (size: 179.0 B, free: 530.0 MB)
16/03/17 15:50:12 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:50:12 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=555755765
16/03/17 15:50:12 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 530.0 MB)
16/03/17 15:50:12 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:37002 (size: 173.0 B, free: 530.0 MB)
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: set
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: planning
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: permission
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: economy
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): adding to parents: syn =  Synset('economy.n.01') ; keyword:  distribution  in syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= [u'economy']
reduceFunction_Parents(): returns= ['None', u'economy']
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: composition
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'economy']
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: agency
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'economy']
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'economy']
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'economy']
16/03/17 15:50:21 INFO PythonRunner: Times: total = 8640, boot = 500, init = 399, finish = 7741
16/03/17 15:50:21 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:50:21 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8729 ms on localhost (1/2)
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: bend
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: giant
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: astatine
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: present
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: area
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distribution
mapFunction_Parents(): keyword: distribution ; prevleveltokens: issue
mapFunction_Parents(): keyword= distribution ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:50:21 INFO PythonRunner: Times: total = 9006, boot = 502, init = 402, finish = 8102
16/03/17 15:50:21 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:50:21 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.100 s
16/03/17 15:50:21 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:50:21 INFO DAGScheduler: running: Set()
16/03/17 15:50:21 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:50:21 INFO DAGScheduler: failed: Set()
16/03/17 15:50:21 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:50:21 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:50:21 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=555755765
16/03/17 15:50:21 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.0 MB)
16/03/17 15:50:21 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=555755765
16/03/17 15:50:21 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.0 MB)
16/03/17 15:50:21 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9097 ms on localhost (2/2)
16/03/17 15:50:21 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:50:21 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:37002 (size: 3.0 KB, free: 530.0 MB)
16/03/17 15:50:21 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:50:21 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:21 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:50:21 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:50:21 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:50:21 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:50:21 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:50:21 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:50:21 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:50:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:50:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', 'None', u'economy']
16/03/17 15:50:21 INFO PythonRunner: Times: total = 35, boot = -201, init = 236, finish = 0
16/03/17 15:50:21 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/17 15:50:21 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 76 ms on localhost (1/2)
16/03/17 15:50:21 INFO PythonRunner: Times: total = 208, boot = 207, init = 0, finish = 1
16/03/17 15:50:21 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:50:21 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.232 s
16/03/17 15:50:21 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.367296 s
16/03/17 15:50:21 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 238 ms on localhost (2/2)
16/03/17 15:50:21 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:50:21 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:50:21 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:50:21 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:21 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:50:21 INFO DAGScheduler: Missing parents: List()
16/03/17 15:50:21 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:50:21 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=555755765
16/03/17 15:50:21 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.0 MB)
16/03/17 15:50:21 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24940, maxMem=555755765
16/03/17 15:50:21 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
16/03/17 15:50:21 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:37002 (size: 3.3 KB, free: 530.0 MB)
16/03/17 15:50:21 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:50:21 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:21 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:50:21 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:50:21 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/17 15:50:21 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:50:21 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:50:22 INFO PythonRunner: Times: total = 46, boot = -52, init = 98, finish = 0
16/03/17 15:50:22 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:50:22 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 58 ms on localhost (1/2)
16/03/17 15:50:22 INFO PythonRunner: Times: total = 130, boot = 130, init = 0, finish = 0
16/03/17 15:50:22 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1351 bytes result sent to driver
16/03/17 15:50:22 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 143 ms on localhost (2/2)
16/03/17 15:50:22 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:50:22 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.134 s
16/03/17 15:50:22 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.153567 s
16/03/17 15:50:22 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:50:22 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:50:22 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:50:22 INFO MemoryStore: MemoryStore cleared
16/03/17 15:50:22 INFO BlockManager: BlockManager stopped
16/03/17 15:50:22 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:50:22 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:50:22 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:50:22 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:50:22 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:50:22 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:50:23 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:50:23 INFO SecurityManager: Changing view acls to: root
16/03/17 15:50:23 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:50:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:50:23 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:50:23 INFO Remoting: Starting remoting
16/03/17 15:50:23 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:37352]
16/03/17 15:50:23 INFO Utils: Successfully started service 'sparkDriver' on port 37352.
16/03/17 15:50:23 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:50:23 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:50:23 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-24134a6a-aa8f-4682-bfa8-6c1ee9b2a51d
16/03/17 15:50:23 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
16/03/17 15:50:23 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-13e7ec6e-1913-4e31-8821-5da27922d08b
16/03/17 15:50:23 INFO HttpServer: Starting HTTP Server
16/03/17 15:50:23 INFO Utils: Successfully started service 'HTTP file server' on port 53556.
16/03/17 15:50:23 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:50:23 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:50:23 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:50:23 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-a89bd527-132a-4b06-a7aa-287cd13eb801/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:50:23 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210023341
16/03/17 15:50:23 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:50:23 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:50:23 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34605.
16/03/17 15:50:23 INFO NettyBlockTransferService: Server created on 34605
16/03/17 15:50:23 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:50:23 INFO BlockManagerMasterEndpoint: Registering block manager localhost:34605 with 530.0 MB RAM, BlockManagerId(driver, localhost, 34605)
16/03/17 15:50:23 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:50:23 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:50:23 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:23 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:50:23 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:50:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:50:23 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:50:23 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555755765
16/03/17 15:50:23 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)
16/03/17 15:50:23 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555755765
16/03/17 15:50:23 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)
16/03/17 15:50:23 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:34605 (size: 4.1 KB, free: 530.0 MB)
16/03/17 15:50:23 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:50:23 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:23 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:50:23 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:50:23 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:50:23 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:50:23 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210023341
16/03/17 15:50:23 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:50:23 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-a89bd527-132a-4b06-a7aa-287cd13eb801/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:50:23 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:50:23 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=555755765
16/03/17 15:50:23 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 530.0 MB)
16/03/17 15:50:23 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:34605 (size: 179.0 B, free: 530.0 MB)
16/03/17 15:50:23 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:50:23 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=555755765
16/03/17 15:50:23 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 530.0 MB)
16/03/17 15:50:23 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:34605 (size: 173.0 B, free: 530.0 MB)
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: set
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: bend
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: giant
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: astatine
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: present
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: area
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: issue
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:50:32 INFO PythonRunner: Times: total = 8535, boot = 470, init = 404, finish = 7661
16/03/17 15:50:32 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:50:32 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8780 ms on localhost (1/2)
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: planning
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: permission
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: economy
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: composition
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  property  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: agency
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): property
mapFunction_Parents(): keyword: property ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= property ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/17 15:50:32 INFO PythonRunner: Times: total = 8689, boot = 471, init = 402, finish = 7816
16/03/17 15:50:32 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:50:32 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.929 s
16/03/17 15:50:32 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:50:32 INFO DAGScheduler: running: Set()
16/03/17 15:50:32 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:50:32 INFO DAGScheduler: failed: Set()
16/03/17 15:50:32 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:50:32 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:50:32 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=555755765
16/03/17 15:50:32 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.0 MB)
16/03/17 15:50:32 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8931 ms on localhost (2/2)
16/03/17 15:50:32 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:50:32 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=555755765
16/03/17 15:50:32 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.0 MB)
16/03/17 15:50:32 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:34605 (size: 3.0 KB, free: 530.0 MB)
16/03/17 15:50:32 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:50:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:32 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:50:32 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:50:32 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:50:32 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:50:32 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:50:32 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:50:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:50:32 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:50:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:50:32 INFO PythonRunner: Times: total = 52, boot = 43, init = 8, finish = 1
16/03/17 15:50:32 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:50:32 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 71 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'composition']
16/03/17 15:50:32 INFO PythonRunner: Times: total = 241, boot = 240, init = 0, finish = 1
16/03/17 15:50:32 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1287 bytes result sent to driver
16/03/17 15:50:32 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.256 s
16/03/17 15:50:32 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.208485 s
16/03/17 15:50:32 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 254 ms on localhost (2/2)
16/03/17 15:50:32 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:50:32 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:50:32 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:50:32 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:32 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:50:32 INFO DAGScheduler: Missing parents: List()
16/03/17 15:50:32 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:50:32 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=555755765
16/03/17 15:50:32 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.0 MB)
16/03/17 15:50:32 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24940, maxMem=555755765
16/03/17 15:50:32 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
16/03/17 15:50:32 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:34605 (size: 3.3 KB, free: 530.0 MB)
16/03/17 15:50:32 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:50:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:32 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:50:32 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:50:32 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2368 bytes)
16/03/17 15:50:32 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:50:32 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:50:32 INFO PythonRunner: Times: total = 46, boot = -95, init = 141, finish = 0
16/03/17 15:50:32 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1355 bytes result sent to driver
16/03/17 15:50:32 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 55 ms on localhost (1/2)
16/03/17 15:50:32 INFO PythonRunner: Times: total = 112, boot = 112, init = 0, finish = 0
16/03/17 15:50:32 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:50:32 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 125 ms on localhost (2/2)
16/03/17 15:50:32 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:50:32 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.126 s
16/03/17 15:50:32 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.136637 s
16/03/17 15:50:32 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:50:32 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:50:33 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:50:33 INFO MemoryStore: MemoryStore cleared
16/03/17 15:50:33 INFO BlockManager: BlockManager stopped
16/03/17 15:50:33 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:50:33 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:50:33 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:50:33 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:50:33 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:50:33 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:50:33 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:50:33 INFO SecurityManager: Changing view acls to: root
16/03/17 15:50:33 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:50:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:50:33 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:50:33 INFO Remoting: Starting remoting
16/03/17 15:50:33 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:57563]
16/03/17 15:50:33 INFO Utils: Successfully started service 'sparkDriver' on port 57563.
16/03/17 15:50:34 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:50:34 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:50:34 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a84f42cd-0c8d-4d54-89d2-1f02d45625aa
16/03/17 15:50:34 INFO MemoryStore: MemoryStore started with capacity 528.5 MB
16/03/17 15:50:34 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-797b12cb-8b40-4551-89cc-29979fca646c
16/03/17 15:50:34 INFO HttpServer: Starting HTTP Server
16/03/17 15:50:34 INFO Utils: Successfully started service 'HTTP file server' on port 40399.
16/03/17 15:50:34 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:50:34 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:50:34 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:50:34 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-adb084aa-5b13-4184-9d8b-b6bd5380631c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:50:34 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210034107
16/03/17 15:50:34 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:50:34 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:50:34 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44575.
16/03/17 15:50:34 INFO NettyBlockTransferService: Server created on 44575
16/03/17 15:50:34 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:50:34 INFO BlockManagerMasterEndpoint: Registering block manager localhost:44575 with 528.5 MB RAM, BlockManagerId(driver, localhost, 44575)
16/03/17 15:50:34 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:50:34 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:50:34 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:34 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:50:34 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:50:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:50:34 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:50:34 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=554198630
16/03/17 15:50:34 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 528.5 MB)
16/03/17 15:50:34 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=554198630
16/03/17 15:50:34 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 528.5 MB)
16/03/17 15:50:34 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:44575 (size: 4.1 KB, free: 528.5 MB)
16/03/17 15:50:34 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:50:34 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:34 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:50:34 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:50:34 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:50:34 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:50:34 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210034107
16/03/17 15:50:34 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:50:34 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-adb084aa-5b13-4184-9d8b-b6bd5380631c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:50:34 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:50:34 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=554198630
16/03/17 15:50:34 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 528.5 MB)
16/03/17 15:50:34 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:44575 (size: 179.0 B, free: 528.5 MB)
16/03/17 15:50:34 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:50:34 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=554198630
16/03/17 15:50:34 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 528.5 MB)
16/03/17 15:50:34 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:44575 (size: 173.0 B, free: 528.5 MB)
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: set
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  distinguished  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: planning
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: permission
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: economy
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: composition
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: agency
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/17 15:50:43 INFO PythonRunner: Times: total = 9502, boot = 461, init = 409, finish = 8632
16/03/17 15:50:43 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:50:43 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9560 ms on localhost (1/2)
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: bend
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: giant
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: astatine
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: present
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: area
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  distinguished  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: issue
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/17 15:50:44 INFO PythonRunner: Times: total = 9736, boot = 474, init = 430, finish = 8832
16/03/17 15:50:44 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:50:44 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.792 s
16/03/17 15:50:44 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:50:44 INFO DAGScheduler: running: Set()
16/03/17 15:50:44 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:50:44 INFO DAGScheduler: failed: Set()
16/03/17 15:50:44 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:50:44 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:50:44 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=554198630
16/03/17 15:50:44 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 528.5 MB)
16/03/17 15:50:44 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=554198630
16/03/17 15:50:44 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 528.5 MB)
16/03/17 15:50:44 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9790 ms on localhost (2/2)
16/03/17 15:50:44 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:50:44 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:44575 (size: 3.0 KB, free: 528.5 MB)
16/03/17 15:50:44 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:50:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:44 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:50:44 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:50:44 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:50:44 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:50:44 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:50:44 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:50:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:50:44 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:50:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'area', u'area']
16/03/17 15:50:44 INFO PythonRunner: Times: total = 24, boot = -45, init = 69, finish = 0
16/03/17 15:50:44 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/17 15:50:44 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 62 ms on localhost (1/2)
16/03/17 15:50:44 INFO PythonRunner: Times: total = 195, boot = 194, init = 1, finish = 0
16/03/17 15:50:44 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:50:44 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.201 s
16/03/17 15:50:44 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 10.028901 s
16/03/17 15:50:44 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 214 ms on localhost (2/2)
16/03/17 15:50:44 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:50:44 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:50:44 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:50:44 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:44 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:50:44 INFO DAGScheduler: Missing parents: List()
16/03/17 15:50:44 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:50:44 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=554198630
16/03/17 15:50:44 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 528.5 MB)
16/03/17 15:50:44 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24940, maxMem=554198630
16/03/17 15:50:44 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 528.5 MB)
16/03/17 15:50:44 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:44575 (size: 3.3 KB, free: 528.5 MB)
16/03/17 15:50:44 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:50:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:44 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:50:44 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:50:44 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/17 15:50:44 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:50:44 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:50:44 INFO PythonRunner: Times: total = 49, boot = -45, init = 94, finish = 0
16/03/17 15:50:44 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:50:44 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 61 ms on localhost (1/2)
16/03/17 15:50:44 INFO PythonRunner: Times: total = 141, boot = 141, init = 0, finish = 0
16/03/17 15:50:44 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/03/17 15:50:44 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 155 ms on localhost (2/2)
16/03/17 15:50:44 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:50:44 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.145 s
16/03/17 15:50:44 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.165739 s
16/03/17 15:50:44 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:50:44 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:50:44 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:50:44 INFO MemoryStore: MemoryStore cleared
16/03/17 15:50:44 INFO BlockManager: BlockManager stopped
16/03/17 15:50:44 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:50:44 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:50:44 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:50:44 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:50:44 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:50:44 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:50:45 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:50:45 INFO SecurityManager: Changing view acls to: root
16/03/17 15:50:45 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:50:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:50:45 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:50:45 INFO Remoting: Starting remoting
16/03/17 15:50:45 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:37597]
16/03/17 15:50:45 INFO Utils: Successfully started service 'sparkDriver' on port 37597.
16/03/17 15:50:45 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:50:45 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:50:45 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2ca0b4c5-ac03-459b-ad95-fc068641b911
16/03/17 15:50:45 INFO MemoryStore: MemoryStore started with capacity 528.5 MB
16/03/17 15:50:45 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-b970f530-f927-418b-b026-bf7de1343b77
16/03/17 15:50:45 INFO HttpServer: Starting HTTP Server
16/03/17 15:50:45 INFO Utils: Successfully started service 'HTTP file server' on port 48351.
16/03/17 15:50:45 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:50:45 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:50:45 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:50:45 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-5a28872e-da44-4cf8-bad0-68d0bbc12fe5/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:50:45 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210045714
16/03/17 15:50:45 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:50:45 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:50:45 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59819.
16/03/17 15:50:45 INFO NettyBlockTransferService: Server created on 59819
16/03/17 15:50:45 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:50:45 INFO BlockManagerMasterEndpoint: Registering block manager localhost:59819 with 528.5 MB RAM, BlockManagerId(driver, localhost, 59819)
16/03/17 15:50:45 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:50:45 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:50:45 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:45 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:50:45 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:50:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:50:45 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:50:45 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=554198630
16/03/17 15:50:45 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 528.5 MB)
16/03/17 15:50:45 INFO MemoryStore: ensureFreeSpace(4157) called with curMem=6576, maxMem=554198630
16/03/17 15:50:45 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 528.5 MB)
16/03/17 15:50:45 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:59819 (size: 4.1 KB, free: 528.5 MB)
16/03/17 15:50:45 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:50:45 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:45 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:50:45 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:50:45 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:50:45 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:50:45 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210045714
16/03/17 15:50:45 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:50:45 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-5a28872e-da44-4cf8-bad0-68d0bbc12fe5/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:50:45 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:50:45 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:50:45 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10733, maxMem=554198630
16/03/17 15:50:45 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 528.5 MB)
16/03/17 15:50:45 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:59819 (size: 179.0 B, free: 528.5 MB)
16/03/17 15:50:45 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10912, maxMem=554198630
16/03/17 15:50:45 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 528.5 MB)
16/03/17 15:50:45 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:59819 (size: 173.0 B, free: 528.5 MB)
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: set
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): adding to parents: syn =  Synset('kilometer.n.01') ; keyword:  metric  in syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= [u'kilometer']
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: planning
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: permission
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: economy
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: composition
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: agency
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): adding to parents: syn =  Synset('kilometer.n.01') ; keyword:  metric  in syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= [u'kilometer']
reduceFunction_Parents(): returns= [u'kilometer', u'kilometer']
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'kilometer', u'kilometer']
16/03/17 15:50:54 INFO PythonRunner: Times: total = 8466, boot = 459, init = 399, finish = 7608
16/03/17 15:50:54 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:50:54 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8533 ms on localhost (1/2)
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: bend
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: giant
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: astatine
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: present
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: area
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): metric
mapFunction_Parents(): keyword: metric ; prevleveltokens: issue
mapFunction_Parents(): keyword= metric ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:50:54 INFO PythonRunner: Times: total = 8615, boot = 470, init = 391, finish = 7754
16/03/17 15:50:54 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:50:54 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.685 s
16/03/17 15:50:54 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:50:54 INFO DAGScheduler: running: Set()
16/03/17 15:50:54 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:50:54 INFO DAGScheduler: failed: Set()
16/03/17 15:50:54 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:50:54 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:50:54 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11085, maxMem=554198630
16/03/17 15:50:54 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 528.5 MB)
16/03/17 15:50:54 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16069, maxMem=554198630
16/03/17 15:50:54 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 528.5 MB)
16/03/17 15:50:54 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8682 ms on localhost (2/2)
16/03/17 15:50:54 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:59819 (size: 3.0 KB, free: 528.5 MB)
16/03/17 15:50:54 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:50:54 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:50:54 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:54 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:50:54 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:50:54 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:50:54 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:50:54 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:50:54 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:50:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:50:54 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:50:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:50:54 INFO PythonRunner: Times: total = 50, boot = 49, init = 1, finish = 0
16/03/17 15:50:54 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:50:54 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 68 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'kilometer', u'kilometer']
16/03/17 15:50:54 INFO PythonRunner: Times: total = 215, boot = 214, init = 0, finish = 1
16/03/17 15:50:54 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1279 bytes result sent to driver
16/03/17 15:50:54 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.240 s
16/03/17 15:50:54 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 240 ms on localhost (2/2)
16/03/17 15:50:54 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.946584 s
16/03/17 15:50:54 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:50:54 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:50:54 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:50:54 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:54 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:50:54 INFO DAGScheduler: Missing parents: List()
16/03/17 15:50:54 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:50:54 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19125, maxMem=554198630
16/03/17 15:50:54 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 528.5 MB)
16/03/17 15:50:54 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24941, maxMem=554198630
16/03/17 15:50:54 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 528.5 MB)
16/03/17 15:50:54 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:59819 (size: 3.3 KB, free: 528.5 MB)
16/03/17 15:50:54 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:50:54 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:54 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:50:54 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:50:54 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2360 bytes)
16/03/17 15:50:54 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:50:54 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:50:54 INFO PythonRunner: Times: total = 44, boot = -75, init = 119, finish = 0
16/03/17 15:50:54 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:50:54 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 53 ms on localhost (1/2)
16/03/17 15:50:55 INFO PythonRunner: Times: total = 139, boot = 139, init = 0, finish = 0
16/03/17 15:50:55 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1358 bytes result sent to driver
16/03/17 15:50:55 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 146 ms on localhost (2/2)
16/03/17 15:50:55 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:50:55 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.147 s
16/03/17 15:50:55 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.154937 s
16/03/17 15:50:55 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:50:55 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:50:55 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:50:55 INFO MemoryStore: MemoryStore cleared
16/03/17 15:50:55 INFO BlockManager: BlockManager stopped
16/03/17 15:50:55 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:50:55 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:50:55 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:50:55 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:50:55 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:50:55 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:50:56 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:50:56 INFO SecurityManager: Changing view acls to: root
16/03/17 15:50:56 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:50:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:50:56 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:50:56 INFO Remoting: Starting remoting
16/03/17 15:50:56 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:51741]
16/03/17 15:50:56 INFO Utils: Successfully started service 'sparkDriver' on port 51741.
16/03/17 15:50:56 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:50:56 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:50:56 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3b46e972-6818-41d8-8d55-a12dac1fdd74
16/03/17 15:50:56 INFO MemoryStore: MemoryStore started with capacity 528.5 MB
16/03/17 15:50:56 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-20807971-8a7c-461c-8be8-e54efe7eb289
16/03/17 15:50:56 INFO HttpServer: Starting HTTP Server
16/03/17 15:50:56 INFO Utils: Successfully started service 'HTTP file server' on port 49102.
16/03/17 15:50:56 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:50:56 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:50:56 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:50:56 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-cd61cec1-cf4d-4988-83d9-e99d1ffd0255/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:50:56 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210056275
16/03/17 15:50:56 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:50:56 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:50:56 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49431.
16/03/17 15:50:56 INFO NettyBlockTransferService: Server created on 49431
16/03/17 15:50:56 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:50:56 INFO BlockManagerMasterEndpoint: Registering block manager localhost:49431 with 528.5 MB RAM, BlockManagerId(driver, localhost, 49431)
16/03/17 15:50:56 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:50:56 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:50:56 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:56 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:50:56 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:50:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:50:56 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:50:56 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=554198630
16/03/17 15:50:56 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 528.5 MB)
16/03/17 15:50:56 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=554198630
16/03/17 15:50:56 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 528.5 MB)
16/03/17 15:50:56 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:49431 (size: 4.1 KB, free: 528.5 MB)
16/03/17 15:50:56 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:50:56 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:50:56 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:50:56 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:50:56 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:50:56 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:50:56 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210056275
16/03/17 15:50:56 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:50:56 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-cd61cec1-cf4d-4988-83d9-e99d1ffd0255/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:50:56 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:50:56 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10732, maxMem=554198630
16/03/17 15:50:56 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 528.5 MB)
16/03/17 15:50:56 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:49431 (size: 173.0 B, free: 528.5 MB)
16/03/17 15:50:56 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:50:56 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10905, maxMem=554198630
16/03/17 15:50:56 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 528.5 MB)
16/03/17 15:50:56 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:49431 (size: 179.0 B, free: 528.5 MB)
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: area
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: bend
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: giant
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: astatine
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  heaviest  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: present
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: area
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: issue
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/17 15:51:05 INFO PythonRunner: Times: total = 8694, boot = 474, init = 381, finish = 7839
16/03/17 15:51:05 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:51:05 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8777 ms on localhost (1/2)
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: planning
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: permission
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: economy
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: composition
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: agency
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): heaviest
mapFunction_Parents(): keyword: heaviest ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= heaviest ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:51:05 INFO PythonRunner: Times: total = 8793, boot = 482, init = 413, finish = 7898
16/03/17 15:51:05 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:51:05 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8890 ms on localhost (2/2)
16/03/17 15:51:05 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:51:05 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.887 s
16/03/17 15:51:05 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:51:05 INFO DAGScheduler: running: Set()
16/03/17 15:51:05 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:51:05 INFO DAGScheduler: failed: Set()
16/03/17 15:51:05 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:51:05 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:51:05 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=554198630
16/03/17 15:51:05 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 528.5 MB)
16/03/17 15:51:05 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=554198630
16/03/17 15:51:05 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 528.5 MB)
16/03/17 15:51:05 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:49431 (size: 3.0 KB, free: 528.5 MB)
16/03/17 15:51:05 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:51:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:51:05 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:51:05 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:51:05 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:51:05 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:51:05 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:51:05 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:51:05 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:51:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:51:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'astatine', 'None']
16/03/17 15:51:05 INFO PythonRunner: Times: total = 134, boot = 133, init = 0, finish = 1
16/03/17 15:51:05 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/03/17 15:51:05 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 149 ms on localhost (1/2)
16/03/17 15:51:05 INFO PythonRunner: Times: total = 196, boot = 195, init = 0, finish = 1
16/03/17 15:51:05 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:51:05 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 214 ms on localhost (2/2)
16/03/17 15:51:05 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:51:05 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.211 s
16/03/17 15:51:05 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.126879 s
16/03/17 15:51:05 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:51:05 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:51:05 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:51:05 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:51:05 INFO DAGScheduler: Missing parents: List()
16/03/17 15:51:05 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:51:05 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=554198630
16/03/17 15:51:05 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 528.5 MB)
16/03/17 15:51:05 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24940, maxMem=554198630
16/03/17 15:51:05 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 528.5 MB)
16/03/17 15:51:05 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:49431 (size: 3.3 KB, free: 528.5 MB)
16/03/17 15:51:05 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:51:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:51:05 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:51:05 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:49431 in memory (size: 3.0 KB, free: 528.5 MB)
16/03/17 15:51:05 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:51:05 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/03/17 15:51:05 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:51:05 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:51:05 INFO PythonRunner: Times: total = 12, boot = -136, init = 148, finish = 0
16/03/17 15:51:05 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/03/17 15:51:05 INFO PythonRunner: Times: total = 34, boot = -251, init = 285, finish = 0
16/03/17 15:51:05 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:51:05 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 53 ms on localhost (1/2)
16/03/17 15:51:05 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 53 ms on localhost (2/2)
16/03/17 15:51:05 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:51:05 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.057 s
16/03/17 15:51:05 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.379403 s
16/03/17 15:51:05 INFO ContextCleaner: Cleaned accumulator 287
16/03/17 15:51:05 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:49431 in memory (size: 4.1 KB, free: 528.5 MB)
16/03/17 15:51:06 INFO ContextCleaner: Cleaned accumulator 286
16/03/17 15:51:06 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:51:06 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:51:06 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:51:06 INFO MemoryStore: MemoryStore cleared
16/03/17 15:51:06 INFO BlockManager: BlockManager stopped
16/03/17 15:51:06 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:51:06 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:51:06 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:51:06 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:51:06 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:51:06 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:51:06 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:51:07 INFO SecurityManager: Changing view acls to: root
16/03/17 15:51:07 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:51:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:51:07 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:51:07 INFO Remoting: Starting remoting
16/03/17 15:51:07 INFO Utils: Successfully started service 'sparkDriver' on port 48444.
16/03/17 15:51:07 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:48444]
16/03/17 15:51:07 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:51:07 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:51:07 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5168eb04-dd49-465f-b04d-342bdabb7651
16/03/17 15:51:07 INFO MemoryStore: MemoryStore started with capacity 524.7 MB
16/03/17 15:51:07 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-0e6ba6ce-e382-4032-acc7-c52fc67d0d09
16/03/17 15:51:07 INFO HttpServer: Starting HTTP Server
16/03/17 15:51:07 INFO Utils: Successfully started service 'HTTP file server' on port 57178.
16/03/17 15:51:07 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:51:07 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:51:07 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:51:07 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-587f71b9-b97e-4343-8c5b-a42722adc2a7/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:51:07 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210067242
16/03/17 15:51:07 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:51:07 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:51:07 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35970.
16/03/17 15:51:07 INFO NettyBlockTransferService: Server created on 35970
16/03/17 15:51:07 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:51:07 INFO BlockManagerMasterEndpoint: Registering block manager localhost:35970 with 524.7 MB RAM, BlockManagerId(driver, localhost, 35970)
16/03/17 15:51:07 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:51:07 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:51:07 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:51:07 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:51:07 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:51:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:51:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:51:07 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:51:07 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=550235013
16/03/17 15:51:07 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 524.7 MB)
16/03/17 15:51:07 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=550235013
16/03/17 15:51:07 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 524.7 MB)
16/03/17 15:51:07 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:35970 (size: 4.1 KB, free: 524.7 MB)
16/03/17 15:51:07 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:51:07 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:51:07 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:51:07 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:51:07 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:51:07 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:51:07 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210067242
16/03/17 15:51:07 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:51:07 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-587f71b9-b97e-4343-8c5b-a42722adc2a7/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:51:07 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:51:07 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:51:07 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10732, maxMem=550235013
16/03/17 15:51:07 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 524.7 MB)
16/03/17 15:51:07 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10905, maxMem=550235013
16/03/17 15:51:07 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 524.7 MB)
16/03/17 15:51:07 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:35970 (size: 173.0 B, free: 524.7 MB)
16/03/17 15:51:07 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:35970 (size: 179.0 B, free: 524.7 MB)
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: area
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: bend
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: giant
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: astatine
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: present
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: area
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: issue
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:51:16 INFO PythonRunner: Times: total = 8570, boot = 464, init = 460, finish = 7646
16/03/17 15:51:16 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:51:16 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8632 ms on localhost (1/2)
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: planning
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: permission
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: economy
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: composition
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: agency
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purposes
mapFunction_Parents(): keyword: purposes ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= purposes ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:51:16 INFO PythonRunner: Times: total = 8906, boot = 462, init = 471, finish = 7973
16/03/17 15:51:16 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:51:16 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.966 s
16/03/17 15:51:16 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:51:16 INFO DAGScheduler: running: Set()
16/03/17 15:51:16 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:51:16 INFO DAGScheduler: failed: Set()
16/03/17 15:51:16 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:51:16 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:51:16 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=550235013
16/03/17 15:51:16 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 524.7 MB)
16/03/17 15:51:16 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=550235013
16/03/17 15:51:16 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 524.7 MB)
16/03/17 15:51:16 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8961 ms on localhost (2/2)
16/03/17 15:51:16 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:51:16 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:35970 (size: 3.0 KB, free: 524.7 MB)
16/03/17 15:51:16 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:51:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:51:16 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:51:16 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:51:16 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:51:16 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:51:16 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:51:16 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:51:16 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:51:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:51:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', 'None']
16/03/17 15:51:16 INFO PythonRunner: Times: total = 21, boot = -166, init = 186, finish = 1
16/03/17 15:51:16 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1269 bytes result sent to driver
16/03/17 15:51:16 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 42 ms on localhost (1/2)
16/03/17 15:51:16 INFO PythonRunner: Times: total = 221, boot = 220, init = 0, finish = 1
16/03/17 15:51:16 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:51:16 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 230 ms on localhost (2/2)
16/03/17 15:51:16 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:51:16 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.235 s
16/03/17 15:51:16 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.223720 s
16/03/17 15:51:16 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:51:16 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:51:16 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:51:16 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:51:16 INFO DAGScheduler: Missing parents: List()
16/03/17 15:51:16 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:51:16 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=550235013
16/03/17 15:51:16 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 524.7 MB)
16/03/17 15:51:16 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24940, maxMem=550235013
16/03/17 15:51:16 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 524.7 MB)
16/03/17 15:51:16 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:35970 (size: 3.3 KB, free: 524.7 MB)
16/03/17 15:51:16 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:51:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:51:16 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:51:16 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:51:16 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2350 bytes)
16/03/17 15:51:16 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:51:16 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:51:16 INFO PythonRunner: Times: total = 47, boot = -132, init = 179, finish = 0
16/03/17 15:51:16 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1337 bytes result sent to driver
16/03/17 15:51:16 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 54 ms on localhost (1/2)
16/03/17 15:51:16 INFO PythonRunner: Times: total = 130, boot = 130, init = 0, finish = 0
16/03/17 15:51:16 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:51:16 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 135 ms on localhost (2/2)
16/03/17 15:51:16 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:51:16 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.134 s
16/03/17 15:51:16 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.146476 s
16/03/17 15:51:16 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:51:16 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:51:16 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:51:16 INFO MemoryStore: MemoryStore cleared
16/03/17 15:51:16 INFO BlockManager: BlockManager stopped
16/03/17 15:51:16 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:51:16 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:51:16 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:51:17 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:51:17 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:51:17 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:51:17 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:51:17 INFO SecurityManager: Changing view acls to: root
16/03/17 15:51:17 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:51:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:51:17 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:51:17 INFO Remoting: Starting remoting
16/03/17 15:51:17 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:49863]
16/03/17 15:51:17 INFO Utils: Successfully started service 'sparkDriver' on port 49863.
16/03/17 15:51:17 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:51:17 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:51:17 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9e132028-36ab-4ea6-8ea1-dc25fca19d9a
16/03/17 15:51:17 INFO MemoryStore: MemoryStore started with capacity 524.7 MB
16/03/17 15:51:17 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-250ca469-5299-4f55-b637-131f0c15e32b
16/03/17 15:51:17 INFO HttpServer: Starting HTTP Server
16/03/17 15:51:18 INFO Utils: Successfully started service 'HTTP file server' on port 44254.
16/03/17 15:51:18 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:51:18 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:51:18 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:51:18 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-930b8393-990e-4220-b164-980cb3d7f379/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:51:18 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210078068
16/03/17 15:51:18 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:51:18 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:51:18 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35026.
16/03/17 15:51:18 INFO NettyBlockTransferService: Server created on 35026
16/03/17 15:51:18 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:51:18 INFO BlockManagerMasterEndpoint: Registering block manager localhost:35026 with 524.7 MB RAM, BlockManagerId(driver, localhost, 35026)
16/03/17 15:51:18 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:51:18 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:51:18 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:51:18 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:51:18 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:51:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:51:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:51:18 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:51:18 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=550235013
16/03/17 15:51:18 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 524.7 MB)
16/03/17 15:51:18 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=550235013
16/03/17 15:51:18 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 524.7 MB)
16/03/17 15:51:18 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:35026 (size: 4.1 KB, free: 524.7 MB)
16/03/17 15:51:18 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:51:18 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:51:18 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:51:18 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:51:18 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:51:18 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:51:18 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210078068
16/03/17 15:51:18 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:51:18 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-930b8393-990e-4220-b164-980cb3d7f379/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:51:18 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:51:18 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=550235013
16/03/17 15:51:18 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 524.7 MB)
16/03/17 15:51:18 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:35026 (size: 179.0 B, free: 524.7 MB)
16/03/17 15:51:18 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:51:18 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=550235013
16/03/17 15:51:18 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 524.7 MB)
16/03/17 15:51:18 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:35026 (size: 173.0 B, free: 524.7 MB)
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: asfer_pickle_string_load(): picklef.readlines():general general
mapFunction_Parents(): keyword:  general ; prevleveltokens: area
; prevleveltokens: set
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: bend
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: giant
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: astatine
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: present
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: area
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: issue
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:51:26 INFO PythonRunner: Times: total = 8636, boot = 461, init = 393, finish = 7782
16/03/17 15:51:26 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:51:26 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8708 ms on localhost (1/2)
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: planning
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: permission
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: economy
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: composition
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: agency
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): general
mapFunction_Parents(): keyword: general ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= general ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:51:27 INFO PythonRunner: Times: total = 8863, boot = 461, init = 401, finish = 8001
16/03/17 15:51:27 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:51:27 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8918 ms on localhost (2/2)
16/03/17 15:51:27 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:51:27 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.923 s
16/03/17 15:51:27 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:51:27 INFO DAGScheduler: running: Set()
16/03/17 15:51:27 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:51:27 INFO DAGScheduler: failed: Set()
16/03/17 15:51:27 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:51:27 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:51:27 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=550235013
16/03/17 15:51:27 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 524.7 MB)
16/03/17 15:51:27 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=550235013
16/03/17 15:51:27 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 524.7 MB)
16/03/17 15:51:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:35026 (size: 3.0 KB, free: 524.7 MB)
16/03/17 15:51:27 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:51:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:51:27 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:51:27 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:51:27 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:51:27 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:51:27 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:51:27 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:51:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:51:27 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:51:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:51:27 INFO PythonRunner: Times: total = 33, boot = -41, init = 73, finish = 1
16/03/17 15:51:27 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:51:27 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 52 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None']
16/03/17 15:51:27 INFO PythonRunner: Times: total = 205, boot = 204, init = 0, finish = 1
16/03/17 15:51:27 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1269 bytes result sent to driver
16/03/17 15:51:27 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 219 ms on localhost (2/2)
16/03/17 15:51:27 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:51:27 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.220 s
16/03/17 15:51:27 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.163000 s
16/03/17 15:51:27 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:51:27 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:51:27 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:51:27 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:51:27 INFO DAGScheduler: Missing parents: List()
16/03/17 15:51:27 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:51:27 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=550235013
16/03/17 15:51:27 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 524.7 MB)
16/03/17 15:51:27 INFO MemoryStore: ensureFreeSpace(3377) called with curMem=24940, maxMem=550235013
16/03/17 15:51:27 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 524.7 MB)
16/03/17 15:51:27 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:35026 (size: 3.3 KB, free: 524.7 MB)
16/03/17 15:51:27 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:51:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:51:27 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:51:27 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:51:27 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2350 bytes)
16/03/17 15:51:27 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:51:27 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:51:27 INFO PythonRunner: Times: total = 53, boot = -71, init = 124, finish = 0
16/03/17 15:51:27 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:51:27 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 61 ms on localhost (1/2)
16/03/17 15:51:27 INFO PythonRunner: Times: total = 115, boot = 115, init = 0, finish = 0
16/03/17 15:51:27 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1337 bytes result sent to driver
16/03/17 15:51:27 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 124 ms on localhost (2/2)
16/03/17 15:51:27 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:51:27 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.109 s
16/03/17 15:51:27 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.134954 s
16/03/17 15:51:27 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:51:27 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:51:27 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:51:27 INFO MemoryStore: MemoryStore cleared
16/03/17 15:51:27 INFO BlockManager: BlockManager stopped
16/03/17 15:51:27 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:51:27 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:51:27 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:51:27 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:51:27 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:51:27 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:51:28 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:51:28 INFO SecurityManager: Changing view acls to: root
16/03/17 15:51:28 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:51:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:51:28 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:51:28 INFO Remoting: Starting remoting
16/03/17 15:51:28 INFO Utils: Successfully started service 'sparkDriver' on port 47636.
16/03/17 15:51:28 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:47636]
16/03/17 15:51:28 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:51:28 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:51:28 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-13869b45-cb3a-4093-ac50-436f84192bf9
16/03/17 15:51:28 INFO MemoryStore: MemoryStore started with capacity 524.7 MB
16/03/17 15:51:28 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-7f9f0b3c-31b0-45f1-b1c3-dc567b621e22
16/03/17 15:51:28 INFO HttpServer: Starting HTTP Server
16/03/17 15:51:28 INFO Utils: Successfully started service 'HTTP file server' on port 33172.
16/03/17 15:51:28 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:51:28 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:51:28 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:51:28 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-a92ab672-14d5-4d17-96a1-858fffad2b56/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:51:28 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210088839
16/03/17 15:51:28 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:51:28 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:51:28 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59352.
16/03/17 15:51:28 INFO NettyBlockTransferService: Server created on 59352
16/03/17 15:51:28 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:51:28 INFO BlockManagerMasterEndpoint: Registering block manager localhost:59352 with 524.7 MB RAM, BlockManagerId(driver, localhost, 59352)
16/03/17 15:51:28 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:51:28 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:51:28 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:51:28 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:51:28 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:51:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:51:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:51:28 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:51:28 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=550235013
16/03/17 15:51:28 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 524.7 MB)
16/03/17 15:51:28 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=550235013
16/03/17 15:51:28 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 524.7 MB)
16/03/17 15:51:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:59352 (size: 4.1 KB, free: 524.7 MB)
16/03/17 15:51:28 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:51:28 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:51:28 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:51:28 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:51:28 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:51:28 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:51:28 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210088839
16/03/17 15:51:28 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:51:28 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-a92ab672-14d5-4d17-96a1-858fffad2b56/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:51:28 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:51:29 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:51:29 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=550235013
16/03/17 15:51:29 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 524.7 MB)
16/03/17 15:51:29 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:59352 (size: 179.0 B, free: 524.7 MB)
16/03/17 15:51:29 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=550235013
16/03/17 15:51:29 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 524.7 MB)
16/03/17 15:51:29 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:59352 (size: 173.0 B, free: 524.7 MB)
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: set
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: planning
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: permission
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): adding to parents: syn =  Synset('permission.n.01') ; keyword:  something  in syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= [u'permission']
reduceFunction_Parents(): returns= ['None', u'permission']
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: economy
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'permission']
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: composition
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'permission']
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: agency
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'permission']
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'permission']
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'permission']
16/03/17 15:51:37 INFO PythonRunner: Times: total = 8469, boot = 462, init = 388, finish = 7619
16/03/17 15:51:37 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:51:37 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8524 ms on localhost (1/2)
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: bend
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: giant
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: astatine
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: present
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: area
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): something
mapFunction_Parents(): keyword: something ; prevleveltokens: issue
mapFunction_Parents(): keyword= something ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:51:37 INFO PythonRunner: Times: total = 8766, boot = 462, init = 398, finish = 7906
16/03/17 15:51:37 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:51:37 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.819 s
16/03/17 15:51:37 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:51:37 INFO DAGScheduler: running: Set()
16/03/17 15:51:37 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:51:37 INFO DAGScheduler: failed: Set()
16/03/17 15:51:37 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:51:37 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:51:37 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=550235013
16/03/17 15:51:37 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 524.7 MB)
16/03/17 15:51:37 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=550235013
16/03/17 15:51:37 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 524.7 MB)
16/03/17 15:51:37 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8817 ms on localhost (2/2)
16/03/17 15:51:37 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:51:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:59352 (size: 3.0 KB, free: 524.7 MB)
16/03/17 15:51:37 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:51:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:51:37 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:51:37 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:51:37 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:51:37 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:51:37 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:51:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:51:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:51:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:51:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', 'None', u'permission']
16/03/17 15:51:37 INFO PythonRunner: Times: total = 26, boot = -123, init = 148, finish = 1
16/03/17 15:51:37 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1286 bytes result sent to driver
16/03/17 15:51:37 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 55 ms on localhost (1/2)
16/03/17 15:51:38 INFO PythonRunner: Times: total = 223, boot = 222, init = 1, finish = 0
16/03/17 15:51:38 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:51:38 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 244 ms on localhost (2/2)
16/03/17 15:51:38 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:51:38 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.244 s
16/03/17 15:51:38 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.082264 s
16/03/17 15:51:38 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:51:38 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:51:38 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:51:38 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:51:38 INFO DAGScheduler: Missing parents: List()
16/03/17 15:51:38 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:51:38 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=550235013
16/03/17 15:51:38 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 524.7 MB)
16/03/17 15:51:38 INFO MemoryStore: ensureFreeSpace(3379) called with curMem=24940, maxMem=550235013
16/03/17 15:51:38 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 524.7 MB)
16/03/17 15:51:38 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:59352 (size: 3.3 KB, free: 524.7 MB)
16/03/17 15:51:38 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:51:38 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:51:38 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:51:38 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:51:38 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2367 bytes)
16/03/17 15:51:38 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:51:38 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:51:38 INFO PythonRunner: Times: total = 265, boot = 103, init = 162, finish = 0
16/03/17 15:51:38 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:51:38 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 286 ms on localhost (1/2)
16/03/17 15:51:38 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:59352 in memory (size: 3.0 KB, free: 524.7 MB)
16/03/17 15:51:38 INFO PythonRunner: Times: total = 300, boot = -75, init = 375, finish = 0
16/03/17 15:51:38 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1354 bytes result sent to driver
16/03/17 15:51:38 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 317 ms on localhost (2/2)
16/03/17 15:51:38 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:51:38 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.318 s
16/03/17 15:51:38 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.327030 s
16/03/17 15:51:38 INFO ContextCleaner: Cleaned accumulator 299
16/03/17 15:51:38 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:59352 in memory (size: 4.1 KB, free: 524.7 MB)
16/03/17 15:51:38 INFO ContextCleaner: Cleaned accumulator 298
16/03/17 15:51:38 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:51:38 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:51:38 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:51:38 INFO MemoryStore: MemoryStore cleared
16/03/17 15:51:38 INFO BlockManager: BlockManager stopped
16/03/17 15:51:38 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:51:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:51:38 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:51:38 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:51:38 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:51:38 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:51:39 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:51:39 INFO SecurityManager: Changing view acls to: root
16/03/17 15:51:39 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:51:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:51:39 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:51:39 INFO Remoting: Starting remoting
16/03/17 15:51:39 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:59472]
16/03/17 15:51:39 INFO Utils: Successfully started service 'sparkDriver' on port 59472.
16/03/17 15:51:39 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:51:39 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:51:39 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-51b49e11-3cdb-43f3-b578-eb89884da6df
16/03/17 15:51:39 INFO MemoryStore: MemoryStore started with capacity 523.3 MB
16/03/17 15:51:39 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-1ec50183-d958-46fd-ac30-e9d194c85bdc
16/03/17 15:51:39 INFO HttpServer: Starting HTTP Server
16/03/17 15:51:39 INFO Utils: Successfully started service 'HTTP file server' on port 59206.
16/03/17 15:51:39 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:51:39 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:51:39 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:51:39 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-69dd0b8c-6611-45f3-ba37-b8a60807e543/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:51:39 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210099657
16/03/17 15:51:39 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:51:39 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:51:39 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46394.
16/03/17 15:51:39 INFO NettyBlockTransferService: Server created on 46394
16/03/17 15:51:39 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:51:39 INFO BlockManagerMasterEndpoint: Registering block manager localhost:46394 with 523.3 MB RAM, BlockManagerId(driver, localhost, 46394)
16/03/17 15:51:39 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:51:39 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:51:39 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:51:39 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:51:39 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:51:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:51:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:51:39 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:51:39 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=548677877
16/03/17 15:51:39 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.3 MB)
16/03/17 15:51:39 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=548677877
16/03/17 15:51:39 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.2 MB)
16/03/17 15:51:39 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:46394 (size: 4.1 KB, free: 523.3 MB)
16/03/17 15:51:39 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:51:39 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:51:39 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:51:39 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:51:39 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:51:39 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:51:39 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210099657
16/03/17 15:51:39 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:51:39 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-69dd0b8c-6611-45f3-ba37-b8a60807e543/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:51:39 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:51:39 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:51:39 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10732, maxMem=548677877
16/03/17 15:51:39 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 523.2 MB)
16/03/17 15:51:39 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10905, maxMem=548677877
16/03/17 15:51:39 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:46394 (size: 173.0 B, free: 523.3 MB)
16/03/17 15:51:39 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 523.2 MB)
16/03/17 15:51:39 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:46394 (size: 179.0 B, free: 523.3 MB)
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: set
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: planning
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: bend
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: permission
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: economy
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: composition
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: agency
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: giant
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: astatine
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: present
16/03/17 15:51:48 INFO PythonRunner: Times: total = 8493, boot = 482, init = 388, finish = 7623
16/03/17 15:51:48 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: Chennai
mapFunction_Parents(): keyword=16/03/17 15:51:48 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8560 ms on localhost (1/2)
 bishop ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  bishop  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: area
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): bishop
mapFunction_Parents(): keyword: bishop ; prevleveltokens: issue
mapFunction_Parents(): keyword= bishop ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
16/03/17 15:51:48 INFO PythonRunner: Times: total = 8574, boot = 470, init = 410, finish = 7694
16/03/17 15:51:48 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:51:48 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8642 ms on localhost (2/2)
16/03/17 15:51:48 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:51:48 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.644 s
16/03/17 15:51:48 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:51:48 INFO DAGScheduler: running: Set()
16/03/17 15:51:48 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:51:48 INFO DAGScheduler: failed: Set()
16/03/17 15:51:48 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:51:48 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:51:48 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=548677877
16/03/17 15:51:48 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.2 MB)
16/03/17 15:51:48 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=548677877
16/03/17 15:51:48 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.2 MB)
16/03/17 15:51:48 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:46394 (size: 3.0 KB, free: 523.3 MB)
16/03/17 15:51:48 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:51:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:51:48 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:51:48 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:51:48 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:51:48 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:51:48 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:51:48 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:51:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:51:48 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:51:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
reduceFunction_Parents(): returns= ['None', u'metropolitan', 'None']
16/03/17 15:51:48 INFO PythonRunner: Times: total = 140, boot = 138, init = 1, finish = 1
16/03/17 15:51:48 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1288 bytes result sent to driver
16/03/17 15:51:48 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 155 ms on localhost (1/2)
16/03/17 15:51:48 INFO PythonRunner: Times: total = 213, boot = 213, init = 0, finish = 0
16/03/17 15:51:48 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:51:48 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.219 s
16/03/17 15:51:48 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 230 ms on localhost (2/2)
16/03/17 15:51:48 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:51:48 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.900325 s
16/03/17 15:51:48 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:51:48 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:51:48 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:51:48 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:51:48 INFO DAGScheduler: Missing parents: List()
16/03/17 15:51:48 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:51:48 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=548677877
16/03/17 15:51:48 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.2 MB)
16/03/17 15:51:48 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24940, maxMem=548677877
16/03/17 15:51:48 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.2 MB)
16/03/17 15:51:48 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:46394 (size: 3.3 KB, free: 523.2 MB)
16/03/17 15:51:48 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:51:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:51:48 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:51:48 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:51:48 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2369 bytes)
16/03/17 15:51:48 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:51:48 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:51:48 INFO PythonRunner: Times: total = 72, boot = 72, init = 0, finish = 0
16/03/17 15:51:48 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1356 bytes result sent to driver
16/03/17 15:51:48 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 79 ms on localhost (1/2)
16/03/17 15:51:48 INFO PythonRunner: Times: total = 162, boot = 162, init = 0, finish = 0
16/03/17 15:51:48 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:51:48 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 171 ms on localhost (2/2)
16/03/17 15:51:48 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:51:48 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.169 s
16/03/17 15:51:48 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.179495 s
16/03/17 15:51:49 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:51:49 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:51:49 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:51:49 INFO MemoryStore: MemoryStore cleared
16/03/17 15:51:49 INFO BlockManager: BlockManager stopped
16/03/17 15:51:49 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:51:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:51:49 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:51:49 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:51:49 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:51:49 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:51:49 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:51:49 INFO SecurityManager: Changing view acls to: root
16/03/17 15:51:49 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:51:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:51:50 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:51:50 INFO Remoting: Starting remoting
16/03/17 15:51:50 INFO Utils: Successfully started service 'sparkDriver' on port 40696.
16/03/17 15:51:50 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:40696]
16/03/17 15:51:50 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:51:50 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:51:50 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-adb1fbbc-ef8f-484f-8088-5bd522179435
16/03/17 15:51:50 INFO MemoryStore: MemoryStore started with capacity 523.3 MB
16/03/17 15:51:50 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-c74222bf-f2b0-42da-a091-13a45744708b
16/03/17 15:51:50 INFO HttpServer: Starting HTTP Server
16/03/17 15:51:50 INFO Utils: Successfully started service 'HTTP file server' on port 50831.
16/03/17 15:51:50 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:51:50 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:51:50 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:51:50 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-be356665-d456-454d-b13e-bf527ac6d8ff/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:51:50 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210110239
16/03/17 15:51:50 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:51:50 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:51:50 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56853.
16/03/17 15:51:50 INFO NettyBlockTransferService: Server created on 56853
16/03/17 15:51:50 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:51:50 INFO BlockManagerMasterEndpoint: Registering block manager localhost:56853 with 523.3 MB RAM, BlockManagerId(driver, localhost, 56853)
16/03/17 15:51:50 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:51:50 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:51:50 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:51:50 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:51:50 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:51:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:51:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:51:50 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:51:50 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=548677877
16/03/17 15:51:50 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.3 MB)
16/03/17 15:51:50 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=548677877
16/03/17 15:51:50 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.2 MB)
16/03/17 15:51:50 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:56853 (size: 4.1 KB, free: 523.3 MB)
16/03/17 15:51:50 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:51:50 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:51:50 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:51:50 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:51:50 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:51:50 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:51:50 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210110239
16/03/17 15:51:50 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:51:50 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-be356665-d456-454d-b13e-bf527ac6d8ff/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:51:50 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:51:50 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:51:50 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=548677877
16/03/17 15:51:50 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 523.2 MB)
16/03/17 15:51:50 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:56853 (size: 179.0 B, free: 523.3 MB)
16/03/17 15:51:50 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=548677877
16/03/17 15:51:50 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 523.2 MB)
16/03/17 15:51:50 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:56853 (size: 173.0 B, free: 523.3 MB)
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: set
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: planning
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: permission
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: economy
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: composition
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: agency
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:51:59 INFO PythonRunner: Times: total = 8879, boot = 474, init = 627, finish = 7778
16/03/17 15:51:59 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:51:59 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8942 ms on localhost (1/2)
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  Synset('set.n.01') ; keyword:  things  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: bend
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: giant
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: astatine
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: present
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: area
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): things
mapFunction_Parents(): keyword: things ; prevleveltokens: issue
mapFunction_Parents(): keyword= things ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
16/03/17 15:51:59 INFO PythonRunner: Times: total = 9508, boot = 515, init = 634, finish = 8359
16/03/17 15:51:59 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:52:00 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.622 s
16/03/17 15:52:00 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:52:00 INFO DAGScheduler: running: Set()
16/03/17 15:52:00 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:52:00 INFO DAGScheduler: failed: Set()
16/03/17 15:52:00 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:52:00 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:52:00 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=548677877
16/03/17 15:52:00 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.2 MB)
16/03/17 15:52:00 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9620 ms on localhost (2/2)
16/03/17 15:52:00 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:52:00 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=548677877
16/03/17 15:52:00 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.2 MB)
16/03/17 15:52:00 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:56853 (size: 3.0 KB, free: 523.3 MB)
16/03/17 15:52:00 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:52:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:00 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:52:00 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:52:00 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:52:00 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:52:00 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:52:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:52:00 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:52:00 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:52:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:52:00 INFO PythonRunner: Times: total = 41, boot = -500, init = 541, finish = 0
16/03/17 15:52:00 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:52:00 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 76 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'set', 'None']
16/03/17 15:52:00 INFO PythonRunner: Times: total = 182, boot = 181, init = 1, finish = 0
16/03/17 15:52:00 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1271 bytes result sent to driver
16/03/17 15:52:00 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 208 ms on localhost (2/2)
16/03/17 15:52:00 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:52:00 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.209 s
16/03/17 15:52:00 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.851740 s
16/03/17 15:52:00 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:52:00 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:52:00 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:00 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:52:00 INFO DAGScheduler: Missing parents: List()
16/03/17 15:52:00 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:52:00 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=548677877
16/03/17 15:52:00 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.2 MB)
16/03/17 15:52:00 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24940, maxMem=548677877
16/03/17 15:52:00 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.2 MB)
16/03/17 15:52:00 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:56853 (size: 3.3 KB, free: 523.2 MB)
16/03/17 15:52:00 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:52:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:00 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:52:00 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:52:00 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/17 15:52:00 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:52:00 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:52:00 INFO PythonRunner: Times: total = 49, boot = -50, init = 99, finish = 0
16/03/17 15:52:00 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1336 bytes result sent to driver
16/03/17 15:52:00 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 57 ms on localhost (1/2)
16/03/17 15:52:00 INFO PythonRunner: Times: total = 128, boot = 127, init = 1, finish = 0
16/03/17 15:52:00 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:52:00 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 134 ms on localhost (2/2)
16/03/17 15:52:00 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:52:00 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.129 s
16/03/17 15:52:00 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.144702 s
16/03/17 15:52:00 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:52:00 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:52:00 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:52:00 INFO MemoryStore: MemoryStore cleared
16/03/17 15:52:00 INFO BlockManager: BlockManager stopped
16/03/17 15:52:00 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:52:00 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:52:00 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:52:00 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:52:00 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:52:00 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:52:01 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:52:01 INFO SecurityManager: Changing view acls to: root
16/03/17 15:52:01 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:52:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:52:01 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:52:01 INFO Remoting: Starting remoting
16/03/17 15:52:01 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:57874]
16/03/17 15:52:01 INFO Utils: Successfully started service 'sparkDriver' on port 57874.
16/03/17 15:52:01 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:52:01 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:52:01 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0976733d-c528-4963-9bbc-ed6a5b9fa4d7
16/03/17 15:52:01 INFO MemoryStore: MemoryStore started with capacity 523.3 MB
16/03/17 15:52:01 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-2c324bc9-65b1-4386-b2dd-9940dfecb82b
16/03/17 15:52:01 INFO HttpServer: Starting HTTP Server
16/03/17 15:52:01 INFO Utils: Successfully started service 'HTTP file server' on port 36608.
16/03/17 15:52:01 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:52:01 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:52:01 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:52:01 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-208ec16c-bc4a-41ca-9cf6-43356317f428/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:52:01 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210121722
16/03/17 15:52:01 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:52:01 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:52:01 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44801.
16/03/17 15:52:01 INFO NettyBlockTransferService: Server created on 44801
16/03/17 15:52:01 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:52:01 INFO BlockManagerMasterEndpoint: Registering block manager localhost:44801 with 523.3 MB RAM, BlockManagerId(driver, localhost, 44801)
16/03/17 15:52:01 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:52:01 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:52:01 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:01 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:52:01 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:52:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:52:01 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:52:01 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=548677877
16/03/17 15:52:01 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.3 MB)
16/03/17 15:52:01 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=548677877
16/03/17 15:52:01 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.2 MB)
16/03/17 15:52:01 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:44801 (size: 4.1 KB, free: 523.3 MB)
16/03/17 15:52:01 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:52:01 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:01 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:52:01 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:52:01 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:52:01 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:52:01 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210121722
16/03/17 15:52:01 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:52:01 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-208ec16c-bc4a-41ca-9cf6-43356317f428/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:52:01 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:52:01 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10732, maxMem=548677877
16/03/17 15:52:01 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 523.2 MB)
16/03/17 15:52:01 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:44801 (size: 173.0 B, free: 523.3 MB)
16/03/17 15:52:01 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:52:01 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10905, maxMem=548677877
16/03/17 15:52:01 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 523.2 MB)
16/03/17 15:52:01 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:44801 (size: 179.0 B, free: 523.3 MB)
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: set
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: planning
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: permission
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: economy
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: composition
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: agency
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  ['NSynset('set.n.01') ; keyword:  belong  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
onasfer_pickle_string_load(): picklef.readlines():e belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: bend
']
16/03/17 15:52:10 INFO PythonRunner: Times: total = 8555, boot = 462, init = 388, finish = 7705
16/03/17 15:52:10 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: giant
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: astatine
16/03/17 15:52:10 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8629 ms on localhost (1/2)
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: present
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: area
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: issue
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
16/03/17 15:52:10 INFO PythonRunner: Times: total = 8670, boot = 454, init = 410, finish = 7806
16/03/17 15:52:10 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:52:10 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8736 ms on localhost (2/2)
16/03/17 15:52:10 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:52:10 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.738 s
16/03/17 15:52:10 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:52:10 INFO DAGScheduler: running: Set()
16/03/17 15:52:10 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:52:10 INFO DAGScheduler: failed: Set()
16/03/17 15:52:10 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:52:10 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:52:10 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=548677877
16/03/17 15:52:10 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.2 MB)
16/03/17 15:52:10 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=548677877
16/03/17 15:52:10 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.2 MB)
16/03/17 15:52:10 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:44801 (size: 3.0 KB, free: 523.3 MB)
16/03/17 15:52:10 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:52:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:10 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:52:10 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:52:10 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:52:10 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:52:10 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:52:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:52:10 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:52:10 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:52:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:52:10 INFO PythonRunner: Times: total = 121, boot = 120, init = 0, finish = 1
16/03/17 15:52:10 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:52:10 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 143 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'set', 'None']
16/03/17 15:52:10 INFO PythonRunner: Times: total = 208, boot = 207, init = 0, finish = 1
16/03/17 15:52:10 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1271 bytes result sent to driver
16/03/17 15:52:10 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.214 s
16/03/17 15:52:10 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.985599 s
16/03/17 15:52:10 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 226 ms on localhost (2/2)
16/03/17 15:52:10 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:52:10 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:52:10 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:52:10 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:10 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:52:10 INFO DAGScheduler: Missing parents: List()
16/03/17 15:52:10 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:52:10 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=548677877
16/03/17 15:52:10 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.2 MB)
16/03/17 15:52:10 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24940, maxMem=548677877
16/03/17 15:52:10 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.2 MB)
16/03/17 15:52:10 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:44801 (size: 3.3 KB, free: 523.2 MB)
16/03/17 15:52:10 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:52:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:10 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:52:10 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:52:10 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/17 15:52:10 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:52:10 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:52:11 INFO PythonRunner: Times: total = 280, boot = 242, init = 38, finish = 0
16/03/17 15:52:11 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1336 bytes result sent to driver
16/03/17 15:52:11 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:44801 in memory (size: 3.0 KB, free: 523.3 MB)
16/03/17 15:52:11 INFO PythonRunner: Times: total = 295, boot = -26, init = 321, finish = 0
16/03/17 15:52:11 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:52:11 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 310 ms on localhost (1/2)
16/03/17 15:52:11 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 310 ms on localhost (2/2)
16/03/17 15:52:11 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:52:11 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.042 s
16/03/17 15:52:11 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.331024 s
16/03/17 15:52:11 INFO ContextCleaner: Cleaned accumulator 311
16/03/17 15:52:11 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:44801 in memory (size: 4.1 KB, free: 523.3 MB)
16/03/17 15:52:11 INFO ContextCleaner: Cleaned accumulator 310
16/03/17 15:52:11 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:52:11 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:52:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:52:11 INFO MemoryStore: MemoryStore cleared
16/03/17 15:52:11 INFO BlockManager: BlockManager stopped
16/03/17 15:52:11 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:52:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:52:11 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:52:11 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:52:11 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:52:12 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:52:12 INFO SecurityManager: Changing view acls to: root
16/03/17 15:52:12 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:52:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:52:12 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:52:12 INFO Remoting: Starting remoting
16/03/17 15:52:12 INFO Utils: Successfully started service 'sparkDriver' on port 60242.
16/03/17 15:52:12 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:60242]
16/03/17 15:52:12 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:52:12 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:52:12 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-49aa991a-e21e-4189-bb46-b23aee29aa68
16/03/17 15:52:12 INFO MemoryStore: MemoryStore started with capacity 523.1 MB
16/03/17 15:52:12 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-e9299663-2535-4081-b2db-726734580a6d
16/03/17 15:52:12 INFO HttpServer: Starting HTTP Server
16/03/17 15:52:12 INFO Utils: Successfully started service 'HTTP file server' on port 52505.
16/03/17 15:52:12 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:52:12 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:52:12 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:52:12 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-f341d7cd-95d2-4bf3-ae48-76bcb428c62f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:52:12 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210132578
16/03/17 15:52:12 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:52:12 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:52:12 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 32861.
16/03/17 15:52:12 INFO NettyBlockTransferService: Server created on 32861
16/03/17 15:52:12 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:52:12 INFO BlockManagerMasterEndpoint: Registering block manager localhost:32861 with 523.1 MB RAM, BlockManagerId(driver, localhost, 32861)
16/03/17 15:52:12 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:52:12 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:52:12 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:12 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:52:12 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:52:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:52:12 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:52:12 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=548536320
16/03/17 15:52:12 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.1 MB)
16/03/17 15:52:12 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=548536320
16/03/17 15:52:12 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.1 MB)
16/03/17 15:52:12 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:32861 (size: 4.1 KB, free: 523.1 MB)
16/03/17 15:52:12 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:52:12 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:12 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:52:12 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:52:12 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:52:12 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:52:12 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210132578
16/03/17 15:52:12 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:52:12 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-f341d7cd-95d2-4bf3-ae48-76bcb428c62f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:52:12 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:52:12 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10732, maxMem=548536320
16/03/17 15:52:12 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 523.1 MB)
16/03/17 15:52:12 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:32861 (size: 173.0 B, free: 523.1 MB)
16/03/17 15:52:12 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:52:12 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10905, maxMem=548536320
16/03/17 15:52:12 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 523.1 MB)
16/03/17 15:52:12 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:32861 (size: 179.0 B, free: 523.1 MB)
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: set
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: bend
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: giant
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: astatine
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  uranium  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: present
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: area
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: issue
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/17 15:52:21 INFO PythonRunner: Times: total = 8500, boot = 468, init = 421, finish = 7611
16/03/17 15:52:21 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:52:21 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8557 ms on localhost (1/2)
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: planning
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: permission
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: economy
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: composition
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: agency
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:52:21 INFO PythonRunner: Times: total = 8672, boot = 474, init = 380, finish = 7818
16/03/17 15:52:21 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:52:21 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8739 ms on localhost (2/2)
16/03/17 15:52:21 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:52:21 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.745 s
16/03/17 15:52:21 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:52:21 INFO DAGScheduler: running: Set()
16/03/17 15:52:21 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:52:21 INFO DAGScheduler: failed: Set()
16/03/17 15:52:21 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:52:21 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:52:21 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=548536320
16/03/17 15:52:21 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.1 MB)
16/03/17 15:52:21 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=548536320
16/03/17 15:52:21 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.1 MB)
16/03/17 15:52:21 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:32861 (size: 3.0 KB, free: 523.1 MB)
16/03/17 15:52:21 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:52:21 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:21 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:52:21 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:52:21 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:52:21 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:52:21 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:52:21 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:52:21 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:52:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:52:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:52:21 INFO PythonRunner: Times: total = 28, boot = -4, init = 32, finish = 0
16/03/17 15:52:21 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:52:21 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 44 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'astatine', 'None']
16/03/17 15:52:21 INFO PythonRunner: Times: total = 203, boot = 202, init = 0, finish = 1
16/03/17 15:52:21 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/03/17 15:52:21 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.221 s
16/03/17 15:52:21 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.986303 s
16/03/17 15:52:21 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 221 ms on localhost (2/2)
16/03/17 15:52:21 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:52:21 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:52:21 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:52:21 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:21 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:52:21 INFO DAGScheduler: Missing parents: List()
16/03/17 15:52:21 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:52:21 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=548536320
16/03/17 15:52:21 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.1 MB)
16/03/17 15:52:21 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24940, maxMem=548536320
16/03/17 15:52:21 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.1 MB)
16/03/17 15:52:21 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:32861 (size: 3.3 KB, free: 523.1 MB)
16/03/17 15:52:21 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:52:21 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:21 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:52:21 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:52:21 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/03/17 15:52:21 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:52:21 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:52:21 INFO PythonRunner: Times: total = 56, boot = -49, init = 105, finish = 0
16/03/17 15:52:21 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/03/17 15:52:21 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 67 ms on localhost (1/2)
16/03/17 15:52:21 INFO PythonRunner: Times: total = 110, boot = 110, init = 0, finish = 0
16/03/17 15:52:21 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:52:21 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 121 ms on localhost (2/2)
16/03/17 15:52:21 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:52:21 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.118 s
16/03/17 15:52:21 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.133995 s
16/03/17 15:52:22 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:52:22 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:52:22 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:52:22 INFO MemoryStore: MemoryStore cleared
16/03/17 15:52:22 INFO BlockManager: BlockManager stopped
16/03/17 15:52:22 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:52:22 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:52:22 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:52:22 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:52:22 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:52:22 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:52:22 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:52:22 INFO SecurityManager: Changing view acls to: root
16/03/17 15:52:22 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:52:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:52:22 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:52:22 INFO Remoting: Starting remoting
16/03/17 15:52:23 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:59000]
16/03/17 15:52:23 INFO Utils: Successfully started service 'sparkDriver' on port 59000.
16/03/17 15:52:23 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:52:23 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:52:23 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b44a2495-0389-478f-91b7-cccbd8016832
16/03/17 15:52:23 INFO MemoryStore: MemoryStore started with capacity 523.1 MB
16/03/17 15:52:23 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-a130e865-4c2f-4fdf-8084-6000c3a5a897
16/03/17 15:52:23 INFO HttpServer: Starting HTTP Server
16/03/17 15:52:23 INFO Utils: Successfully started service 'HTTP file server' on port 55669.
16/03/17 15:52:23 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:52:23 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:52:23 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:52:23 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-3580ca87-3ea9-4f08-9179-e42a263597c0/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:52:23 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210143144
16/03/17 15:52:23 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:52:23 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:52:23 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58602.
16/03/17 15:52:23 INFO NettyBlockTransferService: Server created on 58602
16/03/17 15:52:23 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:52:23 INFO BlockManagerMasterEndpoint: Registering block manager localhost:58602 with 523.1 MB RAM, BlockManagerId(driver, localhost, 58602)
16/03/17 15:52:23 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:52:23 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:52:23 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:23 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:52:23 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:52:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:52:23 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:52:23 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=548536320
16/03/17 15:52:23 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.1 MB)
16/03/17 15:52:23 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=548536320
16/03/17 15:52:23 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.1 MB)
16/03/17 15:52:23 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:58602 (size: 4.1 KB, free: 523.1 MB)
16/03/17 15:52:23 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:52:23 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:23 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:52:23 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:52:23 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:52:23 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:52:23 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210143144
16/03/17 15:52:23 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:52:23 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-3580ca87-3ea9-4f08-9179-e42a263597c0/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:52:23 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:52:23 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=548536320
16/03/17 15:52:23 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 523.1 MB)
16/03/17 15:52:23 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:58602 (size: 179.0 B, free: 523.1 MB)
16/03/17 15:52:23 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:52:23 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=548536320
16/03/17 15:52:23 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 523.1 MB)
16/03/17 15:52:23 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:58602 (size: 173.0 B, free: 523.1 MB)
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: set
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: planning
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: permission
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: economy
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: composition
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  arrangement  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: agency
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/17 15:52:31 INFO PythonRunner: Times: total = 8157, boot = 465, init = 395, finish = 7297
16/03/17 15:52:31 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:52:31 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8220 ms on localhost (1/2)
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: bend
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: giant
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: astatine
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: present
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: area
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: issue
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:52:32 INFO PythonRunner: Times: total = 8726, boot = 479, init = 417, finish = 7830
16/03/17 15:52:32 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:52:32 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8782 ms on localhost (2/2)
16/03/17 15:52:32 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:52:32 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.788 s
16/03/17 15:52:32 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:52:32 INFO DAGScheduler: running: Set()
16/03/17 15:52:32 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:52:32 INFO DAGScheduler: failed: Set()
16/03/17 15:52:32 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:52:32 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:52:32 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=548536320
16/03/17 15:52:32 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.1 MB)
16/03/17 15:52:32 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=548536320
16/03/17 15:52:32 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.1 MB)
16/03/17 15:52:32 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:58602 (size: 3.0 KB, free: 523.1 MB)
16/03/17 15:52:32 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:52:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:32 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:52:32 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:52:32 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:52:32 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:52:32 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:52:32 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:52:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:52:32 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:52:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
reduceFunction_Parents(): returns= ['None', 'None', u'composition']
16/03/17 15:52:32 INFO PythonRunner: Times: total = 34, boot = -380, init = 413, finish = 1
16/03/17 15:52:32 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1287 bytes result sent to driver
16/03/17 15:52:32 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 46 ms on localhost (1/2)
16/03/17 15:52:32 INFO PythonRunner: Times: total = 195, boot = 194, init = 0, finish = 1
16/03/17 15:52:32 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:52:32 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 212 ms on localhost (2/2)
16/03/17 15:52:32 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:52:32 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.201 s
16/03/17 15:52:32 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.023329 s
16/03/17 15:52:32 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:52:32 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:52:32 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:32 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:52:32 INFO DAGScheduler: Missing parents: List()
16/03/17 15:52:32 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:52:32 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=548536320
16/03/17 15:52:32 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.1 MB)
16/03/17 15:52:32 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24940, maxMem=548536320
16/03/17 15:52:32 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.1 MB)
16/03/17 15:52:32 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:58602 (size: 3.3 KB, free: 523.1 MB)
16/03/17 15:52:32 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:52:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:32 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:52:32 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:52:32 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2368 bytes)
16/03/17 15:52:32 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:52:32 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:52:32 INFO PythonRunner: Times: total = 50, boot = -46, init = 96, finish = 0
16/03/17 15:52:32 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:52:32 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 62 ms on localhost (1/2)
16/03/17 15:52:32 INFO PythonRunner: Times: total = 159, boot = 158, init = 0, finish = 1
16/03/17 15:52:32 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1355 bytes result sent to driver
16/03/17 15:52:32 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 167 ms on localhost (2/2)
16/03/17 15:52:32 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:52:32 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.169 s
16/03/17 15:52:32 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.178972 s
16/03/17 15:52:32 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:52:32 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:52:32 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:52:32 INFO MemoryStore: MemoryStore cleared
16/03/17 15:52:32 INFO BlockManager: BlockManager stopped
16/03/17 15:52:32 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:52:32 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:52:32 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:52:32 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:52:32 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:52:32 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:52:33 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:52:33 INFO SecurityManager: Changing view acls to: root
16/03/17 15:52:33 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:52:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:52:33 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:52:33 INFO Remoting: Starting remoting
16/03/17 15:52:33 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:40383]
16/03/17 15:52:33 INFO Utils: Successfully started service 'sparkDriver' on port 40383.
16/03/17 15:52:33 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:52:33 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:52:33 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-20beb99c-7202-4ec4-95f9-9f509ee87474
16/03/17 15:52:33 INFO MemoryStore: MemoryStore started with capacity 523.1 MB
16/03/17 15:52:33 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-23dc808c-902e-4bef-89bd-1caf0f1aa92f
16/03/17 15:52:33 INFO HttpServer: Starting HTTP Server
16/03/17 15:52:33 INFO Utils: Successfully started service 'HTTP file server' on port 44691.
16/03/17 15:52:33 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:52:33 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:52:33 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:52:33 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-d1ca68d6-c671-4f37-b720-89eeba621495/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:52:33 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210153773
16/03/17 15:52:33 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:52:33 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:52:33 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60503.
16/03/17 15:52:33 INFO NettyBlockTransferService: Server created on 60503
16/03/17 15:52:33 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:52:33 INFO BlockManagerMasterEndpoint: Registering block manager localhost:60503 with 523.1 MB RAM, BlockManagerId(driver, localhost, 60503)
16/03/17 15:52:33 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:52:33 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:52:33 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:33 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:52:33 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:52:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:52:33 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:52:33 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=548536320
16/03/17 15:52:33 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.1 MB)
16/03/17 15:52:33 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=548536320
16/03/17 15:52:33 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.1 MB)
16/03/17 15:52:33 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:60503 (size: 4.1 KB, free: 523.1 MB)
16/03/17 15:52:33 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:52:33 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:33 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:52:33 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:52:33 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:52:33 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:52:33 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210153773
16/03/17 15:52:33 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:52:33 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-d1ca68d6-c671-4f37-b720-89eeba621495/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:52:33 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:52:33 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=548536320
16/03/17 15:52:33 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 523.1 MB)
16/03/17 15:52:33 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:60503 (size: 179.0 B, free: 523.1 MB)
16/03/17 15:52:34 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:52:34 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=548536320
16/03/17 15:52:34 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 523.1 MB)
16/03/17 15:52:34 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:60503 (size: 173.0 B, free: 523.1 MB)
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: set
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: planning
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: permission
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: economy
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: composition
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  parts  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: agency
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/17 15:52:42 INFO PythonRunner: Times: total = 8420, boot = 475, init = 378, finish = 7567
16/03/17 15:52:42 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:52:42 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8503 ms on localhost (1/2)
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: bend
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: giant
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: astatine
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: present
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: area
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: issue
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:52:42 INFO PythonRunner: Times: total = 8867, boot = 470, init = 401, finish = 7996
16/03/17 15:52:42 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:52:42 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8951 ms on localhost (2/2)
16/03/17 15:52:42 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:52:42 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.942 s
16/03/17 15:52:42 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:52:42 INFO DAGScheduler: running: Set()
16/03/17 15:52:42 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:52:42 INFO DAGScheduler: failed: Set()
16/03/17 15:52:42 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:52:42 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:52:42 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=548536320
16/03/17 15:52:42 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.1 MB)
16/03/17 15:52:43 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=548536320
16/03/17 15:52:43 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.1 MB)
16/03/17 15:52:43 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:60503 (size: 3.0 KB, free: 523.1 MB)
16/03/17 15:52:43 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:52:43 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:43 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:52:43 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:52:43 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:52:43 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:52:43 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:52:43 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:52:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:52:43 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:52:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', 'None', u'composition']
16/03/17 15:52:43 INFO PythonRunner: Times: total = 18, boot = -599, init = 616, finish = 1
16/03/17 15:52:43 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1287 bytes result sent to driver
16/03/17 15:52:43 INFO PythonRunner: Times: total = 49, boot = -97, init = 146, finish = 0
16/03/17 15:52:43 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:52:43 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 86 ms on localhost (1/2)
16/03/17 15:52:43 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 87 ms on localhost (2/2)
16/03/17 15:52:43 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:52:43 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.087 s
16/03/17 15:52:43 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.384431 s
16/03/17 15:52:43 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:52:43 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:52:43 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:43 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:52:43 INFO DAGScheduler: Missing parents: List()
16/03/17 15:52:43 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:52:43 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=548536320
16/03/17 15:52:43 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.1 MB)
16/03/17 15:52:43 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24940, maxMem=548536320
16/03/17 15:52:43 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.1 MB)
16/03/17 15:52:43 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:60503 (size: 3.3 KB, free: 523.1 MB)
16/03/17 15:52:43 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:52:43 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:43 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:52:43 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:52:43 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2368 bytes)
16/03/17 15:52:43 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:52:43 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:52:43 INFO PythonRunner: Times: total = 169, boot = 160, init = 1, finish = 8
16/03/17 15:52:43 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:52:43 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 177 ms on localhost (1/2)
16/03/17 15:52:43 INFO PythonRunner: Times: total = 208, boot = 208, init = 0, finish = 0
16/03/17 15:52:43 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1355 bytes result sent to driver
16/03/17 15:52:43 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 219 ms on localhost (2/2)
16/03/17 15:52:43 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:52:43 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.207 s
16/03/17 15:52:43 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.233401 s
16/03/17 15:52:43 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:52:43 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:52:43 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:52:43 INFO MemoryStore: MemoryStore cleared
16/03/17 15:52:43 INFO BlockManager: BlockManager stopped
16/03/17 15:52:43 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:52:43 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:52:43 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:52:43 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:52:43 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:52:43 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:52:44 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:52:44 INFO SecurityManager: Changing view acls to: root
16/03/17 15:52:44 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:52:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:52:44 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:52:44 INFO Remoting: Starting remoting
16/03/17 15:52:44 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:58399]
16/03/17 15:52:44 INFO Utils: Successfully started service 'sparkDriver' on port 58399.
16/03/17 15:52:44 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:52:44 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:52:44 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1f5fe30e-c120-47db-a407-758d70ae4df5
16/03/17 15:52:44 INFO MemoryStore: MemoryStore started with capacity 518.1 MB
16/03/17 15:52:44 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-e26427f9-3a57-4baf-be7d-e6fa2eb324d6
16/03/17 15:52:44 INFO HttpServer: Starting HTTP Server
16/03/17 15:52:44 INFO Utils: Successfully started service 'HTTP file server' on port 44215.
16/03/17 15:52:44 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:52:44 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:52:44 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:52:44 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-ccd0db4c-5398-4831-a9bb-753c6bf07bc4/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:52:44 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210164889
16/03/17 15:52:44 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:52:44 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:52:44 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57965.
16/03/17 15:52:44 INFO NettyBlockTransferService: Server created on 57965
16/03/17 15:52:44 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:52:44 INFO BlockManagerMasterEndpoint: Registering block manager localhost:57965 with 518.1 MB RAM, BlockManagerId(driver, localhost, 57965)
16/03/17 15:52:44 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:52:45 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:52:45 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:45 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:52:45 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:52:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:52:45 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:52:45 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=543298682
16/03/17 15:52:45 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 518.1 MB)
16/03/17 15:52:45 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=543298682
16/03/17 15:52:45 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 518.1 MB)
16/03/17 15:52:45 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:57965 (size: 4.1 KB, free: 518.1 MB)
16/03/17 15:52:45 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:52:45 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:45 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:52:45 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:52:45 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:52:45 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:52:45 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210164889
16/03/17 15:52:45 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:52:45 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-ccd0db4c-5398-4831-a9bb-753c6bf07bc4/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:52:45 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:52:45 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=543298682
16/03/17 15:52:45 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 518.1 MB)
16/03/17 15:52:45 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:57965 (size: 179.0 B, free: 518.1 MB)
16/03/17 15:52:45 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:52:45 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=543298682
16/03/17 15:52:45 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 518.1 MB)
16/03/17 15:52:45 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:57965 (size: 173.0 B, free: 518.1 MB)
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: area
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: planning
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: permission
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: economy
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: composition
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: agency
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:52:53 INFO PythonRunner: Times: total = 8838, boot = 460, init = 427, finish = 7951
16/03/17 15:52:53 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:52:53 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8893 ms on localhost (1/2)
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: bend
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: giant
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: astatine
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: present
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  speech  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: area
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: issue
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/17 15:52:54 INFO PythonRunner: Times: total = 9080, boot = 468, init = 379, finish = 8233
16/03/17 15:52:54 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:52:54 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.135 s
16/03/17 15:52:54 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:52:54 INFO DAGScheduler: running: Set()
16/03/17 15:52:54 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:52:54 INFO DAGScheduler: failed: Set()
16/03/17 15:52:54 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:52:54 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:52:54 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=543298682
16/03/17 15:52:54 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 518.1 MB)
16/03/17 15:52:54 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=543298682
16/03/17 15:52:54 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 518.1 MB)
16/03/17 15:52:54 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9132 ms on localhost (2/2)
16/03/17 15:52:54 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:52:54 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:57965 (size: 3.0 KB, free: 518.1 MB)
16/03/17 15:52:54 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:52:54 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:54 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:52:54 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:52:54 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:52:54 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:52:54 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:52:54 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:52:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:52:54 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:52:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'present', 'None']
16/03/17 15:52:54 INFO PythonRunner: Times: total = 32, boot = -68, init = 99, finish = 1
16/03/17 15:52:54 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/17 15:52:54 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 62 ms on localhost (1/2)
16/03/17 15:52:54 INFO PythonRunner: Times: total = 203, boot = 202, init = 1, finish = 0
16/03/17 15:52:54 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:52:54 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 222 ms on localhost (2/2)
16/03/17 15:52:54 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:52:54 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.208 s
16/03/17 15:52:54 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.374899 s
16/03/17 15:52:54 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:52:54 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:52:54 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:54 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:52:54 INFO DAGScheduler: Missing parents: List()
16/03/17 15:52:54 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:52:54 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=543298682
16/03/17 15:52:54 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 518.1 MB)
16/03/17 15:52:54 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24940, maxMem=543298682
16/03/17 15:52:54 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 518.1 MB)
16/03/17 15:52:54 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:57965 (size: 3.3 KB, free: 518.1 MB)
16/03/17 15:52:54 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:52:54 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:54 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:52:54 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:52:54 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/17 15:52:54 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:52:54 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:52:54 INFO PythonRunner: Times: total = 48, boot = -116, init = 164, finish = 0
16/03/17 15:52:54 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:52:54 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 56 ms on localhost (1/2)
16/03/17 15:52:54 INFO PythonRunner: Times: total = 90, boot = 90, init = 0, finish = 0
16/03/17 15:52:54 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1351 bytes result sent to driver
16/03/17 15:52:54 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 101 ms on localhost (2/2)
16/03/17 15:52:54 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:52:54 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.102 s
16/03/17 15:52:54 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.112910 s
16/03/17 15:52:54 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:52:54 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:52:54 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:52:54 INFO MemoryStore: MemoryStore cleared
16/03/17 15:52:54 INFO BlockManager: BlockManager stopped
16/03/17 15:52:54 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:52:54 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:52:54 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:52:54 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:52:54 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:52:54 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:52:55 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:52:55 INFO SecurityManager: Changing view acls to: root
16/03/17 15:52:55 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:52:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:52:55 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:52:55 INFO Remoting: Starting remoting
16/03/17 15:52:55 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:58060]
16/03/17 15:52:55 INFO Utils: Successfully started service 'sparkDriver' on port 58060.
16/03/17 15:52:55 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:52:55 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:52:55 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1df8213b-27a8-45ef-9da8-5fd88cb7bb74
16/03/17 15:52:55 INFO MemoryStore: MemoryStore started with capacity 518.1 MB
16/03/17 15:52:55 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-bb742742-5de3-4a30-ba96-1a623e5a6cbb
16/03/17 15:52:55 INFO HttpServer: Starting HTTP Server
16/03/17 15:52:55 INFO Utils: Successfully started service 'HTTP file server' on port 35331.
16/03/17 15:52:55 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:52:55 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:52:55 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:52:55 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-6916ea2d-6b6b-4bcc-9568-714a5c32f3af/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:52:55 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210175864
16/03/17 15:52:55 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:52:55 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:52:55 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35776.
16/03/17 15:52:55 INFO NettyBlockTransferService: Server created on 35776
16/03/17 15:52:55 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:52:55 INFO BlockManagerMasterEndpoint: Registering block manager localhost:35776 with 518.1 MB RAM, BlockManagerId(driver, localhost, 35776)
16/03/17 15:52:55 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:52:55 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:52:55 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:55 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:52:55 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:52:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:52:55 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:52:55 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=543298682
16/03/17 15:52:55 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 518.1 MB)
16/03/17 15:52:55 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=543298682
16/03/17 15:52:55 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 518.1 MB)
16/03/17 15:52:55 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:35776 (size: 4.1 KB, free: 518.1 MB)
16/03/17 15:52:55 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:52:55 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:52:55 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:52:55 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:52:55 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:52:55 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:52:55 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210175864
16/03/17 15:52:56 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-6916ea2d-6b6b-4bcc-9568-714a5c32f3af/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:52:56 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:52:56 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:52:56 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=543298682
16/03/17 15:52:56 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 518.1 MB)
16/03/17 15:52:56 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:35776 (size: 179.0 B, free: 518.1 MB)
16/03/17 15:52:56 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:52:56 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=543298682
16/03/17 15:52:56 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 518.1 MB)
16/03/17 15:52:56 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:35776 (size: 173.0 B, free: 518.1 MB)
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: set
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: bend
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: giant
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: astatine
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: present
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: area
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  geographical  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: issue
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/17 15:53:04 INFO PythonRunner: Times: total = 8557, boot = 466, init = 410, finish = 7681
16/03/17 15:53:04 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:53:04 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8623 ms on localhost (1/2)
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  geographical  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: planning
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: permission
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: economy
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: composition
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: agency
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/17 15:53:04 INFO PythonRunner: Times: total = 8657, boot = 470, init = 407, finish = 7780
16/03/17 15:53:04 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:53:04 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.726 s
16/03/17 15:53:04 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:53:04 INFO DAGScheduler: running: Set()
16/03/17 15:53:04 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:53:04 INFO DAGScheduler: failed: Set()
16/03/17 15:53:04 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:53:04 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:53:04 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=543298682
16/03/17 15:53:04 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 518.1 MB)
16/03/17 15:53:04 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=543298682
16/03/17 15:53:04 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 518.1 MB)
16/03/17 15:53:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:35776 (size: 3.0 KB, free: 518.1 MB)
16/03/17 15:53:04 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8721 ms on localhost (2/2)
16/03/17 15:53:04 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:53:04 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:53:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:53:04 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:53:04 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:53:04 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:53:04 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:53:04 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:53:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:53:04 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:53:04 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:53:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:53:04 INFO PythonRunner: Times: total = 181, boot = 180, init = 0, finish = 1
16/03/17 15:53:04 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:53:04 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 195 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'area', u'area']
16/03/17 15:53:04 INFO PythonRunner: Times: total = 227, boot = 226, init = 0, finish = 1
16/03/17 15:53:04 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/17 15:53:04 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 245 ms on localhost (2/2)
16/03/17 15:53:04 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:53:04 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.235 s
16/03/17 15:53:04 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.990798 s
16/03/17 15:53:05 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:53:05 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:53:05 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:53:05 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:53:05 INFO DAGScheduler: Missing parents: List()
16/03/17 15:53:05 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:53:05 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=543298682
16/03/17 15:53:05 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 518.1 MB)
16/03/17 15:53:05 INFO MemoryStore: ensureFreeSpace(3377) called with curMem=24940, maxMem=543298682
16/03/17 15:53:05 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 518.1 MB)
16/03/17 15:53:05 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:35776 (size: 3.3 KB, free: 518.1 MB)
16/03/17 15:53:05 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:53:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:53:05 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:53:05 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:53:05 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/17 15:53:05 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:53:05 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:53:05 INFO PythonRunner: Times: total = 89, boot = 89, init = 0, finish = 0
16/03/17 15:53:05 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/03/17 15:53:05 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 101 ms on localhost (1/2)
16/03/17 15:53:05 INFO PythonRunner: Times: total = 98, boot = 98, init = 0, finish = 0
16/03/17 15:53:05 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:53:05 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 108 ms on localhost (2/2)
16/03/17 15:53:05 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:53:05 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.091 s
16/03/17 15:53:05 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.134261 s
16/03/17 15:53:05 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:53:05 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:53:05 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:53:05 INFO MemoryStore: MemoryStore cleared
16/03/17 15:53:05 INFO BlockManager: BlockManager stopped
16/03/17 15:53:05 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:53:05 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:53:05 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:53:05 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:53:05 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:53:05 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:53:06 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:53:06 INFO SecurityManager: Changing view acls to: root
16/03/17 15:53:06 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:53:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:53:06 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:53:06 INFO Remoting: Starting remoting
16/03/17 15:53:06 INFO Utils: Successfully started service 'sparkDriver' on port 51426.
16/03/17 15:53:06 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:51426]
16/03/17 15:53:06 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:53:06 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:53:06 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b4bfb710-ff7e-405b-9108-a3df5e152d14
16/03/17 15:53:06 INFO MemoryStore: MemoryStore started with capacity 518.1 MB
16/03/17 15:53:06 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-89b76d2c-3eb9-4f45-8fa2-2eeeae70b12e
16/03/17 15:53:06 INFO HttpServer: Starting HTTP Server
16/03/17 15:53:06 INFO Utils: Successfully started service 'HTTP file server' on port 53528.
16/03/17 15:53:06 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:53:06 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:53:06 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:53:06 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-72cc9d32-d58c-4dbe-8c9a-e458b93df8ae/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:53:06 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210186491
16/03/17 15:53:06 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:53:06 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:53:06 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36470.
16/03/17 15:53:06 INFO NettyBlockTransferService: Server created on 36470
16/03/17 15:53:06 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:53:06 INFO BlockManagerMasterEndpoint: Registering block manager localhost:36470 with 518.1 MB RAM, BlockManagerId(driver, localhost, 36470)
16/03/17 15:53:06 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:53:06 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:53:06 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:53:06 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:53:06 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:53:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:53:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:53:06 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:53:06 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=543298682
16/03/17 15:53:06 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 518.1 MB)
16/03/17 15:53:06 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=543298682
16/03/17 15:53:06 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 518.1 MB)
16/03/17 15:53:06 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:36470 (size: 4.1 KB, free: 518.1 MB)
16/03/17 15:53:06 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:53:06 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:53:06 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:53:06 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:53:06 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:53:06 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:53:06 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210186491
16/03/17 15:53:06 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:53:06 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-72cc9d32-d58c-4dbe-8c9a-e458b93df8ae/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:53:06 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:53:06 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:53:06 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10732, maxMem=543298682
16/03/17 15:53:06 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 518.1 MB)
16/03/17 15:53:06 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10905, maxMem=543298682
16/03/17 15:53:06 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:36470 (size: 173.0 B, free: 518.1 MB)
16/03/17 15:53:06 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 518.1 MB)
16/03/17 15:53:06 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:36470 (size: 179.0 B, free: 518.1 MB)
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: area
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: bend
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: giant
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: astatine
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: present
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: area
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: issue
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:53:15 INFO PythonRunner: Times: total = 8604, boot = 465, init = 421, finish = 7718
16/03/17 15:53:15 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:53:15 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8664 ms on localhost (1/2)
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: planning
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: permission
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: economy
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: composition
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  spatial  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: agency
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/17 15:53:15 INFO PythonRunner: Times: total = 8776, boot = 481, init = 418, finish = 7877
16/03/17 15:53:15 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:53:15 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8839 ms on localhost (2/2)
16/03/17 15:53:15 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:53:15 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.841 s
16/03/17 15:53:15 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:53:15 INFO DAGScheduler: running: Set()
16/03/17 15:53:15 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:53:15 INFO DAGScheduler: failed: Set()
16/03/17 15:53:15 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:53:15 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:53:15 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=543298682
16/03/17 15:53:15 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 518.1 MB)
16/03/17 15:53:15 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=543298682
16/03/17 15:53:15 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 518.1 MB)
16/03/17 15:53:15 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:36470 (size: 3.0 KB, free: 518.1 MB)
16/03/17 15:53:15 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:53:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:53:15 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:53:15 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:53:15 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:53:15 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:53:15 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:53:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:53:15 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:53:15 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:53:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
reduceFunction_Parents(): returns= ['None', 'None', u'composition']
16/03/17 15:53:15 INFO PythonRunner: Times: total = 31, boot = -8, init = 38, finish = 1
16/03/17 15:53:15 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1287 bytes result sent to driver
16/03/17 15:53:15 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 81 ms on localhost (1/2)
16/03/17 15:53:15 INFO PythonRunner: Times: total = 211, boot = 210, init = 1, finish = 0
16/03/17 15:53:15 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:53:15 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 232 ms on localhost (2/2)
16/03/17 15:53:15 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:53:15 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.218 s
16/03/17 15:53:15 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.312440 s
16/03/17 15:53:16 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:53:16 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:53:16 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:53:16 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:53:16 INFO DAGScheduler: Missing parents: List()
16/03/17 15:53:16 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:53:16 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=543298682
16/03/17 15:53:16 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 518.1 MB)
16/03/17 15:53:16 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24940, maxMem=543298682
16/03/17 15:53:16 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 518.1 MB)
16/03/17 15:53:16 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:36470 (size: 3.3 KB, free: 518.1 MB)
16/03/17 15:53:16 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:53:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:53:16 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:53:16 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:53:16 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2368 bytes)
16/03/17 15:53:16 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:53:16 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:53:16 INFO PythonRunner: Times: total = 79, boot = -72, init = 151, finish = 0
16/03/17 15:53:16 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1355 bytes result sent to driver
16/03/17 15:53:16 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 88 ms on localhost (1/2)
16/03/17 15:53:16 INFO PythonRunner: Times: total = 81, boot = 81, init = 0, finish = 0
16/03/17 15:53:16 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:53:16 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 97 ms on localhost (2/2)
16/03/17 15:53:16 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:53:16 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.079 s
16/03/17 15:53:16 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.111558 s
16/03/17 15:53:16 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:53:16 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:53:16 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:53:16 INFO MemoryStore: MemoryStore cleared
16/03/17 15:53:16 INFO BlockManager: BlockManager stopped
16/03/17 15:53:16 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:53:16 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:53:16 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:53:17 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:53:17 INFO SecurityManager: Changing view acls to: root
16/03/17 15:53:17 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:53:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:53:17 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:53:17 INFO Remoting: Starting remoting
16/03/17 15:53:17 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:39738]
16/03/17 15:53:17 INFO Utils: Successfully started service 'sparkDriver' on port 39738.
16/03/17 15:53:17 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:53:17 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:53:17 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2300271d-c6f1-44d5-993e-05001e8ea81b
16/03/17 15:53:17 INFO MemoryStore: MemoryStore started with capacity 522.9 MB
16/03/17 15:53:17 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-834a65bf-6d67-42c6-8121-63305b075aa4
16/03/17 15:53:17 INFO HttpServer: Starting HTTP Server
16/03/17 15:53:17 INFO Utils: Successfully started service 'HTTP file server' on port 41316.
16/03/17 15:53:17 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:53:17 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:53:17 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:53:17 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-0d2504f3-daa2-4f73-9dc9-5943ca2cde1f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:53:17 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210197455
16/03/17 15:53:17 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:53:17 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:53:17 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44713.
16/03/17 15:53:17 INFO NettyBlockTransferService: Server created on 44713
16/03/17 15:53:17 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:53:17 INFO BlockManagerMasterEndpoint: Registering block manager localhost:44713 with 522.9 MB RAM, BlockManagerId(driver, localhost, 44713)
16/03/17 15:53:17 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:53:17 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:53:17 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:53:17 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:53:17 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:53:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:53:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:53:17 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:53:17 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=548253204
16/03/17 15:53:17 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 522.8 MB)
16/03/17 15:53:17 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=548253204
16/03/17 15:53:17 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 522.8 MB)
16/03/17 15:53:17 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:44713 (size: 4.1 KB, free: 522.9 MB)
16/03/17 15:53:17 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:53:17 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:53:17 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:53:17 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:53:17 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:53:17 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:53:17 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210197455
16/03/17 15:53:17 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:53:17 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-0d2504f3-daa2-4f73-9dc9-5943ca2cde1f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:53:17 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:53:17 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:53:17 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=548253204
16/03/17 15:53:17 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 522.8 MB)
16/03/17 15:53:17 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=548253204
16/03/17 15:53:17 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 522.8 MB)
16/03/17 15:53:17 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:44713 (size: 179.0 B, free: 522.9 MB)
16/03/17 15:53:17 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:44713 (size: 173.0 B, free: 522.9 MB)
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: set
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: bend
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: giant
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: astatine
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: present
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Nadu  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: area
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: issue
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/17 15:53:26 INFO PythonRunner: Times: total = 8568, boot = 475, init = 423, finish = 7670
16/03/17 15:53:26 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:53:26 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8637 ms on localhost (1/2)
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: planning
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: permission
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: economy
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: composition
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: agency
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Nadu  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/17 15:53:26 INFO PythonRunner: Times: total = 8944, boot = 490, init = 403, finish = 8051
16/03/17 15:53:26 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:53:26 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.005 s
16/03/17 15:53:26 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:53:26 INFO DAGScheduler: running: Set()
16/03/17 15:53:26 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:53:26 INFO DAGScheduler: failed: Set()
16/03/17 15:53:26 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:53:26 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:53:26 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=548253204
16/03/17 15:53:26 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 522.8 MB)
16/03/17 15:53:26 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=548253204
16/03/17 15:53:26 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 522.8 MB)
16/03/17 15:53:26 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:44713 (size: 3.0 KB, free: 522.8 MB)
16/03/17 15:53:26 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:53:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:53:26 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:53:26 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9001 ms on localhost (2/2)
16/03/17 15:53:26 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:53:26 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:53:26 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:53:26 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:53:26 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:53:26 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:53:26 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:53:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:53:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:53:26 INFO PythonRunner: Times: total = 29, boot = -187, init = 215, finish = 1
16/03/17 15:53:26 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1297 bytes result sent to driver
reduceFunction_Parents(): returns= ['None', u'Chennai', 'None', u'Chennai']
16/03/17 15:53:26 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 46 ms on localhost (1/2)
16/03/17 15:53:26 INFO PythonRunner: Times: total = 213, boot = 212, init = 1, finish = 0
16/03/17 15:53:26 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:53:26 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 229 ms on localhost (2/2)
16/03/17 15:53:26 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:53:26 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.227 s
16/03/17 15:53:26 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.254362 s
16/03/17 15:53:26 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:53:26 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:53:26 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:53:26 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:53:26 INFO DAGScheduler: Missing parents: List()
16/03/17 15:53:26 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:53:26 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=548253204
16/03/17 15:53:26 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 522.8 MB)
16/03/17 15:53:26 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24940, maxMem=548253204
16/03/17 15:53:26 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 522.8 MB)
16/03/17 15:53:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:44713 (size: 3.3 KB, free: 522.8 MB)
16/03/17 15:53:26 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:53:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:53:26 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:53:26 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:53:26 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2378 bytes)
16/03/17 15:53:26 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:53:26 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:53:27 INFO PythonRunner: Times: total = 66, boot = -89, init = 155, finish = 0
16/03/17 15:53:27 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1365 bytes result sent to driver
16/03/17 15:53:27 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 92 ms on localhost (1/2)
16/03/17 15:53:27 INFO PythonRunner: Times: total = 89, boot = 89, init = 0, finish = 0
16/03/17 15:53:27 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:53:27 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 100 ms on localhost (2/2)
16/03/17 15:53:27 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:53:27 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.101 s
16/03/17 15:53:27 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.110875 s
16/03/17 15:53:27 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:53:27 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:53:27 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:53:27 INFO MemoryStore: MemoryStore cleared
16/03/17 15:53:27 INFO BlockManager: BlockManager stopped
16/03/17 15:53:27 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:53:27 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:53:27 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:53:27 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:53:27 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:53:27 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:53:28 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:53:28 INFO SecurityManager: Changing view acls to: root
16/03/17 15:53:28 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:53:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:53:28 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:53:28 INFO Remoting: Starting remoting
16/03/17 15:53:28 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:35169]
16/03/17 15:53:28 INFO Utils: Successfully started service 'sparkDriver' on port 35169.
16/03/17 15:53:28 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:53:28 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:53:28 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-29431fbc-79ad-4113-9b80-48a747cff106
16/03/17 15:53:28 INFO MemoryStore: MemoryStore started with capacity 522.9 MB
16/03/17 15:53:28 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-26a7119c-9daa-49a7-9fca-584454d9a868
16/03/17 15:53:28 INFO HttpServer: Starting HTTP Server
16/03/17 15:53:28 INFO Utils: Successfully started service 'HTTP file server' on port 37612.
16/03/17 15:53:28 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:53:28 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:53:28 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:53:28 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-c5783bee-b90f-4214-981a-8a1ecddf4def/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:53:28 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210208309
16/03/17 15:53:28 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:53:28 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:53:28 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58885.
16/03/17 15:53:28 INFO NettyBlockTransferService: Server created on 58885
16/03/17 15:53:28 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:53:28 INFO BlockManagerMasterEndpoint: Registering block manager localhost:58885 with 522.9 MB RAM, BlockManagerId(driver, localhost, 58885)
16/03/17 15:53:28 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:53:28 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:53:28 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:53:28 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:53:28 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:53:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:53:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:53:28 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:53:28 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=548253204
16/03/17 15:53:28 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 522.8 MB)
16/03/17 15:53:28 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=548253204
16/03/17 15:53:28 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 522.8 MB)
16/03/17 15:53:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:58885 (size: 4.1 KB, free: 522.9 MB)
16/03/17 15:53:28 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:53:28 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:53:28 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:53:28 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:53:28 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:53:28 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:53:28 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210208309
16/03/17 15:53:28 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:53:28 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-c5783bee-b90f-4214-981a-8a1ecddf4def/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:53:28 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:53:28 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10732, maxMem=548253204
16/03/17 15:53:28 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 522.8 MB)
16/03/17 15:53:28 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:58885 (size: 173.0 B, free: 522.9 MB)
16/03/17 15:53:28 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:53:28 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10905, maxMem=548253204
16/03/17 15:53:28 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 522.8 MB)
16/03/17 15:53:28 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:58885 (size: 179.0 B, free: 522.9 MB)
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: set
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: planning
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: permission
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: economy
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: composition
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: agency
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:53:37 INFO PythonRunner: Times: total = 8578, boot = 487, init = 391, finish = 7700
16/03/17 15:53:37 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:53:37 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8693 ms on localhost (1/2)
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: bend
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): adding to parents: syn =  Synset('bend.n.01') ; keyword:  circular  in syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= [u'bend']
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: giant
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: astatine
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: present
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: area
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: issue
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
16/03/17 15:53:37 INFO PythonRunner: Times: total = 8816, boot = 479, init = 425, finish = 7912
16/03/17 15:53:37 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:53:37 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8918 ms on localhost (2/2)
16/03/17 15:53:37 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:53:37 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.910 s
16/03/17 15:53:37 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:53:37 INFO DAGScheduler: running: Set()
16/03/17 15:53:37 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:53:37 INFO DAGScheduler: failed: Set()
16/03/17 15:53:37 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:53:37 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:53:37 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=548253204
16/03/17 15:53:37 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 522.8 MB)
16/03/17 15:53:37 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=548253204
16/03/17 15:53:37 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 522.8 MB)
16/03/17 15:53:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:58885 (size: 3.0 KB, free: 522.8 MB)
16/03/17 15:53:37 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:53:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:53:37 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:53:37 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:53:37 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:53:37 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:53:37 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:53:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:53:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:53:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:53:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:53:37 INFO PythonRunner: Times: total = 33, boot = -60, init = 93, finish = 0
16/03/17 15:53:37 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:53:37 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 83 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'bend', 'None']
16/03/17 15:53:37 INFO PythonRunner: Times: total = 210, boot = 209, init = 0, finish = 1
16/03/17 15:53:37 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1272 bytes result sent to driver
16/03/17 15:53:37 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.231 s
16/03/17 15:53:37 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.184893 s
16/03/17 15:53:37 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 229 ms on localhost (2/2)
16/03/17 15:53:37 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:53:37 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:53:37 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:53:37 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:53:37 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:53:37 INFO DAGScheduler: Missing parents: List()
16/03/17 15:53:37 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:53:37 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=548253204
16/03/17 15:53:37 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 522.8 MB)
16/03/17 15:53:37 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24940, maxMem=548253204
16/03/17 15:53:37 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 522.8 MB)
16/03/17 15:53:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:58885 (size: 3.3 KB, free: 522.8 MB)
16/03/17 15:53:37 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:53:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:53:37 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:53:37 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:53:37 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2353 bytes)
16/03/17 15:53:37 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:53:37 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:53:37 INFO PythonRunner: Times: total = 60, boot = 60, init = 0, finish = 0
16/03/17 15:53:37 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:53:37 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 69 ms on localhost (1/2)
16/03/17 15:53:37 INFO PythonRunner: Times: total = 67, boot = -36, init = 103, finish = 0
16/03/17 15:53:37 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1337 bytes result sent to driver
16/03/17 15:53:37 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 80 ms on localhost (2/2)
16/03/17 15:53:37 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:53:37 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.082 s
16/03/17 15:53:37 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.090376 s
16/03/17 15:53:37 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:53:37 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:53:38 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:53:38 INFO MemoryStore: MemoryStore cleared
16/03/17 15:53:38 INFO BlockManager: BlockManager stopped
16/03/17 15:53:38 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:53:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:53:38 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:53:38 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:53:38 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:53:38 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:53:38 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:53:38 INFO SecurityManager: Changing view acls to: root
16/03/17 15:53:38 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:53:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:53:38 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:53:38 INFO Remoting: Starting remoting
16/03/17 15:53:38 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:53593]
16/03/17 15:53:38 INFO Utils: Successfully started service 'sparkDriver' on port 53593.
16/03/17 15:53:38 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:53:38 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:53:38 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-03f83988-87b6-4fe0-b64a-45491b07a329
16/03/17 15:53:38 INFO MemoryStore: MemoryStore started with capacity 522.9 MB
16/03/17 15:53:39 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-de062171-0abf-492a-a84c-27594b4b74ac
16/03/17 15:53:39 INFO HttpServer: Starting HTTP Server
16/03/17 15:53:39 INFO Utils: Successfully started service 'HTTP file server' on port 58145.
16/03/17 15:53:39 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:53:39 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:53:39 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:53:39 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-3d2fb7f1-52a5-4bae-9d3c-9f13de948af0/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:53:39 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210219312
16/03/17 15:53:39 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:53:39 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:53:39 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51307.
16/03/17 15:53:39 INFO NettyBlockTransferService: Server created on 51307
16/03/17 15:53:39 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:53:39 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51307 with 522.9 MB RAM, BlockManagerId(driver, localhost, 51307)
16/03/17 15:53:39 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:53:39 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:53:39 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:53:39 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:53:39 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:53:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:53:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:53:39 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:53:39 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=548253204
16/03/17 15:53:39 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 522.8 MB)
16/03/17 15:53:39 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=548253204
16/03/17 15:53:39 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 522.8 MB)
16/03/17 15:53:39 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51307 (size: 4.1 KB, free: 522.9 MB)
16/03/17 15:53:39 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:53:39 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:53:39 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:53:39 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:53:39 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:53:39 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:53:39 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210219312
16/03/17 15:53:39 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:53:39 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-3d2fb7f1-52a5-4bae-9d3c-9f13de948af0/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:53:39 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:53:39 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=548253204
16/03/17 15:53:39 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 522.8 MB)
16/03/17 15:53:39 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:53:39 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:51307 (size: 179.0 B, free: 522.9 MB)
16/03/17 15:53:39 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=548253204
16/03/17 15:53:39 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 522.8 MB)
16/03/17 15:53:39 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:51307 (size: 173.0 B, free: 522.9 MB)
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: set
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: bend
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: giant
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: astatine
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  product  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: present
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: area
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: issue
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/17 15:53:48 INFO PythonRunner: Times: total = 8590, boot = 468, init = 415, finish = 7707
16/03/17 15:53:48 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:53:48 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8663 ms on localhost (1/2)
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: planning
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: permission
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: economy
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: composition
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: agency
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:53:48 INFO PythonRunner: Times: total = 8839, boot = 467, init = 393, finish = 7979
16/03/17 15:53:48 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:53:48 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.896 s
16/03/17 15:53:48 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:53:48 INFO DAGScheduler: running: Set()
16/03/17 15:53:48 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:53:48 INFO DAGScheduler: failed: Set()
16/03/17 15:53:48 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:53:48 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:53:48 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=548253204
16/03/17 15:53:48 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 522.8 MB)
16/03/17 15:53:48 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=548253204
16/03/17 15:53:48 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 522.8 MB)
16/03/17 15:53:48 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8894 ms on localhost (2/2)
16/03/17 15:53:48 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:53:48 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51307 (size: 3.0 KB, free: 522.8 MB)
16/03/17 15:53:48 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:53:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:53:48 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:53:48 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:53:48 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:53:48 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:53:48 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:53:48 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:53:48 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:53:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:53:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'astatine', 'None']
16/03/17 15:53:48 INFO PythonRunner: Times: total = 27, boot = -69, init = 95, finish = 1
16/03/17 15:53:48 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/03/17 15:53:48 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 64 ms on localhost (1/2)
16/03/17 15:53:48 INFO PythonRunner: Times: total = 204, boot = 203, init = 1, finish = 0
16/03/17 15:53:48 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:53:48 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 223 ms on localhost (2/2)
16/03/17 15:53:48 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:53:48 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.220 s
16/03/17 15:53:48 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.141752 s
16/03/17 15:53:48 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:53:48 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:53:48 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:53:48 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:53:48 INFO DAGScheduler: Missing parents: List()
16/03/17 15:53:48 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:53:48 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=548253204
16/03/17 15:53:48 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 522.8 MB)
16/03/17 15:53:48 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24940, maxMem=548253204
16/03/17 15:53:48 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 522.8 MB)
16/03/17 15:53:48 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:51307 (size: 3.3 KB, free: 522.8 MB)
16/03/17 15:53:48 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:53:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:53:48 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:53:48 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:53:48 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/03/17 15:53:48 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:53:48 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:53:48 INFO PythonRunner: Times: total = 62, boot = -45, init = 107, finish = 0
16/03/17 15:53:48 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:53:48 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 72 ms on localhost (1/2)
16/03/17 15:53:48 INFO PythonRunner: Times: total = 130, boot = 130, init = 0, finish = 0
16/03/17 15:53:48 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/03/17 15:53:48 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 140 ms on localhost (2/2)
16/03/17 15:53:48 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:53:48 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.127 s
16/03/17 15:53:48 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.151205 s
16/03/17 15:53:48 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:53:48 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:53:48 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:53:48 INFO MemoryStore: MemoryStore cleared
16/03/17 15:53:48 INFO BlockManager: BlockManager stopped
16/03/17 15:53:48 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:53:48 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:53:48 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:53:48 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:53:48 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:53:48 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:53:49 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:53:49 INFO SecurityManager: Changing view acls to: root
16/03/17 15:53:49 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:53:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:53:49 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:53:49 INFO Remoting: Starting remoting
16/03/17 15:53:49 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:52247]
16/03/17 15:53:49 INFO Utils: Successfully started service 'sparkDriver' on port 52247.
16/03/17 15:53:49 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:53:49 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:53:49 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c4061300-2a2c-4322-b74c-3d020d232da8
16/03/17 15:53:49 INFO MemoryStore: MemoryStore started with capacity 523.3 MB
16/03/17 15:53:49 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-575329a0-011a-4fe3-9746-8c720b03a5b9
16/03/17 15:53:49 INFO HttpServer: Starting HTTP Server
16/03/17 15:53:49 INFO Utils: Successfully started service 'HTTP file server' on port 57702.
16/03/17 15:53:49 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:53:50 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:53:50 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:53:50 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-1b0ae94a-1640-4cea-b1d3-7e3e9dda6071/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:53:50 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210230063
16/03/17 15:53:50 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:53:50 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:53:50 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52045.
16/03/17 15:53:50 INFO NettyBlockTransferService: Server created on 52045
16/03/17 15:53:50 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:53:50 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52045 with 523.3 MB RAM, BlockManagerId(driver, localhost, 52045)
16/03/17 15:53:50 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:53:50 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:53:50 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:53:50 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:53:50 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:53:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:53:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:53:50 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:53:50 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=548677877
16/03/17 15:53:50 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.3 MB)
16/03/17 15:53:50 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=548677877
16/03/17 15:53:50 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.2 MB)
16/03/17 15:53:50 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52045 (size: 4.1 KB, free: 523.3 MB)
16/03/17 15:53:50 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:53:50 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:53:50 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:53:50 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:53:50 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:53:50 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:53:50 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210230063
16/03/17 15:53:50 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:53:50 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-1b0ae94a-1640-4cea-b1d3-7e3e9dda6071/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:53:50 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:53:50 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=548677877
16/03/17 15:53:50 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 523.2 MB)
16/03/17 15:53:50 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:52045 (size: 179.0 B, free: 523.3 MB)
16/03/17 15:53:50 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:53:50 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=548677877
16/03/17 15:53:50 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 523.2 MB)
16/03/17 15:53:50 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:52045 (size: 173.0 B, free: 523.3 MB)
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: area
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: planning
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: permission
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: economy
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: composition
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: agency
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:53:58 INFO PythonRunner: Times: total = 8262, boot = 471, init = 421, finish = 7370
16/03/17 15:53:58 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:53:58 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8354 ms on localhost (1/2)
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  Synset('set.n.01') ; keyword:  used  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: bend
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: giant
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: astatine
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: present
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: area
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: issue
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
16/03/17 15:53:58 INFO PythonRunner: Times: total = 8569, boot = 482, init = 399, finish = 7688
16/03/17 15:53:58 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:53:58 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8658 ms on localhost (2/2)
16/03/17 15:53:58 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:53:58 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.646 s
16/03/17 15:53:58 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:53:58 INFO DAGScheduler: running: Set()
16/03/17 15:53:58 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:53:58 INFO DAGScheduler: failed: Set()
16/03/17 15:53:58 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:53:58 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:53:58 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=548677877
16/03/17 15:53:58 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.2 MB)
16/03/17 15:53:58 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=548677877
16/03/17 15:53:58 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.2 MB)
16/03/17 15:53:58 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52045 (size: 3.0 KB, free: 523.3 MB)
16/03/17 15:53:58 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:53:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:53:58 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:53:58 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:53:58 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:53:58 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:53:58 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:53:58 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:53:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:53:58 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:53:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= [u'set', 'None']
16/03/17 15:53:58 INFO PythonRunner: Times: total = 35, boot = -137, init = 172, finish = 0
16/03/17 15:53:58 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1271 bytes result sent to driver
16/03/17 15:53:58 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 103 ms on localhost (1/2)
16/03/17 15:53:59 INFO PythonRunner: Times: total = 211, boot = 210, init = 1, finish = 0
16/03/17 15:53:59 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:53:59 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.198 s
16/03/17 15:53:59 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.908903 s
16/03/17 15:53:59 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 228 ms on localhost (2/2)
16/03/17 15:53:59 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:53:59 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:53:59 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:53:59 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:53:59 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:53:59 INFO DAGScheduler: Missing parents: List()
16/03/17 15:53:59 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:53:59 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=548677877
16/03/17 15:53:59 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.2 MB)
16/03/17 15:53:59 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24940, maxMem=548677877
16/03/17 15:53:59 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.2 MB)
16/03/17 15:53:59 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:52045 (size: 3.3 KB, free: 523.2 MB)
16/03/17 15:53:59 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:53:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:53:59 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:53:59 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:53:59 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/17 15:53:59 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:53:59 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:53:59 INFO PythonRunner: Times: total = 70, boot = -52, init = 122, finish = 0
16/03/17 15:53:59 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:53:59 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 78 ms on localhost (1/2)
16/03/17 15:53:59 INFO PythonRunner: Times: total = 130, boot = 130, init = 0, finish = 0
16/03/17 15:53:59 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1336 bytes result sent to driver
16/03/17 15:53:59 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 145 ms on localhost (2/2)
16/03/17 15:53:59 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:53:59 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.127 s
16/03/17 15:53:59 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.165077 s
16/03/17 15:53:59 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:53:59 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:53:59 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:53:59 INFO MemoryStore: MemoryStore cleared
16/03/17 15:53:59 INFO BlockManager: BlockManager stopped
16/03/17 15:53:59 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:53:59 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:53:59 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:53:59 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:53:59 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:54:00 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:54:00 INFO SecurityManager: Changing view acls to: root
16/03/17 15:54:00 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:54:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:54:00 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:54:00 INFO Remoting: Starting remoting
16/03/17 15:54:00 INFO Utils: Successfully started service 'sparkDriver' on port 58300.
16/03/17 15:54:00 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:58300]
16/03/17 15:54:00 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:54:00 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:54:00 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-09dd960c-5234-4996-ba0d-40496d0bad7b
16/03/17 15:54:00 INFO MemoryStore: MemoryStore started with capacity 523.3 MB
16/03/17 15:54:00 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-fd7a10f8-adf5-4a8d-a0fc-bd790b370b0d
16/03/17 15:54:00 INFO HttpServer: Starting HTTP Server
16/03/17 15:54:00 INFO Utils: Successfully started service 'HTTP file server' on port 45205.
16/03/17 15:54:00 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:54:00 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:54:00 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:54:00 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-291fdb17-e9b5-47ca-8f4a-aafaa118b259/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:54:00 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210240645
16/03/17 15:54:00 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:54:00 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:54:00 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42331.
16/03/17 15:54:00 INFO NettyBlockTransferService: Server created on 42331
16/03/17 15:54:00 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:54:00 INFO BlockManagerMasterEndpoint: Registering block manager localhost:42331 with 523.3 MB RAM, BlockManagerId(driver, localhost, 42331)
16/03/17 15:54:00 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:54:00 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:54:00 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:54:00 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:54:00 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:54:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:54:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:54:00 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:54:00 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=548677877
16/03/17 15:54:00 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.3 MB)
16/03/17 15:54:00 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=548677877
16/03/17 15:54:00 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.2 MB)
16/03/17 15:54:00 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:42331 (size: 4.1 KB, free: 523.3 MB)
16/03/17 15:54:00 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:54:00 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:54:00 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:54:00 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:54:00 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:54:00 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:54:00 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210240645
16/03/17 15:54:00 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:54:00 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-291fdb17-e9b5-47ca-8f4a-aafaa118b259/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:54:00 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:54:00 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:54:00 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=548677877
16/03/17 15:54:00 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 523.2 MB)
16/03/17 15:54:00 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:42331 (size: 179.0 B, free: 523.3 MB)
16/03/17 15:54:00 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=548677877
16/03/17 15:54:00 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 523.2 MB)
16/03/17 15:54:00 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:42331 (size: 173.0 B, free: 523.3 MB)
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: area
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: bend
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: giant
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: astatine
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: present
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: area
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  usually  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: issue
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/17 15:54:09 INFO PythonRunner: Times: total = 8586, boot = 472, init = 392, finish = 7722
16/03/17 15:54:09 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:54:09 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8665 ms on localhost (1/2)
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  usually  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: planning
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: permission
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: economy
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: composition
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: agency
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/17 15:54:09 INFO PythonRunner: Times: total = 8684, boot = 469, init = 405, finish = 7810
16/03/17 15:54:09 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:54:09 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8758 ms on localhost (2/2)
16/03/17 15:54:09 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:54:09 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.760 s
16/03/17 15:54:09 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:54:09 INFO DAGScheduler: running: Set()
16/03/17 15:54:09 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:54:09 INFO DAGScheduler: failed: Set()
16/03/17 15:54:09 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:54:09 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:54:09 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=548677877
16/03/17 15:54:09 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.2 MB)
16/03/17 15:54:09 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=548677877
16/03/17 15:54:09 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.2 MB)
16/03/17 15:54:09 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:42331 (size: 3.0 KB, free: 523.3 MB)
16/03/17 15:54:09 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:54:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:54:09 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:54:09 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:54:09 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:54:09 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:54:09 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:54:09 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:54:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:54:09 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:54:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:54:09 INFO PythonRunner: Times: total = 223, boot = 222, init = 0, finish = 1
16/03/17 15:54:09 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:54:09 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 242 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'area', u'area']
16/03/17 15:54:09 INFO PythonRunner: Times: total = 257, boot = 254, init = 1, finish = 2
16/03/17 15:54:09 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/17 15:54:09 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.261 s
16/03/17 15:54:09 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.058434 s
16/03/17 15:54:09 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 275 ms on localhost (2/2)
16/03/17 15:54:09 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:54:10 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:54:10 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:54:10 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:54:10 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:54:10 INFO DAGScheduler: Missing parents: List()
16/03/17 15:54:10 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:54:10 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=548677877
16/03/17 15:54:10 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.2 MB)
16/03/17 15:54:10 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:42331 in memory (size: 3.0 KB, free: 523.3 MB)
16/03/17 15:54:10 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=16900, maxMem=548677877
16/03/17 15:54:10 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.2 MB)
16/03/17 15:54:10 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:42331 (size: 3.3 KB, free: 523.3 MB)
16/03/17 15:54:10 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:54:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:54:10 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:54:10 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:54:10 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/17 15:54:10 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:54:10 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:54:10 INFO PythonRunner: Times: total = 11, boot = -108, init = 119, finish = 0
16/03/17 15:54:10 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:54:10 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 37 ms on localhost (1/2)
16/03/17 15:54:10 INFO PythonRunner: Times: total = 10, boot = -191, init = 201, finish = 0
16/03/17 15:54:10 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/03/17 15:54:10 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 60 ms on localhost (2/2)
16/03/17 15:54:10 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:54:10 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.054 s
16/03/17 15:54:10 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.071148 s
16/03/17 15:54:10 INFO ContextCleaner: Cleaned accumulator 355
16/03/17 15:54:10 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:42331 in memory (size: 4.1 KB, free: 523.3 MB)
16/03/17 15:54:10 INFO ContextCleaner: Cleaned accumulator 354
16/03/17 15:54:10 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:54:10 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:54:10 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:54:10 INFO MemoryStore: MemoryStore cleared
16/03/17 15:54:10 INFO BlockManager: BlockManager stopped
16/03/17 15:54:10 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:54:10 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:54:10 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:54:10 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:54:10 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:54:10 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:54:11 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:54:11 INFO SecurityManager: Changing view acls to: root
16/03/17 15:54:11 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:54:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:54:11 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:54:11 INFO Remoting: Starting remoting
16/03/17 15:54:11 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:44517]
16/03/17 15:54:11 INFO Utils: Successfully started service 'sparkDriver' on port 44517.
16/03/17 15:54:11 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:54:11 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:54:11 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c6f578b9-d118-4d0f-84ce-1a8a0eb90dff
16/03/17 15:54:11 INFO MemoryStore: MemoryStore started with capacity 523.8 MB
16/03/17 15:54:11 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-33bfc841-f02f-4b48-84f4-6dbad324ff19
16/03/17 15:54:11 INFO HttpServer: Starting HTTP Server
16/03/17 15:54:11 INFO Utils: Successfully started service 'HTTP file server' on port 54374.
16/03/17 15:54:11 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:54:11 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:54:11 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:54:11 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-e9733d58-4d11-43a2-8500-0fa09c504394/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:54:11 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210251643
16/03/17 15:54:11 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:54:11 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:54:11 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51426.
16/03/17 15:54:11 INFO NettyBlockTransferService: Server created on 51426
16/03/17 15:54:11 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:54:11 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51426 with 523.8 MB RAM, BlockManagerId(driver, localhost, 51426)
16/03/17 15:54:11 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:54:11 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:54:11 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:54:11 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:54:11 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:54:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:54:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:54:11 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:54:11 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=549244108
16/03/17 15:54:11 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.8 MB)
16/03/17 15:54:11 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=549244108
16/03/17 15:54:11 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.8 MB)
16/03/17 15:54:11 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51426 (size: 4.1 KB, free: 523.8 MB)
16/03/17 15:54:11 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:54:11 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:54:11 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:54:11 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:54:11 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:54:11 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:54:11 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210251643
16/03/17 15:54:11 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:54:11 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-e9733d58-4d11-43a2-8500-0fa09c504394/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:54:11 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:54:11 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:54:11 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=549244108
16/03/17 15:54:11 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 523.8 MB)
16/03/17 15:54:11 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=549244108
16/03/17 15:54:11 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 523.8 MB)
16/03/17 15:54:11 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:51426 (size: 179.0 B, free: 523.8 MB)
16/03/17 15:54:11 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:51426 (size: 173.0 B, free: 523.8 MB)
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: set
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: bend
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: giant
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: astatine
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: present
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  moment  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: area
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: issue
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/17 15:54:20 INFO PythonRunner: Times: total = 8589, boot = 538, init = 410, finish = 7641
16/03/17 15:54:20 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary'16/03/17 15:54:20 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8651 ms on localhost (1/2)
, u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: planning
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: permission
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: economy
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: composition
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: agency
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:54:20 INFO PythonRunner: Times: total = 8679, boot = 546, init = 400, finish = 7733
16/03/17 15:54:20 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:54:20 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.750 s
16/03/17 15:54:20 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:54:20 INFO DAGScheduler: running: Set()
16/03/17 15:54:20 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:54:20 INFO DAGScheduler: failed: Set()
16/03/17 15:54:20 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:54:20 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:54:20 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=549244108
16/03/17 15:54:20 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.8 MB)
16/03/17 15:54:20 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=549244108
16/03/17 15:54:20 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.8 MB)
16/03/17 15:54:20 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51426 (size: 3.0 KB, free: 523.8 MB)
16/03/17 15:54:20 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:54:20 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:54:20 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:54:20 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8743 ms on localhost (2/2)
16/03/17 15:54:20 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:54:20 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:54:20 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:54:20 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:54:20 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:54:20 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:54:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:54:20 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:54:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'present', 'None']
16/03/17 15:54:20 INFO PythonRunner: Times: total = 116, boot = 114, init = 1, finish = 1
16/03/17 15:54:20 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/17 15:54:20 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 135 ms on localhost (1/2)
16/03/17 15:54:20 INFO PythonRunner: Times: total = 234, boot = 233, init = 0, finish = 1
16/03/17 15:54:20 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:54:20 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.261 s
16/03/17 15:54:20 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.028468 s
16/03/17 15:54:20 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 261 ms on localhost (2/2)
16/03/17 15:54:20 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:54:20 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:54:20 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:54:20 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:54:20 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:54:20 INFO DAGScheduler: Missing parents: List()
16/03/17 15:54:20 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:54:20 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=549244108
16/03/17 15:54:20 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.8 MB)
16/03/17 15:54:20 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24940, maxMem=549244108
16/03/17 15:54:20 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.8 MB)
16/03/17 15:54:20 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:51426 (size: 3.3 KB, free: 523.8 MB)
16/03/17 15:54:20 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:54:20 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:54:20 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:54:20 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:54:20 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/17 15:54:20 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:54:20 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:54:20 INFO PythonRunner: Times: total = 17, boot = -31, init = 48, finish = 0
16/03/17 15:54:20 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:54:20 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 40 ms on localhost (1/2)
16/03/17 15:54:21 INFO PythonRunner: Times: total = 131, boot = 131, init = 0, finish = 0
16/03/17 15:54:21 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1351 bytes result sent to driver
16/03/17 15:54:21 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 141 ms on localhost (2/2)
16/03/17 15:54:21 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:54:21 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.143 s
16/03/17 15:54:21 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.151546 s
16/03/17 15:54:21 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:54:21 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:54:21 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:54:21 INFO MemoryStore: MemoryStore cleared
16/03/17 15:54:21 INFO BlockManager: BlockManager stopped
16/03/17 15:54:21 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:54:21 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:54:21 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:54:21 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:54:21 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:54:21 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:54:22 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:54:22 INFO SecurityManager: Changing view acls to: root
16/03/17 15:54:22 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:54:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:54:22 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:54:22 INFO Remoting: Starting remoting
16/03/17 15:54:22 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:54734]
16/03/17 15:54:22 INFO Utils: Successfully started service 'sparkDriver' on port 54734.
16/03/17 15:54:22 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:54:22 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:54:22 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a914852b-cc9a-4b33-8cbe-08fd92c0dfb8
16/03/17 15:54:22 INFO MemoryStore: MemoryStore started with capacity 523.8 MB
16/03/17 15:54:22 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-502a238f-dfeb-493c-950f-e76d6eae4cc2
16/03/17 15:54:22 INFO HttpServer: Starting HTTP Server
16/03/17 15:54:22 INFO Utils: Successfully started service 'HTTP file server' on port 58261.
16/03/17 15:54:22 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:54:22 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:54:22 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:54:22 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-aa4adbac-e883-42bb-8a49-307f34bba05c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:54:22 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210262324
16/03/17 15:54:22 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:54:22 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:54:22 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 48617.
16/03/17 15:54:22 INFO NettyBlockTransferService: Server created on 48617
16/03/17 15:54:22 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:54:22 INFO BlockManagerMasterEndpoint: Registering block manager localhost:48617 with 523.8 MB RAM, BlockManagerId(driver, localhost, 48617)
16/03/17 15:54:22 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:54:22 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:54:22 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:54:22 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:54:22 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:54:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:54:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:54:22 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:54:22 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=549244108
16/03/17 15:54:22 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.8 MB)
16/03/17 15:54:22 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=549244108
16/03/17 15:54:22 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.8 MB)
16/03/17 15:54:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:48617 (size: 4.1 KB, free: 523.8 MB)
16/03/17 15:54:22 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:54:22 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:54:22 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:54:22 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:54:22 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:54:22 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:54:22 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210262324
16/03/17 15:54:22 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:54:22 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-aa4adbac-e883-42bb-8a49-307f34bba05c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:54:22 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:54:22 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=549244108
16/03/17 15:54:22 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 523.8 MB)
16/03/17 15:54:22 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:48617 (size: 179.0 B, free: 523.8 MB)
16/03/17 15:54:22 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:54:22 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=549244108
16/03/17 15:54:22 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 523.8 MB)
16/03/17 15:54:22 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:48617 (size: 173.0 B, free: 523.8 MB)
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: area
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  purpose  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: planning
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: permission
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: economy
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: composition
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: agency
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/17 15:54:31 INFO PythonRunner: Times: total = 8585, boot = 505, init = 415, finish = 7665
16/03/17 15:54:31 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:54:31 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8668 ms on localhost (1/2)
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: bend
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: giant
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: astatine
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: present
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: area
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  purpose  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: issue
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/17 15:54:31 INFO PythonRunner: Times: total = 8781, boot = 511, init = 385, finish = 7885
16/03/17 15:54:31 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:54:31 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.875 s
16/03/17 15:54:31 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:54:31 INFO DAGScheduler: running: Set()
16/03/17 15:54:31 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:54:31 INFO DAGScheduler: failed: Set()
16/03/17 15:54:31 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:54:31 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:54:31 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8871 ms on localhost (2/2)
16/03/17 15:54:31 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:54:31 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=549244108
16/03/17 15:54:31 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.8 MB)
16/03/17 15:54:31 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=549244108
16/03/17 15:54:31 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.8 MB)
16/03/17 15:54:31 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:48617 (size: 3.0 KB, free: 523.8 MB)
16/03/17 15:54:31 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:54:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:54:31 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:54:31 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:54:31 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:54:31 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:54:31 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:54:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:54:31 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:54:31 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:54:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:54:31 INFO PythonRunner: Times: total = 37, boot = -17, init = 54, finish = 0
16/03/17 15:54:31 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:54:31 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 67 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'area', u'area']
16/03/17 15:54:31 INFO PythonRunner: Times: total = 228, boot = 226, init = 1, finish = 1
16/03/17 15:54:31 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/17 15:54:31 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.233 s
16/03/17 15:54:31 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.145234 s
16/03/17 15:54:31 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 249 ms on localhost (2/2)
16/03/17 15:54:31 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:54:31 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:54:31 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:54:31 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:54:31 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:54:31 INFO DAGScheduler: Missing parents: List()
16/03/17 15:54:31 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:54:31 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=549244108
16/03/17 15:54:31 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.8 MB)
16/03/17 15:54:31 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24940, maxMem=549244108
16/03/17 15:54:31 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.8 MB)
16/03/17 15:54:31 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:48617 (size: 3.3 KB, free: 523.8 MB)
16/03/17 15:54:31 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:54:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:54:31 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:54:31 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:54:31 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/17 15:54:31 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:54:31 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:54:31 INFO PythonRunner: Times: total = 55, boot = -49, init = 104, finish = 0
16/03/17 15:54:31 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/03/17 15:54:31 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 73 ms on localhost (1/2)
16/03/17 15:54:31 INFO PythonRunner: Times: total = 178, boot = 178, init = 0, finish = 0
16/03/17 15:54:31 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:54:31 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 194 ms on localhost (2/2)
16/03/17 15:54:31 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:54:31 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.173 s
16/03/17 15:54:31 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.205443 s
16/03/17 15:54:31 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:54:31 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:54:32 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:54:32 INFO MemoryStore: MemoryStore cleared
16/03/17 15:54:32 INFO BlockManager: BlockManager stopped
16/03/17 15:54:32 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:54:32 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:54:32 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:54:32 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:54:32 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:54:32 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:54:32 INFO SecurityManager: Changing view acls to: root
16/03/17 15:54:32 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:54:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:54:32 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:54:32 INFO Remoting: Starting remoting
16/03/17 15:54:33 INFO Utils: Successfully started service 'sparkDriver' on port 50551.
16/03/17 15:54:33 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:50551]
16/03/17 15:54:33 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:54:33 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:54:33 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-775b4a0d-b4b2-4607-8ced-c44875771574
16/03/17 15:54:33 INFO MemoryStore: MemoryStore started with capacity 523.8 MB
16/03/17 15:54:33 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-c358bac6-9e67-4f50-a0ba-448de83db527
16/03/17 15:54:33 INFO HttpServer: Starting HTTP Server
16/03/17 15:54:33 INFO Utils: Successfully started service 'HTTP file server' on port 41449.
16/03/17 15:54:33 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:54:33 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:54:33 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:54:33 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-2aa328d2-ea94-4481-ac7d-f15dbb5f8403/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:54:33 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210273162
16/03/17 15:54:33 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:54:33 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:54:33 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60063.
16/03/17 15:54:33 INFO NettyBlockTransferService: Server created on 60063
16/03/17 15:54:33 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:54:33 INFO BlockManagerMasterEndpoint: Registering block manager localhost:60063 with 523.8 MB RAM, BlockManagerId(driver, localhost, 60063)
16/03/17 15:54:33 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:54:33 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:54:33 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:54:33 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:54:33 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:54:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:54:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:54:33 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:54:33 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=549244108
16/03/17 15:54:33 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.8 MB)
16/03/17 15:54:33 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=549244108
16/03/17 15:54:33 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.8 MB)
16/03/17 15:54:33 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:60063 (size: 4.1 KB, free: 523.8 MB)
16/03/17 15:54:33 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:54:33 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:54:33 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:54:33 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:54:33 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:54:33 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:54:33 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210273162
16/03/17 15:54:33 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:54:33 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-2aa328d2-ea94-4481-ac7d-f15dbb5f8403/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:54:33 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:54:33 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:54:33 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10732, maxMem=549244108
16/03/17 15:54:33 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 523.8 MB)
16/03/17 15:54:33 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10905, maxMem=549244108
16/03/17 15:54:33 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:60063 (size: 173.0 B, free: 523.8 MB)
16/03/17 15:54:33 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 523.8 MB)
16/03/17 15:54:33 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:60063 (size: 179.0 B, free: 523.8 MB)
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: area
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: bend
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): adding to parents: syn =  Synset('bend.n.01') ; keyword:  segment  in syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= [u'bend']
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: giant
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: astatine
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: present
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: area
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: issue
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
16/03/17 15:54:42 INFO PythonRunner: Times: total = 8542, boot = 462, init = 380, finish = 7700
16/03/17 15:54:42 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:54:42 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8624 ms on localhost (1/2)
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: planning
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: permission
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: economy
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: composition
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: agency
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:54:42 INFO PythonRunner: Times: total = 8665, boot = 471, init = 426, finish = 7768
16/03/17 15:54:42 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:54:42 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.748 s
16/03/17 15:54:42 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:54:42 INFO DAGScheduler: running: Set()
16/03/17 15:54:42 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:54:42 INFO DAGScheduler: failed: Set()
16/03/17 15:54:42 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:54:42 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:54:42 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=549244108
16/03/17 15:54:42 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.8 MB)
16/03/17 15:54:42 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=549244108
16/03/17 15:54:42 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.8 MB)
16/03/17 15:54:42 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8743 ms on localhost (2/2)
16/03/17 15:54:42 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:54:42 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:60063 (size: 3.0 KB, free: 523.8 MB)
16/03/17 15:54:42 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:54:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:54:42 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:54:42 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:54:42 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:54:42 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:54:42 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:54:42 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:54:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:54:42 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:54:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
reduceFunction_Parents(): returns= [u'bend', 'None']
16/03/17 15:54:42 INFO PythonRunner: Times: total = 108, boot = 106, init = 1, finish = 1
16/03/17 15:54:42 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1272 bytes result sent to driver
16/03/17 15:54:42 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 124 ms on localhost (1/2)
16/03/17 15:54:42 INFO PythonRunner: Times: total = 240, boot = 239, init = 1, finish = 0
16/03/17 15:54:42 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:54:42 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.262 s
16/03/17 15:54:42 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 262 ms on localhost (2/2)
16/03/17 15:54:42 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.027573 s
16/03/17 15:54:42 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:54:42 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:54:42 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:54:42 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:54:42 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:54:42 INFO DAGScheduler: Missing parents: List()
16/03/17 15:54:42 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:54:42 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=549244108
16/03/17 15:54:42 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.8 MB)
16/03/17 15:54:42 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24940, maxMem=549244108
16/03/17 15:54:42 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.8 MB)
16/03/17 15:54:42 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:60063 (size: 3.3 KB, free: 523.8 MB)
16/03/17 15:54:42 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:54:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:54:42 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:54:42 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:54:42 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2353 bytes)
16/03/17 15:54:42 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:54:42 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:54:42 INFO PythonRunner: Times: total = 18, boot = -32, init = 50, finish = 0
16/03/17 15:54:42 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1337 bytes result sent to driver
16/03/17 15:54:42 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 56 ms on localhost (1/2)
16/03/17 15:54:43 INFO PythonRunner: Times: total = 300, boot = 293, init = 7, finish = 0
16/03/17 15:54:43 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:54:43 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 311 ms on localhost (2/2)
16/03/17 15:54:43 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:54:43 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.297 s
16/03/17 15:54:43 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.320223 s
16/03/17 15:54:43 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:54:43 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:54:43 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:54:43 INFO MemoryStore: MemoryStore cleared
16/03/17 15:54:43 INFO BlockManager: BlockManager stopped
16/03/17 15:54:43 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:54:43 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:54:43 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:54:43 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:54:43 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:54:43 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:54:44 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:54:44 INFO SecurityManager: Changing view acls to: root
16/03/17 15:54:44 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:54:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:54:44 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:54:44 INFO Remoting: Starting remoting
16/03/17 15:54:44 INFO Utils: Successfully started service 'sparkDriver' on port 45763.
16/03/17 15:54:44 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:45763]
16/03/17 15:54:44 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:54:44 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:54:44 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-fb64b662-bf0c-44ef-9c53-fb8530fd3e79
16/03/17 15:54:44 INFO MemoryStore: MemoryStore started with capacity 523.5 MB
16/03/17 15:54:44 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-690fbec0-c90d-417b-93e5-27a7c1b49926
16/03/17 15:54:44 INFO HttpServer: Starting HTTP Server
16/03/17 15:54:44 INFO Utils: Successfully started service 'HTTP file server' on port 56377.
16/03/17 15:54:44 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:54:44 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:54:44 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:54:44 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-bd8388f1-b95b-4425-b180-7521dfab3842/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:54:44 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210284272
16/03/17 15:54:44 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:54:44 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:54:44 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59725.
16/03/17 15:54:44 INFO NettyBlockTransferService: Server created on 59725
16/03/17 15:54:44 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:54:44 INFO BlockManagerMasterEndpoint: Registering block manager localhost:59725 with 523.5 MB RAM, BlockManagerId(driver, localhost, 59725)
16/03/17 15:54:44 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:54:44 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:54:44 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:54:44 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:54:44 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:54:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:54:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:54:44 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:54:44 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=548960993
16/03/17 15:54:44 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.5 MB)
16/03/17 15:54:44 INFO MemoryStore: ensureFreeSpace(4154) called with curMem=6576, maxMem=548960993
16/03/17 15:54:44 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.5 MB)
16/03/17 15:54:44 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:59725 (size: 4.1 KB, free: 523.5 MB)
16/03/17 15:54:44 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:54:44 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:54:44 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:54:44 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:54:44 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:54:44 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:54:44 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210284272
16/03/17 15:54:44 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:54:44 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-bd8388f1-b95b-4425-b180-7521dfab3842/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:54:44 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:54:44 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:54:44 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10730, maxMem=548960993
16/03/17 15:54:44 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 523.5 MB)
16/03/17 15:54:44 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:59725 (size: 179.0 B, free: 523.5 MB)
16/03/17 15:54:44 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10909, maxMem=548960993
16/03/17 15:54:44 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 523.5 MB)
16/03/17 15:54:44 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:59725 (size: 173.0 B, free: 523.5 MB)
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: set
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: bend
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: giant
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: astatine
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  radioactive  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: present
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []mapFunction_Parents(): keyword=
 radioactive ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
reduceFunction_Parents(): returns= asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword:[ radioactive ; prevleveltokens: Chennai
]
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: planning
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: area
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
'asfer_pickle_string_load(): picklef.readlines(): radioactive
NmapFunction_Parents(): keyword: radioactive ; prevleveltokens: issue
one']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: permission
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: economy
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: composition
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', mapFunction_Parents(): keyword=u'the' radioactive ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
, u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: agency
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:54:53 INFO PythonRunner: Times: total = 8899, boot = 469, init = 419, finish = 8011
16/03/17 15:54:53 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:54:53 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8965 ms on localhost (1/2)
16/03/17 15:54:53 INFO PythonRunner: Times: total = 8948, boot = 462, init = 390, finish = 8096
16/03/17 15:54:53 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:54:53 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.022 s
16/03/17 15:54:53 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:54:53 INFO DAGScheduler: running: Set()
16/03/17 15:54:53 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:54:53 INFO DAGScheduler: failed: Set()
16/03/17 15:54:53 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:54:53 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:54:53 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11082, maxMem=548960993
16/03/17 15:54:53 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.5 MB)
16/03/17 15:54:53 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16066, maxMem=548960993
16/03/17 15:54:53 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.5 MB)
16/03/17 15:54:53 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9020 ms on localhost (2/2)
16/03/17 15:54:53 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:54:53 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:59725 (size: 3.0 KB, free: 523.5 MB)
16/03/17 15:54:53 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:54:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:54:53 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:54:53 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:54:53 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:54:53 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:54:53 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:54:53 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:54:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:54:53 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:54:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:54:53 INFO PythonRunner: Times: total = 230, boot = 229, init = 1, finish = 0
16/03/17 15:54:53 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:54:53 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 246 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'astatine', 'None']
16/03/17 15:54:53 INFO PythonRunner: Times: total = 261, boot = 260, init = 0, finish = 1
16/03/17 15:54:53 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/03/17 15:54:53 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.284 s
16/03/17 15:54:53 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.326288 s
16/03/17 15:54:53 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 285 ms on localhost (2/2)
16/03/17 15:54:53 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:54:53 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:54:53 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:54:53 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:54:53 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:54:53 INFO DAGScheduler: Missing parents: List()
16/03/17 15:54:53 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:54:53 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19121, maxMem=548960993
16/03/17 15:54:53 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.5 MB)
16/03/17 15:54:53 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24937, maxMem=548960993
16/03/17 15:54:53 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.5 MB)
16/03/17 15:54:53 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:59725 (size: 3.3 KB, free: 523.5 MB)
16/03/17 15:54:53 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:54:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:54:53 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:54:53 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:54:53 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/03/17 15:54:53 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:54:53 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:54:53 INFO PythonRunner: Times: total = 106, boot = 106, init = 0, finish = 0
16/03/17 15:54:53 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:54:53 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 112 ms on localhost (1/2)
16/03/17 15:54:53 INFO PythonRunner: Times: total = 107, boot = 107, init = 0, finish = 0
16/03/17 15:54:53 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/03/17 15:54:53 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 116 ms on localhost (2/2)
16/03/17 15:54:53 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:54:53 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.090 s
16/03/17 15:54:53 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.133031 s
16/03/17 15:54:54 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:54:54 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:54:54 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:54:54 INFO MemoryStore: MemoryStore cleared
16/03/17 15:54:54 INFO BlockManager: BlockManager stopped
16/03/17 15:54:54 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:54:54 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:54:54 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:54:54 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:54:54 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:54:54 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:54:55 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:54:55 INFO SecurityManager: Changing view acls to: root
16/03/17 15:54:55 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:54:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:54:55 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:54:55 INFO Remoting: Starting remoting
16/03/17 15:54:55 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:37451]
16/03/17 15:54:55 INFO Utils: Successfully started service 'sparkDriver' on port 37451.
16/03/17 15:54:55 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:54:55 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:54:55 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9c33264b-ccbe-4d23-b546-96258517c2b9
16/03/17 15:54:55 INFO MemoryStore: MemoryStore started with capacity 523.5 MB
16/03/17 15:54:55 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-a4653426-5f60-425d-82a5-7306d81a8dd7
16/03/17 15:54:55 INFO HttpServer: Starting HTTP Server
16/03/17 15:54:55 INFO Utils: Successfully started service 'HTTP file server' on port 51585.
16/03/17 15:54:55 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:54:55 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:54:55 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:54:55 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-a80c7140-4bf5-42ca-80fc-3de4706b9abd/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:54:55 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210295249
16/03/17 15:54:55 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:54:55 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:54:55 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43967.
16/03/17 15:54:55 INFO NettyBlockTransferService: Server created on 43967
16/03/17 15:54:55 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:54:55 INFO BlockManagerMasterEndpoint: Registering block manager localhost:43967 with 523.5 MB RAM, BlockManagerId(driver, localhost, 43967)
16/03/17 15:54:55 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:54:55 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:54:55 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:54:55 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:54:55 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:54:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:54:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:54:55 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:54:55 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=548960993
16/03/17 15:54:55 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.5 MB)
16/03/17 15:54:55 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=548960993
16/03/17 15:54:55 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.5 MB)
16/03/17 15:54:55 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:43967 (size: 4.1 KB, free: 523.5 MB)
16/03/17 15:54:55 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:54:55 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:54:55 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:54:55 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:54:55 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:54:55 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:54:55 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210295249
16/03/17 15:54:55 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:54:55 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-a80c7140-4bf5-42ca-80fc-3de4706b9abd/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:54:55 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:54:55 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:54:55 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10732, maxMem=548960993
16/03/17 15:54:55 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 523.5 MB)
16/03/17 15:54:55 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10905, maxMem=548960993
16/03/17 15:54:55 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:43967 (size: 173.0 B, free: 523.5 MB)
16/03/17 15:54:55 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 523.5 MB)
16/03/17 15:54:55 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:43967 (size: 179.0 B, free: 523.5 MB)
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: area
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: planning
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: permission
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: economy
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: composition
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: agency
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:55:04 INFO PythonRunner: Times: total = 8617, boot = 469, init = 409, finish = 7739
16/03/17 15:55:04 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:55:04 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8694 ms on localhost (1/2)
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: bend
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: giant
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: astatine
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: present
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  happening  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: area
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: issue
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/17 15:55:04 INFO PythonRunner: Times: total = 8944, boot = 464, init = 401, finish = 8079
16/03/17 15:55:04 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:55:04 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9011 ms on localhost (2/2)
16/03/17 15:55:04 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:55:04 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.015 s
16/03/17 15:55:04 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:55:04 INFO DAGScheduler: running: Set()
16/03/17 15:55:04 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:55:04 INFO DAGScheduler: failed: Set()
16/03/17 15:55:04 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:55:04 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:55:04 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=548960993
16/03/17 15:55:04 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.5 MB)
16/03/17 15:55:04 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=548960993
16/03/17 15:55:04 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.5 MB)
16/03/17 15:55:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:43967 (size: 3.0 KB, free: 523.5 MB)
16/03/17 15:55:04 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:55:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:55:04 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:55:04 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:55:04 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:55:04 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:55:04 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:55:04 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:55:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:55:04 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:55:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'present', 'None']
16/03/17 15:55:04 INFO PythonRunner: Times: total = 28, boot = -150, init = 178, finish = 0
16/03/17 15:55:04 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/17 15:55:04 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 71 ms on localhost (1/2)
16/03/17 15:55:04 INFO PythonRunner: Times: total = 230, boot = 230, init = 0, finish = 0
16/03/17 15:55:04 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:55:04 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 252 ms on localhost (2/2)
16/03/17 15:55:04 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:55:04 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.252 s
16/03/17 15:55:04 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.286744 s
16/03/17 15:55:04 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:55:04 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:55:04 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:55:04 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:55:04 INFO DAGScheduler: Missing parents: List()
16/03/17 15:55:04 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:55:04 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=548960993
16/03/17 15:55:04 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.5 MB)
16/03/17 15:55:04 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24940, maxMem=548960993
16/03/17 15:55:04 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.5 MB)
16/03/17 15:55:04 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:43967 (size: 3.3 KB, free: 523.5 MB)
16/03/17 15:55:04 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:55:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:55:04 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:55:04 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:55:04 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/17 15:55:04 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:55:04 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:55:04 INFO PythonRunner: Times: total = 73, boot = -105, init = 178, finish = 0
16/03/17 15:55:04 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:55:04 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 80 ms on localhost (1/2)
16/03/17 15:55:04 INFO PythonRunner: Times: total = 93, boot = 92, init = 1, finish = 0
16/03/17 15:55:04 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1351 bytes result sent to driver
16/03/17 15:55:04 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 103 ms on localhost (2/2)
16/03/17 15:55:04 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:55:04 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.104 s
16/03/17 15:55:04 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.118698 s
16/03/17 15:55:04 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:55:04 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:55:05 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:55:05 INFO MemoryStore: MemoryStore cleared
16/03/17 15:55:05 INFO BlockManager: BlockManager stopped
16/03/17 15:55:05 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:55:05 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:55:05 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:55:05 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:55:05 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:55:05 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:55:05 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:55:05 INFO SecurityManager: Changing view acls to: root
16/03/17 15:55:05 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:55:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:55:06 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:55:06 INFO Remoting: Starting remoting
16/03/17 15:55:06 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:49738]
16/03/17 15:55:06 INFO Utils: Successfully started service 'sparkDriver' on port 49738.
16/03/17 15:55:06 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:55:06 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:55:06 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-31ae82eb-4d41-410a-8c18-1f477d9e3ead
16/03/17 15:55:06 INFO MemoryStore: MemoryStore started with capacity 525.6 MB
16/03/17 15:55:06 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-454b5fd6-b712-4e88-bb06-b9b03deadb18
16/03/17 15:55:06 INFO HttpServer: Starting HTTP Server
16/03/17 15:55:06 INFO Utils: Successfully started service 'HTTP file server' on port 39117.
16/03/17 15:55:06 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:55:06 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:55:06 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:55:06 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-2e87dfc1-3813-4ca7-beea-0451094e1131/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:55:06 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210306306
16/03/17 15:55:06 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:55:06 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:55:06 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56237.
16/03/17 15:55:06 INFO NettyBlockTransferService: Server created on 56237
16/03/17 15:55:06 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:55:06 INFO BlockManagerMasterEndpoint: Registering block manager localhost:56237 with 525.6 MB RAM, BlockManagerId(driver, localhost, 56237)
16/03/17 15:55:06 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:55:06 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:55:06 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:55:06 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:55:06 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:55:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:55:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:55:06 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:55:06 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=551084359
16/03/17 15:55:06 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 525.5 MB)
16/03/17 15:55:06 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=551084359
16/03/17 15:55:06 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 525.5 MB)
16/03/17 15:55:06 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:56237 (size: 4.1 KB, free: 525.6 MB)
16/03/17 15:55:06 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:55:06 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:55:06 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:55:06 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:55:06 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:55:06 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:55:06 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210306306
16/03/17 15:55:06 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:55:06 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-2e87dfc1-3813-4ca7-beea-0451094e1131/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:55:06 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:55:06 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=551084359
16/03/17 15:55:06 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 525.5 MB)
16/03/17 15:55:06 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:56237 (size: 179.0 B, free: 525.6 MB)
16/03/17 15:55:06 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:55:06 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=551084359
16/03/17 15:55:06 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 525.5 MB)
16/03/17 15:55:06 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:56237 (size: 173.0 B, free: 525.6 MB)
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: set
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: planning
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: permission
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: economy
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: composition
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: agency
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:55:14 INFO PythonRunner: Times: total = 8333, boot = 468, init = 401, finish = 7464
16/03/17 15:55:14 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:55:14 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8398 ms on localhost (1/2)
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: bend
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): adding to parents: syn =  Synset('bend.n.01') ; keyword:  curve  in syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= [u'bend']
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: giant
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: astatine
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: present
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: area
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: issue
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
16/03/17 15:55:15 INFO PythonRunner: Times: total = 8685, boot = 476, init = 409, finish = 7800
16/03/17 15:55:15 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:55:15 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.753 s
16/03/17 15:55:15 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:55:15 INFO DAGScheduler: running: Set()
16/03/17 15:55:15 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:55:15 INFO DAGScheduler: failed: Set()
16/03/17 15:55:15 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:55:15 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:55:15 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=551084359
16/03/17 15:55:15 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 525.5 MB)
16/03/17 15:55:15 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=551084359
16/03/17 15:55:15 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 525.5 MB)
16/03/17 15:55:15 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8748 ms on localhost (2/2)
16/03/17 15:55:15 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:55:15 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:56237 (size: 3.0 KB, free: 525.5 MB)
16/03/17 15:55:15 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:55:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:55:15 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:55:15 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:55:15 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:55:15 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:55:15 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:55:15 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:55:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:55:15 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:55:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= [u'bend', 'None']
16/03/17 15:55:15 INFO PythonRunner: Times: total = 31, boot = -177, init = 208, finish = 0
16/03/17 15:55:15 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1272 bytes result sent to driver
16/03/17 15:55:15 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 76 ms on localhost (1/2)
16/03/17 15:55:15 INFO PythonRunner: Times: total = 210, boot = 209, init = 1, finish = 0
16/03/17 15:55:15 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:55:15 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.236 s
16/03/17 15:55:15 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.011298 s
16/03/17 15:55:15 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 237 ms on localhost (2/2)
16/03/17 15:55:15 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:55:15 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:55:15 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:55:15 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:55:15 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:55:15 INFO DAGScheduler: Missing parents: List()
16/03/17 15:55:15 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:55:15 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=551084359
16/03/17 15:55:15 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 525.5 MB)
16/03/17 15:55:15 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24940, maxMem=551084359
16/03/17 15:55:15 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 525.5 MB)
16/03/17 15:55:15 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:56237 (size: 3.3 KB, free: 525.5 MB)
16/03/17 15:55:15 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:55:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:55:15 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:55:15 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:55:15 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2353 bytes)
16/03/17 15:55:15 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:55:15 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:55:15 INFO PythonRunner: Times: total = 62, boot = -118, init = 180, finish = 0
16/03/17 15:55:15 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:55:15 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 73 ms on localhost (1/2)
16/03/17 15:55:15 INFO PythonRunner: Times: total = 78, boot = 78, init = 0, finish = 0
16/03/17 15:55:15 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1337 bytes result sent to driver
16/03/17 15:55:15 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 90 ms on localhost (2/2)
16/03/17 15:55:15 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:55:15 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.076 s
16/03/17 15:55:15 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.099526 s
16/03/17 15:55:15 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:55:15 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:55:15 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:55:15 INFO MemoryStore: MemoryStore cleared
16/03/17 15:55:15 INFO BlockManager: BlockManager stopped
16/03/17 15:55:15 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:55:15 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:55:15 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:55:15 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:55:15 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:55:15 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:55:16 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:55:16 INFO SecurityManager: Changing view acls to: root
16/03/17 15:55:16 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:55:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:55:16 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:55:16 INFO Remoting: Starting remoting
16/03/17 15:55:16 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:49305]
16/03/17 15:55:16 INFO Utils: Successfully started service 'sparkDriver' on port 49305.
16/03/17 15:55:16 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:55:16 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:55:16 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-6c2eca96-dd8d-416c-bab7-7de3abbfe6e3
16/03/17 15:55:16 INFO MemoryStore: MemoryStore started with capacity 525.6 MB
16/03/17 15:55:16 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-79be1bdb-7582-4b97-aba7-6048c842dcf3
16/03/17 15:55:16 INFO HttpServer: Starting HTTP Server
16/03/17 15:55:16 INFO Utils: Successfully started service 'HTTP file server' on port 49707.
16/03/17 15:55:16 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:55:16 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:55:16 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:55:16 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-b90bb469-9936-4354-942b-18ea03b0acfd/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:55:16 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210316933
16/03/17 15:55:16 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:55:16 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:55:16 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60957.
16/03/17 15:55:16 INFO NettyBlockTransferService: Server created on 60957
16/03/17 15:55:16 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:55:16 INFO BlockManagerMasterEndpoint: Registering block manager localhost:60957 with 525.6 MB RAM, BlockManagerId(driver, localhost, 60957)
16/03/17 15:55:16 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:55:17 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:55:17 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:55:17 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:55:17 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:55:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:55:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:55:17 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:55:17 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=551084359
16/03/17 15:55:17 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 525.5 MB)
16/03/17 15:55:17 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=551084359
16/03/17 15:55:17 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 525.5 MB)
16/03/17 15:55:17 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:60957 (size: 4.1 KB, free: 525.6 MB)
16/03/17 15:55:17 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:55:17 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:55:17 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:55:17 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:55:17 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:55:17 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:55:17 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210316933
16/03/17 15:55:17 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:55:17 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-b90bb469-9936-4354-942b-18ea03b0acfd/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:55:17 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:55:17 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=551084359
16/03/17 15:55:17 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 525.5 MB)
16/03/17 15:55:17 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:60957 (size: 179.0 B, free: 525.6 MB)
16/03/17 15:55:17 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:55:17 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=551084359
16/03/17 15:55:17 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 525.5 MB)
16/03/17 15:55:17 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:60957 (size: 173.0 B, free: 525.6 MB)
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword:; prevleveltokens: together ; prevleveltokens: set
 area
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: planning
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: permission
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: economy
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: composition
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: agency
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:55:25 INFO PythonRunner: Times: total = 8569, boot = 476, init = 419, finish = 7674
16/03/17 15:55:25 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:55:25 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8635 ms on localhost (1/2)
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  Synset('set.n.01') ; keyword:  together  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: bend
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: giant
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: astatine
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: present
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: area
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: issue
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
16/03/17 15:55:25 INFO PythonRunner: Times: total = 8770, boot = 483, init = 409, finish = 7878
16/03/17 15:55:25 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:55:25 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8838 ms on localhost (2/2)
16/03/17 15:55:25 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:55:25 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.840 s
16/03/17 15:55:25 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:55:25 INFO DAGScheduler: running: Set()
16/03/17 15:55:25 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:55:25 INFO DAGScheduler: failed: Set()
16/03/17 15:55:25 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:55:25 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:55:25 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=551084359
16/03/17 15:55:25 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 525.5 MB)
16/03/17 15:55:25 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=551084359
16/03/17 15:55:25 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 525.5 MB)
16/03/17 15:55:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:60957 (size: 3.0 KB, free: 525.5 MB)
16/03/17 15:55:25 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:55:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:55:25 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:55:25 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:55:25 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:55:25 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:55:25 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:55:25 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:55:25 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:55:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:55:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= [u'set', 'None']
16/03/17 15:55:25 INFO PythonRunner: Times: total = 45, boot = 25, init = 17, finish = 3
16/03/17 15:55:26 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1271 bytes result sent to driver
16/03/17 15:55:26 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 67 ms on localhost (1/2)
16/03/17 15:55:26 INFO PythonRunner: Times: total = 214, boot = 213, init = 0, finish = 1
16/03/17 15:55:26 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:55:26 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 233 ms on localhost (2/2)
16/03/17 15:55:26 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:55:26 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.235 s
16/03/17 15:55:26 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.095933 s
16/03/17 15:55:26 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:55:26 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:55:26 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:55:26 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:55:26 INFO DAGScheduler: Missing parents: List()
16/03/17 15:55:26 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:55:26 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=551084359
16/03/17 15:55:26 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 525.5 MB)
16/03/17 15:55:26 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24940, maxMem=551084359
16/03/17 15:55:26 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 525.5 MB)
16/03/17 15:55:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:60957 (size: 3.3 KB, free: 525.5 MB)
16/03/17 15:55:26 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:55:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:55:26 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:55:26 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:55:26 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/17 15:55:26 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:55:26 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:55:26 INFO PythonRunner: Times: total = 57, boot = -21, init = 78, finish = 0
16/03/17 15:55:26 INFO PythonRunner: Times: total = 31, boot = 26, init = 5, finish = 0
16/03/17 15:55:26 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1336 bytes result sent to driver
16/03/17 15:55:26 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:55:26 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 73 ms on localhost (1/2)
16/03/17 15:55:26 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 73 ms on localhost (2/2)
16/03/17 15:55:26 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:55:26 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.076 s
16/03/17 15:55:26 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.085454 s
16/03/17 15:55:26 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:55:26 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:55:26 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:55:26 INFO MemoryStore: MemoryStore cleared
16/03/17 15:55:26 INFO BlockManager: BlockManager stopped
16/03/17 15:55:26 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:55:26 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:55:26 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:55:26 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:55:26 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:55:26 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:55:27 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:55:27 INFO SecurityManager: Changing view acls to: root
16/03/17 15:55:27 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:55:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:55:27 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:55:27 INFO Remoting: Starting remoting
16/03/17 15:55:27 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:45194]
16/03/17 15:55:27 INFO Utils: Successfully started service 'sparkDriver' on port 45194.
16/03/17 15:55:27 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:55:27 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:55:27 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c45fd63e-37db-4640-beb0-f7faa24340d7
16/03/17 15:55:27 INFO MemoryStore: MemoryStore started with capacity 525.6 MB
16/03/17 15:55:27 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-f214f167-6508-42f8-8875-d8ba14928238
16/03/17 15:55:27 INFO HttpServer: Starting HTTP Server
16/03/17 15:55:27 INFO Utils: Successfully started service 'HTTP file server' on port 39584.
16/03/17 15:55:27 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:55:27 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:55:27 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:55:27 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-34cb7bf7-f47a-402a-a0ed-63c254782c8d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:55:27 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210327727
16/03/17 15:55:27 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:55:27 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:55:27 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43285.
16/03/17 15:55:27 INFO NettyBlockTransferService: Server created on 43285
16/03/17 15:55:27 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:55:27 INFO BlockManagerMasterEndpoint: Registering block manager localhost:43285 with 525.6 MB RAM, BlockManagerId(driver, localhost, 43285)
16/03/17 15:55:27 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:55:27 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:55:27 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:55:27 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:55:27 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:55:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:55:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:55:27 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:55:27 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=551084359
16/03/17 15:55:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 525.5 MB)
16/03/17 15:55:28 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=551084359
16/03/17 15:55:28 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 525.5 MB)
16/03/17 15:55:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:43285 (size: 4.1 KB, free: 525.6 MB)
16/03/17 15:55:28 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:55:28 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:55:28 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:55:28 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:55:28 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:55:28 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:55:28 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210327727
16/03/17 15:55:28 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:55:28 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-34cb7bf7-f47a-402a-a0ed-63c254782c8d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:55:28 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:55:28 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10732, maxMem=551084359
16/03/17 15:55:28 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 525.5 MB)
16/03/17 15:55:28 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:43285 (size: 173.0 B, free: 525.6 MB)
16/03/17 15:55:28 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:55:28 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10905, maxMem=551084359
16/03/17 15:55:28 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 525.5 MB)
16/03/17 15:55:28 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:43285 (size: 179.0 B, free: 525.6 MB)
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: area
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: bend
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: giant
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: astatine
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  element  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: present
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: area
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: issue
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/17 15:55:36 INFO PythonRunner: Times: total = 8496, boot = 455, init = 400, finish = 7641
16/03/17 15:55:36 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:55:36 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8571 ms on localhost (1/2)
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: planning
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: permission
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: economy
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: composition
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: agency
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:55:37 INFO PythonRunner: Times: total = 8827, boot = 465, init = 448, finish = 7914
16/03/17 15:55:37 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:55:37 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.893 s
16/03/17 15:55:37 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:55:37 INFO DAGScheduler: running: Set()
16/03/17 15:55:37 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:55:37 INFO DAGScheduler: failed: Set()
16/03/17 15:55:37 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:55:37 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:55:37 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=551084359
16/03/17 15:55:37 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 525.5 MB)
16/03/17 15:55:37 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=551084359
16/03/17 15:55:37 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 525.5 MB)
16/03/17 15:55:37 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8890 ms on localhost (2/2)
16/03/17 15:55:37 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:55:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:43285 (size: 3.0 KB, free: 525.5 MB)
16/03/17 15:55:37 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:55:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:55:37 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:55:37 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:55:37 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:55:37 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:55:37 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:55:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:55:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:55:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:55:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
reduceFunction_Parents(): returns= ['None', u'astatine', 'None']
16/03/17 15:55:37 INFO PythonRunner: Times: total = 21, boot = -144, init = 164, finish = 1
16/03/17 15:55:37 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/03/17 15:55:37 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 67 ms on localhost (1/2)
16/03/17 15:55:37 INFO PythonRunner: Times: total = 240, boot = 239, init = 0, finish = 1
16/03/17 15:55:37 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:55:37 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 251 ms on localhost (2/2)
16/03/17 15:55:37 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.250 s
16/03/17 15:55:37 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:55:37 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.464675 s
16/03/17 15:55:37 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:55:37 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:55:37 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:55:37 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:55:37 INFO DAGScheduler: Missing parents: List()
16/03/17 15:55:37 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:55:37 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=551084359
16/03/17 15:55:37 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 525.5 MB)
16/03/17 15:55:37 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24940, maxMem=551084359
16/03/17 15:55:37 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 525.5 MB)
16/03/17 15:55:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:43285 (size: 3.3 KB, free: 525.5 MB)
16/03/17 15:55:37 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:55:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:55:37 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:55:37 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:55:37 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/03/17 15:55:37 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:55:37 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:55:37 INFO PythonRunner: Times: total = 66, boot = -106, init = 172, finish = 0
16/03/17 15:55:37 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/03/17 15:55:37 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 72 ms on localhost (1/2)
16/03/17 15:55:37 INFO PythonRunner: Times: total = 102, boot = 102, init = 0, finish = 0
16/03/17 15:55:37 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:55:37 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 114 ms on localhost (2/2)
16/03/17 15:55:37 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:55:37 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.115 s
16/03/17 15:55:37 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.123190 s
16/03/17 15:55:37 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:55:37 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:55:37 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:55:37 INFO MemoryStore: MemoryStore cleared
16/03/17 15:55:37 INFO BlockManager: BlockManager stopped
16/03/17 15:55:37 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:55:37 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:55:37 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:55:37 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:55:37 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:55:38 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:55:38 INFO SecurityManager: Changing view acls to: root
16/03/17 15:55:38 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:55:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:55:38 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:55:38 INFO Remoting: Starting remoting
16/03/17 15:55:38 INFO Utils: Successfully started service 'sparkDriver' on port 53013.
16/03/17 15:55:38 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:53013]
16/03/17 15:55:38 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:55:38 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:55:38 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e8d57173-9b78-4de8-9e1a-af7b9284f2f1
16/03/17 15:55:38 INFO MemoryStore: MemoryStore started with capacity 524.6 MB
16/03/17 15:55:38 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-d50b07ce-27bf-411a-8fd2-93426bfa41d0
16/03/17 15:55:38 INFO HttpServer: Starting HTTP Server
16/03/17 15:55:38 INFO Utils: Successfully started service 'HTTP file server' on port 53143.
16/03/17 15:55:38 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:55:38 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:55:38 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:55:38 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-a5b591de-f071-4bd6-8197-6ac06d2a79d4/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:55:38 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210338837
16/03/17 15:55:38 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:55:38 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:55:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42999.
16/03/17 15:55:38 INFO NettyBlockTransferService: Server created on 42999
16/03/17 15:55:38 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:55:38 INFO BlockManagerMasterEndpoint: Registering block manager localhost:42999 with 524.6 MB RAM, BlockManagerId(driver, localhost, 42999)
16/03/17 15:55:38 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:55:38 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:55:38 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:55:38 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:55:38 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:55:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:55:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:55:38 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:55:38 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=550093455
16/03/17 15:55:38 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 524.6 MB)
16/03/17 15:55:38 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=550093455
16/03/17 15:55:38 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 524.6 MB)
16/03/17 15:55:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:42999 (size: 4.1 KB, free: 524.6 MB)
16/03/17 15:55:38 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:55:38 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:55:38 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:55:38 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:55:38 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:55:38 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:55:38 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210338837
16/03/17 15:55:39 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:55:39 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-a5b591de-f071-4bd6-8197-6ac06d2a79d4/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:55:39 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:55:39 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=550093455
16/03/17 15:55:39 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 524.6 MB)
16/03/17 15:55:39 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:42999 (size: 179.0 B, free: 524.6 MB)
16/03/17 15:55:39 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:55:39 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=550093455
16/03/17 15:55:39 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 524.6 MB)
16/03/17 15:55:39 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:42999 (size: 173.0 B, free: 524.6 MB)
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: set
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: planning
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: permission
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: economy
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: composition
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: agency
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:55:48 INFO PythonRunner: Times: total = 9113, boot = 472, init = 459, finish = 8182
16/03/17 15:55:48 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:55:48 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9184 ms on localhost (1/2)
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: bend
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: giant
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): adding to parents: syn =  Synset('colossus.n.02') ; keyword:  person  in syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= [u'giant']
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: astatine
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: present
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: area
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: issue
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
16/03/17 15:55:48 INFO PythonRunner: Times: total = 9278, boot = 487, init = 457, finish = 8334
16/03/17 15:55:48 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:55:48 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.359 s
16/03/17 15:55:48 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:55:48 INFO DAGScheduler: running: Set()
16/03/17 15:55:48 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:55:48 INFO DAGScheduler: failed: Set()
16/03/17 15:55:48 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9355 ms on localhost (2/2)
16/03/17 15:55:48 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:55:48 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:55:48 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:55:48 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=550093455
16/03/17 15:55:48 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 524.6 MB)
16/03/17 15:55:48 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=550093455
16/03/17 15:55:48 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 524.6 MB)
16/03/17 15:55:48 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:42999 (size: 3.0 KB, free: 524.6 MB)
16/03/17 15:55:48 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:55:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:55:48 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:55:48 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:55:48 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:55:48 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:55:48 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:55:48 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:55:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/17 15:55:48 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:55:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'giant', 'None']
16/03/17 15:55:48 INFO PythonRunner: Times: total = 46, boot = 43, init = 1, finish = 2
16/03/17 15:55:48 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1281 bytes result sent to driver
16/03/17 15:55:48 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 92 ms on localhost (1/2)
16/03/17 15:55:48 INFO PythonRunner: Times: total = 322, boot = 321, init = 0, finish = 1
16/03/17 15:55:48 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:55:48 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.332 s
16/03/17 15:55:48 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.721009 s
16/03/17 15:55:48 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 334 ms on localhost (2/2)
16/03/17 15:55:48 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:55:48 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:55:48 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:55:48 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:55:48 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:55:48 INFO DAGScheduler: Missing parents: List()
16/03/17 15:55:48 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:55:48 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=550093455
16/03/17 15:55:48 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 524.6 MB)
16/03/17 15:55:48 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24940, maxMem=550093455
16/03/17 15:55:48 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 524.6 MB)
16/03/17 15:55:48 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:42999 (size: 3.3 KB, free: 524.6 MB)
16/03/17 15:55:48 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:55:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:55:48 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:55:48 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:55:48 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2362 bytes)
16/03/17 15:55:48 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:55:48 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:55:48 INFO PythonRunner: Times: total = 61, boot = -160, init = 221, finish = 0
16/03/17 15:55:48 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1349 bytes result sent to driver
16/03/17 15:55:48 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 72 ms on localhost (1/2)
16/03/17 15:55:48 INFO PythonRunner: Times: total = 191, boot = 191, init = 0, finish = 0
16/03/17 15:55:48 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:55:48 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 201 ms on localhost (2/2)
16/03/17 15:55:48 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:55:48 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.199 s
16/03/17 15:55:48 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.210755 s
16/03/17 15:55:49 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:55:49 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:55:49 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:55:49 INFO MemoryStore: MemoryStore cleared
16/03/17 15:55:49 INFO BlockManager: BlockManager stopped
16/03/17 15:55:49 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:55:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:55:49 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:55:49 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:55:49 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:55:49 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:55:49 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:55:49 INFO SecurityManager: Changing view acls to: root
16/03/17 15:55:49 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:55:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:55:50 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:55:50 INFO Remoting: Starting remoting
16/03/17 15:55:50 INFO Utils: Successfully started service 'sparkDriver' on port 49536.
16/03/17 15:55:50 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:49536]
16/03/17 15:55:50 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:55:50 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:55:50 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-6a740994-8ad6-4232-a8d4-94dffc4756c8
16/03/17 15:55:50 INFO MemoryStore: MemoryStore started with capacity 524.6 MB
16/03/17 15:55:50 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-a25fe2ae-e6b1-49b0-b539-0b4a86723763
16/03/17 15:55:50 INFO HttpServer: Starting HTTP Server
16/03/17 15:55:50 INFO Utils: Successfully started service 'HTTP file server' on port 48887.
16/03/17 15:55:50 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:55:50 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:55:50 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:55:50 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-0b9d4cfd-cdf7-456f-8d78-57cf4d7e09ea/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:55:50 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210350276
16/03/17 15:55:50 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:55:50 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:55:50 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54170.
16/03/17 15:55:50 INFO NettyBlockTransferService: Server created on 54170
16/03/17 15:55:50 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:55:50 INFO BlockManagerMasterEndpoint: Registering block manager localhost:54170 with 524.6 MB RAM, BlockManagerId(driver, localhost, 54170)
16/03/17 15:55:50 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:55:50 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:55:50 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:55:50 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:55:50 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:55:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:55:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:55:50 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:55:50 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=550093455
16/03/17 15:55:50 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 524.6 MB)
16/03/17 15:55:50 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=550093455
16/03/17 15:55:50 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 524.6 MB)
16/03/17 15:55:50 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:54170 (size: 4.1 KB, free: 524.6 MB)
16/03/17 15:55:50 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:55:50 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:55:50 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:55:50 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:55:50 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:55:50 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:55:50 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210350276
16/03/17 15:55:50 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:55:50 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-0b9d4cfd-cdf7-456f-8d78-57cf4d7e09ea/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:55:50 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:55:50 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:55:50 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=550093455
16/03/17 15:55:50 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 524.6 MB)
16/03/17 15:55:50 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=550093455
16/03/17 15:55:50 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 524.6 MB)
16/03/17 15:55:50 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:54170 (size: 179.0 B, free: 524.6 MB)
16/03/17 15:55:50 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:54170 (size: 173.0 B, free: 524.6 MB)
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: area
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: bend
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: planning
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: giant
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: permission
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): adding to parents: syn =  Synset('colossus.n.02') ; keyword:  reputation  in syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= [u'giant']
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: astatine
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
reputationasfer_pickle_string_load(): picklef.readlines():
 reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: present
mapFunction_Parents(): keyword: reputation ; prevleveltokens: economy
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: composition
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: agency
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
[]asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword:
 reputation ; prevleveltokens: area
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
u'Bengal', asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword:u'Tamil' reputation ; prevleveltokens: issue
, u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:55:59 INFO PythonRunner: Times: total = 8720, boot = 527, init = 598, finish = 7595
16/03/17 15:55:59 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
16/03/17 15:55:59 INFO PythonRunner: Times: total = 8742, boot = 515, init = 589, finish = 7638
16/03/17 15:55:59 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:55:59 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8812 ms on localhost (1/2)
16/03/17 15:55:59 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.816 s
16/03/17 15:55:59 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:55:59 INFO DAGScheduler: running: Set()
16/03/17 15:55:59 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:55:59 INFO DAGScheduler: failed: Set()
16/03/17 15:55:59 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8815 ms on localhost (2/2)
16/03/17 15:55:59 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:55:59 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:55:59 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:55:59 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=550093455
16/03/17 15:55:59 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 524.6 MB)
16/03/17 15:55:59 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=550093455
16/03/17 15:55:59 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 524.6 MB)
16/03/17 15:55:59 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:54170 (size: 3.0 KB, free: 524.6 MB)
16/03/17 15:55:59 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:55:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:55:59 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:55:59 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:55:59 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:55:59 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:55:59 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:55:59 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:55:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:55:59 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:55:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'giant', 'None']
16/03/17 15:55:59 INFO PythonRunner: Times: total = 199, boot = 198, init = 1, finish = 0
16/03/17 15:55:59 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1281 bytes result sent to driver
16/03/17 15:55:59 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 222 ms on localhost (1/2)
16/03/17 15:55:59 INFO PythonRunner: Times: total = 224, boot = 223, init = 1, finish = 0
16/03/17 15:55:59 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:55:59 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 242 ms on localhost (2/2)
16/03/17 15:55:59 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:55:59 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.222 s
16/03/17 15:55:59 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.082407 s
16/03/17 15:55:59 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:55:59 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:55:59 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:55:59 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:55:59 INFO DAGScheduler: Missing parents: List()
16/03/17 15:55:59 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:55:59 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=550093455
16/03/17 15:55:59 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 524.6 MB)
16/03/17 15:55:59 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24940, maxMem=550093455
16/03/17 15:55:59 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 524.6 MB)
16/03/17 15:55:59 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:54170 (size: 3.3 KB, free: 524.6 MB)
16/03/17 15:55:59 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:55:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:55:59 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:55:59 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:55:59 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2362 bytes)
16/03/17 15:55:59 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:55:59 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:55:59 INFO PythonRunner: Times: total = 105, boot = 105, init = 0, finish = 0
16/03/17 15:55:59 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1349 bytes result sent to driver
16/03/17 15:55:59 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 116 ms on localhost (1/2)
16/03/17 15:55:59 INFO PythonRunner: Times: total = 133, boot = 133, init = 0, finish = 0
16/03/17 15:55:59 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:55:59 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 141 ms on localhost (2/2)
16/03/17 15:55:59 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:55:59 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.128 s
16/03/17 15:55:59 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.152359 s
16/03/17 15:55:59 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:55:59 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:55:59 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:55:59 INFO MemoryStore: MemoryStore cleared
16/03/17 15:55:59 INFO BlockManager: BlockManager stopped
16/03/17 15:55:59 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:55:59 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:55:59 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:55:59 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:55:59 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:55:59 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:56:00 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:56:00 INFO SecurityManager: Changing view acls to: root
16/03/17 15:56:00 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:56:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:56:01 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:56:01 INFO Remoting: Starting remoting
16/03/17 15:56:01 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:38350]
16/03/17 15:56:01 INFO Utils: Successfully started service 'sparkDriver' on port 38350.
16/03/17 15:56:01 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:56:01 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:56:01 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-6a084e19-996b-4f55-a7cb-df597e2739c6
16/03/17 15:56:01 INFO MemoryStore: MemoryStore started with capacity 527.0 MB
16/03/17 15:56:01 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-205b3ea8-4a85-4887-924b-05594693d61d
16/03/17 15:56:01 INFO HttpServer: Starting HTTP Server
16/03/17 15:56:01 INFO Utils: Successfully started service 'HTTP file server' on port 48413.
16/03/17 15:56:01 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:56:01 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:56:01 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:56:01 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-caeb6f7a-4fa5-4c0d-9e3d-e1ea98b9f8ab/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:56:01 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210361236
16/03/17 15:56:01 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:56:01 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:56:01 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60116.
16/03/17 15:56:01 INFO NettyBlockTransferService: Server created on 60116
16/03/17 15:56:01 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:56:01 INFO BlockManagerMasterEndpoint: Registering block manager localhost:60116 with 527.0 MB RAM, BlockManagerId(driver, localhost, 60116)
16/03/17 15:56:01 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:56:01 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:56:01 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:56:01 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:56:01 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:56:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:56:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:56:01 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:56:01 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=552641495
16/03/17 15:56:01 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 527.0 MB)
16/03/17 15:56:01 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=552641495
16/03/17 15:56:01 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 527.0 MB)
16/03/17 15:56:01 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:60116 (size: 4.1 KB, free: 527.0 MB)
16/03/17 15:56:01 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:56:01 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:56:01 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:56:01 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:56:01 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:56:01 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:56:01 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210361236
16/03/17 15:56:01 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:56:01 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-caeb6f7a-4fa5-4c0d-9e3d-e1ea98b9f8ab/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:56:01 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:56:01 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=552641495
16/03/17 15:56:01 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 527.0 MB)
16/03/17 15:56:01 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:60116 (size: 179.0 B, free: 527.0 MB)
16/03/17 15:56:01 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:56:01 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=552641495
16/03/17 15:56:01 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 527.0 MB)
16/03/17 15:56:01 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:60116 (size: 173.0 B, free: 527.0 MB)
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: set
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: planning
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: permission
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: economy
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: composition
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: agency
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:56:09 INFO PythonRunner: Times: total = 8502, boot = 478, init = 413, finish = 7611
16/03/17 15:56:09 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:56:09 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8590 ms on localhost (1/2)
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: bend
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: giant
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: astatine
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: present
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  time  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: area
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: issue
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/17 15:56:10 INFO PythonRunner: Times: total = 8946, boot = 480, init = 406, finish = 8060
16/03/17 15:56:10 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:56:10 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.037 s
16/03/17 15:56:10 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:56:10 INFO DAGScheduler: running: Set()
16/03/17 15:56:10 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:56:10 INFO DAGScheduler: failed: Set()
16/03/17 15:56:10 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:56:10 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:56:10 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=552641495
16/03/17 15:56:10 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 527.0 MB)
16/03/17 15:56:10 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=552641495
16/03/17 15:56:10 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 527.0 MB)
16/03/17 15:56:10 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:60116 (size: 3.0 KB, free: 527.0 MB)
16/03/17 15:56:10 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:56:10 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9034 ms on localhost (2/2)
16/03/17 15:56:10 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:56:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:56:10 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:56:10 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:56:10 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:56:10 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:56:10 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:56:10 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:56:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
16/03/17 15:56:10 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:56:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
reduceFunction_Parents(): returns= ['None', u'present', 'None']
16/03/17 15:56:10 INFO PythonRunner: Times: total = 31, boot = -285, init = 315, finish = 1
16/03/17 15:56:10 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/17 15:56:10 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 74 ms on localhost (1/2)
16/03/17 15:56:10 INFO PythonRunner: Times: total = 188, boot = 187, init = 1, finish = 0
16/03/17 15:56:10 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:56:10 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 206 ms on localhost (2/2)
16/03/17 15:56:10 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:56:10 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.191 s
16/03/17 15:56:10 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.269669 s
16/03/17 15:56:10 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:56:10 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:56:10 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:56:10 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:56:10 INFO DAGScheduler: Missing parents: List()
16/03/17 15:56:10 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:56:10 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=552641495
16/03/17 15:56:10 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 527.0 MB)
16/03/17 15:56:10 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24940, maxMem=552641495
16/03/17 15:56:10 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 527.0 MB)
16/03/17 15:56:10 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:60116 (size: 3.3 KB, free: 527.0 MB)
16/03/17 15:56:10 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:56:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:56:10 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:56:10 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:56:10 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/17 15:56:10 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:56:10 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:56:10 INFO PythonRunner: Times: total = 62, boot = -33, init = 95, finish = 0
16/03/17 15:56:10 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:56:10 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 71 ms on localhost (1/2)
16/03/17 15:56:10 INFO PythonRunner: Times: total = 99, boot = 98, init = 1, finish = 0
16/03/17 15:56:10 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1351 bytes result sent to driver
16/03/17 15:56:10 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 111 ms on localhost (2/2)
16/03/17 15:56:10 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:56:10 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.096 s
16/03/17 15:56:10 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.124166 s
16/03/17 15:56:10 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:56:10 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:56:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:56:11 INFO MemoryStore: MemoryStore cleared
16/03/17 15:56:11 INFO BlockManager: BlockManager stopped
16/03/17 15:56:11 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:56:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:56:11 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:56:11 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:56:11 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:56:11 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:56:11 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:56:11 INFO SecurityManager: Changing view acls to: root
16/03/17 15:56:11 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:56:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:56:11 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:56:11 INFO Remoting: Starting remoting
16/03/17 15:56:12 INFO Utils: Successfully started service 'sparkDriver' on port 42027.
16/03/17 15:56:12 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:42027]
16/03/17 15:56:12 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:56:12 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:56:12 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9784875f-0e5f-4191-8913-7df5926390be
16/03/17 15:56:12 INFO MemoryStore: MemoryStore started with capacity 527.0 MB
16/03/17 15:56:12 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-b4d37fca-274c-4b88-9003-658ce8bffcc8
16/03/17 15:56:12 INFO HttpServer: Starting HTTP Server
16/03/17 15:56:12 INFO Utils: Successfully started service 'HTTP file server' on port 56680.
16/03/17 15:56:12 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:56:12 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:56:12 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:56:12 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-cc9e3564-e282-4b94-a615-5a32a7c6055b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:56:12 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210372159
16/03/17 15:56:12 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:56:12 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:56:12 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46779.
16/03/17 15:56:12 INFO NettyBlockTransferService: Server created on 46779
16/03/17 15:56:12 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:56:12 INFO BlockManagerMasterEndpoint: Registering block manager localhost:46779 with 527.0 MB RAM, BlockManagerId(driver, localhost, 46779)
16/03/17 15:56:12 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:56:12 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:56:12 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:56:12 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:56:12 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:56:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:56:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:56:12 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:56:12 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=552641495
16/03/17 15:56:12 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 527.0 MB)
16/03/17 15:56:12 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=552641495
16/03/17 15:56:12 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 527.0 MB)
16/03/17 15:56:12 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:46779 (size: 4.1 KB, free: 527.0 MB)
16/03/17 15:56:12 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:56:12 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:56:12 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:56:12 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:56:12 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:56:12 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:56:12 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210372159
16/03/17 15:56:12 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:56:12 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-cc9e3564-e282-4b94-a615-5a32a7c6055b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:56:12 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:56:12 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:56:12 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=552641495
16/03/17 15:56:12 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 527.0 MB)
16/03/17 15:56:12 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=552641495
16/03/17 15:56:12 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 527.0 MB)
16/03/17 15:56:12 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:46779 (size: 179.0 B, free: 527.0 MB)
16/03/17 15:56:12 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:46779 (size: 173.0 B, free: 527.0 MB)
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: set
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: planning
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: permission
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: economy
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: composition
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: agency
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:56:20 INFO PythonRunner: Times: total = 8397, boot = 470, init = 400, finish = 7527
16/03/17 15:56:20 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:56:20 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8455 ms on localhost (1/2)
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: bend
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: giant
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: astatine
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: present
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  position  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: area
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: issue
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
16/03/17 15:56:20 INFO PythonRunner: Times: total = 8613, boot = 476, init = 423, finish = 7714
16/03/17 15:56:20 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:56:20 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.673 s
16/03/17 15:56:20 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:56:20 INFO DAGScheduler: running: Set()
16/03/17 15:56:20 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:56:20 INFO DAGScheduler: failed: Set()
16/03/17 15:56:20 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:56:20 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:56:20 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=552641495
16/03/17 15:56:20 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 527.0 MB)
16/03/17 15:56:20 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=552641495
16/03/17 15:56:20 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 527.0 MB)
16/03/17 15:56:20 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8667 ms on localhost (2/2)
16/03/17 15:56:20 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:56:20 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:46779 (size: 3.0 KB, free: 527.0 MB)
16/03/17 15:56:20 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:56:20 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:56:20 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:56:20 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:56:20 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:56:20 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:56:20 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:56:20 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:56:20 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:56:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:56:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'metropolitan', 'None']
16/03/17 15:56:21 INFO PythonRunner: Times: total = 30, boot = -27, init = 56, finish = 1
16/03/17 15:56:21 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1288 bytes result sent to driver
16/03/17 15:56:21 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 54 ms on localhost (1/2)
16/03/17 15:56:21 INFO PythonRunner: Times: total = 205, boot = 204, init = 1, finish = 0
16/03/17 15:56:21 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:56:21 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 222 ms on localhost (2/2)
16/03/17 15:56:21 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:56:21 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.222 s
16/03/17 15:56:21 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.913066 s
16/03/17 15:56:21 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:56:21 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:56:21 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:56:21 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:56:21 INFO DAGScheduler: Missing parents: List()
16/03/17 15:56:21 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:56:21 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=552641495
16/03/17 15:56:21 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 527.0 MB)
16/03/17 15:56:21 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24940, maxMem=552641495
16/03/17 15:56:21 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 527.0 MB)
16/03/17 15:56:21 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:46779 (size: 3.3 KB, free: 527.0 MB)
16/03/17 15:56:21 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:56:21 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:56:21 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:56:21 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:56:21 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2369 bytes)
16/03/17 15:56:21 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:56:21 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:56:21 INFO PythonRunner: Times: total = 60, boot = 60, init = 0, finish = 0
16/03/17 15:56:21 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:56:21 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 71 ms on localhost (1/2)
16/03/17 15:56:21 INFO PythonRunner: Times: total = 64, boot = -77, init = 141, finish = 0
16/03/17 15:56:21 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1356 bytes result sent to driver
16/03/17 15:56:21 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 77 ms on localhost (2/2)
16/03/17 15:56:21 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:56:21 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.063 s
16/03/17 15:56:21 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.087329 s
16/03/17 15:56:21 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:56:21 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:56:21 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:56:21 INFO MemoryStore: MemoryStore cleared
16/03/17 15:56:21 INFO BlockManager: BlockManager stopped
16/03/17 15:56:21 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:56:21 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:56:21 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:56:21 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:56:21 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:56:21 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:56:22 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:56:22 INFO SecurityManager: Changing view acls to: root
16/03/17 15:56:22 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:56:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:56:22 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:56:22 INFO Remoting: Starting remoting
16/03/17 15:56:22 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:34708]
16/03/17 15:56:22 INFO Utils: Successfully started service 'sparkDriver' on port 34708.
16/03/17 15:56:22 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:56:22 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:56:22 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c95b8094-5a08-45a5-9a5b-397335256b5b
16/03/17 15:56:22 INFO MemoryStore: MemoryStore started with capacity 527.0 MB
16/03/17 15:56:22 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-ca50e492-697b-4490-944c-c2f205fd0e5f
16/03/17 15:56:22 INFO HttpServer: Starting HTTP Server
16/03/17 15:56:22 INFO Utils: Successfully started service 'HTTP file server' on port 54450.
16/03/17 15:56:22 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:56:22 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:56:22 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:56:22 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-c7b99b60-c91c-48ce-9884-9eaab61f49d8/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:56:22 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210382653
16/03/17 15:56:22 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:56:22 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:56:22 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33405.
16/03/17 15:56:22 INFO NettyBlockTransferService: Server created on 33405
16/03/17 15:56:22 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:56:22 INFO BlockManagerMasterEndpoint: Registering block manager localhost:33405 with 527.0 MB RAM, BlockManagerId(driver, localhost, 33405)
16/03/17 15:56:22 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:56:22 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:56:22 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:56:22 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:56:22 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:56:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:56:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:56:22 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:56:22 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=552641495
16/03/17 15:56:22 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 527.0 MB)
16/03/17 15:56:22 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=552641495
16/03/17 15:56:22 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 527.0 MB)
16/03/17 15:56:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:33405 (size: 4.1 KB, free: 527.0 MB)
16/03/17 15:56:22 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:56:22 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:56:22 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:56:22 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2432 bytes)
16/03/17 15:56:22 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2434 bytes)
16/03/17 15:56:22 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:56:22 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210382653
16/03/17 15:56:22 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:56:22 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-c7b99b60-c91c-48ce-9884-9eaab61f49d8/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:56:23 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:56:23 INFO MemoryStore: ensureFreeSpace(179) called with curMem=10732, maxMem=552641495
16/03/17 15:56:23 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 179.0 B, free 527.0 MB)
16/03/17 15:56:23 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:33405 (size: 179.0 B, free: 527.0 MB)
16/03/17 15:56:23 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:56:23 INFO MemoryStore: ensureFreeSpace(173) called with curMem=10911, maxMem=552641495
16/03/17 15:56:23 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 173.0 B, free 527.0 MB)
16/03/17 15:56:23 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:33405 (size: 173.0 B, free: 527.0 MB)
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: set
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: bend
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: giant
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: astatine
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: present
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: area
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: planning
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: issue
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: permission
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: economy
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: composition
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: agency
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['16/03/17 15:56:31 INFO PythonRunner: Times: total = 8582, boot = 467, init = 423, finish = 7692
16/03/17 15:56:31 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: Chennai
16/03/17 15:56:31 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8670 ms on localhost (1/2)
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/17 15:56:31 INFO PythonRunner: Times: total = 8622, boot = 459, init = 419, finish = 7744
16/03/17 15:56:31 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:56:31 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.714 s
16/03/17 15:56:31 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:56:31 INFO DAGScheduler: running: Set()
16/03/17 15:56:31 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:56:31 INFO DAGScheduler: failed: Set()
16/03/17 15:56:31 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:56:31 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/17 15:56:31 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11084, maxMem=552641495
16/03/17 15:56:31 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 527.0 MB)
16/03/17 15:56:31 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16068, maxMem=552641495
16/03/17 15:56:31 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 527.0 MB)
16/03/17 15:56:31 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8710 ms on localhost (2/2)
16/03/17 15:56:31 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:56:31 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:33405 (size: 3.0 KB, free: 527.0 MB)
16/03/17 15:56:31 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:56:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:56:31 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:56:31 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:56:31 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:56:31 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:56:31 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:56:31 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:56:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:56:31 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:56:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', 'None']
16/03/17 15:56:31 INFO PythonRunner: Times: total = 165, boot = 164, init = 0, finish = 1
16/03/17 15:56:31 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1269 bytes result sent to driver
16/03/17 15:56:31 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 180 ms on localhost (1/2)
16/03/17 15:56:31 INFO PythonRunner: Times: total = 261, boot = 260, init = 1, finish = 0
16/03/17 15:56:31 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:56:31 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 281 ms on localhost (2/2)
16/03/17 15:56:31 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:56:31 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.267 s
16/03/17 15:56:31 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.012908 s
16/03/17 15:56:32 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/17 15:56:32 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/17 15:56:32 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:56:32 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:56:32 INFO DAGScheduler: Missing parents: List()
16/03/17 15:56:32 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/17 15:56:32 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19124, maxMem=552641495
16/03/17 15:56:32 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 527.0 MB)
16/03/17 15:56:32 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24940, maxMem=552641495
16/03/17 15:56:32 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 527.0 MB)
16/03/17 15:56:32 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:33405 (size: 3.3 KB, free: 527.0 MB)
16/03/17 15:56:32 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:56:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/17 15:56:32 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:56:32 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:56:32 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2350 bytes)
16/03/17 15:56:32 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:56:32 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:56:32 INFO PythonRunner: Times: total = 34, boot = 34, init = 0, finish = 0
16/03/17 15:56:32 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:56:32 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 49 ms on localhost (1/2)
16/03/17 15:56:32 INFO PythonRunner: Times: total = 127, boot = 127, init = 0, finish = 0
16/03/17 15:56:32 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1337 bytes result sent to driver
16/03/17 15:56:32 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 143 ms on localhost (2/2)
16/03/17 15:56:32 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:56:32 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.126 s
16/03/17 15:56:32 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.158893 s
16/03/17 15:56:32 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:56:32 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:56:32 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:56:32 INFO MemoryStore: MemoryStore cleared
16/03/17 15:56:32 INFO BlockManager: BlockManager stopped
16/03/17 15:56:32 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:56:32 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:56:32 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:56:32 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:56:32 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:56:32 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:56:33 INFO SparkContext: Running Spark version 1.5.2
16/03/17 15:56:33 INFO SecurityManager: Changing view acls to: root
16/03/17 15:56:33 INFO SecurityManager: Changing modify acls to: root
16/03/17 15:56:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/17 15:56:33 INFO Slf4jLogger: Slf4jLogger started
16/03/17 15:56:33 INFO Remoting: Starting remoting
16/03/17 15:56:33 INFO Utils: Successfully started service 'sparkDriver' on port 40355.
16/03/17 15:56:33 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:40355]
16/03/17 15:56:33 INFO SparkEnv: Registering MapOutputTracker
16/03/17 15:56:33 INFO SparkEnv: Registering BlockManagerMaster
16/03/17 15:56:33 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-831f3e09-acbe-4f99-a51d-7ff8d5104130
16/03/17 15:56:33 INFO MemoryStore: MemoryStore started with capacity 526.5 MB
16/03/17 15:56:33 INFO HttpFileServer: HTTP File server directory is /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/httpd-a10b5484-dbb7-4e70-9d23-52bfa445f14d
16/03/17 15:56:33 INFO HttpServer: Starting HTTP Server
16/03/17 15:56:33 INFO Utils: Successfully started service 'HTTP file server' on port 56049.
16/03/17 15:56:33 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/17 15:56:33 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/17 15:56:33 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/17 15:56:33 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-161b029d-7882-4186-bc07-4595ecfd0479/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:56:33 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210393483
16/03/17 15:56:33 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/17 15:56:33 INFO Executor: Starting executor ID driver on host localhost
16/03/17 15:56:33 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54357.
16/03/17 15:56:33 INFO NettyBlockTransferService: Server created on 54357
16/03/17 15:56:33 INFO BlockManagerMaster: Trying to register BlockManager
16/03/17 15:56:33 INFO BlockManagerMasterEndpoint: Registering block manager localhost:54357 with 526.5 MB RAM, BlockManagerId(driver, localhost, 54357)
16/03/17 15:56:33 INFO BlockManagerMaster: Registered BlockManager
16/03/17 15:56:33 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230
16/03/17 15:56:33 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/17 15:56:33 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) with 2 output partitions
16/03/17 15:56:33 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/17 15:56:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/17 15:56:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/17 15:56:33 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230), which has no missing parents
16/03/17 15:56:33 INFO MemoryStore: ensureFreeSpace(6560) called with curMem=0, maxMem=552075264
16/03/17 15:56:33 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 526.5 MB)
16/03/17 15:56:33 INFO MemoryStore: ensureFreeSpace(4147) called with curMem=6560, maxMem=552075264
16/03/17 15:56:33 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 526.5 MB)
16/03/17 15:56:33 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:54357 (size: 4.0 KB, free: 526.5 MB)
16/03/17 15:56:33 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/17 15:56:33 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/17 15:56:33 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/17 15:56:33 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 3016 bytes)
16/03/17 15:56:33 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 3065 bytes)
16/03/17 15:56:33 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/17 15:56:33 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458210393483
16/03/17 15:56:33 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/17 15:56:33 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/userFiles-161b029d-7882-4186-bc07-4595ecfd0479/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/17 15:56:33 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/17 15:56:33 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/17 15:56:33 INFO MemoryStore: ensureFreeSpace(692) called with curMem=10707, maxMem=552075264
16/03/17 15:56:33 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 692.0 B, free 526.5 MB)
16/03/17 15:56:33 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:54357 (size: 692.0 B, free: 526.5 MB)
16/03/17 15:56:33 INFO MemoryStore: ensureFreeSpace(662) called with curMem=11399, maxMem=552075264
16/03/17 15:56:33 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 662.0 B, free 526.5 MB)
16/03/17 15:56:33 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:54357 (size: 662.0 B, free: 526.5 MB)
mapFunction(): freqterms1: serving
mapFunction(): freqterms1: city
mapFunction(): freqterms1: Madras
mapFunction(): freqterms1: Bengal
mapFunction(): freqterms1: course
mapFunction(): freqterms1: relation
mapFunction(): freqterms1: geography
mapFunction(): freqterms1: group
mapFunction(): freqterms1: decay
mapFunction(): freqterms1: program
mapFunction(): freqterms1: Tamil
mapFunction(): freqterms1: exceptional
mapFunction(): freqterms1: Bay
mapFunction(): freqterms1: use
mapFunction(): freqterms1: formulating
mapFunction(): freqterms1: serves
mapFunction(): freqterms1: item
mapFunction(): freqterms1: consumption
mapFunction(): freqterms1: miles
mapFunction(): freqterms1: Eastern
mapFunction(): freqterms1: stretch
mapFunction(): freqterms1: unstable
mapFunction(): freqterms1: including
mapFunction(): freqterms1: people
mapFunction(): freqterms1: series
mapFunction(): freqterms1: Christianity
mapFunction(): freqterms1: culture
mapFunction(): freqterms1: archbishop
mapFunction(): freqterms1: meters
mapFunction(): freqterms1: system
mapFunction(): freqterms1: halogen
mapFunction(): freqterms1: continuous
mapFunction(): freqterms1: special
mapFunction(): freqterms1: western
mapFunction(): freqterms1: 0.621371
mapFunction(): freqterms1: Orthodox
mapFunction(): freqterms1: particular
mapFunction(): freqterms1: given
mapFunction(): freqterms1: definite
mapFunction(): freqterms1: boundary
mapFunction(): freqterms1: business
mapFunction(): freqterms1: importance
mapFunction(): freqterms1: equivalent
mapFunction(): freqterms1: thorium
mapFunction(): freqterms1: approval
mapFunction(): freqterms1: providing
mapFunction(): freqterms1: region
mapFunction(): freqterms1: title
mapFunction(): freqterms1: kind
mapFunction(): freqterms1: equal
mapFunction(): freqterms1: length
mapFunction(): freqterms1: official
mapFunction(): freqterms1: resulting
mapFunction(): freqterms1: act
mapFunction(): freqterms1: patriarch
mapFunction(): freqterms1: Church
mapFunction(): freqterms1: action
mapFunction(): freqterms1: distribution
mapFunction(): freqterms1: property
mapFunction(): freqterms1: distinguished
mapFunction(): freqterms1: whole
mapFunction(): freqterms1: metric
mapFunction(): freqterms1: businesses
mapFunction(): freqterms1: 1000
mapFunction(): freqterms1: formerly
mapFunction(): freqterms1: period
mapFunction(): freqterms1: heaviest
mapFunction(): freqterms1: highly
mapFunction(): freqterms1: production
mapFunction(): freqterms1: indefinite
mapFunction(): freqterms1: unit
mapFunction(): freqterms1: purposes
mapFunction(): freqterms1: general
16/03/17 15:56:43 INFO PythonRunner: Times: total = 10175, boot = 463, init = 371, finish = 9341
16/03/17 15:56:43 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/17 15:56:43 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 10243 ms on localhost (1/2)
mapFunction(): freqterms1: something
mapFunction(): freqterms1: bishop
mapFunction(): freqterms1: things
mapFunction(): freqterms1: belong
mapFunction(): freqterms1: uranium
mapFunction(): freqterms1: arrangement
mapFunction(): freqterms1: parts
mapFunction(): freqterms1: speech
mapFunction(): freqterms1: geographical
mapFunction(): freqterms1: spatial
mapFunction(): freqterms1: Nadu
mapFunction(): freqterms1: circular
mapFunction(): freqterms1: product
mapFunction(): freqterms1: used
mapFunction(): freqterms1: usually
mapFunction(): freqterms1: moment
mapFunction(): freqterms1: purpose
mapFunction(): freqterms1: segment
mapFunction(): freqterms1: radioactive
mapFunction(): freqterms1: happening
mapFunction(): freqterms1: curve
mapFunction(): freqterms1: together
mapFunction(): freqterms1: element
mapFunction(): freqterms1: person
mapFunction(): freqterms1: reputation
mapFunction(): freqterms1: time
mapFunction(): freqterms1: position
mapFunction(): freqterms1: quantity
16/03/17 15:56:44 INFO PythonRunner: Times: total = 10830, boot = 465, init = 429, finish = 9936
16/03/17 15:56:44 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/17 15:56:44 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) finished in 10.894 s
16/03/17 15:56:44 INFO DAGScheduler: looking for newly runnable stages
16/03/17 15:56:44 INFO DAGScheduler: running: Set()
16/03/17 15:56:44 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/17 15:56:44 INFO DAGScheduler: failed: Set()
16/03/17 15:56:44 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/17 15:56:44 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230), which is now runnable
16/03/17 15:56:44 INFO MemoryStore: ensureFreeSpace(4976) called with curMem=12061, maxMem=552075264
16/03/17 15:56:44 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 526.5 MB)
16/03/17 15:56:44 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=17037, maxMem=552075264
16/03/17 15:56:44 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 526.5 MB)
16/03/17 15:56:44 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 10890 ms on localhost (2/2)
16/03/17 15:56:44 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/17 15:56:44 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:54357 (size: 3.0 KB, free: 526.5 MB)
16/03/17 15:56:44 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/17 15:56:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/17 15:56:44 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/17 15:56:44 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:56:44 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/17 15:56:44 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/17 15:56:44 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:56:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:56:44 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/17 15:56:44 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/17 15:56:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/17 15:56:44 INFO PythonRunner: Times: total = 39, boot = -471, init = 510, finish = 0
16/03/17 15:56:44 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/17 15:56:44 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 79 ms on localhost (1/2)
16/03/17 15:56:44 INFO PythonRunner: Times: total = 209, boot = 204, init = 1, finish = 4
16/03/17 15:56:44 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 11013 bytes result sent to driver
16/03/17 15:56:44 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 237 ms on localhost (2/2)
16/03/17 15:56:44 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/17 15:56:44 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) finished in 0.223 s
16/03/17 15:56:44 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230, took 11.151168 s
16/03/17 15:56:44 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230
16/03/17 15:56:44 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) with 2 output partitions
16/03/17 15:56:44 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/17 15:56:44 INFO DAGScheduler: Parents of final stage: List()
16/03/17 15:56:44 INFO DAGScheduler: Missing parents: List()
16/03/17 15:56:44 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230), which has no missing parents
16/03/17 15:56:44 INFO MemoryStore: ensureFreeSpace(5872) called with curMem=20085, maxMem=552075264
16/03/17 15:56:44 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 526.5 MB)
16/03/17 15:56:44 INFO MemoryStore: ensureFreeSpace(3419) called with curMem=25957, maxMem=552075264
16/03/17 15:56:44 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 526.5 MB)
16/03/17 15:56:44 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:54357 (size: 3.3 KB, free: 526.5 MB)
16/03/17 15:56:44 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/17 15:56:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/17 15:56:44 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/17 15:56:44 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/17 15:56:44 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 11962 bytes)
16/03/17 15:56:44 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/17 15:56:44 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/17 15:56:44 INFO PythonRunner: Times: total = 55, boot = 54, init = 0, finish = 1
16/03/17 15:56:44 INFO PythonRunner: Times: total = 54, boot = -133, init = 187, finish = 0
16/03/17 15:56:44 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/17 15:56:44 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 80 ms on localhost (1/2)
16/03/17 15:56:45 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 11320 bytes result sent to driver
16/03/17 15:56:45 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 97 ms on localhost (2/2)
16/03/17 15:56:45 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/17 15:56:45 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) finished in 0.098 s
16/03/17 15:56:45 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230, took 0.124054 s
16/03/17 15:56:45 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/17 15:56:45 INFO DAGScheduler: Stopping DAGScheduler
16/03/17 15:56:45 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/17 15:56:45 INFO MemoryStore: MemoryStore cleared
16/03/17 15:56:45 INFO BlockManager: BlockManager stopped
16/03/17 15:56:45 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/17 15:56:45 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/17 15:56:45 INFO SparkContext: Successfully stopped SparkContext
16/03/17 15:56:45 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/17 15:56:45 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/17 15:56:45 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/17 15:58:51 INFO ShutdownHookManager: Shutdown hook called
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-bbfea9dd-a071-4810-9ea4-687b78f4dbb4
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-4c542cf6-9484-445c-8d75-48b0e1c5d88c
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-e835adde-a8d9-4b50-aea9-6cb8888dc64f
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-c9a23f55-e40e-4a0c-9d1c-22750f0e51e2
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-f9bd9091-59ea-49a6-a12f-147c7e7225c5
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-f5a41d7c-31b0-40a1-aa29-6491056027ac
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-ff8b1709-620e-421e-91f6-4863c9dc28ff
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-e4f772c3-b9c1-4a1b-847a-e847bac41fed
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-15e9626c-82c6-4e6b-9166-ce150ebfb703
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-dbde118d-cbae-4191-8f43-8e05ce629b66
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-de4f758a-4e35-4bf7-aaf8-8a232b1add8a
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-276f4593-52b1-417f-8a82-6ea545f37f06
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-6ca408bd-223c-4f67-bd46-4f6230e6a3dc
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-a384f67b-569f-461f-8842-596d6df4d86f
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-3b784625-0e91-4277-8ddb-23d635dc46c7
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-09d465e5-45d1-43da-a94f-1002c4079709
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-8cbd0c8d-9f76-4991-85cc-5271044c3bd0
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-5b9ffa7f-7b5c-4586-a8ab-bbe102a67242
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-ccaa8fbb-3e64-45a9-9900-e6ad4734b313
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-847797fc-cde7-46a9-84b4-58498d5cedcb
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-283e4aa3-f5f8-411f-b4ae-27c7145d7ce0
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-e923cb59-59bf-4b7f-938f-3a889ac3b975
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-7e8f7cf0-3687-4495-af9a-8757c33ec411
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-117645f3-0258-4c87-9021-c81eba5945d9
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-21626763-d09d-4648-9fa1-b7299b659798
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-a36f7bde-2dc0-47c9-b994-ec1705f1a471
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-054f59c3-99c3-4138-a912-84c30fad5bbb
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-a0e6cbd9-e877-46f5-99ba-e2f375b883be
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-ea5dd835-a9bf-4999-8eeb-0b0907168cdd
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-0cfdb51e-8f17-48e5-869e-42d137ad736e
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-af453e9e-97a1-4239-8e50-d44244fd660b
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-29566580-3fdd-4fed-af5d-f800997582a9
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-7dadedd5-7a55-4465-9e7e-b7de3b189e99
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-aef5757c-fe84-4801-bf4f-cb2beb68066e
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-b4a37595-5a4d-4825-bc2b-42733087f9ce
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-b608083f-14bd-4f6b-9540-53bf24827fcf
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-23d8d0f6-f5de-4aa3-9230-71bdd59242c5
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-95a8838a-9b5c-4c11-b450-05e7dd2712cf
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-08f98aa2-48e9-44a4-b7fe-67112f626ab3
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777/pyspark-6a69fab4-7933-452f-a3d2-56d11905d1ab
16/03/17 15:58:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cd3ca5-0bb8-4a1d-bff0-37ac45f1c777
