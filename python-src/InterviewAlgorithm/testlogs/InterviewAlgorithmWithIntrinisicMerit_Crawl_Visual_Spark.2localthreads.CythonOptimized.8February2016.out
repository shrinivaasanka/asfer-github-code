16/02/08 15:49:07 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/02/08 15:49:07 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219) finished in 8.283 s
16/02/08 15:49:07 INFO DAGScheduler: looking for newly runnable stages
16/02/08 15:49:07 INFO DAGScheduler: running: Set()
16/02/08 15:49:07 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/02/08 15:49:07 INFO DAGScheduler: failed: Set()
16/02/08 15:49:07 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/02/08 15:49:07 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221), which is now runnable
16/02/08 15:49:07 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=548394762
16/02/08 15:49:07 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.0 MB)
16/02/08 15:49:07 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=548394762
16/02/08 15:49:07 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.0 MB)
16/02/08 15:49:07 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8281 ms on localhost (2/2)
16/02/08 15:49:07 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:44326 (size: 3.0 KB, free: 523.0 MB)
16/02/08 15:49:07 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/02/08 15:49:07 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/02/08 15:49:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:49:07 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/02/08 15:49:07 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:49:07 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:49:07 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/02/08 15:49:07 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/02/08 15:49:07 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:49:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/02/08 15:49:07 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:49:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
reduceFunction_Parents(): returns= ['None', u'area', 'None']
16/02/08 15:49:07 INFO PythonRunner: Times: total = 26, boot = -23, init = 49, finish = 0
16/02/08 15:49:07 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1280 bytes result sent to driver
16/02/08 15:49:07 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 49 ms on localhost (1/2)
16/02/08 15:49:07 INFO PythonRunner: Times: total = 214, boot = 213, init = 1, finish = 0
16/02/08 15:49:07 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/02/08 15:49:07 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 234 ms on localhost (2/2)
16/02/08 15:49:07 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/02/08 15:49:07 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) finished in 0.232 s
16/02/08 15:49:07 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221, took 8.538268 s
16/02/08 15:49:07 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224
16/02/08 15:49:07 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) with 2 output partitions
16/02/08 15:49:07 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:49:07 INFO DAGScheduler: Parents of final stage: List()
16/02/08 15:49:07 INFO DAGScheduler: Missing parents: List()
16/02/08 15:49:07 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224), which has no missing parents
16/02/08 15:49:07 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=548394762
16/02/08 15:49:07 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.0 MB)
16/02/08 15:49:07 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=548394762
16/02/08 15:49:07 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.0 MB)
16/02/08 15:49:07 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:44326 (size: 3.3 KB, free: 523.0 MB)
16/02/08 15:49:07 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/02/08 15:49:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:49:07 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/02/08 15:49:07 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/02/08 15:49:07 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2361 bytes)
16/02/08 15:49:07 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/02/08 15:49:07 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/02/08 15:49:07 INFO PythonRunner: Times: total = 75, boot = -122, init = 197, finish = 0
16/02/08 15:49:07 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/02/08 15:49:07 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 84 ms on localhost (1/2)
16/02/08 15:49:07 INFO PythonRunner: Times: total = 99, boot = 99, init = 0, finish = 0
16/02/08 15:49:07 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/02/08 15:49:07 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 112 ms on localhost (2/2)
16/02/08 15:49:07 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/02/08 15:49:07 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) finished in 0.113 s
16/02/08 15:49:07 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224, took 0.141976 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/02/08 15:49:07 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/02/08 15:49:07 INFO DAGScheduler: Stopping DAGScheduler
16/02/08 15:49:07 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/02/08 15:49:07 INFO MemoryStore: MemoryStore cleared
16/02/08 15:49:07 INFO BlockManager: BlockManager stopped
16/02/08 15:49:07 INFO BlockManagerMaster: BlockManagerMaster stopped
16/02/08 15:49:07 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/02/08 15:49:07 INFO SparkContext: Successfully stopped SparkContext
16/02/08 15:49:07 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/02/08 15:49:07 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/02/08 15:49:07 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'area', u'None']
16/02/08 15:49:08 INFO SparkContext: Running Spark version 1.5.2
16/02/08 15:49:08 INFO SecurityManager: Changing view acls to: root
16/02/08 15:49:08 INFO SecurityManager: Changing modify acls to: root
16/02/08 15:49:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/02/08 15:49:08 INFO Slf4jLogger: Slf4jLogger started
16/02/08 15:49:08 INFO Remoting: Starting remoting
16/02/08 15:49:09 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:50242]
16/02/08 15:49:09 INFO Utils: Successfully started service 'sparkDriver' on port 50242.
16/02/08 15:49:09 INFO SparkEnv: Registering MapOutputTracker
16/02/08 15:49:09 INFO SparkEnv: Registering BlockManagerMaster
16/02/08 15:49:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5b2ac9ef-6b9c-43c2-8a24-bf502edaf1a7
16/02/08 15:49:09 INFO MemoryStore: MemoryStore started with capacity 517.3 MB
16/02/08 15:49:09 INFO HttpFileServer: HTTP File server directory is /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/httpd-5f722727-6731-43e0-988e-4397924b0786
16/02/08 15:49:09 INFO HttpServer: Starting HTTP Server
16/02/08 15:49:09 INFO Utils: Successfully started service 'HTTP file server' on port 36143.
16/02/08 15:49:09 INFO SparkEnv: Registering OutputCommitCoordinator
16/02/08 15:49:09 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/02/08 15:49:09 INFO SparkUI: Started SparkUI at http://localhost:4040
16/02/08 15:49:09 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-77c82901-bf78-4dad-bd3b-a09b941fb1db/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/02/08 15:49:09 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926749608
16/02/08 15:49:09 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/02/08 15:49:09 INFO Executor: Starting executor ID driver on host localhost
16/02/08 15:49:09 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54169.
16/02/08 15:49:09 INFO NettyBlockTransferService: Server created on 54169
16/02/08 15:49:09 INFO BlockManagerMaster: Trying to register BlockManager
16/02/08 15:49:09 INFO BlockManagerMasterEndpoint: Registering block manager localhost:54169 with 517.3 MB RAM, BlockManagerId(driver, localhost, 54169)
16/02/08 15:49:09 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): Nadu
16/02/08 15:49:09 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221
16/02/08 15:49:09 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:49:09 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) with 2 output partitions
16/02/08 15:49:09 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:49:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/02/08 15:49:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/02/08 15:49:09 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219), which has no missing parents
16/02/08 15:49:09 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=542449336
16/02/08 15:49:09 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 517.3 MB)
16/02/08 15:49:09 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=542449336
16/02/08 15:49:09 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 517.3 MB)
16/02/08 15:49:09 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:54169 (size: 4.1 KB, free: 517.3 MB)
16/02/08 15:49:09 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/02/08 15:49:09 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:49:09 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/02/08 15:49:09 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2423 bytes)
16/02/08 15:49:09 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2413 bytes)
16/02/08 15:49:09 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/02/08 15:49:09 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926749608
16/02/08 15:49:09 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/02/08 15:49:09 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-77c82901-bf78-4dad-bd3b-a09b941fb1db/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Nadu  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: area
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: elaborate
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: exist
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'be', u',', u'an', u'have', u'existence', u'extant'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: commissariat
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'supply', u'of', u'foods', u'or', u'stock'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: town
mapFunction_Parents(): keyword= Nadu 16/02/08 15:49:17 INFO PythonRunner: Times: total = 8129, boot = 458, init = 386, finish = 7285
16/02/08 15:49:17 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
; syndef_tokens= set([u'a', u'urban', u'smaller', u'area', u'is', u'that', u'an', u'city', u'boundary', u'fixed', u'with', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: state
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'nation', u'of', u'one', u'districts', u'constituent', u'the', u'territory', u'occupied', u'by', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: bend
16/02/08 15:49:17 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8209 ms on localhost (1/2)
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: giant
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: astatine
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: present
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Nadu  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/02/08 15:49:18 INFO PythonRunner: Times: total = 8236, boot = 455, init = 380, finish = 7401
16/02/08 15:49:18 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/02/08 15:49:18 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8310 ms on localhost (2/2)
16/02/08 15:49:18 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/02/08 15:49:18 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219) finished in 8.312 s
16/02/08 15:49:18 INFO DAGScheduler: looking for newly runnable stages
16/02/08 15:49:18 INFO DAGScheduler: running: Set()
16/02/08 15:49:18 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/02/08 15:49:18 INFO DAGScheduler: failed: Set()
16/02/08 15:49:18 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/02/08 15:49:18 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221), which is now runnable
16/02/08 15:49:18 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=542449336
16/02/08 15:49:18 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 517.3 MB)
16/02/08 15:49:18 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=542449336
16/02/08 15:49:18 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 517.3 MB)
16/02/08 15:49:18 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:54169 (size: 3.0 KB, free: 517.3 MB)
16/02/08 15:49:18 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/02/08 15:49:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:49:18 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/02/08 15:49:18 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:49:18 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:49:18 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/02/08 15:49:18 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/02/08 15:49:18 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:49:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/02/08 15:49:18 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:49:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= [u'Chennai', 'None', u'Chennai']
16/02/08 15:49:18 INFO PythonRunner: Times: total = 132, boot = 131, init = 0, finish = 1
16/02/08 15:49:18 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1289 bytes result sent to driver
16/02/08 15:49:18 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 152 ms on localhost (1/2)
16/02/08 15:49:18 INFO PythonRunner: Times: total = 201, boot = 201, init = 0, finish = 0
16/02/08 15:49:18 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/02/08 15:49:18 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 233 ms on localhost (2/2)
16/02/08 15:49:18 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/02/08 15:49:18 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) finished in 0.223 s
16/02/08 15:49:18 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221, took 8.576511 s
16/02/08 15:49:18 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224
16/02/08 15:49:18 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) with 2 output partitions
16/02/08 15:49:18 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:49:18 INFO DAGScheduler: Parents of final stage: List()
16/02/08 15:49:18 INFO DAGScheduler: Missing parents: List()
16/02/08 15:49:18 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224), which has no missing parents
16/02/08 15:49:18 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=542449336
16/02/08 15:49:18 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 517.3 MB)
16/02/08 15:49:18 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=542449336
16/02/08 15:49:18 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 517.3 MB)
16/02/08 15:49:18 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:54169 (size: 3.3 KB, free: 517.3 MB)
16/02/08 15:49:18 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/02/08 15:49:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:49:18 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/02/08 15:49:18 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/02/08 15:49:18 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2370 bytes)
16/02/08 15:49:18 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/02/08 15:49:18 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/02/08 15:49:18 INFO PythonRunner: Times: total = 66, boot = 65, init = 1, finish = 0
16/02/08 15:49:18 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1354 bytes result sent to driver
16/02/08 15:49:18 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 73 ms on localhost (1/2)
16/02/08 15:49:18 INFO PythonRunner: Times: total = 180, boot = 180, init = 0, finish = 0
16/02/08 15:49:18 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/02/08 15:49:18 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 189 ms on localhost (2/2)
16/02/08 15:49:18 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/02/08 15:49:18 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) finished in 0.177 s
16/02/08 15:49:18 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224, took 0.202648 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/02/08 15:49:18 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/02/08 15:49:18 INFO DAGScheduler: Stopping DAGScheduler
16/02/08 15:49:18 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/02/08 15:49:18 INFO MemoryStore: MemoryStore cleared
16/02/08 15:49:18 INFO BlockManager: BlockManager stopped
16/02/08 15:49:18 INFO BlockManagerMaster: BlockManagerMaster stopped
16/02/08 15:49:18 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/02/08 15:49:18 INFO SparkContext: Successfully stopped SparkContext
16/02/08 15:49:18 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/02/08 15:49:18 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/02/08 15:49:18 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'Chennai', u'None', u'Chennai']
16/02/08 15:49:19 INFO SparkContext: Running Spark version 1.5.2
16/02/08 15:49:19 INFO SecurityManager: Changing view acls to: root
16/02/08 15:49:19 INFO SecurityManager: Changing modify acls to: root
16/02/08 15:49:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/02/08 15:49:19 INFO Slf4jLogger: Slf4jLogger started
16/02/08 15:49:19 INFO Remoting: Starting remoting
16/02/08 15:49:19 INFO Utils: Successfully started service 'sparkDriver' on port 57315.
16/02/08 15:49:19 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:57315]
16/02/08 15:49:19 INFO SparkEnv: Registering MapOutputTracker
16/02/08 15:49:19 INFO SparkEnv: Registering BlockManagerMaster
16/02/08 15:49:19 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2342a8a5-3aeb-43c3-b6aa-373b824f4ae1
16/02/08 15:49:19 INFO MemoryStore: MemoryStore started with capacity 517.3 MB
16/02/08 15:49:19 INFO HttpFileServer: HTTP File server directory is /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/httpd-a58227c5-8beb-4b26-8813-4bbb9e7e6490
16/02/08 15:49:19 INFO HttpServer: Starting HTTP Server
16/02/08 15:49:19 INFO Utils: Successfully started service 'HTTP file server' on port 46278.
16/02/08 15:49:19 INFO SparkEnv: Registering OutputCommitCoordinator
16/02/08 15:49:20 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/02/08 15:49:20 INFO SparkUI: Started SparkUI at http://localhost:4040
16/02/08 15:49:20 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-71fefd37-67e5-4ed9-b333-1c66714afdec/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/02/08 15:49:20 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926760217
16/02/08 15:49:20 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/02/08 15:49:20 INFO Executor: Starting executor ID driver on host localhost
16/02/08 15:49:20 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50122.
16/02/08 15:49:20 INFO NettyBlockTransferService: Server created on 50122
16/02/08 15:49:20 INFO BlockManagerMaster: Trying to register BlockManager
16/02/08 15:49:20 INFO BlockManagerMasterEndpoint: Registering block manager localhost:50122 with 517.3 MB RAM, BlockManagerId(driver, localhost, 50122)
16/02/08 15:49:20 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): stock
16/02/08 15:49:20 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221
16/02/08 15:49:20 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:49:20 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) with 2 output partitions
16/02/08 15:49:20 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:49:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/02/08 15:49:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/02/08 15:49:20 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219), which has no missing parents
16/02/08 15:49:20 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=542449336
16/02/08 15:49:20 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 517.3 MB)
16/02/08 15:49:20 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=542449336
16/02/08 15:49:20 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 517.3 MB)
16/02/08 15:49:20 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:50122 (size: 4.1 KB, free: 517.3 MB)
16/02/08 15:49:20 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/02/08 15:49:20 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:49:20 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/02/08 15:49:20 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2423 bytes)
16/02/08 15:49:20 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2413 bytes)
16/02/08 15:49:20 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/02/08 15:49:20 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926760217
16/02/08 15:49:20 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/02/08 15:49:20 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-71fefd37-67e5-4ed9-b333-1c66714afdec/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): stock
mapFunction_Parents(): keyword: stock ; prevleveltokens: kilometer
asfer_pickle_string_load(): picklef.readlines(): stock
mapFunction_Parents(): keyword: stock ; prevleveltokens: set
mapFunction_Parents(): keyword= stock ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): stock
mapFunction_Parents(): keyword: stock ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= stock ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): stock
mapFunction_Parents(): keyword: stock ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= stock ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): stock
mapFunction_Parents(): keyword: stock ; prevleveltokens: area
mapFunction_Parents(): keyword= stock ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): stock
mapFunction_Parents(): keyword: stock ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= stock ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): stock
mapFunction_Parents(): keyword: stock ; prevleveltokens: elaborate
mapFunction_Parents(): keyword= stock ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): stock
mapFunction_Parents(): keyword: stock ; prevleveltokens: exist
mapFunction_Parents(): keyword= stock ; syndef_tokens= set([u'be', u',', u'an', u'have', u'existence', u'extant'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): stock
mapFunction_Parents(): keyword: stock ; prevleveltokens: commissariat
mapFunction_Parents(): keyword= stock ; syndef_tokens= set([u'a', u'supply', u'of', u'foods', u'or', u'stock'])
mapFunction_Parents(): adding to parents: syn =  Synset('commissariat.n.01') ; keyword:  stock  in syndef_tokens= set([u'a', u'supply', u'of', u'foods', u'or', u'stock'])
mapFunction_Parents(): returns= [u'commissariat']
reduceFunction_Parents(): returns= ['None', u'commissariat']
16/02/08 15:49:28 INFO PythonRunner: Times: total = 8188, boot = 457, init = 389, finish = 7342
16/02/08 15:49:28 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/02/08 15:49:28 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8259 ms on localhost (1/2)
mapFunction_Parents(): keyword= stock ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): stock
mapFunction_Parents(): keyword: stock ; prevleveltokens: town
mapFunction_Parents(): keyword= stock ; syndef_tokens= set([u'a', u'urban', u'smaller', u'area', u'is', u'that', u'an', u'city', u'boundary', u'fixed', u'with', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): stock
mapFunction_Parents(): keyword: stock ; prevleveltokens: state
mapFunction_Parents(): keyword= stock ; syndef_tokens= set([u'a', u'nation', u'of', u'one', u'districts', u'constituent', u'the', u'territory', u'occupied', u'by', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): stock
mapFunction_Parents(): keyword: stock ; prevleveltokens: bend
mapFunction_Parents(): keyword= stock ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): stock
mapFunction_Parents(): keyword: stock ; prevleveltokens: giant
mapFunction_Parents(): keyword= stock ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): stock
mapFunction_Parents(): keyword: stock ; prevleveltokens: astatine
mapFunction_Parents(): keyword= stock ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): stock
mapFunction_Parents(): keyword: stock ; prevleveltokens: present
mapFunction_Parents(): keyword= stock ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): stock
mapFunction_Parents(): keyword: stock ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= stock ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/02/08 15:49:28 INFO PythonRunner: Times: total = 8404, boot = 466, init = 387, finish = 7551
16/02/08 15:49:28 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/02/08 15:49:28 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219) finished in 8.469 s
16/02/08 15:49:28 INFO DAGScheduler: looking for newly runnable stages
16/02/08 15:49:28 INFO DAGScheduler: running: Set()
16/02/08 15:49:28 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/02/08 15:49:28 INFO DAGScheduler: failed: Set()
16/02/08 15:49:28 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/02/08 15:49:28 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221), which is now runnable
16/02/08 15:49:28 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=542449336
16/02/08 15:49:28 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 517.3 MB)
16/02/08 15:49:28 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=542449336
16/02/08 15:49:28 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 517.3 MB)
16/02/08 15:49:28 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8468 ms on localhost (2/2)
16/02/08 15:49:28 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/02/08 15:49:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:50122 (size: 3.0 KB, free: 517.3 MB)
16/02/08 15:49:28 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/02/08 15:49:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:49:28 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/02/08 15:49:28 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:49:28 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:49:28 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/02/08 15:49:28 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/02/08 15:49:28 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:49:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/02/08 15:49:28 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:49:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/02/08 15:49:28 INFO PythonRunner: Times: total = 37, boot = -56, init = 93, finish = 0
16/02/08 15:49:28 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/02/08 15:49:28 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 68 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'commissariat', 'None']
16/02/08 15:49:29 INFO PythonRunner: Times: total = 220, boot = 217, init = 1, finish = 2
16/02/08 15:49:29 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1288 bytes result sent to driver
16/02/08 15:49:29 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 234 ms on localhost (2/2)
16/02/08 15:49:29 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) finished in 0.235 s
16/02/08 15:49:29 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221, took 8.729986 s
16/02/08 15:49:29 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/02/08 15:49:29 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224
16/02/08 15:49:29 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) with 2 output partitions
16/02/08 15:49:29 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:49:29 INFO DAGScheduler: Parents of final stage: List()
16/02/08 15:49:29 INFO DAGScheduler: Missing parents: List()
16/02/08 15:49:29 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224), which has no missing parents
16/02/08 15:49:29 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=542449336
16/02/08 15:49:29 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 517.3 MB)
16/02/08 15:49:29 INFO MemoryStore: ensureFreeSpace(3377) called with curMem=24572, maxMem=542449336
16/02/08 15:49:29 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 517.3 MB)
16/02/08 15:49:29 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:50122 (size: 3.3 KB, free: 517.3 MB)
16/02/08 15:49:29 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/02/08 15:49:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:49:29 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/02/08 15:49:29 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/02/08 15:49:29 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2369 bytes)
16/02/08 15:49:29 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/02/08 15:49:29 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/02/08 15:49:29 INFO PythonRunner: Times: total = 63, boot = -71, init = 134, finish = 0
16/02/08 15:49:29 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/02/08 15:49:29 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 71 ms on localhost (1/2)
16/02/08 15:49:29 INFO PythonRunner: Times: total = 96, boot = 95, init = 1, finish = 0
16/02/08 15:49:29 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1356 bytes result sent to driver
16/02/08 15:49:29 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 108 ms on localhost (2/2)
16/02/08 15:49:29 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/02/08 15:49:29 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) finished in 0.092 s
16/02/08 15:49:29 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224, took 0.124600 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/02/08 15:49:29 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/02/08 15:49:29 INFO DAGScheduler: Stopping DAGScheduler
16/02/08 15:49:29 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/02/08 15:49:29 INFO MemoryStore: MemoryStore cleared
16/02/08 15:49:29 INFO BlockManager: BlockManager stopped
16/02/08 15:49:29 INFO BlockManagerMaster: BlockManagerMaster stopped
16/02/08 15:49:29 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/02/08 15:49:29 INFO SparkContext: Successfully stopped SparkContext
16/02/08 15:49:29 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/02/08 15:49:29 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/02/08 15:49:29 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'commissariat', u'None']
16/02/08 15:49:30 INFO SparkContext: Running Spark version 1.5.2
16/02/08 15:49:30 INFO SecurityManager: Changing view acls to: root
16/02/08 15:49:30 INFO SecurityManager: Changing modify acls to: root
16/02/08 15:49:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/02/08 15:49:30 INFO Slf4jLogger: Slf4jLogger started
16/02/08 15:49:30 INFO Remoting: Starting remoting
16/02/08 15:49:30 INFO Utils: Successfully started service 'sparkDriver' on port 55904.
16/02/08 15:49:30 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:55904]
16/02/08 15:49:30 INFO SparkEnv: Registering MapOutputTracker
16/02/08 15:49:30 INFO SparkEnv: Registering BlockManagerMaster
16/02/08 15:49:30 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-53ed7976-1010-4d54-a6ed-e445406b7e4f
16/02/08 15:49:30 INFO MemoryStore: MemoryStore started with capacity 517.3 MB
16/02/08 15:49:30 INFO HttpFileServer: HTTP File server directory is /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/httpd-35d3ace7-01be-48f2-b4db-2f4c900825b6
16/02/08 15:49:30 INFO HttpServer: Starting HTTP Server
16/02/08 15:49:30 INFO Utils: Successfully started service 'HTTP file server' on port 52816.
16/02/08 15:49:30 INFO SparkEnv: Registering OutputCommitCoordinator
16/02/08 15:49:30 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/02/08 15:49:30 INFO SparkUI: Started SparkUI at http://localhost:4040
16/02/08 15:49:30 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-346c8ee5-1ae4-4290-bb28-cf827a79b937/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/02/08 15:49:30 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926770795
16/02/08 15:49:30 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/02/08 15:49:30 INFO Executor: Starting executor ID driver on host localhost
16/02/08 15:49:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36847.
16/02/08 15:49:30 INFO NettyBlockTransferService: Server created on 36847
16/02/08 15:49:30 INFO BlockManagerMaster: Trying to register BlockManager
16/02/08 15:49:30 INFO BlockManagerMasterEndpoint: Registering block manager localhost:36847 with 517.3 MB RAM, BlockManagerId(driver, localhost, 36847)
16/02/08 15:49:30 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): product
16/02/08 15:49:30 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221
16/02/08 15:49:30 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:49:30 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) with 2 output partitions
16/02/08 15:49:30 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:49:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/02/08 15:49:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/02/08 15:49:30 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219), which has no missing parents
16/02/08 15:49:30 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=542449336
16/02/08 15:49:30 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 517.3 MB)
16/02/08 15:49:30 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=542449336
16/02/08 15:49:30 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 517.3 MB)
16/02/08 15:49:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:36847 (size: 4.1 KB, free: 517.3 MB)
16/02/08 15:49:30 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/02/08 15:49:30 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:49:30 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/02/08 15:49:30 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2423 bytes)
16/02/08 15:49:30 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2413 bytes)
16/02/08 15:49:30 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/02/08 15:49:30 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926770795
16/02/08 15:49:30 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/02/08 15:49:30 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-346c8ee5-1ae4-4290-bb28-cf827a79b937/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: area
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: town
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: elaborate
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'urban', u'smaller', u'area', u'is', u'that', u'an', u'city', u'boundary', u'fixed', u'with', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: state
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details'mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'nation', u'of', u'one', u'districts', u'constituent', u'the', u'territory', u'occupied', u'by', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: bend
, u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: exist
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'be', u',', u'an', u'have', u'existence', u'extant'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: commissariat
mapFunction_Parents(): keyword= product ; syndef_tokens=mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: giant
 set([u'a', u'supply', u'of', u'foods', u'or', u'stock'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: astatine
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  product  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series'16/02/08 15:49:39 INFO PythonRunner: Times: total = 8081, boot = 461, init = 400, finish = 7220
16/02/08 15:49:39 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
, u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: present
16/02/08 15:49:39 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8136 ms on localhost (1/2)
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/02/08 15:49:39 INFO PythonRunner: Times: total = 8149, boot = 455, init = 388, finish = 7306
16/02/08 15:49:39 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/02/08 15:49:39 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8209 ms on localhost (2/2)
16/02/08 15:49:39 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/02/08 15:49:39 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219) finished in 8.219 s
16/02/08 15:49:39 INFO DAGScheduler: looking for newly runnable stages
16/02/08 15:49:39 INFO DAGScheduler: running: Set()
16/02/08 15:49:39 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/02/08 15:49:39 INFO DAGScheduler: failed: Set()
16/02/08 15:49:39 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/02/08 15:49:39 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221), which is now runnable
16/02/08 15:49:39 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=542449336
16/02/08 15:49:39 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 517.3 MB)
16/02/08 15:49:39 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=542449336
16/02/08 15:49:39 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 517.3 MB)
16/02/08 15:49:39 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:36847 (size: 3.0 KB, free: 517.3 MB)
16/02/08 15:49:39 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/02/08 15:49:39 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:49:39 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/02/08 15:49:39 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:49:39 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:49:39 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/02/08 15:49:39 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:49:39 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/02/08 15:49:39 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:49:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/02/08 15:49:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/02/08 15:49:39 INFO PythonRunner: Times: total = 104, boot = 103, init = 1, finish = 0
16/02/08 15:49:39 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/02/08 15:49:39 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 123 ms on localhost (1/2)
16/02/08 15:49:39 INFO PythonRunner: Times: total = 234, boot = 233, init = 1, finish = 0
16/02/08 15:49:39 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/02/08 15:49:39 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) finished in 0.239 s
16/02/08 15:49:39 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221, took 8.501199 s
16/02/08 15:49:39 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 255 ms on localhost (2/2)
16/02/08 15:49:39 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/02/08 15:49:39 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:36847 in memory (size: 3.0 KB, free: 517.3 MB)
16/02/08 15:49:39 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224
16/02/08 15:49:39 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) with 2 output partitions
16/02/08 15:49:39 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:49:39 INFO DAGScheduler: Parents of final stage: List()
16/02/08 15:49:39 INFO ContextCleaner: Cleaned accumulator 331
16/02/08 15:49:39 INFO DAGScheduler: Missing parents: List()
16/02/08 15:49:39 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224), which has no missing parents
16/02/08 15:49:39 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:36847 in memory (size: 4.1 KB, free: 517.3 MB)
16/02/08 15:49:39 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=0, maxMem=542449336
16/02/08 15:49:39 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 517.3 MB)
16/02/08 15:49:39 INFO ContextCleaner: Cleaned accumulator 330
16/02/08 15:49:39 INFO MemoryStore: ensureFreeSpace(3377) called with curMem=5816, maxMem=542449336
16/02/08 15:49:39 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 517.3 MB)
16/02/08 15:49:39 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:36847 (size: 3.3 KB, free: 517.3 MB)
16/02/08 15:49:39 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/02/08 15:49:39 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:49:39 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/02/08 15:49:39 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/02/08 15:49:39 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/02/08 15:49:39 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/02/08 15:49:39 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/02/08 15:49:39 INFO PythonRunner: Times: total = 9, boot = -251, init = 260, finish = 0
16/02/08 15:49:39 INFO PythonRunner: Times: total = 9, boot = -149, init = 158, finish = 0
16/02/08 15:49:39 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/02/08 15:49:39 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/02/08 15:49:39 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 47 ms on localhost (1/2)
16/02/08 15:49:39 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 48 ms on localhost (2/2)
16/02/08 15:49:39 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/02/08 15:49:39 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) finished in 0.048 s
16/02/08 15:49:39 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224, took 0.064144 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/02/08 15:49:39 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/02/08 15:49:39 INFO DAGScheduler: Stopping DAGScheduler
16/02/08 15:49:40 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/02/08 15:49:40 INFO MemoryStore: MemoryStore cleared
16/02/08 15:49:40 INFO BlockManager: BlockManager stopped
16/02/08 15:49:40 INFO BlockManagerMaster: BlockManagerMaster stopped
16/02/08 15:49:40 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/02/08 15:49:40 INFO SparkContext: Successfully stopped SparkContext
16/02/08 15:49:40 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'astatine']
16/02/08 15:49:40 INFO SparkContext: Running Spark version 1.5.2
16/02/08 15:49:40 INFO SecurityManager: Changing view acls to: root
16/02/08 15:49:40 INFO SecurityManager: Changing modify acls to: root
16/02/08 15:49:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/02/08 15:49:40 INFO Slf4jLogger: Slf4jLogger started
16/02/08 15:49:40 INFO Remoting: Starting remoting
16/02/08 15:49:40 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:46787]
16/02/08 15:49:40 INFO Utils: Successfully started service 'sparkDriver' on port 46787.
16/02/08 15:49:40 INFO SparkEnv: Registering MapOutputTracker
16/02/08 15:49:40 INFO SparkEnv: Registering BlockManagerMaster
16/02/08 15:49:40 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3db8e1d6-7a41-40f8-b2c4-32cc6ca490aa
16/02/08 15:49:40 INFO MemoryStore: MemoryStore started with capacity 522.6 MB
16/02/08 15:49:41 INFO HttpFileServer: HTTP File server directory is /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/httpd-cfa7c58d-6f16-4d2c-9741-c88a14a617c3
16/02/08 15:49:41 INFO HttpServer: Starting HTTP Server
16/02/08 15:49:41 INFO Utils: Successfully started service 'HTTP file server' on port 45292.
16/02/08 15:49:41 INFO SparkEnv: Registering OutputCommitCoordinator
16/02/08 15:49:41 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/02/08 15:49:41 INFO SparkUI: Started SparkUI at http://localhost:4040
16/02/08 15:49:41 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-f11cb918-d7f2-4992-b6e4-3c8a34f66cca/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/02/08 15:49:41 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926781509
16/02/08 15:49:41 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/02/08 15:49:41 INFO Executor: Starting executor ID driver on host localhost
16/02/08 15:49:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49757.
16/02/08 15:49:41 INFO NettyBlockTransferService: Server created on 49757
16/02/08 15:49:41 INFO BlockManagerMaster: Trying to register BlockManager
16/02/08 15:49:41 INFO BlockManagerMasterEndpoint: Registering block manager localhost:49757 with 522.6 MB RAM, BlockManagerId(driver, localhost, 49757)
16/02/08 15:49:41 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): used
16/02/08 15:49:41 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221
16/02/08 15:49:41 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:49:41 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) with 2 output partitions
16/02/08 15:49:41 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:49:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/02/08 15:49:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/02/08 15:49:41 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219), which has no missing parents
16/02/08 15:49:41 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=547970088
16/02/08 15:49:41 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 522.6 MB)
16/02/08 15:49:41 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=547970088
16/02/08 15:49:41 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 522.6 MB)
16/02/08 15:49:41 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:49757 (size: 4.1 KB, free: 522.6 MB)
16/02/08 15:49:41 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/02/08 15:49:41 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:49:41 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/02/08 15:49:41 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2423 bytes)
16/02/08 15:49:41 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2413 bytes)
16/02/08 15:49:41 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/02/08 15:49:41 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926781509
16/02/08 15:49:41 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/02/08 15:49:41 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-f11cb918-d7f2-4992-b6e4-3c8a34f66cca/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: kilometer
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: set
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: area
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: elaborate
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: exist
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'be', u',', u'an', u'have', u'existence', u'extant'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: commissariat
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'supply', u'of', u'foods', u'or', u'stock'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/02/08 15:49:49 INFO PythonRunner: Times: total = 7907, boot = 449, init = 377, finish = 7081
16/02/08 15:49:49 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/02/08 15:49:49 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7976 ms on localhost (1/2)
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  Synset('set.n.01') ; keyword:  used  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: town
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'urban', u'smaller', u'area', u'is', u'that', u'an', u'city', u'boundary', u'fixed', u'with', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: state
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'nation', u'of', u'one', u'districts', u'constituent', u'the', u'territory', u'occupied', u'by', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: bend
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: giant
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: astatine
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: present
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
16/02/08 15:49:49 INFO PythonRunner: Times: total = 8141, boot = 463, init = 383, finish = 7295
16/02/08 15:49:49 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/02/08 15:49:49 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8201 ms on localhost (2/2)
16/02/08 15:49:49 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/02/08 15:49:49 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219) finished in 8.203 s
16/02/08 15:49:49 INFO DAGScheduler: looking for newly runnable stages
16/02/08 15:49:49 INFO DAGScheduler: running: Set()
16/02/08 15:49:49 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/02/08 15:49:49 INFO DAGScheduler: failed: Set()
16/02/08 15:49:49 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/02/08 15:49:49 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221), which is now runnable
16/02/08 15:49:49 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=547970088
16/02/08 15:49:49 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 522.6 MB)
16/02/08 15:49:49 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=547970088
16/02/08 15:49:49 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 522.6 MB)
16/02/08 15:49:49 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:49757 (size: 3.0 KB, free: 522.6 MB)
16/02/08 15:49:49 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/02/08 15:49:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:49:49 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/02/08 15:49:49 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:49:49 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:49:49 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/02/08 15:49:49 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:49:49 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/02/08 15:49:49 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:49:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/02/08 15:49:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
reduceFunction_Parents(): returns= ['None', u'set']
16/02/08 15:49:49 INFO PythonRunner: Times: total = 32, boot = -79, init = 111, finish = 0
16/02/08 15:49:49 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1271 bytes result sent to driver
16/02/08 15:49:49 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 87 ms on localhost (1/2)
16/02/08 15:49:50 INFO PythonRunner: Times: total = 191, boot = 191, init = 0, finish = 0
16/02/08 15:49:50 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/02/08 15:49:50 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 219 ms on localhost (2/2)
16/02/08 15:49:50 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/02/08 15:49:50 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) finished in 0.206 s
16/02/08 15:49:50 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221, took 8.449690 s
16/02/08 15:49:50 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224
16/02/08 15:49:50 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) with 2 output partitions
16/02/08 15:49:50 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:49:50 INFO DAGScheduler: Parents of final stage: List()
16/02/08 15:49:50 INFO DAGScheduler: Missing parents: List()
16/02/08 15:49:50 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224), which has no missing parents
16/02/08 15:49:50 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=547970088
16/02/08 15:49:50 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 522.6 MB)
16/02/08 15:49:50 INFO MemoryStore: ensureFreeSpace(3377) called with curMem=24572, maxMem=547970088
16/02/08 15:49:50 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 522.6 MB)
16/02/08 15:49:50 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:49757 (size: 3.3 KB, free: 522.6 MB)
16/02/08 15:49:50 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/02/08 15:49:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:49:50 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/02/08 15:49:50 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/02/08 15:49:50 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2352 bytes)
16/02/08 15:49:50 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/02/08 15:49:50 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/02/08 15:49:50 INFO PythonRunner: Times: total = 51, boot = -80, init = 131, finish = 0
16/02/08 15:49:50 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1336 bytes result sent to driver
16/02/08 15:49:50 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 64 ms on localhost (1/2)
16/02/08 15:49:50 INFO PythonRunner: Times: total = 77, boot = 77, init = 0, finish = 0
16/02/08 15:49:50 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/02/08 15:49:50 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 84 ms on localhost (2/2)
16/02/08 15:49:50 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/02/08 15:49:50 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) finished in 0.076 s
16/02/08 15:49:50 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224, took 0.100465 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/02/08 15:49:50 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/02/08 15:49:50 INFO DAGScheduler: Stopping DAGScheduler
16/02/08 15:49:50 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/02/08 15:49:50 INFO MemoryStore: MemoryStore cleared
16/02/08 15:49:50 INFO BlockManager: BlockManager stopped
16/02/08 15:49:50 INFO BlockManagerMaster: BlockManagerMaster stopped
16/02/08 15:49:50 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/02/08 15:49:50 INFO SparkContext: Successfully stopped SparkContext
16/02/08 15:49:50 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'set']
16/02/08 15:49:51 INFO SparkContext: Running Spark version 1.5.2
16/02/08 15:49:51 INFO SecurityManager: Changing view acls to: root
16/02/08 15:49:51 INFO SecurityManager: Changing modify acls to: root
16/02/08 15:49:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/02/08 15:49:51 INFO Slf4jLogger: Slf4jLogger started
16/02/08 15:49:51 INFO Remoting: Starting remoting
16/02/08 15:49:51 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:47722]
16/02/08 15:49:51 INFO Utils: Successfully started service 'sparkDriver' on port 47722.
16/02/08 15:49:51 INFO SparkEnv: Registering MapOutputTracker
16/02/08 15:49:51 INFO SparkEnv: Registering BlockManagerMaster
16/02/08 15:49:51 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c69fbd96-a3ba-4123-a261-a4090236b441
16/02/08 15:49:51 INFO MemoryStore: MemoryStore started with capacity 522.6 MB
16/02/08 15:49:51 INFO HttpFileServer: HTTP File server directory is /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/httpd-185a6201-2fa8-4643-8d2f-7a4a279fcba7
16/02/08 15:49:51 INFO HttpServer: Starting HTTP Server
16/02/08 15:49:51 INFO Utils: Successfully started service 'HTTP file server' on port 44923.
16/02/08 15:49:51 INFO SparkEnv: Registering OutputCommitCoordinator
16/02/08 15:49:51 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/02/08 15:49:51 INFO SparkUI: Started SparkUI at http://localhost:4040
16/02/08 15:49:51 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-ed69d6d3-09bb-4163-a425-1ea5c9cceb9a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/02/08 15:49:51 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926791935
16/02/08 15:49:51 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/02/08 15:49:51 INFO Executor: Starting executor ID driver on host localhost
16/02/08 15:49:51 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52723.
16/02/08 15:49:51 INFO NettyBlockTransferService: Server created on 52723
16/02/08 15:49:51 INFO BlockManagerMaster: Trying to register BlockManager
16/02/08 15:49:51 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52723 with 522.6 MB RAM, BlockManagerId(driver, localhost, 52723)
16/02/08 15:49:51 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): moment
16/02/08 15:49:52 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221
16/02/08 15:49:52 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:49:52 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) with 2 output partitions
16/02/08 15:49:52 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:49:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/02/08 15:49:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/02/08 15:49:52 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219), which has no missing parents
16/02/08 15:49:52 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=547970088
16/02/08 15:49:52 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 522.6 MB)
16/02/08 15:49:52 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=547970088
16/02/08 15:49:52 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 522.6 MB)
16/02/08 15:49:52 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52723 (size: 4.1 KB, free: 522.6 MB)
16/02/08 15:49:52 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/02/08 15:49:52 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:49:52 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/02/08 15:49:52 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2423 bytes)
16/02/08 15:49:52 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2413 bytes)
16/02/08 15:49:52 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/02/08 15:49:52 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926791935
16/02/08 15:49:52 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/02/08 15:49:52 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-ed69d6d3-09bb-4163-a425-1ea5c9cceb9a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: kilometer
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: set
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: town
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'urban', u'smaller', u'area', u'is', u'that', u'an', u'city', u'boundary', u'fixed', u'with', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: state

mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: area
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword:mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'nation', u'of', u'one', u'districts', u'constituent', u'the', u'territory', u'occupied', u'by', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: bend
 moment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: elaborate
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: exist
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'be', u',', u'an', u'have', u'existence', u'extant'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: commissariat
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: giant
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'supply', u'of', u'foods', u'or', u'stock'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: astatine
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: present
16/02/08 15:50:00 INFO PythonRunner: Times: total = 8171, boot = 449, init = 370, finish = 7352
16/02/08 15:50:00 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
mapFunction_Parents(): keyword=16/02/08 15:50:00 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8247 ms on localhost (1/2)
 moment ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  moment  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/02/08 15:50:00 INFO PythonRunner: Times: total = 8213, boot = 458, init = 383, finish = 7372
16/02/08 15:50:00 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/02/08 15:50:00 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219) finished in 8.292 s
16/02/08 15:50:00 INFO DAGScheduler: looking for newly runnable stages
16/02/08 15:50:00 INFO DAGScheduler: running: Set()
16/02/08 15:50:00 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/02/08 15:50:00 INFO DAGScheduler: failed: Set()
16/02/08 15:50:00 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/02/08 15:50:00 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221), which is now runnable
16/02/08 15:50:00 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=547970088
16/02/08 15:50:00 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 522.6 MB)
16/02/08 15:50:00 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=547970088
16/02/08 15:50:00 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8290 ms on localhost (2/2)
16/02/08 15:50:00 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/02/08 15:50:00 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 522.6 MB)
16/02/08 15:50:00 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52723 (size: 3.0 KB, free: 522.6 MB)
16/02/08 15:50:00 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/02/08 15:50:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:50:00 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/02/08 15:50:00 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:50:00 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:50:00 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/02/08 15:50:00 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/02/08 15:50:00 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:50:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/02/08 15:50:00 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:50:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/02/08 15:50:00 INFO PythonRunner: Times: total = 167, boot = 166, init = 0, finish = 1
16/02/08 15:50:00 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/02/08 15:50:00 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 185 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'present']
16/02/08 15:50:00 INFO PythonRunner: Times: total = 187, boot = 186, init = 0, finish = 1
16/02/08 15:50:00 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/02/08 15:50:00 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) finished in 0.208 s
16/02/08 15:50:00 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 214 ms on localhost (2/2)
16/02/08 15:50:00 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/02/08 15:50:00 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221, took 8.550424 s
16/02/08 15:50:00 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224
16/02/08 15:50:00 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) with 2 output partitions
16/02/08 15:50:00 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:50:00 INFO DAGScheduler: Parents of final stage: List()
16/02/08 15:50:00 INFO DAGScheduler: Missing parents: List()
16/02/08 15:50:00 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224), which has no missing parents
16/02/08 15:50:00 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=547970088
16/02/08 15:50:00 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 522.6 MB)
16/02/08 15:50:00 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=547970088
16/02/08 15:50:00 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 522.6 MB)
16/02/08 15:50:00 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:52723 (size: 3.3 KB, free: 522.6 MB)
16/02/08 15:50:00 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/02/08 15:50:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:50:00 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/02/08 15:50:00 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/02/08 15:50:00 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/02/08 15:50:00 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/02/08 15:50:00 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/02/08 15:50:00 INFO PythonRunner: Times: total = 98, boot = 97, init = 1, finish = 0
16/02/08 15:50:00 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1351 bytes result sent to driver
16/02/08 15:50:00 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 120 ms on localhost (1/2)
16/02/08 15:50:00 INFO PythonRunner: Times: total = 108, boot = 108, init = 0, finish = 0
16/02/08 15:50:00 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/02/08 15:50:00 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 130 ms on localhost (2/2)
16/02/08 15:50:00 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/02/08 15:50:00 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) finished in 0.128 s
16/02/08 15:50:00 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224, took 0.143420 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/02/08 15:50:00 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/02/08 15:50:00 INFO DAGScheduler: Stopping DAGScheduler
16/02/08 15:50:01 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/02/08 15:50:01 INFO MemoryStore: MemoryStore cleared
16/02/08 15:50:01 INFO BlockManager: BlockManager stopped
16/02/08 15:50:01 INFO BlockManagerMaster: BlockManagerMaster stopped
16/02/08 15:50:01 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/02/08 15:50:01 INFO SparkContext: Successfully stopped SparkContext
16/02/08 15:50:01 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/02/08 15:50:01 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/02/08 15:50:01 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'present']
16/02/08 15:50:01 INFO SparkContext: Running Spark version 1.5.2
16/02/08 15:50:01 INFO SecurityManager: Changing view acls to: root
16/02/08 15:50:01 INFO SecurityManager: Changing modify acls to: root
16/02/08 15:50:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/02/08 15:50:01 INFO Slf4jLogger: Slf4jLogger started
16/02/08 15:50:01 INFO Remoting: Starting remoting
16/02/08 15:50:01 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:36521]
16/02/08 15:50:01 INFO Utils: Successfully started service 'sparkDriver' on port 36521.
16/02/08 15:50:01 INFO SparkEnv: Registering MapOutputTracker
16/02/08 15:50:01 INFO SparkEnv: Registering BlockManagerMaster
16/02/08 15:50:02 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0530bd07-f659-466c-964f-77d2bc6c1383
16/02/08 15:50:02 INFO MemoryStore: MemoryStore started with capacity 522.6 MB
16/02/08 15:50:02 INFO HttpFileServer: HTTP File server directory is /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/httpd-280e9055-179b-4483-a63a-50b3f0ceec18
16/02/08 15:50:02 INFO HttpServer: Starting HTTP Server
16/02/08 15:50:02 INFO Utils: Successfully started service 'HTTP file server' on port 42264.
16/02/08 15:50:02 INFO SparkEnv: Registering OutputCommitCoordinator
16/02/08 15:50:02 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/02/08 15:50:02 INFO SparkUI: Started SparkUI at http://localhost:4040
16/02/08 15:50:02 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-92d16387-76f2-42ba-a7fa-263683dd2f77/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/02/08 15:50:02 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926802529
16/02/08 15:50:02 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/02/08 15:50:02 INFO Executor: Starting executor ID driver on host localhost
16/02/08 15:50:02 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57252.
16/02/08 15:50:02 INFO NettyBlockTransferService: Server created on 57252
16/02/08 15:50:02 INFO BlockManagerMaster: Trying to register BlockManager
16/02/08 15:50:02 INFO BlockManagerMasterEndpoint: Registering block manager localhost:57252 with 522.6 MB RAM, BlockManagerId(driver, localhost, 57252)
16/02/08 15:50:02 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): purpose
16/02/08 15:50:02 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221
16/02/08 15:50:02 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:50:02 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) with 2 output partitions
16/02/08 15:50:02 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:50:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/02/08 15:50:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/02/08 15:50:02 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219), which has no missing parents
16/02/08 15:50:02 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=547970088
16/02/08 15:50:02 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 522.6 MB)
16/02/08 15:50:02 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=547970088
16/02/08 15:50:02 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 522.6 MB)
16/02/08 15:50:02 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:57252 (size: 4.1 KB, free: 522.6 MB)
16/02/08 15:50:02 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/02/08 15:50:02 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:50:02 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/02/08 15:50:02 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2423 bytes)
16/02/08 15:50:02 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2413 bytes)
16/02/08 15:50:02 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/02/08 15:50:02 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926802529
16/02/08 15:50:02 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/02/08 15:50:02 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-92d16387-76f2-42ba-a7fa-263683dd2f77/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: kilometer
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: set
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: area
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  purpose  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: elaborate
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: exist
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'be', u',', u'an', u'have', u'existence', u'extant'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: commissariat
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'supply', u'of', u'foods', u'or', u'stock'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/02/08 15:50:11 INFO PythonRunner: Times: total = 8073, boot = 456, init = 373, finish = 7244
16/02/08 15:50:11 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/02/08 15:50:11 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8158 ms on localhost (1/2)
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: town
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'urban', u'smaller', u'area', u'is', u'that', u'an', u'city', u'boundary', u'fixed', u'with', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: state
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'nation', u'of', u'one', u'districts', u'constituent', u'the', u'territory', u'occupied', u'by', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: bend
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: giant
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: astatine
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: present
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/02/08 15:50:11 INFO PythonRunner: Times: total = 8299, boot = 451, init = 371, finish = 7477
16/02/08 15:50:11 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/02/08 15:50:11 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8390 ms on localhost (2/2)
16/02/08 15:50:11 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/02/08 15:50:11 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219) finished in 8.385 s
16/02/08 15:50:11 INFO DAGScheduler: looking for newly runnable stages
16/02/08 15:50:11 INFO DAGScheduler: running: Set()
16/02/08 15:50:11 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/02/08 15:50:11 INFO DAGScheduler: failed: Set()
16/02/08 15:50:11 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/02/08 15:50:11 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221), which is now runnable
16/02/08 15:50:11 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=547970088
16/02/08 15:50:11 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 522.6 MB)
16/02/08 15:50:11 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=15700, maxMem=547970088
16/02/08 15:50:11 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 522.6 MB)
16/02/08 15:50:11 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:57252 (size: 3.0 KB, free: 522.6 MB)
16/02/08 15:50:11 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/02/08 15:50:11 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:50:11 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/02/08 15:50:11 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:50:11 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:50:11 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/02/08 15:50:11 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/02/08 15:50:11 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:50:11 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:50:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/02/08 15:50:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/02/08 15:50:11 INFO PythonRunner: Times: total = 45, boot = -74, init = 118, finish = 1
16/02/08 15:50:11 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/02/08 15:50:11 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 83 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'area', 'None']
16/02/08 15:50:11 INFO PythonRunner: Times: total = 212, boot = 211, init = 0, finish = 1
16/02/08 15:50:11 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1280 bytes result sent to driver
16/02/08 15:50:11 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) finished in 0.228 s
16/02/08 15:50:11 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221, took 8.665227 s
16/02/08 15:50:11 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 228 ms on localhost (2/2)
16/02/08 15:50:11 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/02/08 15:50:11 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224
16/02/08 15:50:11 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) with 2 output partitions
16/02/08 15:50:11 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:50:11 INFO DAGScheduler: Parents of final stage: List()
16/02/08 15:50:11 INFO DAGScheduler: Missing parents: List()
16/02/08 15:50:11 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224), which has no missing parents
16/02/08 15:50:11 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18755, maxMem=547970088
16/02/08 15:50:11 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 522.6 MB)
16/02/08 15:50:11 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24571, maxMem=547970088
16/02/08 15:50:11 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 522.6 MB)
16/02/08 15:50:11 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:57252 (size: 3.3 KB, free: 522.6 MB)
16/02/08 15:50:11 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/02/08 15:50:11 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:50:11 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/02/08 15:50:11 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/02/08 15:50:11 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2361 bytes)
16/02/08 15:50:11 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/02/08 15:50:11 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/02/08 15:50:11 INFO PythonRunner: Times: total = 52, boot = -21, init = 73, finish = 0
16/02/08 15:50:11 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/02/08 15:50:11 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 61 ms on localhost (1/2)
16/02/08 15:50:11 INFO PythonRunner: Times: total = 99, boot = 99, init = 0, finish = 0
16/02/08 15:50:11 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/02/08 15:50:11 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 107 ms on localhost (2/2)
16/02/08 15:50:11 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/02/08 15:50:11 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) finished in 0.099 s
16/02/08 15:50:11 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224, took 0.116834 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/02/08 15:50:11 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/02/08 15:50:11 INFO DAGScheduler: Stopping DAGScheduler
16/02/08 15:50:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/02/08 15:50:11 INFO MemoryStore: MemoryStore cleared
16/02/08 15:50:11 INFO BlockManager: BlockManager stopped
16/02/08 15:50:11 INFO BlockManagerMaster: BlockManagerMaster stopped
16/02/08 15:50:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/02/08 15:50:11 INFO SparkContext: Successfully stopped SparkContext
16/02/08 15:50:11 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/02/08 15:50:11 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/02/08 15:50:11 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'area', u'None']
16/02/08 15:50:12 INFO SparkContext: Running Spark version 1.5.2
16/02/08 15:50:12 INFO SecurityManager: Changing view acls to: root
16/02/08 15:50:12 INFO SecurityManager: Changing modify acls to: root
16/02/08 15:50:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/02/08 15:50:12 INFO Slf4jLogger: Slf4jLogger started
16/02/08 15:50:12 INFO Remoting: Starting remoting
16/02/08 15:50:12 INFO Utils: Successfully started service 'sparkDriver' on port 45494.
16/02/08 15:50:12 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:45494]
16/02/08 15:50:12 INFO SparkEnv: Registering MapOutputTracker
16/02/08 15:50:12 INFO SparkEnv: Registering BlockManagerMaster
16/02/08 15:50:12 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-424673ee-6cc6-42e2-8e84-267199be6590
16/02/08 15:50:12 INFO MemoryStore: MemoryStore started with capacity 523.0 MB
16/02/08 15:50:12 INFO HttpFileServer: HTTP File server directory is /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/httpd-dac5e7b0-1a6b-40f8-b4c4-3dd5f9cd3707
16/02/08 15:50:12 INFO HttpServer: Starting HTTP Server
16/02/08 15:50:12 INFO Utils: Successfully started service 'HTTP file server' on port 37145.
16/02/08 15:50:12 INFO SparkEnv: Registering OutputCommitCoordinator
16/02/08 15:50:13 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/02/08 15:50:13 INFO SparkUI: Started SparkUI at http://localhost:4040
16/02/08 15:50:13 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-6556df09-7ddd-4efa-8f2f-1f2e47f67a74/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/02/08 15:50:13 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926813408
16/02/08 15:50:13 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/02/08 15:50:13 INFO Executor: Starting executor ID driver on host localhost
16/02/08 15:50:13 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33140.
16/02/08 15:50:13 INFO NettyBlockTransferService: Server created on 33140
16/02/08 15:50:13 INFO BlockManagerMaster: Trying to register BlockManager
16/02/08 15:50:13 INFO BlockManagerMasterEndpoint: Registering block manager localhost:33140 with 523.0 MB RAM, BlockManagerId(driver, localhost, 33140)
16/02/08 15:50:13 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): segment
16/02/08 15:50:13 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221
16/02/08 15:50:13 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:50:13 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) with 2 output partitions
16/02/08 15:50:13 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:50:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/02/08 15:50:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/02/08 15:50:13 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219), which has no missing parents
16/02/08 15:50:13 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=548394762
16/02/08 15:50:13 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.0 MB)
16/02/08 15:50:13 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=548394762
16/02/08 15:50:13 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.0 MB)
16/02/08 15:50:13 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:33140 (size: 4.1 KB, free: 523.0 MB)
16/02/08 15:50:13 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/02/08 15:50:13 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:50:13 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/02/08 15:50:13 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2423 bytes)
16/02/08 15:50:13 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2413 bytes)
16/02/08 15:50:13 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/02/08 15:50:13 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926813408
16/02/08 15:50:13 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/02/08 15:50:13 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-6556df09-7ddd-4efa-8f2f-1f2e47f67a74/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: kilometer
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: set
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: area
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: elaborate
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: exist
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'be', u',', u'an', u'have', u'existence', u'extant'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: commissariat
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'supply', u'of', u'foods', u'or', u'stock'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/02/08 15:50:21 INFO PythonRunner: Times: total = 8026, boot = 456, init = 374, finish = 7196
16/02/08 15:50:21 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/02/08 15:50:21 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8103 ms on localhost (1/2)
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: town
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'urban', u'smaller', u'area', u'is', u'that', u'an', u'city', u'boundary', u'fixed', u'with', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: state
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'nation', u'of', u'one', u'districts', u'constituent', u'the', u'territory', u'occupied', u'by', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: bend
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): adding to parents: syn =  Synset('bend.n.01') ; keyword:  segment  in syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= [u'bend']
reduceFunction_Parents(): returns= ['None', u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: giant
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: astatine
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: present
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'bend']
16/02/08 15:50:21 INFO PythonRunner: Times: total = 8192, boot = 460, init = 416, finish = 7316
16/02/08 15:50:21 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/02/08 15:50:21 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219) finished in 8.278 s
16/02/08 15:50:21 INFO DAGScheduler: looking for newly runnable stages
16/02/08 15:50:21 INFO DAGScheduler: running: Set()
16/02/08 15:50:21 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/02/08 15:50:21 INFO DAGScheduler: failed: Set()
16/02/08 15:50:21 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/02/08 15:50:21 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221), which is now runnable
16/02/08 15:50:21 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=548394762
16/02/08 15:50:21 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.0 MB)
16/02/08 15:50:21 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=548394762
16/02/08 15:50:21 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.0 MB)
16/02/08 15:50:21 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8276 ms on localhost (2/2)
16/02/08 15:50:21 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:33140 (size: 3.0 KB, free: 523.0 MB)
16/02/08 15:50:21 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/02/08 15:50:21 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/02/08 15:50:21 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:50:21 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/02/08 15:50:21 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:50:21 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:50:21 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/02/08 15:50:21 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:50:21 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/02/08 15:50:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/02/08 15:50:21 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:50:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/02/08 15:50:21 INFO PythonRunner: Times: total = 16, boot = -8, init = 23, finish = 1
16/02/08 15:50:21 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/02/08 15:50:21 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 34 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'bend']
16/02/08 15:50:22 INFO PythonRunner: Times: total = 209, boot = 208, init = 0, finish = 1
16/02/08 15:50:22 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1280 bytes result sent to driver
16/02/08 15:50:22 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 225 ms on localhost (2/2)
16/02/08 15:50:22 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) finished in 0.214 s
16/02/08 15:50:22 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221, took 8.530911 s
16/02/08 15:50:22 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/02/08 15:50:22 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224
16/02/08 15:50:22 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) with 2 output partitions
16/02/08 15:50:22 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:50:22 INFO DAGScheduler: Parents of final stage: List()
16/02/08 15:50:22 INFO DAGScheduler: Missing parents: List()
16/02/08 15:50:22 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224), which has no missing parents
16/02/08 15:50:22 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=548394762
16/02/08 15:50:22 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.0 MB)
16/02/08 15:50:22 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24572, maxMem=548394762
16/02/08 15:50:22 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.0 MB)
16/02/08 15:50:22 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:33140 (size: 3.3 KB, free: 523.0 MB)
16/02/08 15:50:22 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/02/08 15:50:22 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:50:22 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/02/08 15:50:22 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/02/08 15:50:22 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2361 bytes)
16/02/08 15:50:22 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/02/08 15:50:22 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/02/08 15:50:22 INFO PythonRunner: Times: total = 71, boot = -77, init = 148, finish = 0
16/02/08 15:50:22 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/02/08 15:50:22 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 88 ms on localhost (1/2)
16/02/08 15:50:22 INFO PythonRunner: Times: total = 151, boot = 151, init = 0, finish = 0
16/02/08 15:50:22 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/02/08 15:50:22 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 163 ms on localhost (2/2)
16/02/08 15:50:22 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/02/08 15:50:22 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) finished in 0.145 s
16/02/08 15:50:22 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224, took 0.173355 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/02/08 15:50:22 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/02/08 15:50:22 INFO DAGScheduler: Stopping DAGScheduler
16/02/08 15:50:22 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/02/08 15:50:22 INFO MemoryStore: MemoryStore cleared
16/02/08 15:50:22 INFO BlockManager: BlockManager stopped
16/02/08 15:50:22 INFO BlockManagerMaster: BlockManagerMaster stopped
16/02/08 15:50:22 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/02/08 15:50:22 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/02/08 15:50:22 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/02/08 15:50:22 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/02/08 15:50:22 INFO SparkContext: Successfully stopped SparkContext
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'bend']
16/02/08 15:50:23 INFO SparkContext: Running Spark version 1.5.2
16/02/08 15:50:23 INFO SecurityManager: Changing view acls to: root
16/02/08 15:50:23 INFO SecurityManager: Changing modify acls to: root
16/02/08 15:50:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/02/08 15:50:23 INFO Slf4jLogger: Slf4jLogger started
16/02/08 15:50:23 INFO Remoting: Starting remoting
16/02/08 15:50:23 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:51217]
16/02/08 15:50:23 INFO Utils: Successfully started service 'sparkDriver' on port 51217.
16/02/08 15:50:23 INFO SparkEnv: Registering MapOutputTracker
16/02/08 15:50:23 INFO SparkEnv: Registering BlockManagerMaster
16/02/08 15:50:23 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a6880084-fbe5-4ef3-a10e-c80170264460
16/02/08 15:50:23 INFO MemoryStore: MemoryStore started with capacity 523.0 MB
16/02/08 15:50:23 INFO HttpFileServer: HTTP File server directory is /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/httpd-70b1a22e-82ec-4b55-9663-78cac7f36a67
16/02/08 15:50:23 INFO HttpServer: Starting HTTP Server
16/02/08 15:50:23 INFO Utils: Successfully started service 'HTTP file server' on port 36072.
16/02/08 15:50:23 INFO SparkEnv: Registering OutputCommitCoordinator
16/02/08 15:50:23 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/02/08 15:50:23 INFO SparkUI: Started SparkUI at http://localhost:4040
16/02/08 15:50:23 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-8cc82c9d-f507-44a2-94d3-930116306e10/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/02/08 15:50:23 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926823925
16/02/08 15:50:23 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/02/08 15:50:23 INFO Executor: Starting executor ID driver on host localhost
16/02/08 15:50:23 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33926.
16/02/08 15:50:23 INFO NettyBlockTransferService: Server created on 33926
16/02/08 15:50:23 INFO BlockManagerMaster: Trying to register BlockManager
16/02/08 15:50:23 INFO BlockManagerMasterEndpoint: Registering block manager localhost:33926 with 523.0 MB RAM, BlockManagerId(driver, localhost, 33926)
16/02/08 15:50:23 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): single
16/02/08 15:50:24 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221
16/02/08 15:50:24 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:50:24 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) with 2 output partitions
16/02/08 15:50:24 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:50:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/02/08 15:50:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/02/08 15:50:24 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219), which has no missing parents
16/02/08 15:50:24 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=548394762
16/02/08 15:50:24 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.0 MB)
16/02/08 15:50:24 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=548394762
16/02/08 15:50:24 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.0 MB)
16/02/08 15:50:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:33926 (size: 4.1 KB, free: 523.0 MB)
16/02/08 15:50:24 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/02/08 15:50:24 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:50:24 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/02/08 15:50:24 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2423 bytes)
16/02/08 15:50:24 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2413 bytes)
16/02/08 15:50:24 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/02/08 15:50:24 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926823925
16/02/08 15:50:24 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/02/08 15:50:24 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-8cc82c9d-f507-44a2-94d3-930116306e10/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): single
mapFunction_Parents(): keyword: single ; prevleveltokens: kilometer
asfer_pickle_string_load(): picklef.readlines(): single
mapFunction_Parents(): keyword: single ; prevleveltokens: set
mapFunction_Parents(): keyword= single ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): single
mapFunction_Parents(): keyword: single ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= single ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): single
mapFunction_Parents(): keyword: single ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= single ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): single
mapFunction_Parents(): keyword: single ; prevleveltokens: area
mapFunction_Parents(): keyword= single ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): single
mapFunction_Parents(): keyword: single ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= single ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): single
mapFunction_Parents(): keyword: single ; prevleveltokens: elaborate
mapFunction_Parents(): keyword= single ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): single
mapFunction_Parents(): keyword: single ; prevleveltokens: exist
mapFunction_Parents(): keyword= single ; syndef_tokens= set([u'be', u',', u'an', u'have', u'existence', u'extant'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): single
mapFunction_Parents(): keyword: single ; prevleveltokens: commissariat
mapFunction_Parents(): keyword= single ; syndef_tokens= set([u'a', u'supply', u'of', u'foods', u'or', u'stock'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/02/08 15:50:31 INFO PythonRunner: Times: total = 7874, boot = 469, init = 376, finish = 7029
16/02/08 15:50:31 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/02/08 15:50:32 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7950 ms on localhost (1/2)
mapFunction_Parents(): keyword= single ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): single
mapFunction_Parents(): keyword: single ; prevleveltokens: town
mapFunction_Parents(): keyword= single ; syndef_tokens= set([u'a', u'urban', u'smaller', u'area', u'is', u'that', u'an', u'city', u'boundary', u'fixed', u'with', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): single
mapFunction_Parents(): keyword: single ; prevleveltokens: state
mapFunction_Parents(): keyword= single ; syndef_tokens= set([u'a', u'nation', u'of', u'one', u'districts', u'constituent', u'the', u'territory', u'occupied', u'by', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): single
mapFunction_Parents(): keyword: single ; prevleveltokens: bend
mapFunction_Parents(): keyword= single ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): single
mapFunction_Parents(): keyword: single ; prevleveltokens: giant
mapFunction_Parents(): keyword= single ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): single
mapFunction_Parents(): keyword: single ; prevleveltokens: astatine
mapFunction_Parents(): keyword= single ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): single
mapFunction_Parents(): keyword: single ; prevleveltokens: present
mapFunction_Parents(): keyword= single ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): single
mapFunction_Parents(): keyword: single ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= single ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/02/08 15:50:32 INFO PythonRunner: Times: total = 8228, boot = 458, init = 405, finish = 7365
16/02/08 15:50:32 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/02/08 15:50:32 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8289 ms on localhost (2/2)
16/02/08 15:50:32 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/02/08 15:50:32 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219) finished in 8.291 s
16/02/08 15:50:32 INFO DAGScheduler: looking for newly runnable stages
16/02/08 15:50:32 INFO DAGScheduler: running: Set()
16/02/08 15:50:32 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/02/08 15:50:32 INFO DAGScheduler: failed: Set()
16/02/08 15:50:32 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/02/08 15:50:32 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221), which is now runnable
16/02/08 15:50:32 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=548394762
16/02/08 15:50:32 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.0 MB)
16/02/08 15:50:32 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=548394762
16/02/08 15:50:32 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.0 MB)
16/02/08 15:50:32 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:33926 (size: 3.0 KB, free: 523.0 MB)
16/02/08 15:50:32 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/02/08 15:50:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:50:32 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/02/08 15:50:32 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:50:32 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:50:32 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/02/08 15:50:32 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:50:32 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/02/08 15:50:32 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:50:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/02/08 15:50:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
reduceFunction_Parents(): returns= ['None', 'None']
16/02/08 15:50:32 INFO PythonRunner: Times: total = 18, boot = -198, init = 215, finish = 1
16/02/08 15:50:32 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1269 bytes result sent to driver
16/02/08 15:50:32 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 65 ms on localhost (1/2)
16/02/08 15:50:32 INFO PythonRunner: Times: total = 186, boot = 185, init = 0, finish = 1
16/02/08 15:50:32 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/02/08 15:50:32 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) finished in 0.192 s
16/02/08 15:50:32 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221, took 8.526211 s
16/02/08 15:50:32 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 207 ms on localhost (2/2)
16/02/08 15:50:32 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/02/08 15:50:32 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224
16/02/08 15:50:32 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) with 2 output partitions
16/02/08 15:50:32 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:50:32 INFO DAGScheduler: Parents of final stage: List()
16/02/08 15:50:32 INFO DAGScheduler: Missing parents: List()
16/02/08 15:50:32 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224), which has no missing parents
16/02/08 15:50:32 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=548394762
16/02/08 15:50:32 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.0 MB)
16/02/08 15:50:32 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=548394762
16/02/08 15:50:32 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.0 MB)
16/02/08 15:50:32 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:33926 (size: 3.3 KB, free: 523.0 MB)
16/02/08 15:50:32 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/02/08 15:50:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:50:32 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/02/08 15:50:32 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/02/08 15:50:32 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2350 bytes)
16/02/08 15:50:32 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/02/08 15:50:32 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/02/08 15:50:32 INFO PythonRunner: Times: total = 77, boot = 76, init = 0, finish = 1
16/02/08 15:50:32 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1337 bytes result sent to driver
16/02/08 15:50:32 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 102 ms on localhost (1/2)
16/02/08 15:50:32 INFO PythonRunner: Times: total = 92, boot = -93, init = 185, finish = 0
16/02/08 15:50:32 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/02/08 15:50:32 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 114 ms on localhost (2/2)
16/02/08 15:50:32 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/02/08 15:50:32 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) finished in 0.115 s
16/02/08 15:50:32 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224, took 0.128676 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/02/08 15:50:32 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/02/08 15:50:32 INFO DAGScheduler: Stopping DAGScheduler
16/02/08 15:50:32 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/02/08 15:50:32 INFO MemoryStore: MemoryStore cleared
16/02/08 15:50:32 INFO BlockManager: BlockManager stopped
16/02/08 15:50:32 INFO BlockManagerMaster: BlockManagerMaster stopped
16/02/08 15:50:32 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/02/08 15:50:32 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/02/08 15:50:32 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/02/08 15:50:32 INFO SparkContext: Successfully stopped SparkContext
16/02/08 15:50:32 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None']
16/02/08 15:50:33 INFO SparkContext: Running Spark version 1.5.2
16/02/08 15:50:33 INFO SecurityManager: Changing view acls to: root
16/02/08 15:50:33 INFO SecurityManager: Changing modify acls to: root
16/02/08 15:50:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/02/08 15:50:34 INFO Slf4jLogger: Slf4jLogger started
16/02/08 15:50:34 INFO Remoting: Starting remoting
16/02/08 15:50:34 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:35510]
16/02/08 15:50:34 INFO Utils: Successfully started service 'sparkDriver' on port 35510.
16/02/08 15:50:34 INFO SparkEnv: Registering MapOutputTracker
16/02/08 15:50:34 INFO SparkEnv: Registering BlockManagerMaster
16/02/08 15:50:34 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2daba729-d0d8-4462-b989-76e6f759c98a
16/02/08 15:50:34 INFO MemoryStore: MemoryStore started with capacity 523.8 MB
16/02/08 15:50:34 INFO HttpFileServer: HTTP File server directory is /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/httpd-52dd8964-65e1-466c-a72d-23db987ee6d4
16/02/08 15:50:34 INFO HttpServer: Starting HTTP Server
16/02/08 15:50:34 INFO Utils: Successfully started service 'HTTP file server' on port 59097.
16/02/08 15:50:34 INFO SparkEnv: Registering OutputCommitCoordinator
16/02/08 15:50:34 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/02/08 15:50:34 INFO SparkUI: Started SparkUI at http://localhost:4040
16/02/08 15:50:34 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-a7b582e0-0e8b-4638-8640-aeb25aec91c2/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/02/08 15:50:34 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926834669
16/02/08 15:50:34 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/02/08 15:50:34 INFO Executor: Starting executor ID driver on host localhost
16/02/08 15:50:34 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55093.
16/02/08 15:50:34 INFO NettyBlockTransferService: Server created on 55093
16/02/08 15:50:34 INFO BlockManagerMaster: Trying to register BlockManager
16/02/08 15:50:34 INFO BlockManagerMasterEndpoint: Registering block manager localhost:55093 with 523.8 MB RAM, BlockManagerId(driver, localhost, 55093)
16/02/08 15:50:34 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): radioactive
16/02/08 15:50:34 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221
16/02/08 15:50:34 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:50:34 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) with 2 output partitions
16/02/08 15:50:34 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:50:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/02/08 15:50:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/02/08 15:50:34 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219), which has no missing parents
16/02/08 15:50:34 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=549244108
16/02/08 15:50:34 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.8 MB)
16/02/08 15:50:34 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=549244108
16/02/08 15:50:34 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.8 MB)
16/02/08 15:50:34 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:55093 (size: 4.1 KB, free: 523.8 MB)
16/02/08 15:50:34 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/02/08 15:50:34 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:50:34 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/02/08 15:50:34 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2423 bytes)
16/02/08 15:50:34 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2413 bytes)
16/02/08 15:50:34 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/02/08 15:50:34 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926834669
16/02/08 15:50:34 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/02/08 15:50:34 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-a7b582e0-0e8b-4638-8640-aeb25aec91c2/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: town
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'urban', u'smaller', u'area', u'is', u'that', u'an', u'city', u'boundary', u'fixed', u'with', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: state
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'nation', u'of', u'one', u'districts', u'constituent', u'the', u'territory', u'occupied', u'by', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: bend
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: giant
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: astatine
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  radioactive  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: present
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/02/08 15:50:43 INFO PythonRunner: Times: total = 8256, boot = 450, init = 392, finish = 7414
16/02/08 15:50:43 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/02/08 15:50:43 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8323 ms on localhost (1/2)
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: area
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: elaborate
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: exist
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'be', u',', u'an', u'have', u'existence', u'extant'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: commissariat
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'supply', u'of', u'foods', u'or', u'stock'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/02/08 15:50:43 INFO PythonRunner: Times: total = 8918, boot = 466, init = 394, finish = 8058
16/02/08 15:50:43 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/02/08 15:50:43 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8973 ms on localhost (2/2)
16/02/08 15:50:43 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/02/08 15:50:43 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219) finished in 8.975 s
16/02/08 15:50:43 INFO DAGScheduler: looking for newly runnable stages
16/02/08 15:50:43 INFO DAGScheduler: running: Set()
16/02/08 15:50:43 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/02/08 15:50:43 INFO DAGScheduler: failed: Set()
16/02/08 15:50:43 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/02/08 15:50:43 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221), which is now runnable
16/02/08 15:50:43 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=549244108
16/02/08 15:50:43 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.8 MB)
16/02/08 15:50:43 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=549244108
16/02/08 15:50:43 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.8 MB)
16/02/08 15:50:43 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:55093 (size: 3.0 KB, free: 523.8 MB)
16/02/08 15:50:43 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/02/08 15:50:43 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:50:43 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/02/08 15:50:43 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:50:43 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:50:43 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/02/08 15:50:43 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/02/08 15:50:43 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:50:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/02/08 15:50:43 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:50:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/02/08 15:50:43 INFO PythonRunner: Times: total = 42, boot = -469, init = 510, finish = 1
16/02/08 15:50:43 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/02/08 15:50:43 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 74 ms on localhost (1/2)
16/02/08 15:50:44 INFO PythonRunner: Times: total = 208, boot = 207, init = 0, finish = 1
16/02/08 15:50:44 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/02/08 15:50:44 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) finished in 0.241 s
16/02/08 15:50:44 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221, took 9.239730 s
16/02/08 15:50:44 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 242 ms on localhost (2/2)
16/02/08 15:50:44 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/02/08 15:50:44 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224
16/02/08 15:50:44 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) with 2 output partitions
16/02/08 15:50:44 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:50:44 INFO DAGScheduler: Parents of final stage: List()
16/02/08 15:50:44 INFO DAGScheduler: Missing parents: List()
16/02/08 15:50:44 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224), which has no missing parents
16/02/08 15:50:44 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=549244108
16/02/08 15:50:44 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.8 MB)
16/02/08 15:50:44 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=549244108
16/02/08 15:50:44 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.8 MB)
16/02/08 15:50:44 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:55093 (size: 3.3 KB, free: 523.8 MB)
16/02/08 15:50:44 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/02/08 15:50:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:50:44 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/02/08 15:50:44 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/02/08 15:50:44 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/02/08 15:50:44 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/02/08 15:50:44 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/02/08 15:50:44 INFO PythonRunner: Times: total = 21, boot = 2, init = 19, finish = 0
16/02/08 15:50:44 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/02/08 15:50:44 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 34 ms on localhost (1/2)
16/02/08 15:50:44 INFO PythonRunner: Times: total = 51, boot = -68, init = 119, finish = 0
16/02/08 15:50:44 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/02/08 15:50:44 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 61 ms on localhost (2/2)
16/02/08 15:50:44 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/02/08 15:50:44 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) finished in 0.062 s
16/02/08 15:50:44 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224, took 0.110117 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/02/08 15:50:44 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/02/08 15:50:44 INFO DAGScheduler: Stopping DAGScheduler
16/02/08 15:50:44 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/02/08 15:50:44 INFO MemoryStore: MemoryStore cleared
16/02/08 15:50:44 INFO BlockManager: BlockManager stopped
16/02/08 15:50:44 INFO BlockManagerMaster: BlockManagerMaster stopped
16/02/08 15:50:44 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/02/08 15:50:44 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/02/08 15:50:44 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/02/08 15:50:44 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/02/08 15:50:44 INFO SparkContext: Successfully stopped SparkContext
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'astatine']
16/02/08 15:50:45 INFO SparkContext: Running Spark version 1.5.2
16/02/08 15:50:45 INFO SecurityManager: Changing view acls to: root
16/02/08 15:50:45 INFO SecurityManager: Changing modify acls to: root
16/02/08 15:50:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/02/08 15:50:45 INFO Slf4jLogger: Slf4jLogger started
16/02/08 15:50:45 INFO Remoting: Starting remoting
16/02/08 15:50:45 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:51361]
16/02/08 15:50:45 INFO Utils: Successfully started service 'sparkDriver' on port 51361.
16/02/08 15:50:45 INFO SparkEnv: Registering MapOutputTracker
16/02/08 15:50:45 INFO SparkEnv: Registering BlockManagerMaster
16/02/08 15:50:45 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-4ed581f9-e24c-46f6-bac3-ff30d305a229
16/02/08 15:50:45 INFO MemoryStore: MemoryStore started with capacity 523.8 MB
16/02/08 15:50:45 INFO HttpFileServer: HTTP File server directory is /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/httpd-6f7653b4-af5e-404a-b53e-b41b3bb0adb0
16/02/08 15:50:45 INFO HttpServer: Starting HTTP Server
16/02/08 15:50:45 INFO Utils: Successfully started service 'HTTP file server' on port 52712.
16/02/08 15:50:45 INFO SparkEnv: Registering OutputCommitCoordinator
16/02/08 15:50:45 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/02/08 15:50:45 INFO SparkUI: Started SparkUI at http://localhost:4040
16/02/08 15:50:45 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-d3cdb70e-0e87-4aa4-9d8e-d912b413fedc/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/02/08 15:50:45 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926845949
16/02/08 15:50:45 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/02/08 15:50:45 INFO Executor: Starting executor ID driver on host localhost
16/02/08 15:50:46 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59730.
16/02/08 15:50:46 INFO NettyBlockTransferService: Server created on 59730
16/02/08 15:50:46 INFO BlockManagerMaster: Trying to register BlockManager
16/02/08 15:50:46 INFO BlockManagerMasterEndpoint: Registering block manager localhost:59730 with 523.8 MB RAM, BlockManagerId(driver, localhost, 59730)
16/02/08 15:50:46 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): happening
16/02/08 15:50:46 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221
16/02/08 15:50:46 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:50:46 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) with 2 output partitions
16/02/08 15:50:46 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:50:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/02/08 15:50:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/02/08 15:50:46 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219), which has no missing parents
16/02/08 15:50:46 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=549244108
16/02/08 15:50:46 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.8 MB)
16/02/08 15:50:46 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=549244108
16/02/08 15:50:46 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.8 MB)
16/02/08 15:50:46 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:59730 (size: 4.1 KB, free: 523.8 MB)
16/02/08 15:50:46 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/02/08 15:50:46 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:50:46 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/02/08 15:50:46 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2423 bytes)
16/02/08 15:50:46 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2413 bytes)
16/02/08 15:50:46 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/02/08 15:50:46 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926845949
16/02/08 15:50:46 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/02/08 15:50:46 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-d3cdb70e-0e87-4aa4-9d8e-d912b413fedc/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: kilometer
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: set
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: area
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: elaborate
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: exist
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'be', u',', u'an', u'have', u'existence', u'extant'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: commissariat
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'supply', u'of', u'foods', u'or', u'stock'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/02/08 15:50:54 INFO PythonRunner: Times: total = 8099, boot = 512, init = 379, finish = 7208
16/02/08 15:50:54 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/02/08 15:50:54 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8175 ms on localhost (1/2)
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: town
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'urban', u'smaller', u'area', u'is', u'that', u'an', u'city', u'boundary', u'fixed', u'with', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: state
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'nation', u'of', u'one', u'districts', u'constituent', u'the', u'territory', u'occupied', u'by', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: bend
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: giant
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: astatine
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: present
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  happening  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/02/08 15:50:55 INFO PythonRunner: Times: total = 8959, boot = 508, init = 477, finish = 7974
16/02/08 15:50:55 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/02/08 15:50:55 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9026 ms on localhost (2/2)
16/02/08 15:50:55 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/02/08 15:50:55 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219) finished in 9.029 s
16/02/08 15:50:55 INFO DAGScheduler: looking for newly runnable stages
16/02/08 15:50:55 INFO DAGScheduler: running: Set()
16/02/08 15:50:55 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/02/08 15:50:55 INFO DAGScheduler: failed: Set()
16/02/08 15:50:55 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/02/08 15:50:55 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221), which is now runnable
16/02/08 15:50:55 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=549244108
16/02/08 15:50:55 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.8 MB)
16/02/08 15:50:55 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=549244108
16/02/08 15:50:55 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.8 MB)
16/02/08 15:50:55 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:59730 (size: 3.0 KB, free: 523.8 MB)
16/02/08 15:50:55 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/02/08 15:50:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:50:55 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/02/08 15:50:55 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:50:55 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:50:55 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/02/08 15:50:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:50:55 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/02/08 15:50:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:50:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/02/08 15:50:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/02/08 15:50:55 INFO PythonRunner: Times: total = 32, boot = -707, init = 738, finish = 1
16/02/08 15:50:55 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
reduceFunction_Parents(): returns= ['None', 'None', u'present']
16/02/08 15:50:55 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 54 ms on localhost (1/2)
16/02/08 15:50:55 INFO PythonRunner: Times: total = 182, boot = 181, init = 0, finish = 1
16/02/08 15:50:55 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/02/08 15:50:55 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 214 ms on localhost (2/2)
16/02/08 15:50:55 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) finished in 0.195 s
16/02/08 15:50:55 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221, took 9.273006 s
16/02/08 15:50:55 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/02/08 15:50:55 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224
16/02/08 15:50:55 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) with 2 output partitions
16/02/08 15:50:55 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:50:55 INFO DAGScheduler: Parents of final stage: List()
16/02/08 15:50:55 INFO DAGScheduler: Missing parents: List()
16/02/08 15:50:55 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224), which has no missing parents
16/02/08 15:50:55 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=549244108
16/02/08 15:50:55 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.8 MB)
16/02/08 15:50:55 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=549244108
16/02/08 15:50:55 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.8 MB)
16/02/08 15:50:55 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:59730 (size: 3.3 KB, free: 523.8 MB)
16/02/08 15:50:55 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/02/08 15:50:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:50:55 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/02/08 15:50:55 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/02/08 15:50:55 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/02/08 15:50:55 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/02/08 15:50:55 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/02/08 15:50:55 INFO PythonRunner: Times: total = 58, boot = -28, init = 86, finish = 0
16/02/08 15:50:55 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1351 bytes result sent to driver
16/02/08 15:50:55 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 72 ms on localhost (1/2)
16/02/08 15:50:55 INFO PythonRunner: Times: total = 86, boot = 86, init = 0, finish = 0
16/02/08 15:50:55 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/02/08 15:50:55 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 98 ms on localhost (2/2)
16/02/08 15:50:55 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/02/08 15:50:55 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) finished in 0.079 s
16/02/08 15:50:55 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224, took 0.109570 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/02/08 15:50:55 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/02/08 15:50:55 INFO DAGScheduler: Stopping DAGScheduler
16/02/08 15:50:55 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/02/08 15:50:55 INFO MemoryStore: MemoryStore cleared
16/02/08 15:50:55 INFO BlockManager: BlockManager stopped
16/02/08 15:50:55 INFO BlockManagerMaster: BlockManagerMaster stopped
16/02/08 15:50:55 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/02/08 15:50:55 INFO SparkContext: Successfully stopped SparkContext
16/02/08 15:50:55 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/02/08 15:50:55 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/02/08 15:50:55 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'present']
16/02/08 15:50:56 INFO SparkContext: Running Spark version 1.5.2
16/02/08 15:50:56 INFO SecurityManager: Changing view acls to: root
16/02/08 15:50:56 INFO SecurityManager: Changing modify acls to: root
16/02/08 15:50:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/02/08 15:50:56 INFO Slf4jLogger: Slf4jLogger started
16/02/08 15:50:56 INFO Remoting: Starting remoting
16/02/08 15:50:56 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:53295]
16/02/08 15:50:56 INFO Utils: Successfully started service 'sparkDriver' on port 53295.
16/02/08 15:50:56 INFO SparkEnv: Registering MapOutputTracker
16/02/08 15:50:56 INFO SparkEnv: Registering BlockManagerMaster
16/02/08 15:50:56 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c61ed4d7-568b-4dc3-88de-f2f74ffb4d1e
16/02/08 15:50:56 INFO MemoryStore: MemoryStore started with capacity 523.8 MB
16/02/08 15:50:56 INFO HttpFileServer: HTTP File server directory is /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/httpd-dbc5bdc3-6fc0-4826-ae3a-c3401950736c
16/02/08 15:50:56 INFO HttpServer: Starting HTTP Server
16/02/08 15:50:56 INFO Utils: Successfully started service 'HTTP file server' on port 51644.
16/02/08 15:50:56 INFO SparkEnv: Registering OutputCommitCoordinator
16/02/08 15:50:57 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/02/08 15:50:57 INFO SparkUI: Started SparkUI at http://localhost:4040
16/02/08 15:50:57 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-f560bb0f-02ad-4507-8b49-c0bb51e325d2/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/02/08 15:50:57 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926857212
16/02/08 15:50:57 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/02/08 15:50:57 INFO Executor: Starting executor ID driver on host localhost
16/02/08 15:50:57 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54325.
16/02/08 15:50:57 INFO NettyBlockTransferService: Server created on 54325
16/02/08 15:50:57 INFO BlockManagerMaster: Trying to register BlockManager
16/02/08 15:50:57 INFO BlockManagerMasterEndpoint: Registering block manager localhost:54325 with 523.8 MB RAM, BlockManagerId(driver, localhost, 54325)
16/02/08 15:50:57 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): curve
16/02/08 15:50:57 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221
16/02/08 15:50:57 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:50:57 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) with 2 output partitions
16/02/08 15:50:57 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:50:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/02/08 15:50:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/02/08 15:50:57 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219), which has no missing parents
16/02/08 15:50:57 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=549244108
16/02/08 15:50:57 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.8 MB)
16/02/08 15:50:57 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=549244108
16/02/08 15:50:57 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.8 MB)
16/02/08 15:50:57 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:54325 (size: 4.1 KB, free: 523.8 MB)
16/02/08 15:50:57 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/02/08 15:50:57 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:50:57 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/02/08 15:50:57 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2423 bytes)
16/02/08 15:50:57 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2413 bytes)
16/02/08 15:50:57 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/02/08 15:50:57 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926857212
16/02/08 15:50:57 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/02/08 15:50:57 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-f560bb0f-02ad-4507-8b49-c0bb51e325d2/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: kilometer
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: set
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: area
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: elaborate
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: exist
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'be', u',', u'an', u'have', u'existence', u'extant'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: commissariat
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'supply', u'of', u'foods', u'or', u'stock'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/02/08 15:51:07 INFO PythonRunner: Times: total = 9546, boot = 877, init = 458, finish = 8211
16/02/08 15:51:07 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/02/08 15:51:07 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9810 ms on localhost (1/2)
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: town
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'urban', u'smaller', u'area', u'is', u'that', u'an', u'city', u'boundary', u'fixed', u'with', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: state
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'nation', u'of', u'one', u'districts', u'constituent', u'the', u'territory', u'occupied', u'by', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: bend
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): adding to parents: syn =  Synset('bend.n.01') ; keyword:  curve  in syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= [u'bend']
reduceFunction_Parents(): returns= ['None', u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: giant
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: astatine
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: present
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'bend']
16/02/08 15:51:07 INFO PythonRunner: Times: total = 9694, boot = 865, init = 575, finish = 8254
16/02/08 15:51:07 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/02/08 15:51:07 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9968 ms on localhost (2/2)
16/02/08 15:51:07 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/02/08 15:51:07 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219) finished in 9.970 s
16/02/08 15:51:07 INFO DAGScheduler: looking for newly runnable stages
16/02/08 15:51:07 INFO DAGScheduler: running: Set()
16/02/08 15:51:07 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/02/08 15:51:07 INFO DAGScheduler: failed: Set()
16/02/08 15:51:07 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/02/08 15:51:07 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221), which is now runnable
16/02/08 15:51:07 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=549244108
16/02/08 15:51:07 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.8 MB)
16/02/08 15:51:07 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=549244108
16/02/08 15:51:07 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.8 MB)
16/02/08 15:51:07 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:54325 (size: 3.0 KB, free: 523.8 MB)
16/02/08 15:51:07 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/02/08 15:51:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:51:07 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/02/08 15:51:07 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:51:07 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:51:07 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/02/08 15:51:07 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/02/08 15:51:07 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:51:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
16/02/08 15:51:07 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:51:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
16/02/08 15:51:07 INFO PythonRunner: Times: total = 46, boot = 22, init = 24, finish = 0
16/02/08 15:51:07 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/02/08 15:51:07 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 84 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'bend']
16/02/08 15:51:07 INFO PythonRunner: Times: total = 210, boot = 209, init = 0, finish = 1
16/02/08 15:51:07 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1280 bytes result sent to driver
16/02/08 15:51:07 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) finished in 0.241 s
16/02/08 15:51:07 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221, took 10.234212 s
16/02/08 15:51:07 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 237 ms on localhost (2/2)
16/02/08 15:51:07 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/02/08 15:51:07 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224
16/02/08 15:51:07 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) with 2 output partitions
16/02/08 15:51:07 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:51:07 INFO DAGScheduler: Parents of final stage: List()
16/02/08 15:51:07 INFO DAGScheduler: Missing parents: List()
16/02/08 15:51:07 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224), which has no missing parents
16/02/08 15:51:07 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=549244108
16/02/08 15:51:07 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.8 MB)
16/02/08 15:51:07 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=549244108
16/02/08 15:51:07 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.8 MB)
16/02/08 15:51:07 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:54325 (size: 3.3 KB, free: 523.8 MB)
16/02/08 15:51:07 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/02/08 15:51:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:51:07 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/02/08 15:51:07 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/02/08 15:51:07 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2361 bytes)
16/02/08 15:51:07 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/02/08 15:51:07 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/02/08 15:51:07 INFO PythonRunner: Times: total = 69, boot = -125, init = 194, finish = 0
16/02/08 15:51:07 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/02/08 15:51:07 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 77 ms on localhost (1/2)
16/02/08 15:51:07 INFO PythonRunner: Times: total = 89, boot = 88, init = 0, finish = 1
16/02/08 15:51:07 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/02/08 15:51:07 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 100 ms on localhost (2/2)
16/02/08 15:51:07 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/02/08 15:51:07 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) finished in 0.101 s
16/02/08 15:51:07 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224, took 0.116353 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/02/08 15:51:07 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/02/08 15:51:07 INFO DAGScheduler: Stopping DAGScheduler
16/02/08 15:51:07 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/02/08 15:51:07 INFO MemoryStore: MemoryStore cleared
16/02/08 15:51:07 INFO BlockManager: BlockManager stopped
16/02/08 15:51:07 INFO BlockManagerMaster: BlockManagerMaster stopped
16/02/08 15:51:07 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/02/08 15:51:07 INFO SparkContext: Successfully stopped SparkContext
16/02/08 15:51:07 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/02/08 15:51:07 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/02/08 15:51:08 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'bend']
16/02/08 15:51:08 INFO SparkContext: Running Spark version 1.5.2
16/02/08 15:51:08 INFO SecurityManager: Changing view acls to: root
16/02/08 15:51:08 INFO SecurityManager: Changing modify acls to: root
16/02/08 15:51:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/02/08 15:51:08 INFO Slf4jLogger: Slf4jLogger started
16/02/08 15:51:08 INFO Remoting: Starting remoting
16/02/08 15:51:08 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:44362]
16/02/08 15:51:08 INFO Utils: Successfully started service 'sparkDriver' on port 44362.
16/02/08 15:51:08 INFO SparkEnv: Registering MapOutputTracker
16/02/08 15:51:08 INFO SparkEnv: Registering BlockManagerMaster
16/02/08 15:51:08 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-06029dac-93e2-425d-ae4f-59d4e6ff73e5
16/02/08 15:51:08 INFO MemoryStore: MemoryStore started with capacity 523.1 MB
16/02/08 15:51:08 INFO HttpFileServer: HTTP File server directory is /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/httpd-a1f05709-2f4e-4f84-903a-5e4940d6832e
16/02/08 15:51:08 INFO HttpServer: Starting HTTP Server
16/02/08 15:51:09 INFO Utils: Successfully started service 'HTTP file server' on port 49246.
16/02/08 15:51:09 INFO SparkEnv: Registering OutputCommitCoordinator
16/02/08 15:51:09 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/02/08 15:51:09 INFO SparkUI: Started SparkUI at http://localhost:4040
16/02/08 15:51:09 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-a670f3ba-1089-4013-9ed2-9a25335bcd6a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/02/08 15:51:09 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926869496
16/02/08 15:51:09 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/02/08 15:51:09 INFO Executor: Starting executor ID driver on host localhost
16/02/08 15:51:09 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35541.
16/02/08 15:51:09 INFO NettyBlockTransferService: Server created on 35541
16/02/08 15:51:09 INFO BlockManagerMaster: Trying to register BlockManager
16/02/08 15:51:09 INFO BlockManagerMasterEndpoint: Registering block manager localhost:35541 with 523.1 MB RAM, BlockManagerId(driver, localhost, 35541)
16/02/08 15:51:09 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): together
16/02/08 15:51:09 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221
16/02/08 15:51:09 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:51:09 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) with 2 output partitions
16/02/08 15:51:09 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:51:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/02/08 15:51:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/02/08 15:51:09 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219), which has no missing parents
16/02/08 15:51:09 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=548536320
16/02/08 15:51:09 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.1 MB)
16/02/08 15:51:09 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=548536320
16/02/08 15:51:09 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.1 MB)
16/02/08 15:51:09 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:35541 (size: 4.1 KB, free: 523.1 MB)
16/02/08 15:51:09 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/02/08 15:51:09 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:51:09 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/02/08 15:51:09 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2423 bytes)
16/02/08 15:51:09 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2413 bytes)
16/02/08 15:51:09 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/02/08 15:51:09 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926869496
16/02/08 15:51:09 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/02/08 15:51:09 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-a670f3ba-1089-4013-9ed2-9a25335bcd6a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  Synset('set.n.01') ; keyword:  together  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: town
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'urban', u'smaller', u'area', u'is', u'that', u'an', u'city', u'boundary', u'fixed', u'with', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: state
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'nation', u'of', u'one', u'districts', u'constituent', u'the', u'territory', u'occupied', u'by', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: bend
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: giant
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: astatine
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: present
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
16/02/08 15:51:17 INFO PythonRunner: Times: total = 8178, boot = 458, init = 422, finish = 7298
16/02/08 15:51:17 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/02/08 15:51:17 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8253 ms on localhost (1/2)
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: area
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: elaborate
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: exist
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'be', u',', u'an', u'have', u'existence', u'extant'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: commissariat
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'supply', u'of', u'foods', u'or', u'stock'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/02/08 15:51:17 INFO PythonRunner: Times: total = 8264, boot = 447, init = 441, finish = 7376
16/02/08 15:51:17 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/02/08 15:51:17 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219) finished in 8.335 s
16/02/08 15:51:17 INFO DAGScheduler: looking for newly runnable stages
16/02/08 15:51:17 INFO DAGScheduler: running: Set()
16/02/08 15:51:17 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/02/08 15:51:17 INFO DAGScheduler: failed: Set()
16/02/08 15:51:17 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/02/08 15:51:17 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221), which is now runnable
16/02/08 15:51:17 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=548536320
16/02/08 15:51:17 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.1 MB)
16/02/08 15:51:17 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=548536320
16/02/08 15:51:17 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.1 MB)
16/02/08 15:51:17 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8334 ms on localhost (2/2)
16/02/08 15:51:17 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:35541 (size: 3.0 KB, free: 523.1 MB)
16/02/08 15:51:17 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/02/08 15:51:17 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/02/08 15:51:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:51:17 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/02/08 15:51:17 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:51:17 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:51:17 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/02/08 15:51:17 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/02/08 15:51:17 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:51:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/02/08 15:51:17 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:51:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
16/02/08 15:51:18 INFO PythonRunner: Times: total = 119, boot = 118, init = 0, finish = 1
16/02/08 15:51:18 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/02/08 15:51:18 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 135 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'set']
16/02/08 15:51:18 INFO PythonRunner: Times: total = 204, boot = 203, init = 0, finish = 1
16/02/08 15:51:18 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1271 bytes result sent to driver
16/02/08 15:51:18 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 228 ms on localhost (2/2)
16/02/08 15:51:18 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/02/08 15:51:18 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) finished in 0.215 s
16/02/08 15:51:18 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221, took 8.584392 s
16/02/08 15:51:18 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224
16/02/08 15:51:18 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) with 2 output partitions
16/02/08 15:51:18 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:51:18 INFO DAGScheduler: Parents of final stage: List()
16/02/08 15:51:18 INFO DAGScheduler: Missing parents: List()
16/02/08 15:51:18 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224), which has no missing parents
16/02/08 15:51:18 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=548536320
16/02/08 15:51:18 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.1 MB)
16/02/08 15:51:18 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=548536320
16/02/08 15:51:18 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.1 MB)
16/02/08 15:51:18 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:35541 (size: 3.3 KB, free: 523.1 MB)
16/02/08 15:51:18 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/02/08 15:51:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:51:18 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/02/08 15:51:18 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/02/08 15:51:18 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2352 bytes)
16/02/08 15:51:18 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/02/08 15:51:18 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/02/08 15:51:18 INFO PythonRunner: Times: total = 27, boot = 15, init = 12, finish = 0
16/02/08 15:51:18 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/02/08 15:51:18 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 49 ms on localhost (1/2)
16/02/08 15:51:18 INFO PythonRunner: Times: total = 150, boot = 149, init = 1, finish = 0
16/02/08 15:51:18 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1336 bytes result sent to driver
16/02/08 15:51:18 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 159 ms on localhost (2/2)
16/02/08 15:51:18 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/02/08 15:51:18 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) finished in 0.161 s
16/02/08 15:51:18 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224, took 0.173680 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/02/08 15:51:18 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/02/08 15:51:18 INFO DAGScheduler: Stopping DAGScheduler
16/02/08 15:51:18 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/02/08 15:51:18 INFO MemoryStore: MemoryStore cleared
16/02/08 15:51:18 INFO BlockManager: BlockManager stopped
16/02/08 15:51:18 INFO BlockManagerMaster: BlockManagerMaster stopped
16/02/08 15:51:18 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/02/08 15:51:18 INFO SparkContext: Successfully stopped SparkContext
16/02/08 15:51:18 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/02/08 15:51:18 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/02/08 15:51:18 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'set']
16/02/08 15:51:19 INFO SparkContext: Running Spark version 1.5.2
16/02/08 15:51:19 INFO SecurityManager: Changing view acls to: root
16/02/08 15:51:19 INFO SecurityManager: Changing modify acls to: root
16/02/08 15:51:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/02/08 15:51:19 INFO Slf4jLogger: Slf4jLogger started
16/02/08 15:51:19 INFO Remoting: Starting remoting
16/02/08 15:51:19 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:38374]
16/02/08 15:51:19 INFO Utils: Successfully started service 'sparkDriver' on port 38374.
16/02/08 15:51:19 INFO SparkEnv: Registering MapOutputTracker
16/02/08 15:51:19 INFO SparkEnv: Registering BlockManagerMaster
16/02/08 15:51:19 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a3d21493-d35c-4066-b157-065b55d0573f
16/02/08 15:51:19 INFO MemoryStore: MemoryStore started with capacity 523.1 MB
16/02/08 15:51:19 INFO HttpFileServer: HTTP File server directory is /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/httpd-3d479d61-1982-4747-9f89-970ebc775de0
16/02/08 15:51:19 INFO HttpServer: Starting HTTP Server
16/02/08 15:51:19 INFO Utils: Successfully started service 'HTTP file server' on port 34856.
16/02/08 15:51:19 INFO SparkEnv: Registering OutputCommitCoordinator
16/02/08 15:51:20 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/02/08 15:51:20 INFO SparkUI: Started SparkUI at http://localhost:4040
16/02/08 15:51:20 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-aca5112b-465b-405b-9998-8137d1bf3dda/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/02/08 15:51:20 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926880169
16/02/08 15:51:20 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/02/08 15:51:20 INFO Executor: Starting executor ID driver on host localhost
16/02/08 15:51:20 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42827.
16/02/08 15:51:20 INFO NettyBlockTransferService: Server created on 42827
16/02/08 15:51:20 INFO BlockManagerMaster: Trying to register BlockManager
16/02/08 15:51:20 INFO BlockManagerMasterEndpoint: Registering block manager localhost:42827 with 523.1 MB RAM, BlockManagerId(driver, localhost, 42827)
16/02/08 15:51:20 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): element
16/02/08 15:51:20 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221
16/02/08 15:51:20 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:51:20 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) with 2 output partitions
16/02/08 15:51:20 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:51:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/02/08 15:51:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/02/08 15:51:20 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219), which has no missing parents
16/02/08 15:51:20 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=548536320
16/02/08 15:51:20 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.1 MB)
16/02/08 15:51:20 INFO MemoryStore: ensureFreeSpace(4146) called with curMem=6568, maxMem=548536320
16/02/08 15:51:20 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 523.1 MB)
16/02/08 15:51:20 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:42827 (size: 4.0 KB, free: 523.1 MB)
16/02/08 15:51:20 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/02/08 15:51:20 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:51:20 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/02/08 15:51:20 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2423 bytes)
16/02/08 15:51:20 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2413 bytes)
16/02/08 15:51:20 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/02/08 15:51:20 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926880169
16/02/08 15:51:20 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/02/08 15:51:20 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-aca5112b-465b-405b-9998-8137d1bf3dda/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines():asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: set
 element
mapFunction_Parents(): keyword: element ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: town
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'urban', u'smaller', u'area', u'is', u'that', u'an', u'city', u'boundary', u'fixed', u'with', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: state
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'nation', u'of', u'one', u'districts', u'constituent', u'the', u'territory', u'occupied', u'by', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: bend
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: giant
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: astatine
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  element  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: present
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/02/08 15:51:28 INFO PythonRunner: Times: total = 8151, boot = 461, init = 386, finish = 7304
16/02/08 15:51:28 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'0.621371', 16/02/08 15:51:28 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8209 ms on localhost (1/2)
u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: area
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: elaborate
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: exist
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'be', u',', u'an', u'have', u'existence', u'extant'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: commissariat
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'supply', u'of', u'foods', u'or', u'stock'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/02/08 15:51:28 INFO PythonRunner: Times: total = 8282, boot = 451, init = 396, finish = 7435
16/02/08 15:51:28 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/02/08 15:51:28 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219) finished in 8.345 s
16/02/08 15:51:28 INFO DAGScheduler: looking for newly runnable stages
16/02/08 15:51:28 INFO DAGScheduler: running: Set()
16/02/08 15:51:28 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/02/08 15:51:28 INFO DAGScheduler: failed: Set()
16/02/08 15:51:28 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/02/08 15:51:28 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221), which is now runnable
16/02/08 15:51:28 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10714, maxMem=548536320
16/02/08 15:51:28 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.1 MB)
16/02/08 15:51:28 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15698, maxMem=548536320
16/02/08 15:51:28 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.1 MB)
16/02/08 15:51:28 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8341 ms on localhost (2/2)
16/02/08 15:51:28 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/02/08 15:51:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:42827 (size: 3.0 KB, free: 523.1 MB)
16/02/08 15:51:28 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/02/08 15:51:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:51:28 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/02/08 15:51:28 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:51:28 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:51:28 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/02/08 15:51:28 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/02/08 15:51:28 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:51:28 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:51:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/02/08 15:51:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/02/08 15:51:28 INFO PythonRunner: Times: total = 82, boot = 82, init = 0, finish = 0
16/02/08 15:51:28 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/02/08 15:51:28 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 101 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/02/08 15:51:28 INFO PythonRunner: Times: total = 186, boot = 185, init = 1, finish = 0
16/02/08 15:51:28 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/02/08 15:51:28 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 206 ms on localhost (2/2)
16/02/08 15:51:28 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) finished in 0.204 s
16/02/08 15:51:28 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/02/08 15:51:28 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221, took 8.571934 s
16/02/08 15:51:28 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224
16/02/08 15:51:28 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) with 2 output partitions
16/02/08 15:51:28 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:51:28 INFO DAGScheduler: Parents of final stage: List()
16/02/08 15:51:28 INFO DAGScheduler: Missing parents: List()
16/02/08 15:51:28 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224), which has no missing parents
16/02/08 15:51:28 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18754, maxMem=548536320
16/02/08 15:51:28 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.1 MB)
16/02/08 15:51:28 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24570, maxMem=548536320
16/02/08 15:51:28 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.1 MB)
16/02/08 15:51:28 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:42827 (size: 3.3 KB, free: 523.1 MB)
16/02/08 15:51:28 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/02/08 15:51:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:51:28 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/02/08 15:51:28 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/02/08 15:51:28 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/02/08 15:51:28 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/02/08 15:51:28 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/02/08 15:51:28 INFO PythonRunner: Times: total = 14, boot = -33, init = 47, finish = 0
16/02/08 15:51:29 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/02/08 15:51:29 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 44 ms on localhost (1/2)
16/02/08 15:51:29 INFO PythonRunner: Times: total = 154, boot = 153, init = 0, finish = 1
16/02/08 15:51:29 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/02/08 15:51:29 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 163 ms on localhost (2/2)
16/02/08 15:51:29 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/02/08 15:51:29 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) finished in 0.151 s
16/02/08 15:51:29 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224, took 0.173574 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/02/08 15:51:29 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/02/08 15:51:29 INFO DAGScheduler: Stopping DAGScheduler
16/02/08 15:51:29 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/02/08 15:51:29 INFO MemoryStore: MemoryStore cleared
16/02/08 15:51:29 INFO BlockManager: BlockManager stopped
16/02/08 15:51:29 INFO BlockManagerMaster: BlockManagerMaster stopped
16/02/08 15:51:29 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/02/08 15:51:29 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/02/08 15:51:29 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/02/08 15:51:29 INFO SparkContext: Successfully stopped SparkContext
16/02/08 15:51:29 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'astatine']
16/02/08 15:51:30 INFO SparkContext: Running Spark version 1.5.2
16/02/08 15:51:30 INFO SecurityManager: Changing view acls to: root
16/02/08 15:51:30 INFO SecurityManager: Changing modify acls to: root
16/02/08 15:51:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/02/08 15:51:30 INFO Slf4jLogger: Slf4jLogger started
16/02/08 15:51:30 INFO Remoting: Starting remoting
16/02/08 15:51:30 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:58679]
16/02/08 15:51:30 INFO Utils: Successfully started service 'sparkDriver' on port 58679.
16/02/08 15:51:30 INFO SparkEnv: Registering MapOutputTracker
16/02/08 15:51:30 INFO SparkEnv: Registering BlockManagerMaster
16/02/08 15:51:30 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-cdb2c0cb-6015-4ef7-8f51-c68dd7775015
16/02/08 15:51:30 INFO MemoryStore: MemoryStore started with capacity 525.4 MB
16/02/08 15:51:30 INFO HttpFileServer: HTTP File server directory is /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/httpd-d3f5e4c9-fd54-4874-8e06-48bf7d92ba75
16/02/08 15:51:30 INFO HttpServer: Starting HTTP Server
16/02/08 15:51:30 INFO Utils: Successfully started service 'HTTP file server' on port 48851.
16/02/08 15:51:30 INFO SparkEnv: Registering OutputCommitCoordinator
16/02/08 15:51:30 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/02/08 15:51:30 INFO SparkUI: Started SparkUI at http://localhost:4040
16/02/08 15:51:30 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-00fb0510-80df-4539-b426-0c3577f2e14d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/02/08 15:51:30 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926890957
16/02/08 15:51:30 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/02/08 15:51:30 INFO Executor: Starting executor ID driver on host localhost
16/02/08 15:51:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35515.
16/02/08 15:51:31 INFO NettyBlockTransferService: Server created on 35515
16/02/08 15:51:31 INFO BlockManagerMaster: Trying to register BlockManager
16/02/08 15:51:31 INFO BlockManagerMasterEndpoint: Registering block manager localhost:35515 with 525.4 MB RAM, BlockManagerId(driver, localhost, 35515)
16/02/08 15:51:31 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): person
16/02/08 15:51:31 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221
16/02/08 15:51:31 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:51:31 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) with 2 output partitions
16/02/08 15:51:31 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:51:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/02/08 15:51:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/02/08 15:51:31 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219), which has no missing parents
16/02/08 15:51:31 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=550942801
16/02/08 15:51:31 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 525.4 MB)
16/02/08 15:51:31 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=550942801
16/02/08 15:51:31 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 525.4 MB)
16/02/08 15:51:31 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:35515 (size: 4.1 KB, free: 525.4 MB)
16/02/08 15:51:31 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/02/08 15:51:31 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:51:31 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/02/08 15:51:31 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2423 bytes)
16/02/08 15:51:31 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2413 bytes)
16/02/08 15:51:31 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/02/08 15:51:31 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926890957
16/02/08 15:51:31 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/02/08 15:51:31 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-00fb0510-80df-4539-b426-0c3577f2e14d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: area
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: elaborate
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: exist
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'be', u',', u'an', u'have', u'existence', u'extant'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: commissariat
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'supply', u'of', u'foods', u'or', u'stock'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/02/08 15:51:39 INFO PythonRunner: Times: total = 8094, boot = 460, init = 384, finish = 7250
16/02/08 15:51:39 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: town
16/02/08 15:51:39 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8159 ms on localhost (1/2)
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'urban', u'smaller', u'area', u'is', u'that', u'an', u'city', u'boundary', u'fixed', u'with', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: state
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'nation', u'of', u'one', u'districts', u'constituent', u'the', u'territory', u'occupied', u'by', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: bend
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: giant
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): adding to parents: syn =  Synset('colossus.n.02') ; keyword:  person  in syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= [u'giant']
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: astatine
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: present
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
16/02/08 15:51:39 INFO PythonRunner: Times: total = 8212, boot = 453, init = 374, finish = 7385
16/02/08 15:51:39 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/02/08 15:51:39 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219) finished in 8.285 s
16/02/08 15:51:39 INFO DAGScheduler: looking for newly runnable stages
16/02/08 15:51:39 INFO DAGScheduler: running: Set()
16/02/08 15:51:39 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/02/08 15:51:39 INFO DAGScheduler: failed: Set()
16/02/08 15:51:39 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/02/08 15:51:39 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221), which is now runnable
16/02/08 15:51:39 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=550942801
16/02/08 15:51:39 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 525.4 MB)
16/02/08 15:51:39 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=550942801
16/02/08 15:51:39 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 525.4 MB)
16/02/08 15:51:39 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8283 ms on localhost (2/2)
16/02/08 15:51:39 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/02/08 15:51:39 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:35515 (size: 3.0 KB, free: 525.4 MB)
16/02/08 15:51:39 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/02/08 15:51:39 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:51:39 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/02/08 15:51:39 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:51:39 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:51:39 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/02/08 15:51:39 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/02/08 15:51:39 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:51:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/02/08 15:51:39 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:51:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/02/08 15:51:39 INFO PythonRunner: Times: total = 76, boot = 76, init = 0, finish = 0
16/02/08 15:51:39 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/02/08 15:51:39 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 100 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'giant']
16/02/08 15:51:39 INFO PythonRunner: Times: total = 271, boot = 270, init = 1, finish = 0
16/02/08 15:51:39 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1281 bytes result sent to driver
16/02/08 15:51:39 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) finished in 0.267 s
16/02/08 15:51:39 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221, took 8.603989 s
16/02/08 15:51:39 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 289 ms on localhost (2/2)
16/02/08 15:51:39 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/02/08 15:51:39 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224
16/02/08 15:51:39 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) with 2 output partitions
16/02/08 15:51:39 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:51:39 INFO DAGScheduler: Parents of final stage: List()
16/02/08 15:51:39 INFO DAGScheduler: Missing parents: List()
16/02/08 15:51:39 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224), which has no missing parents
16/02/08 15:51:39 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=550942801
16/02/08 15:51:39 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 525.4 MB)
16/02/08 15:51:39 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=550942801
16/02/08 15:51:39 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 525.4 MB)
16/02/08 15:51:39 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:35515 (size: 3.3 KB, free: 525.4 MB)
16/02/08 15:51:39 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/02/08 15:51:39 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:51:39 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/02/08 15:51:39 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/02/08 15:51:39 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2362 bytes)
16/02/08 15:51:39 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/02/08 15:51:39 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/02/08 15:51:39 INFO PythonRunner: Times: total = 59, boot = -109, init = 168, finish = 0
16/02/08 15:51:39 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/02/08 15:51:39 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 67 ms on localhost (1/2)
16/02/08 15:51:39 INFO PythonRunner: Times: total = 99, boot = 98, init = 1, finish = 0
16/02/08 15:51:39 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1349 bytes result sent to driver
16/02/08 15:51:39 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 112 ms on localhost (2/2)
16/02/08 15:51:39 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/02/08 15:51:39 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) finished in 0.097 s
16/02/08 15:51:39 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224, took 0.127427 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/02/08 15:51:39 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/02/08 15:51:39 INFO DAGScheduler: Stopping DAGScheduler
16/02/08 15:51:40 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/02/08 15:51:40 INFO MemoryStore: MemoryStore cleared
16/02/08 15:51:40 INFO BlockManager: BlockManager stopped
16/02/08 15:51:40 INFO BlockManagerMaster: BlockManagerMaster stopped
16/02/08 15:51:40 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/02/08 15:51:40 INFO SparkContext: Successfully stopped SparkContext
16/02/08 15:51:40 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/02/08 15:51:40 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'giant']
16/02/08 15:51:40 INFO SparkContext: Running Spark version 1.5.2
16/02/08 15:51:40 INFO SecurityManager: Changing view acls to: root
16/02/08 15:51:40 INFO SecurityManager: Changing modify acls to: root
16/02/08 15:51:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/02/08 15:51:40 INFO Slf4jLogger: Slf4jLogger started
16/02/08 15:51:40 INFO Remoting: Starting remoting
16/02/08 15:51:41 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:57330]
16/02/08 15:51:41 INFO Utils: Successfully started service 'sparkDriver' on port 57330.
16/02/08 15:51:41 INFO SparkEnv: Registering MapOutputTracker
16/02/08 15:51:41 INFO SparkEnv: Registering BlockManagerMaster
16/02/08 15:51:41 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e28df17d-28de-4920-bc86-261dd198ec4b
16/02/08 15:51:41 INFO MemoryStore: MemoryStore started with capacity 525.4 MB
16/02/08 15:51:41 INFO HttpFileServer: HTTP File server directory is /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/httpd-ae69f035-5352-4eee-85a8-64ae57f39b51
16/02/08 15:51:41 INFO HttpServer: Starting HTTP Server
16/02/08 15:51:41 INFO Utils: Successfully started service 'HTTP file server' on port 34683.
16/02/08 15:51:41 INFO SparkEnv: Registering OutputCommitCoordinator
16/02/08 15:51:41 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/02/08 15:51:41 INFO SparkUI: Started SparkUI at http://localhost:4040
16/02/08 15:51:41 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-8e32c2ae-bc40-4672-a040-ace2f86ea927/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/02/08 15:51:41 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926901629
16/02/08 15:51:41 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/02/08 15:51:41 INFO Executor: Starting executor ID driver on host localhost
16/02/08 15:51:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49086.
16/02/08 15:51:41 INFO NettyBlockTransferService: Server created on 49086
16/02/08 15:51:41 INFO BlockManagerMaster: Trying to register BlockManager
16/02/08 15:51:41 INFO BlockManagerMasterEndpoint: Registering block manager localhost:49086 with 525.4 MB RAM, BlockManagerId(driver, localhost, 49086)
16/02/08 15:51:41 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): reputation
16/02/08 15:51:41 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221
16/02/08 15:51:41 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:51:41 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) with 2 output partitions
16/02/08 15:51:41 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:51:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/02/08 15:51:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/02/08 15:51:41 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219), which has no missing parents
16/02/08 15:51:41 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=550942801
16/02/08 15:51:41 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 525.4 MB)
16/02/08 15:51:41 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=550942801
16/02/08 15:51:41 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 525.4 MB)
16/02/08 15:51:41 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:49086 (size: 4.1 KB, free: 525.4 MB)
16/02/08 15:51:41 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/02/08 15:51:41 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:51:41 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/02/08 15:51:41 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2423 bytes)
16/02/08 15:51:41 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2413 bytes)
16/02/08 15:51:41 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/02/08 15:51:41 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926901629
16/02/08 15:51:41 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/02/08 15:51:41 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-8e32c2ae-bc40-4672-a040-ace2f86ea927/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: kilometer
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: set
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: area
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: elaborate
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: exist
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'be', u',', u'an', u'have', u'existence', u'extant'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: commissariat
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'supply', u'of', u'foods', u'or', u'stock'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/02/08 15:51:49 INFO PythonRunner: Times: total = 8044, boot = 455, init = 371, finish = 7218
16/02/08 15:51:49 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/02/08 15:51:49 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8115 ms on localhost (1/2)
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: town
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'urban', u'smaller', u'area', u'is', u'that', u'an', u'city', u'boundary', u'fixed', u'with', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: state
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'nation', u'of', u'one', u'districts', u'constituent', u'the', u'territory', u'occupied', u'by', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: bend
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: giant
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): adding to parents: syn =  Synset('colossus.n.02') ; keyword:  reputation  in syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= [u'giant']
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: astatine
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: present
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
16/02/08 15:51:50 INFO PythonRunner: Times: total = 8458, boot = 465, init = 401, finish = 7592
16/02/08 15:51:50 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/02/08 15:51:50 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219) finished in 8.522 s
16/02/08 15:51:50 INFO DAGScheduler: looking for newly runnable stages
16/02/08 15:51:50 INFO DAGScheduler: running: Set()
16/02/08 15:51:50 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/02/08 15:51:50 INFO DAGScheduler: failed: Set()
16/02/08 15:51:50 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/02/08 15:51:50 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221), which is now runnable
16/02/08 15:51:50 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=550942801
16/02/08 15:51:50 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 525.4 MB)
16/02/08 15:51:50 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=550942801
16/02/08 15:51:50 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 525.4 MB)
16/02/08 15:51:50 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:49086 (size: 3.0 KB, free: 525.4 MB)
16/02/08 15:51:50 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/02/08 15:51:50 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8531 ms on localhost (2/2)
16/02/08 15:51:50 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/02/08 15:51:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:51:50 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/02/08 15:51:50 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:51:50 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:51:50 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/02/08 15:51:50 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/02/08 15:51:50 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:51:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/02/08 15:51:50 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:51:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
reduceFunction_Parents(): returns= ['None', 'None', u'giant']
16/02/08 15:51:50 INFO PythonRunner: Times: total = 30, boot = -265, init = 294, finish = 1
16/02/08 15:51:50 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1281 bytes result sent to driver
16/02/08 15:51:50 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 75 ms on localhost (1/2)
16/02/08 15:51:50 INFO PythonRunner: Times: total = 178, boot = 177, init = 0, finish = 1
16/02/08 15:51:50 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/02/08 15:51:50 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 199 ms on localhost (2/2)
16/02/08 15:51:50 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/02/08 15:51:50 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) finished in 0.183 s
16/02/08 15:51:50 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221, took 8.764626 s
16/02/08 15:51:50 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224
16/02/08 15:51:50 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) with 2 output partitions
16/02/08 15:51:50 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:51:50 INFO DAGScheduler: Parents of final stage: List()
16/02/08 15:51:50 INFO DAGScheduler: Missing parents: List()
16/02/08 15:51:50 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224), which has no missing parents
16/02/08 15:51:50 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=550942801
16/02/08 15:51:50 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 525.4 MB)
16/02/08 15:51:50 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=550942801
16/02/08 15:51:50 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 525.4 MB)
16/02/08 15:51:50 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:49086 (size: 3.3 KB, free: 525.4 MB)
16/02/08 15:51:50 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/02/08 15:51:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:51:50 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/02/08 15:51:50 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/02/08 15:51:50 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2362 bytes)
16/02/08 15:51:50 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/02/08 15:51:50 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/02/08 15:51:50 INFO PythonRunner: Times: total = 70, boot = -70, init = 140, finish = 0
16/02/08 15:51:50 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/02/08 15:51:50 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 81 ms on localhost (1/2)
16/02/08 15:51:50 INFO PythonRunner: Times: total = 199, boot = 199, init = 0, finish = 0
16/02/08 15:51:50 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1349 bytes result sent to driver
16/02/08 15:51:50 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 209 ms on localhost (2/2)
16/02/08 15:51:50 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/02/08 15:51:50 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) finished in 0.211 s
16/02/08 15:51:50 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224, took 0.219587 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/02/08 15:51:50 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/02/08 15:51:50 INFO DAGScheduler: Stopping DAGScheduler
16/02/08 15:51:51 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/02/08 15:51:51 INFO MemoryStore: MemoryStore cleared
16/02/08 15:51:51 INFO BlockManager: BlockManager stopped
16/02/08 15:51:51 INFO BlockManagerMaster: BlockManagerMaster stopped
16/02/08 15:51:51 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/02/08 15:51:51 INFO SparkContext: Successfully stopped SparkContext
16/02/08 15:51:51 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/02/08 15:51:51 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/02/08 15:51:51 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'giant']
16/02/08 15:51:51 INFO SparkContext: Running Spark version 1.5.2
16/02/08 15:51:51 INFO SecurityManager: Changing view acls to: root
16/02/08 15:51:51 INFO SecurityManager: Changing modify acls to: root
16/02/08 15:51:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/02/08 15:51:51 INFO Slf4jLogger: Slf4jLogger started
16/02/08 15:51:51 INFO Remoting: Starting remoting
16/02/08 15:51:51 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:44827]
16/02/08 15:51:51 INFO Utils: Successfully started service 'sparkDriver' on port 44827.
16/02/08 15:51:51 INFO SparkEnv: Registering MapOutputTracker
16/02/08 15:51:51 INFO SparkEnv: Registering BlockManagerMaster
16/02/08 15:51:51 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-63be8c0b-7f1b-44fe-a7d0-04c2892653e7
16/02/08 15:51:51 INFO MemoryStore: MemoryStore started with capacity 525.4 MB
16/02/08 15:51:52 INFO HttpFileServer: HTTP File server directory is /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/httpd-4820271e-45cb-4c98-9c64-ccca7f28029f
16/02/08 15:51:52 INFO HttpServer: Starting HTTP Server
16/02/08 15:51:52 INFO Utils: Successfully started service 'HTTP file server' on port 40894.
16/02/08 15:51:52 INFO SparkEnv: Registering OutputCommitCoordinator
16/02/08 15:51:52 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/02/08 15:51:52 INFO SparkUI: Started SparkUI at http://localhost:4040
16/02/08 15:51:52 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-c54753c5-fd74-4ec1-a51e-f6550faaff8c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/02/08 15:51:52 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926912400
16/02/08 15:51:52 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/02/08 15:51:52 INFO Executor: Starting executor ID driver on host localhost
16/02/08 15:51:52 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50143.
16/02/08 15:51:52 INFO NettyBlockTransferService: Server created on 50143
16/02/08 15:51:52 INFO BlockManagerMaster: Trying to register BlockManager
16/02/08 15:51:52 INFO BlockManagerMasterEndpoint: Registering block manager localhost:50143 with 525.4 MB RAM, BlockManagerId(driver, localhost, 50143)
16/02/08 15:51:52 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): time
16/02/08 15:51:52 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221
16/02/08 15:51:52 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:51:52 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) with 2 output partitions
16/02/08 15:51:52 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:51:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/02/08 15:51:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/02/08 15:51:52 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219), which has no missing parents
16/02/08 15:51:52 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=550942801
16/02/08 15:51:52 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 525.4 MB)
16/02/08 15:51:52 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=550942801
16/02/08 15:51:52 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 525.4 MB)
16/02/08 15:51:52 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:50143 (size: 4.1 KB, free: 525.4 MB)
16/02/08 15:51:52 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/02/08 15:51:52 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:51:52 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/02/08 15:51:52 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2423 bytes)
16/02/08 15:51:52 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2413 bytes)
16/02/08 15:51:52 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/02/08 15:51:52 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926912400
16/02/08 15:51:52 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/02/08 15:51:52 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-c54753c5-fd74-4ec1-a51e-f6550faaff8c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: town
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'urban', u'smaller', u'area', u'is', u'that', u'an', u'city', u'boundary', u'fixed', u'with', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: state
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'nation', u'of', u'one', u'districts', u'constituent', u'the', u'territory', u'occupied', u'by', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: bend
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: giant
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: astatine
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: present
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  time  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: area
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', 16/02/08 15:52:01 INFO PythonRunner: Times: total = 8648, boot = 466, init = 473, finish = 7709
16/02/08 15:52:01 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
16/02/08 15:52:01 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8709 ms on localhost (1/2)
mapFunction_Parents(): keyword: time ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: elaborate
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: exist
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'be', u',', u'an', u'have', u'existence', u'extant'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: commissariat
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'supply', u'of', u'foods', u'or', u'stock'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/02/08 15:52:01 INFO PythonRunner: Times: total = 8732, boot = 456, init = 585, finish = 7691
16/02/08 15:52:01 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/02/08 15:52:01 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219) finished in 8.804 s
16/02/08 15:52:01 INFO DAGScheduler: looking for newly runnable stages
16/02/08 15:52:01 INFO DAGScheduler: running: Set()
16/02/08 15:52:01 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/02/08 15:52:01 INFO DAGScheduler: failed: Set()
16/02/08 15:52:01 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/02/08 15:52:01 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221), which is now runnable
16/02/08 15:52:01 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=550942801
16/02/08 15:52:01 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 525.4 MB)
16/02/08 15:52:01 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=550942801
16/02/08 15:52:01 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 525.4 MB)
16/02/08 15:52:01 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8802 ms on localhost (2/2)
16/02/08 15:52:01 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/02/08 15:52:01 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:50143 (size: 3.0 KB, free: 525.4 MB)
16/02/08 15:52:01 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/02/08 15:52:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:52:01 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/02/08 15:52:01 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:52:01 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:52:01 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/02/08 15:52:01 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:52:01 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/02/08 15:52:01 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:52:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/02/08 15:52:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
reduceFunction_Parents(): returns= ['None', 'None', u'present']
16/02/08 15:52:01 INFO PythonRunner: Times: total = 146, boot = 145, init = 0, finish = 1
16/02/08 15:52:01 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/02/08 15:52:01 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 174 ms on localhost (1/2)
16/02/08 15:52:01 INFO PythonRunner: Times: total = 227, boot = 226, init = 1, finish = 0
16/02/08 15:52:01 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/02/08 15:52:01 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) finished in 0.256 s
16/02/08 15:52:01 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221, took 9.085237 s
16/02/08 15:52:01 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 255 ms on localhost (2/2)
16/02/08 15:52:01 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/02/08 15:52:01 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224
16/02/08 15:52:01 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) with 2 output partitions
16/02/08 15:52:01 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:52:01 INFO DAGScheduler: Parents of final stage: List()
16/02/08 15:52:01 INFO DAGScheduler: Missing parents: List()
16/02/08 15:52:01 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224), which has no missing parents
16/02/08 15:52:01 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=550942801
16/02/08 15:52:01 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 525.4 MB)
16/02/08 15:52:01 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=550942801
16/02/08 15:52:01 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 525.4 MB)
16/02/08 15:52:01 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:50143 (size: 3.3 KB, free: 525.4 MB)
16/02/08 15:52:01 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/02/08 15:52:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:52:01 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/02/08 15:52:01 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/02/08 15:52:01 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/02/08 15:52:01 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/02/08 15:52:01 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/02/08 15:52:01 INFO PythonRunner: Times: total = 16, boot = 4, init = 12, finish = 0
16/02/08 15:52:01 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/02/08 15:52:01 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 98 ms on localhost (1/2)
16/02/08 15:52:01 INFO PythonRunner: Times: total = 173, boot = 172, init = 1, finish = 0
16/02/08 15:52:01 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1351 bytes result sent to driver
16/02/08 15:52:01 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 195 ms on localhost (2/2)
16/02/08 15:52:01 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/02/08 15:52:01 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) finished in 0.196 s
16/02/08 15:52:01 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224, took 0.206340 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/02/08 15:52:02 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/02/08 15:52:02 INFO DAGScheduler: Stopping DAGScheduler
16/02/08 15:52:02 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/02/08 15:52:02 INFO MemoryStore: MemoryStore cleared
16/02/08 15:52:02 INFO BlockManager: BlockManager stopped
16/02/08 15:52:02 INFO BlockManagerMaster: BlockManagerMaster stopped
16/02/08 15:52:02 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/02/08 15:52:02 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/02/08 15:52:02 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/02/08 15:52:02 INFO SparkContext: Successfully stopped SparkContext
16/02/08 15:52:02 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'present']
16/02/08 15:52:02 INFO SparkContext: Running Spark version 1.5.2
16/02/08 15:52:02 INFO SecurityManager: Changing view acls to: root
16/02/08 15:52:02 INFO SecurityManager: Changing modify acls to: root
16/02/08 15:52:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/02/08 15:52:02 INFO Slf4jLogger: Slf4jLogger started
16/02/08 15:52:02 INFO Remoting: Starting remoting
16/02/08 15:52:03 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:42410]
16/02/08 15:52:03 INFO Utils: Successfully started service 'sparkDriver' on port 42410.
16/02/08 15:52:03 INFO SparkEnv: Registering MapOutputTracker
16/02/08 15:52:03 INFO SparkEnv: Registering BlockManagerMaster
16/02/08 15:52:03 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-48e83154-b60c-4313-a2f0-c4f42798d41f
16/02/08 15:52:03 INFO MemoryStore: MemoryStore started with capacity 524.3 MB
16/02/08 15:52:03 INFO HttpFileServer: HTTP File server directory is /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/httpd-63767c4e-4ec5-425e-af21-b332ccfab2fd
16/02/08 15:52:03 INFO HttpServer: Starting HTTP Server
16/02/08 15:52:03 INFO Utils: Successfully started service 'HTTP file server' on port 53423.
16/02/08 15:52:03 INFO SparkEnv: Registering OutputCommitCoordinator
16/02/08 15:52:03 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/02/08 15:52:03 INFO SparkUI: Started SparkUI at http://localhost:4040
16/02/08 15:52:03 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-83e10b0d-ff4a-4bd8-806d-2f3fdc995527/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/02/08 15:52:03 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926923479
16/02/08 15:52:03 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/02/08 15:52:03 INFO Executor: Starting executor ID driver on host localhost
16/02/08 15:52:03 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52866.
16/02/08 15:52:03 INFO NettyBlockTransferService: Server created on 52866
16/02/08 15:52:03 INFO BlockManagerMaster: Trying to register BlockManager
16/02/08 15:52:03 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52866 with 524.3 MB RAM, BlockManagerId(driver, localhost, 52866)
16/02/08 15:52:03 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): position
16/02/08 15:52:03 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221
16/02/08 15:52:03 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:52:03 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) with 2 output partitions
16/02/08 15:52:03 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:52:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/02/08 15:52:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/02/08 15:52:03 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219), which has no missing parents
16/02/08 15:52:03 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=549810339
16/02/08 15:52:03 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 524.3 MB)
16/02/08 15:52:03 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=549810339
16/02/08 15:52:03 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 524.3 MB)
16/02/08 15:52:03 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52866 (size: 4.1 KB, free: 524.3 MB)
16/02/08 15:52:03 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/02/08 15:52:03 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/08 15:52:03 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/02/08 15:52:03 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2423 bytes)
16/02/08 15:52:03 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2413 bytes)
16/02/08 15:52:03 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/02/08 15:52:03 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926923479
16/02/08 15:52:03 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/02/08 15:52:03 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-83e10b0d-ff4a-4bd8-806d-2f3fdc995527/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: kilometer
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: set
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  position  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: area
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: elaborate
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: exist
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'be', u',', u'an', u'have', u'existence', u'extant'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: commissariat
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'supply', u'of', u'foods', u'or', u'stock'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
16/02/08 15:52:11 INFO PythonRunner: Times: total = 8073, boot = 459, init = 424, finish = 7190
16/02/08 15:52:11 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/02/08 15:52:11 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8138 ms on localhost (1/2)
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: town
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'urban', u'smaller', u'area', u'is', u'that', u'an', u'city', u'boundary', u'fixed', u'with', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: state
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'nation', u'of', u'one', u'districts', u'constituent', u'the', u'territory', u'occupied', u'by', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: bend
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: giant
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: astatine
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: present
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/02/08 15:52:12 INFO PythonRunner: Times: total = 8459, boot = 472, init = 451, finish = 7536
16/02/08 15:52:12 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/02/08 15:52:12 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219) finished in 8.519 s
16/02/08 15:52:12 INFO DAGScheduler: looking for newly runnable stages
16/02/08 15:52:12 INFO DAGScheduler: running: Set()
16/02/08 15:52:12 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/02/08 15:52:12 INFO DAGScheduler: failed: Set()
16/02/08 15:52:12 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/02/08 15:52:12 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221), which is now runnable
16/02/08 15:52:12 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=549810339
16/02/08 15:52:12 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 524.3 MB)
16/02/08 15:52:12 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=549810339
16/02/08 15:52:12 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 524.3 MB)
16/02/08 15:52:12 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8517 ms on localhost (2/2)
16/02/08 15:52:12 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/02/08 15:52:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52866 (size: 3.0 KB, free: 524.3 MB)
16/02/08 15:52:12 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/02/08 15:52:12 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/08 15:52:12 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/02/08 15:52:12 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:52:12 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:52:12 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/02/08 15:52:12 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/02/08 15:52:12 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:52:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/02/08 15:52:12 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:52:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
16/02/08 15:52:12 INFO PythonRunner: Times: total = 30, boot = -232, init = 262, finish = 0
16/02/08 15:52:12 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/02/08 15:52:12 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 71 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'metropolitan', 'None']
16/02/08 15:52:12 INFO PythonRunner: Times: total = 226, boot = 225, init = 0, finish = 1
16/02/08 15:52:12 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1288 bytes result sent to driver
16/02/08 15:52:12 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 246 ms on localhost (2/2)
16/02/08 15:52:12 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/02/08 15:52:12 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) finished in 0.246 s
16/02/08 15:52:12 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221, took 8.787397 s
16/02/08 15:52:12 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224
16/02/08 15:52:12 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) with 2 output partitions
16/02/08 15:52:12 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:52:12 INFO DAGScheduler: Parents of final stage: List()
16/02/08 15:52:12 INFO DAGScheduler: Missing parents: List()
16/02/08 15:52:12 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224), which has no missing parents
16/02/08 15:52:12 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=549810339
16/02/08 15:52:12 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 524.3 MB)
16/02/08 15:52:12 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=549810339
16/02/08 15:52:12 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 524.3 MB)
16/02/08 15:52:12 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:52866 (size: 3.3 KB, free: 524.3 MB)
16/02/08 15:52:12 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/02/08 15:52:12 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/08 15:52:12 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/02/08 15:52:12 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/02/08 15:52:12 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2369 bytes)
16/02/08 15:52:12 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/02/08 15:52:12 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/02/08 15:52:12 INFO PythonRunner: Times: total = 56, boot = -103, init = 159, finish = 0
16/02/08 15:52:12 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/02/08 15:52:12 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 67 ms on localhost (1/2)
16/02/08 15:52:12 INFO PythonRunner: Times: total = 120, boot = 119, init = 1, finish = 0
16/02/08 15:52:12 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1356 bytes result sent to driver
16/02/08 15:52:12 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 135 ms on localhost (2/2)
16/02/08 15:52:12 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/02/08 15:52:12 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) finished in 0.135 s
16/02/08 15:52:12 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224, took 0.150284 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/02/08 15:52:12 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/02/08 15:52:12 INFO DAGScheduler: Stopping DAGScheduler
16/02/08 15:52:12 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/02/08 15:52:12 INFO MemoryStore: MemoryStore cleared
16/02/08 15:52:12 INFO BlockManager: BlockManager stopped
16/02/08 15:52:12 INFO BlockManagerMaster: BlockManagerMaster stopped
16/02/08 15:52:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/02/08 15:52:12 INFO SparkContext: Successfully stopped SparkContext
16/02/08 15:52:12 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/02/08 15:52:12 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/02/08 15:52:12 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'metropolitan', u'None']
InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:freqterms1= [u'serving', u'Madras', u'Bengal', u'including', u'existence', u'geography', u'group', u'title', u'writing', u'add', u'halogen', u'Tamil', u'exceptional', u'kind', u'Bay', u'learned', u'meaning', u'miles', u'unstable', u'circular', u'smaller', u'people', u'series', u'idea', u'Christianity', u'culture', u'meters', u'special', u'0.621371', u'Orthodox', u'boundary', u'body', u'importance', u'equivalent', u'thorium', u'clarify', u'fixed', u'region', u'decay', u'equal', u'length', u'usually', u'1000', u'formerly', u'supply', u'period', u'highly', u'indefinite', u'unit', u'city', u'given', u'area', u'stretch', u'archbishop', u'way', u'urban', u'government', u'continuous', u'western', u'particular', u'extant', u'account', u'patriarch', u'Eastern', u'Church', u'politically', u'distinguished', u'metric', u'heaviest', u'organized', u'foods', u'bishop', u'things', u'belong', u'uranium', u'discourse', u'speech', u'details', u'geographical', u'Nadu', u'stock', u'product', u'used', u'moment', u'purpose', u'segment', u'single', u'radioactive', u'happening', u'curve', u'together', u'element', u'person', u'reputation', u'time', u'position']
16/02/08 15:52:13 INFO SparkContext: Running Spark version 1.5.2
16/02/08 15:52:13 INFO SecurityManager: Changing view acls to: root
16/02/08 15:52:13 INFO SecurityManager: Changing modify acls to: root
16/02/08 15:52:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/02/08 15:52:13 INFO Slf4jLogger: Slf4jLogger started
16/02/08 15:52:13 INFO Remoting: Starting remoting
16/02/08 15:52:13 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:35887]
16/02/08 15:52:13 INFO Utils: Successfully started service 'sparkDriver' on port 35887.
16/02/08 15:52:13 INFO SparkEnv: Registering MapOutputTracker
16/02/08 15:52:13 INFO SparkEnv: Registering BlockManagerMaster
16/02/08 15:52:13 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9a8438a6-8ec8-424f-9d0a-ed656032a046
16/02/08 15:52:13 INFO MemoryStore: MemoryStore started with capacity 524.3 MB
16/02/08 15:52:13 INFO HttpFileServer: HTTP File server directory is /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/httpd-397f7c28-5d38-46e8-8970-318b82b3e922
16/02/08 15:52:13 INFO HttpServer: Starting HTTP Server
16/02/08 15:52:13 INFO Utils: Successfully started service 'HTTP file server' on port 38723.
16/02/08 15:52:13 INFO SparkEnv: Registering OutputCommitCoordinator
16/02/08 15:52:14 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/02/08 15:52:14 INFO SparkUI: Started SparkUI at http://localhost:4040
16/02/08 15:52:14 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-fc693bf7-188e-442f-bfa3-93ee5abf4879/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/02/08 15:52:14 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926934161
16/02/08 15:52:14 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/02/08 15:52:14 INFO Executor: Starting executor ID driver on host localhost
16/02/08 15:52:14 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46973.
16/02/08 15:52:14 INFO NettyBlockTransferService: Server created on 46973
16/02/08 15:52:14 INFO BlockManagerMaster: Trying to register BlockManager
16/02/08 15:52:14 INFO BlockManagerMasterEndpoint: Registering block manager localhost:46973 with 524.3 MB RAM, BlockManagerId(driver, localhost, 46973)
16/02/08 15:52:14 INFO BlockManagerMaster: Registered BlockManager
Spark_MapReduce(): wordsatthislevel: [u'serving', u'Madras', u'Bengal', u'including', u'existence', u'geography', u'group', u'title', u'writing', u'add', u'halogen', u'Tamil', u'exceptional', u'kind', u'Bay', u'learned', u'meaning', u'miles', u'unstable', u'circular', u'smaller', u'people', u'series', u'idea', u'Christianity', u'culture', u'meters', u'special', u'0.621371', u'Orthodox', u'boundary', u'body', u'importance', u'equivalent', u'thorium', u'clarify', u'fixed', u'region', u'decay', u'equal', u'length', u'usually', u'1000', u'formerly', u'supply', u'period', u'highly', u'indefinite', u'unit', u'city', u'given', u'area', u'stretch', u'archbishop', u'way', u'urban', u'government', u'continuous', u'western', u'particular', u'extant', u'account', u'patriarch', u'Eastern', u'Church', u'politically', u'distinguished', u'metric', u'heaviest', u'organized', u'foods', u'bishop', u'things', u'belong', u'uranium', u'discourse', u'speech', u'details', u'geographical', u'Nadu', u'stock', u'product', u'used', u'moment', u'purpose', u'segment', u'single', u'radioactive', u'happening', u'curve', u'together', u'element', u'person', u'reputation', u'time', u'position']
16/02/08 15:52:14 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:161
16/02/08 15:52:14 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:153)
16/02/08 15:52:14 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:161) with 2 output partitions
16/02/08 15:52:14 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:161)
16/02/08 15:52:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/02/08 15:52:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/02/08 15:52:14 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:153), which has no missing parents
16/02/08 15:52:14 INFO MemoryStore: ensureFreeSpace(6552) called with curMem=0, maxMem=549810339
16/02/08 15:52:14 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 524.3 MB)
16/02/08 15:52:14 INFO MemoryStore: ensureFreeSpace(4139) called with curMem=6552, maxMem=549810339
16/02/08 15:52:14 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 524.3 MB)
16/02/08 15:52:14 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:46973 (size: 4.0 KB, free: 524.3 MB)
16/02/08 15:52:14 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/02/08 15:52:14 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:153)
16/02/08 15:52:14 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/02/08 15:52:14 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2972 bytes)
16/02/08 15:52:14 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2989 bytes)
16/02/08 15:52:14 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/02/08 15:52:14 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454926934161
16/02/08 15:52:14 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/02/08 15:52:14 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/userFiles-fc693bf7-188e-442f-bfa3-93ee5abf4879/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
mapFunction(): freqterms1:mapFunction(): freqterms1: unit
 serving
mapFunction(): freqterms1: city
mapFunction(): freqterms1: given
mapFunction(): freqterms1: area
mapFunction(): freqterms1: stretch
mapFunction(): freqterms1: archbishop
mapFunction(): freqterms1: way
mapFunction(): freqterms1: urban
mapFunction(): freqterms1: government
mapFunction(): freqterms1: Madras
mapFunction(): freqterms1: continuous
mapFunction(): freqterms1: western
mapFunction(): freqterms1: Bengal
mapFunction(): freqterms1: including
mapFunction(): freqterms1: particular
mapFunction(): freqterms1: existence
mapFunction(): freqterms1: geography
mapFunction(): freqterms1: extant
mapFunction(): freqterms1: group
mapFunction(): freqterms1: account
mapFunction(): freqterms1: title
mapFunction(): freqterms1: writing
mapFunction(): freqterms1: patriarch
mapFunction(): freqterms1: add
mapFunction(): freqterms1: Eastern
mapFunction(): freqterms1: Church
mapFunction(): freqterms1: politically
mapFunction(): freqterms1: distinguished
mapFunction(): freqterms1: metric
mapFunction(): freqterms1: halogen
mapFunction(): freqterms1: Tamil
mapFunction(): freqterms1: exceptional
mapFunction(): freqterms1: heaviest
mapFunction(): freqterms1: kind
mapFunction(): freqterms1: Bay
mapFunction(): freqterms1: organized
mapFunction(): freqterms1: foods
mapFunction(): freqterms1: bishop
mapFunction(): freqterms1: things
mapFunction(): freqterms1: learned
mapFunction(): freqterms1: meaning
mapFunction(): freqterms1: miles
mapFunction(): freqterms1: belong
mapFunction(): freqterms1: uranium
mapFunction(): freqterms1: unstable
mapFunction(): freqterms1: discourse
mapFunction(): freqterms1: circular
mapFunction(): freqterms1: smaller
mapFunction(): freqterms1: speech
mapFunction(): freqterms1: details
mapFunction(): freqterms1: people
mapFunction(): freqterms1: geographical
mapFunction(): freqterms1: Nadu
mapFunction(): freqterms1: stock
mapFunction(): freqterms1: series
mapFunction(): freqterms1: idea
mapFunction(): freqterms1: Christianity
mapFunction(): freqterms1: culture
mapFunction(): freqterms1: meters
mapFunction(): freqterms1: special
mapFunction(): freqterms1: 0.621371
mapFunction(): freqterms1: Orthodox
mapFunction(): freqterms1: boundary
mapFunction(): freqterms1: product
mapFunction(): freqterms1: body
mapFunction(): freqterms1: used
mapFunction(): freqterms1: importance
mapFunction(): freqterms1: moment
mapFunction(): freqterms1: equivalent
mapFunction(): freqterms1: purpose
mapFunction(): freqterms1: thorium
mapFunction(): freqterms1: clarify
mapFunction(): freqterms1: segment
mapFunction(): freqterms1: fixed
mapFunction(): freqterms1: single
mapFunction(): freqterms1: region
mapFunction(): freqterms1: decay
mapFunction(): freqterms1: equal
mapFunction(): freqterms1: length
mapFunction(): freqterms1: usually
mapFunction(): freqterms1: 1000
mapFunction(): freqterms1: formerly
mapFunction(): freqterms1: supply
mapFunction(): freqterms1: radioactive
mapFunction(): freqterms1: period
mapFunction(): freqterms1: happening
mapFunction(): freqterms1: curve
mapFunction(): freqterms1: highly
mapFunction(): freqterms1: indefinite
mapFunction(): freqterms1: together
16/02/08 15:52:24 INFO PythonRunner: Times: total = 9963, boot = 464, init = 384, finish = 9115
16/02/08 15:52:24 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
mapFunction(): freqterms1: element
16/02/08 15:52:24 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 10023 ms on localhost (1/2)
mapFunction(): freqterms1: person
mapFunction(): freqterms1: reputation
mapFunction(): freqterms1: time
mapFunction(): freqterms1: position
16/02/08 15:52:24 INFO PythonRunner: Times: total = 10153, boot = 458, init = 376, finish = 9319
16/02/08 15:52:24 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/02/08 15:52:24 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:153) finished in 10.208 s
16/02/08 15:52:24 INFO DAGScheduler: looking for newly runnable stages
16/02/08 15:52:24 INFO DAGScheduler: running: Set()
16/02/08 15:52:24 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/02/08 15:52:24 INFO DAGScheduler: failed: Set()
16/02/08 15:52:24 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/02/08 15:52:24 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:161), which is now runnable
16/02/08 15:52:24 INFO MemoryStore: ensureFreeSpace(4976) called with curMem=10691, maxMem=549810339
16/02/08 15:52:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 524.3 MB)
16/02/08 15:52:24 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15667, maxMem=549810339
16/02/08 15:52:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 524.3 MB)
16/02/08 15:52:24 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 10205 ms on localhost (2/2)
16/02/08 15:52:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:46973 (size: 3.0 KB, free: 524.3 MB)
16/02/08 15:52:24 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/02/08 15:52:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:161)
16/02/08 15:52:24 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/02/08 15:52:24 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/02/08 15:52:24 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:52:24 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/08 15:52:24 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/02/08 15:52:24 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/02/08 15:52:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:52:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/02/08 15:52:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/08 15:52:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/02/08 15:52:24 INFO PythonRunner: Times: total = 34, boot = -29, init = 63, finish = 0
16/02/08 15:52:24 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/02/08 15:52:24 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 64 ms on localhost (1/2)
16/02/08 15:52:24 INFO PythonRunner: Times: total = 191, boot = 187, init = 1, finish = 3
16/02/08 15:52:24 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 10233 bytes result sent to driver
16/02/08 15:52:24 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:161) finished in 0.214 s
16/02/08 15:52:24 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:161, took 10.446606 s
16/02/08 15:52:24 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 219 ms on localhost (2/2)
16/02/08 15:52:24 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/02/08 15:52:24 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:164
16/02/08 15:52:24 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:164) with 2 output partitions
16/02/08 15:52:24 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:164)
16/02/08 15:52:24 INFO DAGScheduler: Parents of final stage: List()
16/02/08 15:52:24 INFO DAGScheduler: Missing parents: List()
16/02/08 15:52:24 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:164), which has no missing parents
16/02/08 15:52:24 INFO MemoryStore: ensureFreeSpace(5872) called with curMem=18715, maxMem=549810339
16/02/08 15:52:24 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 524.3 MB)
16/02/08 15:52:24 INFO MemoryStore: ensureFreeSpace(3419) called with curMem=24587, maxMem=549810339
16/02/08 15:52:24 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 524.3 MB)
16/02/08 15:52:24 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:46973 (size: 3.3 KB, free: 524.3 MB)
16/02/08 15:52:24 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/02/08 15:52:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:164)
16/02/08 15:52:24 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/02/08 15:52:24 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/02/08 15:52:24 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 11187 bytes)
16/02/08 15:52:24 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/02/08 15:52:24 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/02/08 15:52:24 INFO PythonRunner: Times: total = 65, boot = -42, init = 107, finish = 0
16/02/08 15:52:24 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/02/08 15:52:24 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 74 ms on localhost (1/2)
16/02/08 15:52:24 INFO PythonRunner: Times: total = 101, boot = 100, init = 0, finish = 1
16/02/08 15:52:24 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 10543 bytes result sent to driver
16/02/08 15:52:24 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 134 ms on localhost (2/2)
16/02/08 15:52:24 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/02/08 15:52:24 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:164) finished in 0.135 s
16/02/08 15:52:24 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:164, took 0.149365 s
Spark_MapReduce() - SparkSQL DataFrame query results:
Row(tokensatthislevel=[u'individual', u'quantity', u'food', u'drink', u'taken', u'part', u'meal', u'state', u'southeastern', u'India', u'Bay', u'Bengal', u'south', u'Andhra', u'Pradesh', u'formerly', u'Madras', u'region', u'whose', u'eastern', u'part', u'Bangladesh', u'whose', u'western', u'part', u'included', u'India', u'part', u'made', u'state', u'fact', u'existing', u'study', u'earth', u'surface', u'includes', u'people', u'responses', u'topography', u'climate', u'soil', u'vegetation', u'number', u'entities', u'members', u'considered', u'unit', u'heading', u'names', u'statute', u'legislative', u'bill', u'give', u'brief', u'summary', u'matters', u'deals', u'act', u'creating', u'written', u'works', u'condition', u'mostly', u'boys', u'characterized', u'behavioral', u'learning', u'disorders', u'five', u'related', u'nonmetallic', u'elements', u'fluorine', u'chlorine', u'bromine', u'iodine', u'astatine', u'monovalent', u'readily', u'form', u'negative', u'ions', u'member', u'mixed', u'Dravidian', u'Caucasian', u'people', u'southern', u'India', u'Sri', u'Lanka', u'deviating', u'widely', u'norm', u'physical', u'mental', u'ability', u'used', u'especially', u'children', u'normal', u'intelligence', u'category', u'things', u'distinguished', u'common', u'characteristic', u'quality', u'indentation', u'shoreline', u'larger', u'cove', u'smaller', u'gulf', u'student', u'certain', u'subject', u'logical', u'consequence', u'unit', u'length', u'equal', u'1,760', u'yards', u'5,280', u'feet', u'exactly', u'1609.344', u'meters', u'lacking', u'stability', u'fixity', u'firmness', u'advertisement', u'usually', u'printed', u'page', u'leaflet', u'intended', u'wide', u'distribution', u'voice', u'faint', u'plural', u'group', u'human', u'beings', u'men', u'women', u'children', u'collectively', u'similar', u'things', u'placed', u'order', u'happening', u'one', u'another', u'personal', u'view', u'monotheistic', u'system', u'beliefs', u'practices', u'based', u'Old', u'Testament', u'teachings', u'Jesus', u'embodied', u'New', u'Testament', u'emphasizing', u'role', u'Jesus', u'savior', u'particular', u'society', u'particular', u'time', u'place', u'basic', u'unit', u'length', u'adopted', u'Systeme', u'International', u"d'Unites", u'approximately', u'1.094', u'yards', u'special', u'offering', u'usually', u'temporary', u'reduced', u'price', u'featured', u'advertising', u'pertaining', u'characteristic', u'Judaism', u'line', u'determining', u'limits', u'area', u'entire', u'structure', u'organism', u'animal', u'plant', u'human', u'prominent', u'status', u'person', u'thing', u'equal', u'another', u'value', u'measure', u'force', u'effect', u'significance', u'etc', u'soft', u'silvery-white', u'tetravalent', u'radioactive', u'metallic', u'element', u'isotope', u'232', u'used', u'power', u'source', u'nuclear', u'reactors', u'occurs', u'thorite', u'monazite', u'sands', u'make', u'clear', u'comprehensible', u'restore', u'replacing', u'part', u'putting', u'together', u'torn', u'broken', u'extended', u'spatial', u'location', u'something', u'gradual', u'decrease', u'stored', u'charge', u'current', u'person', u'equal', u'standing', u'another', u'group', u'linear', u'extent', u'space', u'one', u'end', u'longest', u'dimension', u'something', u'fixed', u'place', u'normal', u'conditions', u'cardinal', u'number', u'product', u'10', u'100', u'previous', u'time', u'amount', u'something', u'available', u'use', u'amount', u'time', u'high', u'degree', u'extent', u'favorably', u'much', u'respect', u'vague', u'clearly', u'defined', u'stated', u'division', u'quantity', u'accepted', u'standard', u'measurement', u'exchange', u'large', u'densely', u'populated', u'urban', u'area', u'include', u'several', u'independent', u'administrative', u'districts', u'assumption', u'taken', u'granted', u'particular', u'geographical', u'region', u'indefinite', u'boundary', u'usually', u'serving', u'special', u'purpose', u'distinguished', u'people', u'culture', u'geography', u'large', u'unbroken', u'expanse', u'distance', u'bishop', u'highest', u'rank', u'result', u'obtained', u'end', u'achieved', u'relating', u'concerned', u'city', u'densely', u'populated', u'area', u'organization', u'governing', u'authority', u'political', u'unit', u'continuing', u'time', u'space', u'without', u'interruption', u'film', u'life', u'western', u'United', u'States', u'period', u'exploration', u'development', u'fact', u'part', u'opposed', u'general', u'still', u'existence', u'extinct', u'destroyed', u'lost', u'record', u'narrative', u'description', u'past', u'events', u'man', u'older', u'higher', u'rank', u'lying', u'toward', u'situated', u'east', u'one', u'groups', u'Christians', u'beliefs', u'forms', u'worship', u'regard', u'social', u'relationships', u'involving', u'authority', u'mark', u'different', u'function', u'topological', u'space', u'gives', u'two', u'points', u'space', u'value', u'equal', u'distance', u'usually', u'describes', u'large', u'person', u'fat', u'large', u'frame', u'carry', u'plan', u'direct', u'complex', u'undertaking', u'substance', u'metabolized', u'animal', u'give', u'energy', u'build', u'tissue', u'senior', u'member', u'Christian', u'clergy', u'spiritual', u'administrative', u'authority', u'appointed', u'Christian', u'churches', u'oversee', u'priests', u'ministers', u'considered', u'churches', u'successors', u'twelve', u'Apostles', u'Christ', u'movable', u'possession', u'especially', u'articles', u'clothing', u'owned', u'possession', u'heavy', u'toxic', u'silvery-white', u'radioactive', u'metallic', u'element', u'occurs', u'many', u'isotopes', u'used', u'nuclear', u'fuels', u'nuclear', u'weapons', u'extended', u'verbal', u'expression', u'speech', u'writing', u'act', u'delivering', u'formal', u'spoken', u'communication', u'audience', u'small', u'part', u'considered', u'separately', u'whole', u'relating', u'science', u'geography', u'capital', u'raised', u'corporation', u'issue', u'shares', u'entitling', u'holders', u'ownership', u'interest', u'equity', u'commodities', u'offered', u'sale', u'put', u'service', u'make', u'work', u'employ', u'particular', u'purpose', u'inherent', u'natural', u'purpose', u'particular', u'point', u'time', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions', u'one', u'several', u'parts', u'pieces', u'fit', u'others', u'constitute', u'whole', u'object', u'base', u'hit', u'batter', u'stops', u'safely', u'first', u'base', u'exhibiting', u'caused', u'radioactivity', u'event', u'happens', u'trace', u'point', u'whose', u'direction', u'motion', u'changes', u'mentally', u'emotionally', u'stable', u'abstract', u'part', u'something', u'human', u'general', u'estimation', u'public', u'person', u'instance', u'single', u'occasion', u'event', u'particular', u'portion', u'space', u'occupied', u'something'])
16/02/08 15:52:25 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/02/08 15:52:25 INFO DAGScheduler: Stopping DAGScheduler
16/02/08 15:52:25 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/02/08 15:52:25 INFO MemoryStore: MemoryStore cleared
16/02/08 15:52:25 INFO BlockManager: BlockManager stopped
16/02/08 15:52:25 INFO BlockManagerMaster: BlockManagerMaster stopped
16/02/08 15:52:25 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/02/08 15:52:25 INFO SparkContext: Successfully stopped SparkContext
16/02/08 15:52:25 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/02/08 15:52:25 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/02/08 15:52:25 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:tokensofthislevel: [u'individual', u'quantity', u'food', u'drink', u'taken', u'part', u'meal', u'state', u'southeastern', u'India', u'Bay', u'Bengal', u'south', u'Andhra', u'Pradesh', u'formerly', u'Madras', u'region', u'whose', u'eastern', u'part', u'Bangladesh', u'whose', u'western', u'part', u'included', u'India', u'part', u'made', u'state', u'fact', u'existing', u'study', u'earth', u'surface', u'includes', u'people', u'responses', u'topography', u'climate', u'soil', u'vegetation', u'number', u'entities', u'members', u'considered', u'unit', u'heading', u'names', u'statute', u'legislative', u'bill', u'give', u'brief', u'summary', u'matters', u'deals', u'act', u'creating', u'written', u'works', u'condition', u'mostly', u'boys', u'characterized', u'behavioral', u'learning', u'disorders', u'five', u'related', u'nonmetallic', u'elements', u'fluorine', u'chlorine', u'bromine', u'iodine', u'astatine', u'monovalent', u'readily', u'form', u'negative', u'ions', u'member', u'mixed', u'Dravidian', u'Caucasian', u'people', u'southern', u'India', u'Sri', u'Lanka', u'deviating', u'widely', u'norm', u'physical', u'mental', u'ability', u'used', u'especially', u'children', u'normal', u'intelligence', u'category', u'things', u'distinguished', u'common', u'characteristic', u'quality', u'indentation', u'shoreline', u'larger', u'cove', u'smaller', u'gulf', u'student', u'certain', u'subject', u'logical', u'consequence', u'unit', u'length', u'equal', u'1,760', u'yards', u'5,280', u'feet', u'exactly', u'1609.344', u'meters', u'lacking', u'stability', u'fixity', u'firmness', u'advertisement', u'usually', u'printed', u'page', u'leaflet', u'intended', u'wide', u'distribution', u'voice', u'faint', u'plural', u'group', u'human', u'beings', u'men', u'women', u'children', u'collectively', u'similar', u'things', u'placed', u'order', u'happening', u'one', u'another', u'personal', u'view', u'monotheistic', u'system', u'beliefs', u'practices', u'based', u'Old', u'Testament', u'teachings', u'Jesus', u'embodied', u'New', u'Testament', u'emphasizing', u'role', u'Jesus', u'savior', u'particular', u'society', u'particular', u'time', u'place', u'basic', u'unit', u'length', u'adopted', u'Systeme', u'International', u"d'Unites", u'approximately', u'1.094', u'yards', u'special', u'offering', u'usually', u'temporary', u'reduced', u'price', u'featured', u'advertising', u'pertaining', u'characteristic', u'Judaism', u'line', u'determining', u'limits', u'area', u'entire', u'structure', u'organism', u'animal', u'plant', u'human', u'prominent', u'status', u'person', u'thing', u'equal', u'another', u'value', u'measure', u'force', u'effect', u'significance', u'etc', u'soft', u'silvery-white', u'tetravalent', u'radioactive', u'metallic', u'element', u'isotope', u'232', u'used', u'power', u'source', u'nuclear', u'reactors', u'occurs', u'thorite', u'monazite', u'sands', u'make', u'clear', u'comprehensible', u'restore', u'replacing', u'part', u'putting', u'together', u'torn', u'broken', u'extended', u'spatial', u'location', u'something', u'gradual', u'decrease', u'stored', u'charge', u'current', u'person', u'equal', u'standing', u'another', u'group', u'linear', u'extent', u'space', u'one', u'end', u'longest', u'dimension', u'something', u'fixed', u'place', u'normal', u'conditions', u'cardinal', u'number', u'product', u'10', u'100', u'previous', u'time', u'amount', u'something', u'available', u'use', u'amount', u'time', u'high', u'degree', u'extent', u'favorably', u'much', u'respect', u'vague', u'clearly', u'defined', u'stated', u'division', u'quantity', u'accepted', u'standard', u'measurement', u'exchange', u'large', u'densely', u'populated', u'urban', u'area', u'include', u'several', u'independent', u'administrative', u'districts', u'assumption', u'taken', u'granted', u'particular', u'geographical', u'region', u'indefinite', u'boundary', u'usually', u'serving', u'special', u'purpose', u'distinguished', u'people', u'culture', u'geography', u'large', u'unbroken', u'expanse', u'distance', u'bishop', u'highest', u'rank', u'result', u'obtained', u'end', u'achieved', u'relating', u'concerned', u'city', u'densely', u'populated', u'area', u'organization', u'governing', u'authority', u'political', u'unit', u'continuing', u'time', u'space', u'without', u'interruption', u'film', u'life', u'western', u'United', u'States', u'period', u'exploration', u'development', u'fact', u'part', u'opposed', u'general', u'still', u'existence', u'extinct', u'destroyed', u'lost', u'record', u'narrative', u'description', u'past', u'events', u'man', u'older', u'higher', u'rank', u'lying', u'toward', u'situated', u'east', u'one', u'groups', u'Christians', u'beliefs', u'forms', u'worship', u'regard', u'social', u'relationships', u'involving', u'authority', u'mark', u'different', u'function', u'topological', u'space', u'gives', u'two', u'points', u'space', u'value', u'equal', u'distance', u'usually', u'describes', u'large', u'person', u'fat', u'large', u'frame', u'carry', u'plan', u'direct', u'complex', u'undertaking', u'substance', u'metabolized', u'animal', u'give', u'energy', u'build', u'tissue', u'senior', u'member', u'Christian', u'clergy', u'spiritual', u'administrative', u'authority', u'appointed', u'Christian', u'churches', u'oversee', u'priests', u'ministers', u'considered', u'churches', u'successors', u'twelve', u'Apostles', u'Christ', u'movable', u'possession', u'especially', u'articles', u'clothing', u'owned', u'possession', u'heavy', u'toxic', u'silvery-white', u'radioactive', u'metallic', u'element', u'occurs', u'many', u'isotopes', u'used', u'nuclear', u'fuels', u'nuclear', u'weapons', u'extended', u'verbal', u'expression', u'speech', u'writing', u'act', u'delivering', u'formal', u'spoken', u'communication', u'audience', u'small', u'part', u'considered', u'separately', u'whole', u'relating', u'science', u'geography', u'capital', u'raised', u'corporation', u'issue', u'shares', u'entitling', u'holders', u'ownership', u'interest', u'equity', u'commodities', u'offered', u'sale', u'put', u'service', u'make', u'work', u'employ', u'particular', u'purpose', u'inherent', u'natural', u'purpose', u'particular', u'point', u'time', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions', u'one', u'several', u'parts', u'pieces', u'fit', u'others', u'constitute', u'whole', u'object', u'base', u'hit', u'batter', u'stops', u'safely', u'first', u'base', u'exhibiting', u'caused', u'radioactivity', u'event', u'happens', u'trace', u'point', u'whose', u'direction', u'motion', u'changes', u'mentally', u'emotionally', u'stable', u'abstract', u'part', u'something', u'human', u'general', u'estimation', u'public', u'person', u'instance', u'single', u'occasion', u'event', u'particular', u'portion', u'space', u'occupied', u'something']
prevlevelsynsets: [Synset('unit_of_measurement.n.01'), Synset('city.n.01'), Synset('given.n.01'), Synset('area.n.01'), Synset('stretch.n.01'), Synset('archbishop.n.01'), Synset('means.n.01'), Synset('urban.a.01'), Synset('helping.n.01'), Synset('government.n.01'), Synset('continuous.a.01'), Synset('tamil_nadu.n.01'), Synset('bengal.n.01'), Synset('western.n.01'), Synset('include.v.01'), Synset('being.n.01'), Synset('particular.n.01'), Synset('geography.n.01'), Synset('extant.a.01'), Synset('group.n.01'), Synset('title.n.01'), Synset('history.n.01'), Synset('writing.n.01'), Synset('patriarch.n.01'), Synset('eastern.s.01'), Synset('church.n.01'), Synset('politically.r.01'), Synset('distinguish.v.01'), Synset('attention_deficit_disorder.n.01'), Synset('halogen.n.01'), Synset('tamil.n.01'), Synset('metric_function.n.01'), Synset('exceeding.s.01'), Synset('kind.n.01'), Synset('fleshy.s.01'), Synset('originator.n.01'), Synset('food.n.01'), Synset('bishop.n.01'), Synset('bay.n.01'), Synset('learn.v.01'), Synset('entail.n.01'), Synset('things.n.01'), Synset('belong.v.01'), Synset('mile.n.01'), Synset('uranium.n.01'), Synset('unstable.a.01'), Synset('circular.n.01'), Synset('discourse.n.01'), Synset('address.n.01'), Synset('little.n.01'), Synset('detail.n.01'), Synset('geographic.a.01'), Synset('people.n.01'), Synset('series.n.01'), Synset('idea.n.01'), Synset('christianity.n.01'), Synset('culture.n.01'), Synset('meter.n.01'), Synset('special.n.01'), Synset('orthodox.a.01'), Synset('stock.n.01'), Synset('boundary.n.01'), Synset('merchandise.n.01'), Synset('body.n.01'), Synset('use.n.01'), Synset('importance.n.01'), Synset('moment.n.01'), Synset('equivalent.n.01'), Synset('thorium.n.01'), Synset('purpose.n.01'), Synset('clarify.v.01'), Synset('section.n.01'), Synset('repair.n.01'), Synset('region.n.01'), Synset('decay.n.01'), Synset('peer.n.01'), Synset('length.n.01'), Synset('normally.r.01'), Synset('thousand.n.01'), Synset('once.r.01'), Synset('single.n.01'), Synset('supply.n.01'), Synset('radioactive.a.01'), Synset('happening.n.01'), Synset('time_period.n.01'), Synset('highly.r.01'), Synset('curve.n.01'), Synset('indefinite.a.01'), Synset('together.s.01'), Synset('component.n.01'), Synset('person.n.01'), Synset('repute.n.01'), Synset('time.n.01'), Synset('position.n.01')]
defaultdict(<type 'list'>, {u'serving': [u'None', u'area', u'None'], u'Madras': [u'Chennai', u'None', u'Chennai'], u'Bengal': [u'Chennai', u'None', u'Chennai'], u'including': [u'None', u'None', u'present'], u'existence': [u'None', u'exist', u'None'], u'geography': [u'None', u'area', u'None'], u'group': [u'None', u'set'], u'title': [u'None', u'metropolitan', u'None'], u'writing': [u'None', u'elaborate', u'None'], u'add': [u'None', u'elaborate', u'None'], u'halogen': [u'None', u'None', u'astatine'], u'Tamil': [u'Chennai', u'None', u'Chennai'], u'exceptional': [u'None', u'None', u'giant'], u'kind': [u'None', u'set'], u'Bay': [u'Chennai', u'None', u'Chennai'], u'boundary': [u'None', u'area', u'town'], u'miles': [u'kilometer', u'kilometer', u'None'], u'unstable': [u'None', u'None', u'astatine'], u'circular': [u'None', u'None', u'bend'], u'smaller': [u'None', u'town'], u'people': [u'None', u'area', u'None'], u'series': [u'None', u'None', u'astatine'], u'idea': [u'None', u'elaborate', u'None'], u'Christianity': [u'None', u'metropolitan', u'None'], u'culture': [u'None', u'area', u'None'], u'meters': [u'kilometer', u'kilometer', u'None'], u'special': [u'None', u'area', u'None'], u'0.621371': [u'kilometer', u'kilometer', u'None'], u'Orthodox': [u'None', u'metropolitan', u'None'], u'learned': [u'None', u'elaborate', u'None'], u'body': [u'None', u'None'], u'importance': [u'None', u'None', u'giant'], u'equivalent': [u'None', u'metropolitan', u'None'], u'thorium': [u'None', u'None', u'astatine'], u'clarify': [u'None', u'elaborate', u'None'], u'fixed': [u'None', u'town'], u'region': [u'None', u'area', u'None'], u'decay': [u'None', u'None', u'astatine'], u'meaning': [u'None', u'elaborate', u'None'], u'length': [u'kilometer', u'kilometer', u'None'], u'usually': [u'None', u'area', u'elaborate', u'None'], u'1000': [u'kilometer', u'kilometer', u'None'], u'formerly': [u'Chennai', u'None', u'Chennai'], u'supply': [u'None', u'commissariat', u'None'], u'period': [u'None', u'None', u'present'], u'highly': [u'None', u'None', u'astatine'], u'indefinite': [u'None', u'area', u'None'], u'unit': [u'kilometer', u'kilometer', u'None'], u'city': [u'Chennai', u'town', u'Chennai'], u'given': [u'None', u'metropolitan', u'None'], u'area': [u'None', u'town'], u'stretch': [u'None', u'None', u'present'], u'archbishop': [u'None', u'metropolitan', u'None'], u'way': [u'None', u'elaborate', u'None'], u'urban': [u'None', u'town'], u'government': [u'None', u'None'], u'continuous': [u'None', u'None', u'present'], u'western': [u'None', u'metropolitan', u'None'], u'particular': [u'None', u'area', u'None'], u'extant': [u'None', u'exist', u'None'], u'account': [u'None', u'elaborate', u'None'], u'patriarch': [u'None', u'metropolitan', u'None'], u'Eastern': [u'None', u'metropolitan', u'None'], u'Church': [u'None', u'metropolitan', u'None'], u'politically': [u'None', u'None'], u'distinguished': [u'None', u'area', u'None'], u'metric': [u'kilometer', u'kilometer', u'None'], u'heaviest': [u'None', u'None', u'astatine'], u'organized': [u'None', u'None'], u'equal': [u'kilometer', u'kilometer', u'None'], u'foods': [u'None', u'commissariat', u'None'], u'bishop': [u'None', u'metropolitan', u'None'], u'things': [u'None', u'set'], u'belong': [u'None', u'set'], u'uranium': [u'None', u'None', u'astatine'], u'discourse': [u'None', u'elaborate', u'None'], u'speech': [u'None', u'None', u'present'], u'details': [u'None', u'elaborate', u'None'], u'geographical': [u'None', u'area', u'None'], u'Nadu': [u'Chennai', u'None', u'Chennai'], u'stock': [u'None', u'commissariat', u'None'], u'product': [u'None', u'None', u'astatine'], u'used': [u'None', u'set'], u'moment': [u'None', u'None', u'present'], u'purpose': [u'None', u'area', u'None'], u'segment': [u'None', u'None', u'bend'], u'single': [u'None', u'None'], u'radioactive': [u'None', u'None', u'astatine'], u'happening': [u'None', u'None', u'present'], u'curve': [u'None', u'None', u'bend'], u'together': [u'None', u'set'], u'element': [u'None', u'None', u'astatine'], u'person': [u'None', u'None', u'giant'], u'reputation': [u'None', u'None', u'giant'], u'time': [u'None', u'None', u'present'], u'position': [u'None', u'metropolitan', u'None']})
ksynset= Synset('helping.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('helping.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('helping.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('include.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('include.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('include.v.01')
lsynset= Synset('present.n.01')
ksynset= Synset('being.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('being.n.01')
lsynset= Synset('exist.v.01')
ksynset= Synset('being.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('group.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('group.n.01')
lsynset= Synset('set.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('writing.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('writing.n.01')
lsynset= Synset('elaborate.v.01')
ksynset= Synset('writing.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('attention_deficit_disorder.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('attention_deficit_disorder.n.01')
lsynset= Synset('elaborate.v.01')
ksynset= Synset('attention_deficit_disorder.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('halogen.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('halogen.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('halogen.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('exceeding.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('exceeding.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('exceeding.s.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('kind.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('kind.n.01')
lsynset= Synset('set.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('town.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unstable.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unstable.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unstable.a.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('circular.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('circular.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('circular.n.01')
lsynset= Synset('bend.n.01')
ksynset= Synset('smaller.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('smaller.s.01')
lsynset= Synset('town.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('series.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('series.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('series.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('idea.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('idea.n.01')
lsynset= Synset('elaborate.v.01')
ksynset= Synset('idea.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('learn.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('learn.v.01')
lsynset= Synset('elaborate.v.01')
ksynset= Synset('learn.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('body.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('body.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('importance.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('importance.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('importance.n.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thorium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thorium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thorium.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('clarify.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('clarify.v.01')
lsynset= Synset('elaborate.v.01')
ksynset= Synset('clarify.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('repair.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('repair.v.01')
lsynset= Synset('town.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('decay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('decay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('decay.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('meaning.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('meaning.n.01')
lsynset= Synset('elaborate.v.01')
ksynset= Synset('meaning.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('area.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('elaborate.v.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('chennai.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('none.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('chennai.n.01')
ksynset= Synset('supply.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('supply.n.01')
lsynset= Synset('commissariat.n.01')
ksynset= Synset('supply.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time_period.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time_period.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time_period.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('highly.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('highly.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('highly.r.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('town.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('area.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('area.n.01')
lsynset= Synset('town.n.01')
ksynset= Synset('stretch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('stretch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('stretch.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('manner.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('manner.n.01')
lsynset= Synset('elaborate.v.01')
ksynset= Synset('manner.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('urban.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('urban.a.01')
lsynset= Synset('town.n.01')
ksynset= Synset('government.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('government.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('continuous.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('continuous.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('continuous.a.01')
lsynset= Synset('present.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('extant.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('extant.a.01')
lsynset= Synset('exist.v.01')
ksynset= Synset('extant.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('history.n.02')
lsynset= Synset('none.n.01')
ksynset= Synset('history.n.02')
lsynset= Synset('elaborate.v.01')
ksynset= Synset('history.n.02')
lsynset= Synset('none.n.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('politically.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('politically.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('area.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('heavy.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('heavy.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('heavy.a.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('form.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('form.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('food.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('food.n.01')
lsynset= Synset('commissariat.n.01')
ksynset= Synset('food.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('things.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('things.n.01')
lsynset= Synset('set.n.01')
ksynset= Synset('belong.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('belong.v.01')
lsynset= Synset('set.n.01')
ksynset= Synset('uranium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('uranium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('uranium.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('discourse.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('discourse.n.01')
lsynset= Synset('elaborate.v.01')
ksynset= Synset('discourse.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('address.n.03')
lsynset= Synset('none.n.01')
ksynset= Synset('address.n.03')
lsynset= Synset('none.n.01')
ksynset= Synset('address.n.03')
lsynset= Synset('present.n.01')
ksynset= Synset('details.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('details.n.01')
lsynset= Synset('elaborate.v.01')
ksynset= Synset('details.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('stock.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('stock.n.01')
lsynset= Synset('commissariat.n.01')
ksynset= Synset('stock.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('use.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('use.v.01')
lsynset= Synset('set.n.01')
ksynset= Synset('moment.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('moment.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('moment.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('section.n.04')
lsynset= Synset('none.n.01')
ksynset= Synset('section.n.04')
lsynset= Synset('none.n.01')
ksynset= Synset('section.n.04')
lsynset= Synset('bend.n.01')
ksynset= Synset('single.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('single.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('radioactive.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('radioactive.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('radioactive.a.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('happening.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('happening.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('happening.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('curve.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('curve.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('curve.n.01')
lsynset= Synset('bend.n.01')
ksynset= Synset('together.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('together.s.01')
lsynset= Synset('set.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('repute.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('repute.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('repute.n.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('time.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('none.n.01')
Core number (sorted) : [(u'area', 14), (u'metropolitan', 12), (u'astatine', 11), (u'elaborate', 11), (u'kilometer', 8), (u'present', 8), (u'Chennai', 7), (u'town', 7), (u'set', 6), (u'giant', 4), (u'boundary', 4), (u'usually', 4), (u'city', 4), (u'commissariat', 3), (u'bend', 3), (u'serving', 2), (u'Madras', 2), (u'Bengal', 2), (u'including', 2), (u'existence', 2), (u'geography', 2), (u'group', 2), (u'decay', 2), (u'writing', 2), (u'add', 2), (u'halogen', 2), (u'circular', 2), (u'Tamil', 2), (u'kind', 2), (u'Bay', 2), (u'meaning', 2), (u'miles', 2), (u'unstable', 2), (u'fixed', 2), (u'people', 2), (u'series', 2), (u'idea', 2), (u'Christianity', 2), (u'culture', 2), (u'meters', 2), (u'special', 2), (u'0.621371', 2), (u'Orthodox', 2), (u'learned', 2), (u'importance', 2), (u'equivalent', 2), (u'thorium', 2), (u'clarify', 2), (u'region', 2), (u'title', 2), (u'equal', 2), (u'length', 2), (u'1000', 2), (u'formerly', 2), (u'supply', 2), (u'period', 2), (u'highly', 2), (u'smaller', 2), (u'indefinite', 2), (u'unit', 2), (u'given', 2), (u'stretch', 2), (u'archbishop', 2), (u'way', 2), (u'urban', 2), (u'continuous', 2), (u'western', 2), (u'particular', 2), (u'extant', 2), (u'account', 2), (u'patriarch', 2), (u'Eastern', 2), (u'Church', 2), (u'distinguished', 2), (u'metric', 2), (u'heaviest', 2), (u'foods', 2), (u'exist', 2), (u'bishop', 2), (u'things', 2), (u'exceptional', 2), (u'uranium', 2), (u'discourse', 2), (u'speech', 2), (u'details', 2), (u'geographical', 2), (u'belong', 2), (u'Nadu', 2), (u'stock', 2), (u'product', 2), (u'used', 2), (u'moment', 2), (u'purpose', 2), (u'segment', 2), (u'radioactive', 2), (u'happening', 2), (u'curve', 2), (u'together', 2), (u'element', 2), (u'person', 2), (u'reputation', 2), (u'time', 2), (u'position', 2), (u'government', 0), (u'body', 0), (u'None', 0), (u'politically', 0), (u'organized', 0), (u'single', 0)]
=============================================================================================================
Unsupervised Classification based on top percentile Core numbers of the definition graph(subgraph of WordNet)
=============================================================================================================
This document belongs to class: area ,core number= 14
This document belongs to class: metropolitan ,core number= 12
This document belongs to class: astatine ,core number= 11
This document belongs to class: elaborate ,core number= 11
This document belongs to class: kilometer ,core number= 8
This document belongs to class: present ,core number= 8
This document belongs to class: Chennai ,core number= 7
This document belongs to class: town ,core number= 7
This document belongs to class: set ,core number= 6
This document belongs to class: giant ,core number= 4
This document belongs to class: boundary ,core number= 4
This document belongs to class: usually ,core number= 4
max_core_number 14
===================================================================
Page Rank of the vertices of RGO Definition Graph
===================================================================
[(u'area', 0.06049913956284764), (u'metropolitan', 0.05826318289452799), (u'astatine', 0.05384149709284674), (u'elaborate', 0.051199014601093794), (u'kilometer', 0.040576439687803126), (u'present', 0.040576439687803126), (u'Chennai', 0.03331917720742451), (u'set', 0.03173306808444068), (u'town', 0.02567095457079789), (u'giant', 0.022889696481078282), (u'commissariat', 0.018468010679397073), (u'bend', 0.018468010679397063), (u'exist', 0.014046324877715857), (u'city', 0.009126437939093433), (u'usually', 0.009073614048095556), (u'boundary', 0.008753695848117688), (u'existence', 0.007413796175194044), (u'extant', 0.007413796175194044), (u'segment', 0.006676848541580507), (u'supply', 0.006676848541580507), (u'stock', 0.006676848541580507), (u'foods', 0.006676848541580507), (u'circular', 0.006676848541580507), (u'curve', 0.006676848541580507), (u'exceptional', 0.006308374724773743), (u'importance', 0.006308374724773743), (u'person', 0.006308374724773743), (u'reputation', 0.006308374724773743), (u'group', 0.005939900907966972), (u'kind', 0.005939900907966972), (u'things', 0.005939900907966972), (u'belong', 0.005939900907966972), (u'used', 0.005939900907966972), (u'together', 0.005939900907966972), (u'including', 0.005755663999563591), (u'miles', 0.005755663999563591), (u'meters', 0.005755663999563591), (u'0.621371', 0.005755663999563591), (u'equal', 0.005755663999563591), (u'length', 0.005755663999563591), (u'1000', 0.005755663999563591), (u'period', 0.005755663999563591), (u'unit', 0.005755663999563591), (u'stretch', 0.005755663999563591), (u'continuous', 0.005755663999563591), (u'moment', 0.005755663999563591), (u'metric', 0.005755663999563591), (u'speech', 0.005755663999563591), (u'happening', 0.005755663999563591), (u'time', 0.005755663999563591), (u'decay', 0.005604924710869914), (u'halogen', 0.005604924710869914), (u'unstable', 0.005604924710869914), (u'series', 0.005604924710869914), (u'thorium', 0.005604924710869914), (u'highly', 0.005604924710869914), (u'heaviest', 0.005604924710869914), (u'uranium', 0.005604924710869914), (u'product', 0.005604924710869914), (u'radioactive', 0.005604924710869914), (u'element', 0.005604924710869914), (u'Christianity', 0.005571427091160203), (u'Orthodox', 0.005571427091160203), (u'equivalent', 0.005571427091160203), (u'title', 0.005571427091160203), (u'given', 0.005571427091160203), (u'archbishop', 0.005571427091160203), (u'western', 0.005571427091160203), (u'patriarch', 0.005571427091160203), (u'Eastern', 0.005571427091160203), (u'Church', 0.005571427091160203), (u'bishop', 0.005571427091160203), (u'position', 0.005571427091160203), (u'Madras', 0.005489713407570958), (u'Bengal', 0.005489713407570958), (u'Tamil', 0.005489713407570958), (u'Bay', 0.005489713407570958), (u'formerly', 0.005489713407570958), (u'Nadu', 0.005489713407570958), (u'writing', 0.00540033859290554), (u'add', 0.00540033859290554), (u'learned', 0.00540033859290554), (u'idea', 0.00540033859290554), (u'clarify', 0.00540033859290554), (u'way', 0.00540033859290554), (u'account', 0.00540033859290554), (u'discourse', 0.00540033859290554), (u'details', 0.00540033859290554), (u'meaning', 0.00540033859290554), (u'serving', 0.005116971316595214), (u'geography', 0.005116971316595214), (u'people', 0.005116971316595214), (u'culture', 0.005116971316595214), (u'special', 0.005116971316595214), (u'region', 0.005116971316595214), (u'indefinite', 0.005116971316595214), (u'particular', 0.005116971316595214), (u'distinguished', 0.005116971316595214), (u'geographical', 0.005116971316595214), (u'purpose', 0.005116971316595214), (u'fixed', 0.005080420392927672), (u'smaller', 0.005080420392927672), (u'urban', 0.005080420392927672), (u'body', 0.0014436958614051977), (u'None', 0.0014436958614051977), (u'politically', 0.0014436958614051977), (u'organized', 0.0014436958614051977), (u'government', 0.0014436958614051977), (u'single', 0.0014436958614051977)]
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - connectivity of RGO Definition Graph - Mengers Theorem
==========================================================================================================
0
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - Maxflow-Mincut of RGO Definition Graph - Minimum Edge Cut
==========================================================================================================
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - Maxflow-Mincut of RGO Definition Graph - Stoer-Wagner
==========================================================================================================
16/02/08 16:21:04 INFO ShutdownHookManager: Shutdown hook called
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-a1d7d40c-0ebe-4edd-a193-0756557d1082
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-40e08bb1-ea13-42ba-b6e2-d7808429f7b1
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-cb7cf7f9-8a2d-4c60-aa05-5028b6678bbf
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-649ed829-3950-4155-a976-ade95c2fdb1b
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-98829d27-e7b7-43eb-9ec3-23da7a91be03
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-2097d970-0865-491e-bfd1-636672185732
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-036709f3-e337-48f4-89eb-eda7e6e440ec
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-e1340f3f-0c3d-42c0-9335-1bfde13593a3
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-d54f0ebc-a7fb-450d-916a-1670849eda16
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-16a020f1-f490-4897-bc35-a366a34ba712
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-911f40c0-bb09-480b-9406-ef28ad32fb1d
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-a0233ae5-5e54-428e-9e76-32c0da3b574e
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-b6241ded-8bb0-48c3-a05f-4eb4510cf185
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-cc5894ea-8166-46e9-b9f8-6eeee67cea66
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-f50b9205-905d-4591-9e56-99de2805afb3
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-a1c4d966-3904-4aab-958c-6681c11790ec
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-720bed38-b68a-4be0-abf0-4cad8a911327
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-cd7df4ba-71df-4d5c-b76f-71211dbf7616
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-f33096c1-b41c-4229-9146-7bba2cd0f30b
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-a96a1337-93ca-447c-8862-f3c164a183f3
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-50ddc420-46a8-4043-9203-3e1b90c398a8
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-9bee9de2-bcb4-46d9-b50c-5c56971a7940
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-6f36bdc1-b48f-46df-b381-367e7dbd5e3d
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-485b954b-fde3-48c3-b18f-3543bbb0b9b0
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-e8e5d360-3a30-406a-a06c-e75c71e88bc7
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-37ddc2fd-0cfe-4b68-9d35-4c39a7973e05
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-59d6c0fe-30b8-4735-896e-a7235b8367d0
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-2935867a-8bbe-48eb-b6e1-9e4638a99754
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-e8a0a321-f19f-4cd4-8886-8dfd1c77dc9c
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-e7d9471a-8cfe-4250-b156-9be7128b88bd
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-f0b4c2b0-e4e0-482c-996d-02c8d4164f1d
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-d6658c68-97e1-49a3-a9ff-f0cfd346309b
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-07399d4e-ec27-4ed6-9d18-26e9168b54dd
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-0a8a6842-65bb-4a1f-b3b3-b0fedef0c5db
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-a337467c-64c1-4454-9f92-431a18c58308
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-b578c405-62e7-41dc-b84a-6f684c477f2d
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-6c5038e0-e5da-4eaa-98bf-77405910aa03
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-67b8fa85-3a3a-4d4b-85ca-4ec2527c1dac
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-68d4fc2e-4565-4b17-9a47-c633aa9a88fd
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-15068dd8-724d-486d-a315-a41a8c728865
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-5cbe0349-fbb2-42b7-8568-fd48a64307c1
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-5efc8042-34e5-421e-b315-f60a50174758
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-d02092e6-a411-4534-847f-96aeb0bf9d20
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-04379a7d-66e7-4b74-8461-8f6d10f816e5
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-4593c73f-3d7b-4424-a1cf-93fd4d59708d
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-b3a461ff-33b9-4095-8801-82422f6a6cab
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-b86ff7c7-ecec-44c9-a102-91a0093a9b39
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-72edd39c-2b5a-4add-a3f0-43c5c37baef9
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-01e902d7-d305-4d14-87fd-3824b644a2ea
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-90abdc59-1619-4733-a44d-d864682edd9a
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-33925bb1-1a77-4a68-90fb-27e65c684c45
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-5aabc883-0f80-4066-bace-4f23633914b0
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-958acf87-ab2b-42be-836c-40f31fcfdaf3
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-a5e10ece-4019-4e56-9169-b6d6ef8dd10c
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-739da298-796e-4e3c-97d8-5b3851a85109
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-b6d9940c-390d-459d-a9ad-87c6ac306c0f
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-983adc8d-4313-4638-8130-e67e8da88a3d
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-e0af9c99-82fa-46d7-83b7-f6e524f8e7df
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-6166f6f1-4c63-4292-9483-a558b7282624
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-6dcb929c-0f3f-4ea6-a80c-2fbcdc38460d
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-f7182a15-ed37-4f98-b8ec-4287d0af00f9
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-54f2ff0f-e035-4458-aa05-2b52f6eb41d3
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-17dbb6b4-114c-4470-84f6-9564988c79f1
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-75f89d19-490a-44f7-aec9-199886672662
16/02/08 16:21:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f1081a-9c83-4f45-9636-918883a7a280/pyspark-04df9e7c-5e00-4d27-881b-0c637dc56c3f

