74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:49:10 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/22 16:49:10 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:49:10 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:49:10 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/22 16:49:10 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/22 16:49:10 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:49:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/22 16:49:10 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:49:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/22 16:49:10 INFO PythonRunner: Times: total = 48, boot = -986, init = 1033, finish = 1
reduceFunction_Parents(): returns= [u'set', 'None']
16/03/22 16:49:10 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1271 bytes result sent to driver
16/03/22 16:49:10 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 104 ms on localhost (1/2)
16/03/22 16:49:10 INFO PythonRunner: Times: total = 246, boot = 245, init = 0, finish = 1
16/03/22 16:49:10 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/22 16:49:10 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.253 s
16/03/22 16:49:10 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 10.088716 s
16/03/22 16:49:10 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 272 ms on localhost (2/2)
16/03/22 16:49:10 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/22 16:49:10 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:49:10 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:49:10 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:49:10 INFO DAGScheduler: Parents of final stage: List()
16/03/22 16:49:10 INFO DAGScheduler: Missing parents: List()
16/03/22 16:49:10 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:49:10 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=549527224
16/03/22 16:49:10 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 524.0 MB)
16/03/22 16:49:10 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24952, maxMem=549527224
16/03/22 16:49:10 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 524.0 MB)
16/03/22 16:49:10 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:39234 (size: 3.3 KB, free: 524.1 MB)
16/03/22 16:49:10 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/22 16:49:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:49:10 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/22 16:49:10 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/22 16:49:10 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/22 16:49:10 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/22 16:49:10 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/22 16:49:10 INFO PythonRunner: Times: total = 73, boot = -45, init = 118, finish = 0
16/03/22 16:49:10 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/22 16:49:10 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 80 ms on localhost (1/2)
16/03/22 16:49:10 INFO PythonRunner: Times: total = 142, boot = 142, init = 0, finish = 0
16/03/22 16:49:10 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1336 bytes result sent to driver
16/03/22 16:49:10 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 151 ms on localhost (2/2)
16/03/22 16:49:10 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/22 16:49:10 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.149 s
16/03/22 16:49:10 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.171982 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/22 16:49:10 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/22 16:49:10 INFO DAGScheduler: Stopping DAGScheduler
16/03/22 16:49:10 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/22 16:49:10 INFO MemoryStore: MemoryStore cleared
16/03/22 16:49:10 INFO BlockManager: BlockManager stopped
16/03/22 16:49:10 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/22 16:49:10 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/22 16:49:10 INFO SparkContext: Successfully stopped SparkContext
16/03/22 16:49:10 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/22 16:49:10 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/22 16:49:10 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'set', u'None']
16/03/22 16:49:11 INFO SparkContext: Running Spark version 1.5.2
16/03/22 16:49:11 INFO SecurityManager: Changing view acls to: root
16/03/22 16:49:11 INFO SecurityManager: Changing modify acls to: root
16/03/22 16:49:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/22 16:49:11 INFO Slf4jLogger: Slf4jLogger started
16/03/22 16:49:11 INFO Remoting: Starting remoting
16/03/22 16:49:11 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:46997]
16/03/22 16:49:11 INFO Utils: Successfully started service 'sparkDriver' on port 46997.
16/03/22 16:49:11 INFO SparkEnv: Registering MapOutputTracker
16/03/22 16:49:11 INFO SparkEnv: Registering BlockManagerMaster
16/03/22 16:49:11 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d64a2097-cd48-4a40-8082-ee833982d763
16/03/22 16:49:11 INFO MemoryStore: MemoryStore started with capacity 524.1 MB
16/03/22 16:49:11 INFO HttpFileServer: HTTP File server directory is /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/httpd-5f781fd9-c323-4fda-afa3-fadabc2fca23
16/03/22 16:49:11 INFO HttpServer: Starting HTTP Server
16/03/22 16:49:11 INFO Utils: Successfully started service 'HTTP file server' on port 59064.
16/03/22 16:49:11 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/22 16:49:11 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/22 16:49:11 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/22 16:49:11 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-648775a4-ae7d-4f1d-b165-cef3ba19caa1/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:49:12 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645551988
16/03/22 16:49:12 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/22 16:49:12 INFO Executor: Starting executor ID driver on host localhost
16/03/22 16:49:12 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35922.
16/03/22 16:49:12 INFO NettyBlockTransferService: Server created on 35922
16/03/22 16:49:12 INFO BlockManagerMaster: Trying to register BlockManager
16/03/22 16:49:12 INFO BlockManagerMasterEndpoint: Registering block manager localhost:35922 with 524.1 MB RAM, BlockManagerId(driver, localhost, 35922)
16/03/22 16:49:12 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): uranium
16/03/22 16:49:12 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:49:12 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:49:12 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:49:12 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:49:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/22 16:49:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/22 16:49:12 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:49:12 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=549527224
16/03/22 16:49:12 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 524.1 MB)
16/03/22 16:49:12 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=549527224
16/03/22 16:49:12 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 524.1 MB)
16/03/22 16:49:12 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:35922 (size: 4.1 KB, free: 524.1 MB)
16/03/22 16:49:12 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/22 16:49:12 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:49:12 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/22 16:49:12 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/22 16:49:12 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/22 16:49:12 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/22 16:49:12 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645551988
16/03/22 16:49:12 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/22 16:49:12 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-648775a4-ae7d-4f1d-b165-cef3ba19caa1/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:49:12 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/22 16:49:12 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10732, maxMem=549527224
16/03/22 16:49:12 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 524.1 MB)
16/03/22 16:49:12 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:35922 (size: 187.0 B, free: 524.1 MB)
16/03/22 16:49:12 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/22 16:49:12 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10919, maxMem=549527224
16/03/22 16:49:12 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 524.1 MB)
16/03/22 16:49:12 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:35922 (size: 177.0 B, free: 524.1 MB)
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: set
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: bend
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: giant
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: astatine
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  uranium  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: present
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: area
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/22 16:49:21 INFO PythonRunner: Times: total = 9686, boot = 482, init = 474, finish = 8730
16/03/22 16:49:21 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/22 16:49:22 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9847 ms on localhost (1/2)
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: issue
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: planning
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: permission
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: economy
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: composition
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: agency
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/22 16:49:22 INFO PythonRunner: Times: total = 9882, boot = 476, init = 395, finish = 9011
16/03/22 16:49:22 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/22 16:49:22 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 10.036 s
16/03/22 16:49:22 INFO DAGScheduler: looking for newly runnable stages
16/03/22 16:49:22 INFO DAGScheduler: running: Set()
16/03/22 16:49:22 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/22 16:49:22 INFO DAGScheduler: failed: Set()
16/03/22 16:49:22 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/22 16:49:22 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/22 16:49:22 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=549527224
16/03/22 16:49:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 524.1 MB)
16/03/22 16:49:22 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=549527224
16/03/22 16:49:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 524.1 MB)
16/03/22 16:49:22 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 10034 ms on localhost (2/2)
16/03/22 16:49:22 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/22 16:49:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:35922 (size: 3.0 KB, free: 524.1 MB)
16/03/22 16:49:22 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/22 16:49:22 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:49:22 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/22 16:49:22 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:49:22 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:49:22 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/22 16:49:22 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/22 16:49:22 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:49:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/22 16:49:22 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:49:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
reduceFunction_Parents(): returns= ['None', u'astatine', 'None']
16/03/22 16:49:22 INFO PythonRunner: Times: total = 137, boot = 120, init = 1, finish = 16
16/03/22 16:49:22 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/03/22 16:49:22 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 156 ms on localhost (1/2)
16/03/22 16:49:22 INFO PythonRunner: Times: total = 259, boot = 259, init = 0, finish = 0
16/03/22 16:49:22 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/22 16:49:22 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.279 s
16/03/22 16:49:22 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 285 ms on localhost (2/2)
16/03/22 16:49:22 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/22 16:49:22 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 10.349458 s
16/03/22 16:49:22 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:49:22 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:49:22 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:49:22 INFO DAGScheduler: Parents of final stage: List()
16/03/22 16:49:22 INFO DAGScheduler: Missing parents: List()
16/03/22 16:49:22 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:49:22 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=549527224
16/03/22 16:49:22 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 524.0 MB)
16/03/22 16:49:22 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24952, maxMem=549527224
16/03/22 16:49:22 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 524.0 MB)
16/03/22 16:49:22 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:35922 (size: 3.3 KB, free: 524.1 MB)
16/03/22 16:49:22 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/22 16:49:22 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:49:22 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/22 16:49:22 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/22 16:49:22 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/03/22 16:49:22 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/22 16:49:22 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/22 16:49:22 INFO PythonRunner: Times: total = 45, boot = -17, init = 62, finish = 0
16/03/22 16:49:22 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/22 16:49:22 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 67 ms on localhost (1/2)
16/03/22 16:49:22 INFO PythonRunner: Times: total = 150, boot = 150, init = 0, finish = 0
16/03/22 16:49:22 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/03/22 16:49:22 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 161 ms on localhost (2/2)
16/03/22 16:49:22 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/22 16:49:22 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.157 s
16/03/22 16:49:22 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.183923 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/22 16:49:22 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/22 16:49:22 INFO DAGScheduler: Stopping DAGScheduler
16/03/22 16:49:23 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/22 16:49:23 INFO MemoryStore: MemoryStore cleared
16/03/22 16:49:23 INFO BlockManager: BlockManager stopped
16/03/22 16:49:23 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/22 16:49:23 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/22 16:49:23 INFO SparkContext: Successfully stopped SparkContext
16/03/22 16:49:23 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/22 16:49:23 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/22 16:49:23 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'astatine', u'None']
16/03/22 16:49:23 INFO SparkContext: Running Spark version 1.5.2
16/03/22 16:49:23 INFO SecurityManager: Changing view acls to: root
16/03/22 16:49:23 INFO SecurityManager: Changing modify acls to: root
16/03/22 16:49:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/22 16:49:23 INFO Slf4jLogger: Slf4jLogger started
16/03/22 16:49:23 INFO Remoting: Starting remoting
16/03/22 16:49:24 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:56336]
16/03/22 16:49:24 INFO Utils: Successfully started service 'sparkDriver' on port 56336.
16/03/22 16:49:24 INFO SparkEnv: Registering MapOutputTracker
16/03/22 16:49:24 INFO SparkEnv: Registering BlockManagerMaster
16/03/22 16:49:24 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3b473255-49ed-4a9f-a087-78021e06b74e
16/03/22 16:49:24 INFO MemoryStore: MemoryStore started with capacity 524.1 MB
16/03/22 16:49:24 INFO HttpFileServer: HTTP File server directory is /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/httpd-113993ba-9f20-48e7-9525-a1989591172f
16/03/22 16:49:24 INFO HttpServer: Starting HTTP Server
16/03/22 16:49:24 INFO Utils: Successfully started service 'HTTP file server' on port 42699.
16/03/22 16:49:24 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/22 16:49:24 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/22 16:49:24 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/22 16:49:24 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-a3d2e316-c65b-41d6-9fd0-727113b0b6c9/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:49:24 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645564758
16/03/22 16:49:24 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/22 16:49:24 INFO Executor: Starting executor ID driver on host localhost
16/03/22 16:49:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37939.
16/03/22 16:49:24 INFO NettyBlockTransferService: Server created on 37939
16/03/22 16:49:24 INFO BlockManagerMaster: Trying to register BlockManager
16/03/22 16:49:24 INFO BlockManagerMasterEndpoint: Registering block manager localhost:37939 with 524.1 MB RAM, BlockManagerId(driver, localhost, 37939)
16/03/22 16:49:24 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): arrangement
16/03/22 16:49:24 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:49:24 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:49:24 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:49:24 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:49:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/22 16:49:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/22 16:49:24 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:49:24 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=549527224
16/03/22 16:49:24 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 524.1 MB)
16/03/22 16:49:24 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=549527224
16/03/22 16:49:24 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 524.1 MB)
16/03/22 16:49:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:37939 (size: 4.1 KB, free: 524.1 MB)
16/03/22 16:49:24 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/22 16:49:24 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:49:24 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/22 16:49:24 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/22 16:49:24 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/22 16:49:24 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/22 16:49:24 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645564758
16/03/22 16:49:24 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/22 16:49:24 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-a3d2e316-c65b-41d6-9fd0-727113b0b6c9/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:49:25 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/22 16:49:25 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/22 16:49:25 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10732, maxMem=549527224
16/03/22 16:49:25 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 524.1 MB)
16/03/22 16:49:25 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10909, maxMem=549527224
16/03/22 16:49:25 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:37939 (size: 177.0 B, free: 524.1 MB)
16/03/22 16:49:25 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 524.1 MB)
16/03/22 16:49:25 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:37939 (size: 187.0 B, free: 524.1 MB)
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: area
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: bend
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: giant
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: astatine
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: present
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: area
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/22 16:49:33 INFO PythonRunner: Times: total = 8640, boot = 524, init = 395, finish = 7721
16/03/22 16:49:33 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/22 16:49:33 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8763 ms on localhost (1/2)
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: issue
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: planning
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: permission
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: economy
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: composition
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  arrangement  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: agency
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/22 16:49:34 INFO PythonRunner: Times: total = 9603, boot = 526, init = 461, finish = 8616
16/03/22 16:49:34 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/22 16:49:34 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 9.716 s
16/03/22 16:49:34 INFO DAGScheduler: looking for newly runnable stages
16/03/22 16:49:34 INFO DAGScheduler: running: Set()
16/03/22 16:49:34 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/22 16:49:34 INFO DAGScheduler: failed: Set()
16/03/22 16:49:34 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/22 16:49:34 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/22 16:49:34 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=549527224
16/03/22 16:49:34 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 524.1 MB)
16/03/22 16:49:34 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=549527224
16/03/22 16:49:34 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 524.1 MB)
16/03/22 16:49:34 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:37939 (size: 3.0 KB, free: 524.1 MB)
16/03/22 16:49:34 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/22 16:49:34 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:49:34 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/22 16:49:34 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9714 ms on localhost (2/2)
16/03/22 16:49:34 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/22 16:49:34 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:49:34 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:49:34 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/22 16:49:34 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:49:34 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/22 16:49:34 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:49:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/22 16:49:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
reduceFunction_Parents(): returns= ['None', 'None', u'composition']
16/03/22 16:49:34 INFO PythonRunner: Times: total = 29, boot = -785, init = 813, finish = 1
16/03/22 16:49:34 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1287 bytes result sent to driver
16/03/22 16:49:34 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 68 ms on localhost (1/2)
16/03/22 16:49:35 INFO PythonRunner: Times: total = 489, boot = 482, init = 7, finish = 0
16/03/22 16:49:35 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/22 16:49:35 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.526 s
16/03/22 16:49:35 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 10.296063 s
16/03/22 16:49:35 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 535 ms on localhost (2/2)
16/03/22 16:49:35 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/22 16:49:35 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:37939 in memory (size: 4.1 KB, free: 524.1 MB)
16/03/22 16:49:35 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:49:35 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:49:35 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:49:35 INFO DAGScheduler: Parents of final stage: List()
16/03/22 16:49:35 INFO DAGScheduler: Missing parents: List()
16/03/22 16:49:35 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:49:35 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=8404, maxMem=549527224
16/03/22 16:49:35 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 524.1 MB)
16/03/22 16:49:35 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=14220, maxMem=549527224
16/03/22 16:49:35 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 524.1 MB)
16/03/22 16:49:35 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:37939 (size: 3.3 KB, free: 524.1 MB)
16/03/22 16:49:35 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/22 16:49:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:49:35 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/22 16:49:35 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/22 16:49:35 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2368 bytes)
16/03/22 16:49:35 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/22 16:49:35 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/22 16:49:35 INFO PythonRunner: Times: total = 30, boot = -39, init = 69, finish = 0
16/03/22 16:49:35 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1355 bytes result sent to driver
16/03/22 16:49:35 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 78 ms on localhost (1/2)
16/03/22 16:49:35 INFO PythonRunner: Times: total = 67, boot = -447, init = 514, finish = 0
16/03/22 16:49:35 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/22 16:49:35 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 80 ms on localhost (2/2)
16/03/22 16:49:35 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/22 16:49:35 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.070 s
16/03/22 16:49:35 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.104214 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/22 16:49:35 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/22 16:49:35 INFO DAGScheduler: Stopping DAGScheduler
16/03/22 16:49:35 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/22 16:49:35 INFO MemoryStore: MemoryStore cleared
16/03/22 16:49:35 INFO BlockManager: BlockManager stopped
16/03/22 16:49:35 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/22 16:49:35 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/22 16:49:35 INFO SparkContext: Successfully stopped SparkContext
16/03/22 16:49:35 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/22 16:49:35 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/22 16:49:35 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'composition']
16/03/22 16:49:36 INFO SparkContext: Running Spark version 1.5.2
16/03/22 16:49:36 INFO SecurityManager: Changing view acls to: root
16/03/22 16:49:36 INFO SecurityManager: Changing modify acls to: root
16/03/22 16:49:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/22 16:49:36 INFO Slf4jLogger: Slf4jLogger started
16/03/22 16:49:36 INFO Remoting: Starting remoting
16/03/22 16:49:36 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:45153]
16/03/22 16:49:36 INFO Utils: Successfully started service 'sparkDriver' on port 45153.
16/03/22 16:49:36 INFO SparkEnv: Registering MapOutputTracker
16/03/22 16:49:36 INFO SparkEnv: Registering BlockManagerMaster
16/03/22 16:49:36 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c646ed13-5111-4307-a0d8-b8e5baabef47
16/03/22 16:49:36 INFO MemoryStore: MemoryStore started with capacity 517.5 MB
16/03/22 16:49:36 INFO HttpFileServer: HTTP File server directory is /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/httpd-acec3105-62af-43ba-8dde-2db35f10dbfc
16/03/22 16:49:36 INFO HttpServer: Starting HTTP Server
16/03/22 16:49:36 INFO Utils: Successfully started service 'HTTP file server' on port 46505.
16/03/22 16:49:36 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/22 16:49:41 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/22 16:49:41 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/22 16:49:41 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-9c457180-6c49-49ef-b8aa-990ff34bddde/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:49:41 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645581768
16/03/22 16:49:41 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/22 16:49:41 INFO Executor: Starting executor ID driver on host localhost
16/03/22 16:49:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58832.
16/03/22 16:49:41 INFO NettyBlockTransferService: Server created on 58832
16/03/22 16:49:41 INFO BlockManagerMaster: Trying to register BlockManager
16/03/22 16:49:41 INFO BlockManagerMasterEndpoint: Registering block manager localhost:58832 with 517.5 MB RAM, BlockManagerId(driver, localhost, 58832)
16/03/22 16:49:41 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): parts
16/03/22 16:49:41 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:49:41 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:49:41 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:49:41 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:49:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/22 16:49:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/22 16:49:41 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:49:41 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=542590894
16/03/22 16:49:41 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 517.4 MB)
16/03/22 16:49:41 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=542590894
16/03/22 16:49:41 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 517.4 MB)
16/03/22 16:49:41 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:58832 (size: 4.1 KB, free: 517.5 MB)
16/03/22 16:49:41 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/22 16:49:41 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:49:41 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/22 16:49:41 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/22 16:49:41 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/22 16:49:41 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/22 16:49:41 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645581768
16/03/22 16:49:41 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/22 16:49:41 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-9c457180-6c49-49ef-b8aa-990ff34bddde/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:49:42 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/22 16:49:42 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10732, maxMem=542590894
16/03/22 16:49:42 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 517.4 MB)
16/03/22 16:49:42 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/22 16:49:42 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:58832 (size: 187.0 B, free: 517.5 MB)
16/03/22 16:49:42 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10919, maxMem=542590894
16/03/22 16:49:42 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 517.4 MB)
16/03/22 16:49:42 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:58832 (size: 177.0 B, free: 517.5 MB)
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: set
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: bend
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: giant
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: astatine
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: present
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: area
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/22 16:49:50 INFO PythonRunner: Times: total = 8949, boot = 484, init = 464, finish = 8001
16/03/22 16:49:50 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/22 16:49:50 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9028 ms on localhost (1/2)
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: issue
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: planning
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: permission
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: economy
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: composition
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  parts  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: agency
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/22 16:49:51 INFO PythonRunner: Times: total = 9207, boot = 479, init = 449, finish = 8279
16/03/22 16:49:51 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/22 16:49:51 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9293 ms on localhost (2/2)
16/03/22 16:49:51 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/22 16:49:51 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 9.298 s
16/03/22 16:49:51 INFO DAGScheduler: looking for newly runnable stages
16/03/22 16:49:51 INFO DAGScheduler: running: Set()
16/03/22 16:49:51 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/22 16:49:51 INFO DAGScheduler: failed: Set()
16/03/22 16:49:51 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/22 16:49:51 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/22 16:49:51 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=542590894
16/03/22 16:49:51 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 517.4 MB)
16/03/22 16:49:51 INFO MemoryStore: ensureFreeSpace(3057) called with curMem=16080, maxMem=542590894
16/03/22 16:49:51 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 517.4 MB)
16/03/22 16:49:51 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:58832 (size: 3.0 KB, free: 517.4 MB)
16/03/22 16:49:51 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/22 16:49:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:49:51 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/22 16:49:51 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:49:51 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:49:51 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/22 16:49:51 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/22 16:49:51 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:49:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/22 16:49:51 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:49:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
16/03/22 16:49:51 INFO PythonRunner: Times: total = 36, boot = -123, init = 158, finish = 1
16/03/22 16:49:51 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/22 16:49:51 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 83 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'composition']
16/03/22 16:49:51 INFO PythonRunner: Times: total = 281, boot = 280, init = 0, finish = 1
16/03/22 16:49:51 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1287 bytes result sent to driver
16/03/22 16:49:51 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.296 s
16/03/22 16:49:51 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 9.661973 s
16/03/22 16:49:51 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 296 ms on localhost (2/2)
16/03/22 16:49:51 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/22 16:49:51 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:49:51 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:49:51 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:49:51 INFO DAGScheduler: Parents of final stage: List()
16/03/22 16:49:51 INFO DAGScheduler: Missing parents: List()
16/03/22 16:49:51 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:49:51 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19137, maxMem=542590894
16/03/22 16:49:51 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 517.4 MB)
16/03/22 16:49:51 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24953, maxMem=542590894
16/03/22 16:49:51 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 517.4 MB)
16/03/22 16:49:51 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:58832 (size: 3.3 KB, free: 517.4 MB)
16/03/22 16:49:51 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/22 16:49:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:49:51 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/22 16:49:51 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/22 16:49:51 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2368 bytes)
16/03/22 16:49:51 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/22 16:49:51 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/22 16:49:51 INFO PythonRunner: Times: total = 78, boot = -162, init = 240, finish = 0
16/03/22 16:49:51 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/22 16:49:51 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 96 ms on localhost (1/2)
16/03/22 16:49:51 INFO PythonRunner: Times: total = 134, boot = 133, init = 0, finish = 1
16/03/22 16:49:51 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1355 bytes result sent to driver
16/03/22 16:49:51 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 149 ms on localhost (2/2)
16/03/22 16:49:51 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/22 16:49:51 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.140 s
16/03/22 16:49:51 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.163174 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/22 16:49:51 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/22 16:49:51 INFO DAGScheduler: Stopping DAGScheduler
16/03/22 16:49:52 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/22 16:49:52 INFO MemoryStore: MemoryStore cleared
16/03/22 16:49:52 INFO BlockManager: BlockManager stopped
16/03/22 16:49:52 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/22 16:49:52 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/22 16:49:52 INFO SparkContext: Successfully stopped SparkContext
16/03/22 16:49:52 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/22 16:49:52 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/22 16:49:52 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'composition']
16/03/22 16:49:52 INFO SparkContext: Running Spark version 1.5.2
16/03/22 16:49:52 INFO SecurityManager: Changing view acls to: root
16/03/22 16:49:52 INFO SecurityManager: Changing modify acls to: root
16/03/22 16:49:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/22 16:49:52 INFO Slf4jLogger: Slf4jLogger started
16/03/22 16:49:52 INFO Remoting: Starting remoting
16/03/22 16:49:52 INFO Utils: Successfully started service 'sparkDriver' on port 46991.
16/03/22 16:49:52 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:46991]
16/03/22 16:49:53 INFO SparkEnv: Registering MapOutputTracker
16/03/22 16:49:53 INFO SparkEnv: Registering BlockManagerMaster
16/03/22 16:49:53 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-46467b24-7d5f-4333-8968-11a711127489
16/03/22 16:49:53 INFO MemoryStore: MemoryStore started with capacity 517.5 MB
16/03/22 16:49:53 INFO HttpFileServer: HTTP File server directory is /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/httpd-2d7b504b-93e2-489e-8a01-9bffff9c90f3
16/03/22 16:49:53 INFO HttpServer: Starting HTTP Server
16/03/22 16:49:53 INFO Utils: Successfully started service 'HTTP file server' on port 57201.
16/03/22 16:49:53 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/22 16:49:53 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/22 16:49:53 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/22 16:49:53 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-79245e97-10d9-449d-9e32-64b254883a7d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:49:53 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645593685
16/03/22 16:49:53 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/22 16:49:53 INFO Executor: Starting executor ID driver on host localhost
16/03/22 16:49:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44435.
16/03/22 16:49:53 INFO NettyBlockTransferService: Server created on 44435
16/03/22 16:49:53 INFO BlockManagerMaster: Trying to register BlockManager
16/03/22 16:49:53 INFO BlockManagerMasterEndpoint: Registering block manager localhost:44435 with 517.5 MB RAM, BlockManagerId(driver, localhost, 44435)
16/03/22 16:49:53 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): speech
16/03/22 16:49:53 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:49:53 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:49:53 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:49:53 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:49:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/22 16:49:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/22 16:49:53 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:49:53 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=542590894
16/03/22 16:49:53 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 517.4 MB)
16/03/22 16:49:53 INFO MemoryStore: ensureFreeSpace(4157) called with curMem=6576, maxMem=542590894
16/03/22 16:49:53 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 517.4 MB)
16/03/22 16:49:53 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:44435 (size: 4.1 KB, free: 517.5 MB)
16/03/22 16:49:53 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/22 16:49:53 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:49:53 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/22 16:49:53 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/22 16:49:53 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/22 16:49:53 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/22 16:49:53 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645593685
16/03/22 16:49:53 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/22 16:49:53 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-79245e97-10d9-449d-9e32-64b254883a7d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:49:53 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/22 16:49:53 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10733, maxMem=542590894
16/03/22 16:49:53 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 517.4 MB)
16/03/22 16:49:53 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:44435 (size: 177.0 B, free: 517.5 MB)
16/03/22 16:49:53 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/22 16:49:53 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10910, maxMem=542590894
16/03/22 16:49:53 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 517.4 MB)
16/03/22 16:49:53 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:44435 (size: 187.0 B, free: 517.5 MB)
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: area
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: bend
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: giant
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: astatine
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: present
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  speech  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'('mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: area
, u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: issue
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
mapFunction_Parents(): keyword= speech ; syndef_tokens=16/03/22 16:50:03 INFO PythonRunner: Times: total = 9167, boot = 482, init = 373, finish = 8312
16/03/22 16:50:03 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
 set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: planning
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: permission
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: economy
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: composition
16/03/22 16:50:03 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9257 ms on localhost (1/2)
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: agency
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/22 16:50:03 INFO PythonRunner: Times: total = 9245, boot = 488, init = 485, finish = 8272
16/03/22 16:50:03 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/22 16:50:03 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 9.331 s
16/03/22 16:50:03 INFO DAGScheduler: looking for newly runnable stages
16/03/22 16:50:03 INFO DAGScheduler: running: Set()
16/03/22 16:50:03 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/22 16:50:03 INFO DAGScheduler: failed: Set()
16/03/22 16:50:03 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/22 16:50:03 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/22 16:50:03 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11097, maxMem=542590894
16/03/22 16:50:03 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 517.4 MB)
16/03/22 16:50:03 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16081, maxMem=542590894
16/03/22 16:50:03 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 517.4 MB)
16/03/22 16:50:03 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9318 ms on localhost (2/2)
16/03/22 16:50:03 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/22 16:50:03 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:44435 (size: 3.0 KB, free: 517.4 MB)
16/03/22 16:50:03 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/22 16:50:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:50:03 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/22 16:50:03 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:50:03 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:50:03 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/22 16:50:03 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:50:03 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/22 16:50:03 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:50:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/22 16:50:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
16/03/22 16:50:03 INFO PythonRunner: Times: total = 211, boot = 210, init = 1, finish = 0
16/03/22 16:50:03 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/22 16:50:03 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 240 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'present', 'None']
16/03/22 16:50:03 INFO PythonRunner: Times: total = 319, boot = 318, init = 0, finish = 1
16/03/22 16:50:03 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/22 16:50:03 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 341 ms on localhost (2/2)
16/03/22 16:50:03 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/22 16:50:03 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.341 s
16/03/22 16:50:03 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 9.692136 s
16/03/22 16:50:03 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:50:03 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:50:03 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:50:03 INFO DAGScheduler: Parents of final stage: List()
16/03/22 16:50:03 INFO DAGScheduler: Missing parents: List()
16/03/22 16:50:03 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:50:03 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19137, maxMem=542590894
16/03/22 16:50:03 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 517.4 MB)
16/03/22 16:50:03 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24953, maxMem=542590894
16/03/22 16:50:03 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 517.4 MB)
16/03/22 16:50:03 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:44435 (size: 3.3 KB, free: 517.4 MB)
16/03/22 16:50:03 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/22 16:50:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:50:03 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/22 16:50:03 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/22 16:50:03 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/22 16:50:03 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/22 16:50:03 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/22 16:50:03 INFO PythonRunner: Times: total = 11, boot = -3, init = 14, finish = 0
16/03/22 16:50:03 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1351 bytes result sent to driver
16/03/22 16:50:03 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 65 ms on localhost (1/2)
16/03/22 16:50:03 INFO PythonRunner: Times: total = 164, boot = 164, init = 0, finish = 0
16/03/22 16:50:03 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/22 16:50:03 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 173 ms on localhost (2/2)
16/03/22 16:50:03 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/22 16:50:03 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.161 s
16/03/22 16:50:03 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.199869 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/22 16:50:03 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/22 16:50:03 INFO DAGScheduler: Stopping DAGScheduler
16/03/22 16:50:04 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/22 16:50:04 INFO MemoryStore: MemoryStore cleared
16/03/22 16:50:04 INFO BlockManager: BlockManager stopped
16/03/22 16:50:04 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/22 16:50:04 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/22 16:50:04 INFO SparkContext: Successfully stopped SparkContext
16/03/22 16:50:04 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/22 16:50:04 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/22 16:50:04 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'present', u'None']
16/03/22 16:50:04 INFO SparkContext: Running Spark version 1.5.2
16/03/22 16:50:04 INFO SecurityManager: Changing view acls to: root
16/03/22 16:50:04 INFO SecurityManager: Changing modify acls to: root
16/03/22 16:50:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/22 16:50:04 INFO Slf4jLogger: Slf4jLogger started
16/03/22 16:50:04 INFO Remoting: Starting remoting
16/03/22 16:50:05 INFO Utils: Successfully started service 'sparkDriver' on port 48906.
16/03/22 16:50:05 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:48906]
16/03/22 16:50:05 INFO SparkEnv: Registering MapOutputTracker
16/03/22 16:50:05 INFO SparkEnv: Registering BlockManagerMaster
16/03/22 16:50:05 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e7077b3f-1c0f-4fef-a428-c80490a0420a
16/03/22 16:50:05 INFO MemoryStore: MemoryStore started with capacity 517.5 MB
16/03/22 16:50:05 INFO HttpFileServer: HTTP File server directory is /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/httpd-2d1dc806-916f-49d1-88db-db52fcd486c1
16/03/22 16:50:05 INFO HttpServer: Starting HTTP Server
16/03/22 16:50:05 INFO Utils: Successfully started service 'HTTP file server' on port 40708.
16/03/22 16:50:05 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/22 16:50:05 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/22 16:50:05 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/22 16:50:05 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-145b0755-afc4-4e4f-b072-f6a541c2c212/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:50:05 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645605715
16/03/22 16:50:05 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/22 16:50:05 INFO Executor: Starting executor ID driver on host localhost
16/03/22 16:50:05 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57595.
16/03/22 16:50:05 INFO NettyBlockTransferService: Server created on 57595
16/03/22 16:50:05 INFO BlockManagerMaster: Trying to register BlockManager
16/03/22 16:50:05 INFO BlockManagerMasterEndpoint: Registering block manager localhost:57595 with 517.5 MB RAM, BlockManagerId(driver, localhost, 57595)
16/03/22 16:50:05 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): geographical
16/03/22 16:50:06 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:50:06 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:50:06 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:50:06 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:50:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/22 16:50:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/22 16:50:06 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:50:06 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=542590894
16/03/22 16:50:06 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 517.4 MB)
16/03/22 16:50:06 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=542590894
16/03/22 16:50:06 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 517.4 MB)
16/03/22 16:50:06 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:57595 (size: 4.1 KB, free: 517.5 MB)
16/03/22 16:50:06 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/22 16:50:06 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:50:06 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/22 16:50:06 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/22 16:50:06 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/22 16:50:06 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/22 16:50:06 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645605715
16/03/22 16:50:06 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-145b0755-afc4-4e4f-b072-f6a541c2c212/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:50:06 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/22 16:50:06 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/22 16:50:06 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10732, maxMem=542590894
16/03/22 16:50:06 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 517.4 MB)
16/03/22 16:50:06 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:57595 (size: 177.0 B, free: 517.5 MB)
16/03/22 16:50:06 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/22 16:50:06 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10909, maxMem=542590894
16/03/22 16:50:06 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 517.4 MB)
16/03/22 16:50:06 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:57595 (size: 187.0 B, free: 517.5 MB)
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: set
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: bend
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: giant
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: astatine
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: present
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: area
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  geographical  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/22 16:50:15 INFO PythonRunner: Times: total = 8831, boot = 486, init = 532, finish = 7813
16/03/22 16:50:15 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/22 16:50:15 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8916 ms on localhost (1/2)
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  geographical  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: issue
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: planning
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: permission
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: economy
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: composition
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: agency
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/22 16:50:15 INFO PythonRunner: Times: total = 9170, boot = 494, init = 388, finish = 8288
16/03/22 16:50:15 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/22 16:50:15 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 9.236 s
16/03/22 16:50:15 INFO DAGScheduler: looking for newly runnable stages
16/03/22 16:50:15 INFO DAGScheduler: running: Set()
16/03/22 16:50:15 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/22 16:50:15 INFO DAGScheduler: failed: Set()
16/03/22 16:50:15 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/22 16:50:15 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/22 16:50:15 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=542590894
16/03/22 16:50:15 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 517.4 MB)
16/03/22 16:50:15 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=542590894
16/03/22 16:50:15 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 517.4 MB)
16/03/22 16:50:15 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9232 ms on localhost (2/2)
16/03/22 16:50:15 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/22 16:50:15 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:57595 (size: 3.0 KB, free: 517.4 MB)
16/03/22 16:50:15 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/22 16:50:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:50:15 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/22 16:50:15 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:50:15 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:50:15 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/22 16:50:15 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/22 16:50:15 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:50:15 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:50:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/22 16:50:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
reduceFunction_Parents(): returns= ['None', u'area', u'area']
16/03/22 16:50:15 INFO PythonRunner: Times: total = 30, boot = -145, init = 174, finish = 1
16/03/22 16:50:15 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/22 16:50:15 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 89 ms on localhost (1/2)
16/03/22 16:50:15 INFO PythonRunner: Times: total = 222, boot = 221, init = 1, finish = 0
16/03/22 16:50:15 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/22 16:50:15 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 243 ms on localhost (2/2)
16/03/22 16:50:15 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/22 16:50:15 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.242 s
16/03/22 16:50:15 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 9.523610 s
16/03/22 16:50:15 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:50:15 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:50:15 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:50:15 INFO DAGScheduler: Parents of final stage: List()
16/03/22 16:50:15 INFO DAGScheduler: Missing parents: List()
16/03/22 16:50:15 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:50:15 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=542590894
16/03/22 16:50:15 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 517.4 MB)
16/03/22 16:50:15 INFO MemoryStore: ensureFreeSpace(3377) called with curMem=24952, maxMem=542590894
16/03/22 16:50:15 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 517.4 MB)
16/03/22 16:50:15 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:57595 (size: 3.3 KB, free: 517.4 MB)
16/03/22 16:50:15 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/22 16:50:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:50:15 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/22 16:50:15 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/22 16:50:15 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/22 16:50:15 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/22 16:50:15 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/22 16:50:15 INFO PythonRunner: Times: total = 121, boot = 120, init = 1, finish = 0
16/03/22 16:50:15 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/22 16:50:15 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 128 ms on localhost (1/2)
16/03/22 16:50:15 INFO PythonRunner: Times: total = 133, boot = 133, init = 0, finish = 0
16/03/22 16:50:15 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/03/22 16:50:15 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 143 ms on localhost (2/2)
16/03/22 16:50:15 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/22 16:50:15 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.145 s
16/03/22 16:50:15 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.165687 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/22 16:50:16 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/22 16:50:16 INFO DAGScheduler: Stopping DAGScheduler
16/03/22 16:50:16 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/22 16:50:16 INFO MemoryStore: MemoryStore cleared
16/03/22 16:50:16 INFO BlockManager: BlockManager stopped
16/03/22 16:50:16 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/22 16:50:16 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/22 16:50:16 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/22 16:50:16 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/22 16:50:16 INFO SparkContext: Successfully stopped SparkContext
16/03/22 16:50:16 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'area', u'area']
16/03/22 16:50:16 INFO SparkContext: Running Spark version 1.5.2
16/03/22 16:50:16 INFO SecurityManager: Changing view acls to: root
16/03/22 16:50:16 INFO SecurityManager: Changing modify acls to: root
16/03/22 16:50:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/22 16:50:16 INFO Slf4jLogger: Slf4jLogger started
16/03/22 16:50:16 INFO Remoting: Starting remoting
16/03/22 16:50:17 INFO Utils: Successfully started service 'sparkDriver' on port 45775.
16/03/22 16:50:17 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:45775]
16/03/22 16:50:17 INFO SparkEnv: Registering MapOutputTracker
16/03/22 16:50:17 INFO SparkEnv: Registering BlockManagerMaster
16/03/22 16:50:17 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-4e70db4f-bd89-42dd-ae58-29d65011b206
16/03/22 16:50:17 INFO MemoryStore: MemoryStore started with capacity 523.5 MB
16/03/22 16:50:17 INFO HttpFileServer: HTTP File server directory is /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/httpd-ccdc5753-0b9c-4a58-bddb-82175c3e5e93
16/03/22 16:50:17 INFO HttpServer: Starting HTTP Server
16/03/22 16:50:17 INFO Utils: Successfully started service 'HTTP file server' on port 46171.
16/03/22 16:50:17 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/22 16:50:17 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/22 16:50:17 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/22 16:50:17 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-efe81237-c360-458d-8a1b-0c42fc34eea1/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:50:17 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645617229
16/03/22 16:50:17 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/22 16:50:17 INFO Executor: Starting executor ID driver on host localhost
16/03/22 16:50:17 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43529.
16/03/22 16:50:17 INFO NettyBlockTransferService: Server created on 43529
16/03/22 16:50:17 INFO BlockManagerMaster: Trying to register BlockManager
16/03/22 16:50:17 INFO BlockManagerMasterEndpoint: Registering block manager localhost:43529 with 523.5 MB RAM, BlockManagerId(driver, localhost, 43529)
16/03/22 16:50:17 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): spatial
16/03/22 16:50:17 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:50:17 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:50:17 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:50:17 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:50:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/22 16:50:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/22 16:50:17 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:50:17 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=548960993
16/03/22 16:50:17 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.5 MB)
16/03/22 16:50:17 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=548960993
16/03/22 16:50:17 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.5 MB)
16/03/22 16:50:17 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:43529 (size: 4.1 KB, free: 523.5 MB)
16/03/22 16:50:17 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/22 16:50:17 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:50:17 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/22 16:50:17 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/22 16:50:17 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/22 16:50:17 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/22 16:50:17 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645617229
16/03/22 16:50:17 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/22 16:50:17 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-efe81237-c360-458d-8a1b-0c42fc34eea1/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:50:17 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/22 16:50:17 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10732, maxMem=548960993
16/03/22 16:50:17 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/22 16:50:17 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 523.5 MB)
16/03/22 16:50:17 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:43529 (size: 187.0 B, free: 523.5 MB)
16/03/22 16:50:17 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10919, maxMem=548960993
16/03/22 16:50:17 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 523.5 MB)
16/03/22 16:50:17 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:43529 (size: 177.0 B, free: 523.5 MB)
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: set
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: issue
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: planning
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: permission
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: economy
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: composition
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  spatial  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: agency
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/22 16:50:26 INFO PythonRunner: Times: total = 8784, boot = 480, init = 450, finish = 7854
16/03/22 16:50:26 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/22 16:50:26 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8878 ms on localhost (1/2)
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: bend
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: giant
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: astatine
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: present
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: area
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/22 16:50:26 INFO PythonRunner: Times: total = 9394, boot = 487, init = 443, finish = 8464
16/03/22 16:50:26 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/22 16:50:26 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 9.475 s
16/03/22 16:50:26 INFO DAGScheduler: looking for newly runnable stages
16/03/22 16:50:26 INFO DAGScheduler: running: Set()
16/03/22 16:50:26 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/22 16:50:26 INFO DAGScheduler: failed: Set()
16/03/22 16:50:26 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/22 16:50:26 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/22 16:50:26 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=548960993
16/03/22 16:50:26 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.5 MB)
16/03/22 16:50:26 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=548960993
16/03/22 16:50:26 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.5 MB)
16/03/22 16:50:26 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9473 ms on localhost (2/2)
16/03/22 16:50:26 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/22 16:50:26 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:43529 (size: 3.0 KB, free: 523.5 MB)
16/03/22 16:50:26 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/22 16:50:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:50:26 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/22 16:50:26 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:50:26 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:50:26 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/22 16:50:26 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/22 16:50:26 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:50:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/22 16:50:26 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:50:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
reduceFunction_Parents(): returns= ['None', 'None', u'composition']
16/03/22 16:50:26 INFO PythonRunner: Times: total = 66, boot = -427, init = 493, finish = 0
16/03/22 16:50:26 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1287 bytes result sent to driver
16/03/22 16:50:27 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 95 ms on localhost (1/2)
16/03/22 16:50:27 INFO PythonRunner: Times: total = 205, boot = 204, init = 1, finish = 0
16/03/22 16:50:27 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/22 16:50:27 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 230 ms on localhost (2/2)
16/03/22 16:50:27 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.217 s
16/03/22 16:50:27 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/22 16:50:27 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 9.737432 s
16/03/22 16:50:27 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:50:27 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:50:27 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:50:27 INFO DAGScheduler: Parents of final stage: List()
16/03/22 16:50:27 INFO DAGScheduler: Missing parents: List()
16/03/22 16:50:27 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:50:27 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=548960993
16/03/22 16:50:27 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.5 MB)
16/03/22 16:50:27 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24952, maxMem=548960993
16/03/22 16:50:27 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.5 MB)
16/03/22 16:50:27 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:43529 (size: 3.3 KB, free: 523.5 MB)
16/03/22 16:50:27 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/22 16:50:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:50:27 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/22 16:50:27 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/22 16:50:27 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2368 bytes)
16/03/22 16:50:27 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/22 16:50:27 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/22 16:50:27 INFO PythonRunner: Times: total = 133, boot = 133, init = 0, finish = 0
16/03/22 16:50:27 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1355 bytes result sent to driver
16/03/22 16:50:27 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 147 ms on localhost (1/2)
16/03/22 16:50:27 INFO PythonRunner: Times: total = 150, boot = 150, init = 0, finish = 0
16/03/22 16:50:27 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/22 16:50:27 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 163 ms on localhost (2/2)
16/03/22 16:50:27 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/22 16:50:27 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.163 s
16/03/22 16:50:27 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.185770 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/22 16:50:27 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/22 16:50:27 INFO DAGScheduler: Stopping DAGScheduler
16/03/22 16:50:27 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/22 16:50:27 INFO MemoryStore: MemoryStore cleared
16/03/22 16:50:27 INFO BlockManager: BlockManager stopped
16/03/22 16:50:27 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/22 16:50:27 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/22 16:50:27 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/22 16:50:27 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/22 16:50:27 INFO SparkContext: Successfully stopped SparkContext
16/03/22 16:50:27 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'composition']
16/03/22 16:50:28 INFO SparkContext: Running Spark version 1.5.2
16/03/22 16:50:28 INFO SecurityManager: Changing view acls to: root
16/03/22 16:50:28 INFO SecurityManager: Changing modify acls to: root
16/03/22 16:50:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/22 16:50:28 INFO Slf4jLogger: Slf4jLogger started
16/03/22 16:50:28 INFO Remoting: Starting remoting
16/03/22 16:50:28 INFO Utils: Successfully started service 'sparkDriver' on port 52458.
16/03/22 16:50:28 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:52458]
16/03/22 16:50:28 INFO SparkEnv: Registering MapOutputTracker
16/03/22 16:50:28 INFO SparkEnv: Registering BlockManagerMaster
16/03/22 16:50:28 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-df837b81-0bfc-4d6f-b2af-1e4773a4280d
16/03/22 16:50:28 INFO MemoryStore: MemoryStore started with capacity 523.5 MB
16/03/22 16:50:28 INFO HttpFileServer: HTTP File server directory is /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/httpd-8e63fcb0-5e73-43a3-ac41-9395454dd190
16/03/22 16:50:28 INFO HttpServer: Starting HTTP Server
16/03/22 16:50:28 INFO Utils: Successfully started service 'HTTP file server' on port 50868.
16/03/22 16:50:28 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/22 16:50:28 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/22 16:50:28 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/22 16:50:28 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-07e5c26a-ffed-4ee8-a30c-c5601a19464c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:50:28 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645628852
16/03/22 16:50:28 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/22 16:50:28 INFO Executor: Starting executor ID driver on host localhost
16/03/22 16:50:28 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43460.
16/03/22 16:50:28 INFO NettyBlockTransferService: Server created on 43460
16/03/22 16:50:28 INFO BlockManagerMaster: Trying to register BlockManager
16/03/22 16:50:28 INFO BlockManagerMasterEndpoint: Registering block manager localhost:43460 with 523.5 MB RAM, BlockManagerId(driver, localhost, 43460)
16/03/22 16:50:28 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): Nadu
16/03/22 16:50:29 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:50:29 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:50:29 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:50:29 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:50:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/22 16:50:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/22 16:50:29 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:50:29 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=548960993
16/03/22 16:50:29 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.5 MB)
16/03/22 16:50:29 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=548960993
16/03/22 16:50:29 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.5 MB)
16/03/22 16:50:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:43460 (size: 4.1 KB, free: 523.5 MB)
16/03/22 16:50:29 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/22 16:50:29 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:50:29 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/22 16:50:29 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/22 16:50:29 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/22 16:50:29 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/22 16:50:29 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645628852
16/03/22 16:50:29 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/22 16:50:29 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-07e5c26a-ffed-4ee8-a30c-c5601a19464c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:50:29 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/22 16:50:29 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10732, maxMem=548960993
16/03/22 16:50:29 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 523.5 MB)
16/03/22 16:50:29 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/22 16:50:29 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:43460 (size: 187.0 B, free: 523.5 MB)
16/03/22 16:50:29 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10919, maxMem=548960993
16/03/22 16:50:29 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 523.5 MB)
16/03/22 16:50:29 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:43460 (size: 177.0 B, free: 523.5 MB)
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: set
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: issue
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: planning
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: permission
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: economy
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: composition
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: agency
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Nadu  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/22 16:50:38 INFO PythonRunner: Times: total = 9618, boot = 488, init = 390, finish = 8740
16/03/22 16:50:38 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/22 16:50:38 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9711 ms on localhost (1/2)
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: bend
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: giant
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: astatine
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: present
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Nadu  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: area
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/22 16:50:39 INFO PythonRunner: Times: total = 10089, boot = 491, init = 493, finish = 9105
16/03/22 16:50:39 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/22 16:50:39 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 10.177 s
16/03/22 16:50:39 INFO DAGScheduler: looking for newly runnable stages
16/03/22 16:50:39 INFO DAGScheduler: running: Set()
16/03/22 16:50:39 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/22 16:50:39 INFO DAGScheduler: failed: Set()
16/03/22 16:50:39 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/22 16:50:39 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/22 16:50:39 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 10183 ms on localhost (2/2)
16/03/22 16:50:39 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/22 16:50:39 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=548960993
16/03/22 16:50:39 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.5 MB)
16/03/22 16:50:39 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=548960993
16/03/22 16:50:39 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.5 MB)
16/03/22 16:50:39 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:43460 (size: 3.0 KB, free: 523.5 MB)
16/03/22 16:50:39 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/22 16:50:39 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:50:39 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/22 16:50:39 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:50:39 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:50:39 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/22 16:50:39 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:50:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/22 16:50:39 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/22 16:50:39 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:50:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'Chennai', 'None', u'Chennai']
16/03/22 16:50:39 INFO PythonRunner: Times: total = 48, boot = -230, init = 277, finish = 1
16/03/22 16:50:39 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1297 bytes result sent to driver
16/03/22 16:50:39 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 147 ms on localhost (1/2)
16/03/22 16:50:39 INFO PythonRunner: Times: total = 380, boot = 379, init = 0, finish = 1
16/03/22 16:50:39 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/22 16:50:39 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 395 ms on localhost (2/2)
16/03/22 16:50:39 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.381 s
16/03/22 16:50:39 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/22 16:50:39 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 10.624127 s
16/03/22 16:50:39 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:50:39 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:50:39 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:50:39 INFO DAGScheduler: Parents of final stage: List()
16/03/22 16:50:39 INFO DAGScheduler: Missing parents: List()
16/03/22 16:50:39 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:50:39 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=548960993
16/03/22 16:50:39 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.5 MB)
16/03/22 16:50:39 INFO MemoryStore: ensureFreeSpace(3377) called with curMem=24952, maxMem=548960993
16/03/22 16:50:39 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.5 MB)
16/03/22 16:50:39 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:43460 (size: 3.3 KB, free: 523.5 MB)
16/03/22 16:50:39 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/22 16:50:39 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:50:39 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/22 16:50:39 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/22 16:50:39 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2378 bytes)
16/03/22 16:50:39 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/22 16:50:39 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/22 16:50:39 INFO PythonRunner: Times: total = 72, boot = -239, init = 311, finish = 0
16/03/22 16:50:39 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/22 16:50:39 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 105 ms on localhost (1/2)
16/03/22 16:50:39 INFO PythonRunner: Times: total = 123, boot = 123, init = 0, finish = 0
16/03/22 16:50:39 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1365 bytes result sent to driver
16/03/22 16:50:39 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 151 ms on localhost (2/2)
16/03/22 16:50:39 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/22 16:50:39 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.119 s
16/03/22 16:50:39 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.171878 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/22 16:50:40 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/22 16:50:40 INFO DAGScheduler: Stopping DAGScheduler
16/03/22 16:50:40 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/22 16:50:40 INFO MemoryStore: MemoryStore cleared
16/03/22 16:50:40 INFO BlockManager: BlockManager stopped
16/03/22 16:50:40 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/22 16:50:40 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/22 16:50:40 INFO SparkContext: Successfully stopped SparkContext
16/03/22 16:50:40 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/22 16:50:40 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/22 16:50:40 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'Chennai', u'None', u'Chennai']
16/03/22 16:50:40 INFO SparkContext: Running Spark version 1.5.2
16/03/22 16:50:40 INFO SecurityManager: Changing view acls to: root
16/03/22 16:50:40 INFO SecurityManager: Changing modify acls to: root
16/03/22 16:50:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/22 16:50:41 INFO Slf4jLogger: Slf4jLogger started
16/03/22 16:50:41 INFO Remoting: Starting remoting
16/03/22 16:50:41 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:47254]
16/03/22 16:50:41 INFO Utils: Successfully started service 'sparkDriver' on port 47254.
16/03/22 16:50:41 INFO SparkEnv: Registering MapOutputTracker
16/03/22 16:50:41 INFO SparkEnv: Registering BlockManagerMaster
16/03/22 16:50:41 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e7b26c84-c010-4133-807b-0077f0f9667b
16/03/22 16:50:41 INFO MemoryStore: MemoryStore started with capacity 523.8 MB
16/03/22 16:50:41 INFO HttpFileServer: HTTP File server directory is /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/httpd-d37dc476-2a06-4ec1-a24a-cf7a1e59ba10
16/03/22 16:50:41 INFO HttpServer: Starting HTTP Server
16/03/22 16:50:41 INFO Utils: Successfully started service 'HTTP file server' on port 37645.
16/03/22 16:50:41 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/22 16:50:41 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/22 16:50:41 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/22 16:50:41 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-44d2d1ac-3f9b-4a95-88e7-6e48d4dc9d85/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:50:41 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645641444
16/03/22 16:50:41 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/22 16:50:41 INFO Executor: Starting executor ID driver on host localhost
16/03/22 16:50:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53460.
16/03/22 16:50:41 INFO NettyBlockTransferService: Server created on 53460
16/03/22 16:50:41 INFO BlockManagerMaster: Trying to register BlockManager
16/03/22 16:50:41 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53460 with 523.8 MB RAM, BlockManagerId(driver, localhost, 53460)
16/03/22 16:50:41 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): circular
16/03/22 16:50:41 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:50:41 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:50:41 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:50:41 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:50:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/22 16:50:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/22 16:50:41 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:50:41 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=549244108
16/03/22 16:50:41 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.8 MB)
16/03/22 16:50:41 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=549244108
16/03/22 16:50:41 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.8 MB)
16/03/22 16:50:41 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53460 (size: 4.1 KB, free: 523.8 MB)
16/03/22 16:50:41 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/22 16:50:41 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:50:41 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/22 16:50:41 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/22 16:50:41 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/22 16:50:41 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/22 16:50:41 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645641444
16/03/22 16:50:41 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/22 16:50:41 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-44d2d1ac-3f9b-4a95-88e7-6e48d4dc9d85/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:50:41 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/22 16:50:41 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10732, maxMem=549244108
16/03/22 16:50:41 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 523.8 MB)
16/03/22 16:50:41 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:53460 (size: 187.0 B, free: 523.8 MB)
16/03/22 16:50:41 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/22 16:50:41 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10919, maxMem=549244108
16/03/22 16:50:41 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 523.8 MB)
16/03/22 16:50:41 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:53460 (size: 177.0 B, free: 523.8 MB)
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: set
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: issue
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: planning
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: permission
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: economy
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: composition
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: agency
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/22 16:50:50 INFO PythonRunner: Times: total = 9282, boot = 577, init = 449, finish = 8256
16/03/22 16:50:50 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/22 16:50:51 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9384 ms on localhost (1/2)
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: bend
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): adding to parents: syn =  Synset('bend.n.01') ; keyword:  circular  in syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= [u'bend']
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: giant
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: astatine
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: present
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: area
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
16/03/22 16:50:51 INFO PythonRunner: Times: total = 9841, boot = 565, init = 477, finish = 8799
16/03/22 16:50:51 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/22 16:50:51 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9977 ms on localhost (2/2)
16/03/22 16:50:51 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 9.978 s
16/03/22 16:50:51 INFO DAGScheduler: looking for newly runnable stages
16/03/22 16:50:51 INFO DAGScheduler: running: Set()
16/03/22 16:50:51 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/22 16:50:51 INFO DAGScheduler: failed: Set()
16/03/22 16:50:51 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/22 16:50:51 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/22 16:50:51 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=549244108
16/03/22 16:50:51 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.8 MB)
16/03/22 16:50:51 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=549244108
16/03/22 16:50:51 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.8 MB)
16/03/22 16:50:51 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/22 16:50:51 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53460 (size: 3.0 KB, free: 523.8 MB)
16/03/22 16:50:51 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/22 16:50:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:50:51 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/22 16:50:51 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:50:51 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:50:51 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/22 16:50:51 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/22 16:50:51 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:50:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
16/03/22 16:50:51 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:50:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
16/03/22 16:50:51 INFO PythonRunner: Times: total = 50, boot = -394, init = 444, finish = 0
16/03/22 16:50:51 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1272 bytes result sent to driver
reduceFunction_Parents(): returns= [u'bend', 'None']
16/03/22 16:50:51 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 82 ms on localhost (1/2)
16/03/22 16:50:51 INFO PythonRunner: Times: total = 257, boot = 256, init = 1, finish = 0
16/03/22 16:50:51 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/22 16:50:51 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 286 ms on localhost (2/2)
16/03/22 16:50:51 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.289 s
16/03/22 16:50:51 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/22 16:50:51 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 10.311184 s
16/03/22 16:50:52 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:50:52 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:50:52 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:50:52 INFO DAGScheduler: Parents of final stage: List()
16/03/22 16:50:52 INFO DAGScheduler: Missing parents: List()
16/03/22 16:50:52 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:50:52 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=549244108
16/03/22 16:50:52 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.8 MB)
16/03/22 16:50:52 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24952, maxMem=549244108
16/03/22 16:50:52 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.8 MB)
16/03/22 16:50:52 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53460 (size: 3.3 KB, free: 523.8 MB)
16/03/22 16:50:52 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/22 16:50:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:50:52 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/22 16:50:52 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/22 16:50:52 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2353 bytes)
16/03/22 16:50:52 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/22 16:50:52 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/22 16:50:52 INFO PythonRunner: Times: total = 62, boot = 62, init = 0, finish = 0
16/03/22 16:50:52 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1337 bytes result sent to driver
16/03/22 16:50:52 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 76 ms on localhost (1/2)
16/03/22 16:50:52 INFO PythonRunner: Times: total = 69, boot = -10, init = 79, finish = 0
16/03/22 16:50:52 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/22 16:50:52 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 80 ms on localhost (2/2)
16/03/22 16:50:52 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/22 16:50:52 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.081 s
16/03/22 16:50:52 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.112872 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/22 16:50:52 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/22 16:50:52 INFO DAGScheduler: Stopping DAGScheduler
16/03/22 16:50:52 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/22 16:50:52 INFO MemoryStore: MemoryStore cleared
16/03/22 16:50:52 INFO BlockManager: BlockManager stopped
16/03/22 16:50:52 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/22 16:50:52 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/22 16:50:52 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/22 16:50:52 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/22 16:50:52 INFO SparkContext: Successfully stopped SparkContext
16/03/22 16:50:52 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'bend', u'None']
16/03/22 16:50:53 INFO SparkContext: Running Spark version 1.5.2
16/03/22 16:50:53 INFO SecurityManager: Changing view acls to: root
16/03/22 16:50:53 INFO SecurityManager: Changing modify acls to: root
16/03/22 16:50:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/22 16:50:53 INFO Slf4jLogger: Slf4jLogger started
16/03/22 16:50:53 INFO Remoting: Starting remoting
16/03/22 16:50:53 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:59205]
16/03/22 16:50:53 INFO Utils: Successfully started service 'sparkDriver' on port 59205.
16/03/22 16:50:53 INFO SparkEnv: Registering MapOutputTracker
16/03/22 16:50:53 INFO SparkEnv: Registering BlockManagerMaster
16/03/22 16:50:53 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-36cca775-e596-479f-b126-c85ccf9271ec
16/03/22 16:50:53 INFO MemoryStore: MemoryStore started with capacity 523.8 MB
16/03/22 16:50:53 INFO HttpFileServer: HTTP File server directory is /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/httpd-f65d88ec-9ac1-44d1-8446-c421527ab018
16/03/22 16:50:53 INFO HttpServer: Starting HTTP Server
16/03/22 16:50:53 INFO Utils: Successfully started service 'HTTP file server' on port 49612.
16/03/22 16:50:53 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/22 16:50:54 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/22 16:50:54 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/22 16:50:54 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-20fc884b-abc7-443c-82b3-cb35d8b329b2/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:50:54 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645654100
16/03/22 16:50:54 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/22 16:50:54 INFO Executor: Starting executor ID driver on host localhost
16/03/22 16:50:54 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33169.
16/03/22 16:50:54 INFO NettyBlockTransferService: Server created on 33169
16/03/22 16:50:54 INFO BlockManagerMaster: Trying to register BlockManager
16/03/22 16:50:54 INFO BlockManagerMasterEndpoint: Registering block manager localhost:33169 with 523.8 MB RAM, BlockManagerId(driver, localhost, 33169)
16/03/22 16:50:54 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): product
16/03/22 16:50:54 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:50:54 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:50:54 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:50:54 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:50:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/22 16:50:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/22 16:50:54 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:50:54 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=549244108
16/03/22 16:50:54 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.8 MB)
16/03/22 16:50:54 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=549244108
16/03/22 16:50:54 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.8 MB)
16/03/22 16:50:54 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:33169 (size: 4.1 KB, free: 523.8 MB)
16/03/22 16:50:54 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/22 16:50:54 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:50:54 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/22 16:50:54 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/22 16:50:54 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/22 16:50:54 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/22 16:50:54 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645654100
16/03/22 16:50:54 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/22 16:50:54 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-20fc884b-abc7-443c-82b3-cb35d8b329b2/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:50:54 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/22 16:50:54 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10732, maxMem=549244108
16/03/22 16:50:54 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 523.8 MB)
16/03/22 16:50:54 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:33169 (size: 187.0 B, free: 523.8 MB)
16/03/22 16:50:54 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/22 16:50:54 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10919, maxMem=549244108
16/03/22 16:50:54 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 523.8 MB)
16/03/22 16:50:54 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:33169 (size: 177.0 B, free: 523.8 MB)
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: set
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: issue
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: planning
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: permission
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: economy
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: composition
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: agency
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/22 16:51:03 INFO PythonRunner: Times: total = 8741, boot = 508, init = 394, finish = 7839
16/03/22 16:51:03 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/22 16:51:03 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8857 ms on localhost (1/2)
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: bend
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: giant
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: astatine
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  product  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: present
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: area
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/22 16:51:03 INFO PythonRunner: Times: total = 9480, boot = 517, init = 483, finish = 8480
16/03/22 16:51:03 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/22 16:51:03 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 9.579 s
16/03/22 16:51:03 INFO DAGScheduler: looking for newly runnable stages
16/03/22 16:51:03 INFO DAGScheduler: running: Set()
16/03/22 16:51:03 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/22 16:51:03 INFO DAGScheduler: failed: Set()
16/03/22 16:51:03 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/22 16:51:03 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/22 16:51:03 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=549244108
16/03/22 16:51:03 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.8 MB)
16/03/22 16:51:03 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9593 ms on localhost (2/2)
16/03/22 16:51:03 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/22 16:51:03 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=549244108
16/03/22 16:51:03 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.8 MB)
16/03/22 16:51:03 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:33169 (size: 3.0 KB, free: 523.8 MB)
16/03/22 16:51:03 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/22 16:51:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:51:03 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/22 16:51:03 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:51:03 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:51:03 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/22 16:51:03 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/22 16:51:03 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:51:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/22 16:51:03 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:51:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
reduceFunction_Parents(): returns= ['None', u'astatine', 'None']
16/03/22 16:51:03 INFO PythonRunner: Times: total = 40, boot = -518, init = 557, finish = 1
16/03/22 16:51:03 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/03/22 16:51:04 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 89 ms on localhost (1/2)
16/03/22 16:51:04 INFO PythonRunner: Times: total = 256, boot = 255, init = 1, finish = 0
16/03/22 16:51:04 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/22 16:51:04 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.283 s
16/03/22 16:51:04 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 9.910255 s
16/03/22 16:51:04 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 275 ms on localhost (2/2)
16/03/22 16:51:04 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/22 16:51:04 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:51:04 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:51:04 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:51:04 INFO DAGScheduler: Parents of final stage: List()
16/03/22 16:51:04 INFO DAGScheduler: Missing parents: List()
16/03/22 16:51:04 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:51:04 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=549244108
16/03/22 16:51:04 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.8 MB)
16/03/22 16:51:04 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24952, maxMem=549244108
16/03/22 16:51:04 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.8 MB)
16/03/22 16:51:04 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:33169 (size: 3.3 KB, free: 523.8 MB)
16/03/22 16:51:04 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/22 16:51:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:51:04 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/22 16:51:04 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/22 16:51:04 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/03/22 16:51:04 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/22 16:51:04 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/22 16:51:04 INFO PythonRunner: Times: total = 65, boot = -90, init = 155, finish = 0
16/03/22 16:51:04 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/03/22 16:51:04 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 74 ms on localhost (1/2)
16/03/22 16:51:04 INFO PythonRunner: Times: total = 207, boot = 206, init = 1, finish = 0
16/03/22 16:51:04 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/22 16:51:04 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 219 ms on localhost (2/2)
16/03/22 16:51:04 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/22 16:51:04 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.202 s
16/03/22 16:51:04 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.233874 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/22 16:51:04 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/22 16:51:04 INFO DAGScheduler: Stopping DAGScheduler
16/03/22 16:51:04 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/22 16:51:04 INFO MemoryStore: MemoryStore cleared
16/03/22 16:51:04 INFO BlockManager: BlockManager stopped
16/03/22 16:51:04 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/22 16:51:04 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/22 16:51:04 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/22 16:51:04 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/22 16:51:04 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/22 16:51:04 INFO SparkContext: Successfully stopped SparkContext
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'astatine', u'None']
16/03/22 16:51:05 INFO SparkContext: Running Spark version 1.5.2
16/03/22 16:51:05 INFO SecurityManager: Changing view acls to: root
16/03/22 16:51:05 INFO SecurityManager: Changing modify acls to: root
16/03/22 16:51:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/22 16:51:05 INFO Slf4jLogger: Slf4jLogger started
16/03/22 16:51:05 INFO Remoting: Starting remoting
16/03/22 16:51:05 INFO Utils: Successfully started service 'sparkDriver' on port 44797.
16/03/22 16:51:05 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:44797]
16/03/22 16:51:05 INFO SparkEnv: Registering MapOutputTracker
16/03/22 16:51:05 INFO SparkEnv: Registering BlockManagerMaster
16/03/22 16:51:05 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-bfb4331f-0011-4adb-9832-cf496f34e2c7
16/03/22 16:51:05 INFO MemoryStore: MemoryStore started with capacity 523.8 MB
16/03/22 16:51:05 INFO HttpFileServer: HTTP File server directory is /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/httpd-c1d169ae-523f-4406-88d5-b9c635340a4a
16/03/22 16:51:05 INFO HttpServer: Starting HTTP Server
16/03/22 16:51:05 INFO Utils: Successfully started service 'HTTP file server' on port 35247.
16/03/22 16:51:05 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/22 16:51:06 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/22 16:51:06 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/22 16:51:06 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-524ea624-c4bd-4f47-9f50-0ca042b01b71/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:51:06 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645666368
16/03/22 16:51:06 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/22 16:51:06 INFO Executor: Starting executor ID driver on host localhost
16/03/22 16:51:06 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55327.
16/03/22 16:51:06 INFO NettyBlockTransferService: Server created on 55327
16/03/22 16:51:06 INFO BlockManagerMaster: Trying to register BlockManager
16/03/22 16:51:06 INFO BlockManagerMasterEndpoint: Registering block manager localhost:55327 with 523.8 MB RAM, BlockManagerId(driver, localhost, 55327)
16/03/22 16:51:06 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): used
16/03/22 16:51:06 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:51:06 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:51:06 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:51:06 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:51:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/22 16:51:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/22 16:51:06 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:51:06 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=549244108
16/03/22 16:51:06 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.8 MB)
16/03/22 16:51:06 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=549244108
16/03/22 16:51:06 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.8 MB)
16/03/22 16:51:06 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:55327 (size: 4.1 KB, free: 523.8 MB)
16/03/22 16:51:06 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/22 16:51:06 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:51:06 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/22 16:51:06 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/22 16:51:06 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/22 16:51:06 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/22 16:51:06 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645666368
16/03/22 16:51:06 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/22 16:51:06 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-524ea624-c4bd-4f47-9f50-0ca042b01b71/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:51:06 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/22 16:51:06 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10732, maxMem=549244108
16/03/22 16:51:06 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 523.8 MB)
16/03/22 16:51:06 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:55327 (size: 177.0 B, free: 523.8 MB)
16/03/22 16:51:06 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/22 16:51:06 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10909, maxMem=549244108
16/03/22 16:51:06 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 523.8 MB)
16/03/22 16:51:06 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:55327 (size: 187.0 B, free: 523.8 MB)
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: area
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  Synset('set.n.01') ; keyword:  used  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: bend
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: giant
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: astatine
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: present
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: area
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
16/03/22 16:51:15 INFO PythonRunner: Times: total = 8841, boot = 484, init = 405, finish = 7952
16/03/22 16:51:15 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/22 16:51:15 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8948 ms on localhost (1/2)
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: issue
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: planning
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: permission
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: economy
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: composition
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: agency
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/22 16:51:16 INFO PythonRunner: Times: total = 9603, boot = 484, init = 470, finish = 8649
16/03/22 16:51:16 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/22 16:51:16 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 9.702 s
16/03/22 16:51:16 INFO DAGScheduler: looking for newly runnable stages
16/03/22 16:51:16 INFO DAGScheduler: running: Set()
16/03/22 16:51:16 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/22 16:51:16 INFO DAGScheduler: failed: Set()
16/03/22 16:51:16 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/22 16:51:16 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/22 16:51:16 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=549244108
16/03/22 16:51:16 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.8 MB)
16/03/22 16:51:16 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=549244108
16/03/22 16:51:16 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.8 MB)
16/03/22 16:51:16 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9700 ms on localhost (2/2)
16/03/22 16:51:16 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/22 16:51:16 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:55327 (size: 3.0 KB, free: 523.8 MB)
16/03/22 16:51:16 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/22 16:51:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:51:16 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/22 16:51:16 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:51:16 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:51:16 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/22 16:51:16 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/22 16:51:16 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:51:16 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:51:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/22 16:51:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= [u'set', 'None']
16/03/22 16:51:16 INFO PythonRunner: Times: total = 38, boot = -571, init = 608, finish = 1
16/03/22 16:51:16 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1271 bytes result sent to driver
16/03/22 16:51:16 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 71 ms on localhost (1/2)
16/03/22 16:51:16 INFO PythonRunner: Times: total = 212, boot = 211, init = 1, finish = 0
16/03/22 16:51:16 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/22 16:51:16 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.244 s
16/03/22 16:51:16 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 9.978766 s
16/03/22 16:51:16 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 243 ms on localhost (2/2)
16/03/22 16:51:16 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/22 16:51:16 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:55327 in memory (size: 4.1 KB, free: 523.8 MB)
16/03/22 16:51:16 INFO ContextCleaner: Cleaned accumulator 350
16/03/22 16:51:17 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:51:17 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:51:17 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:51:17 INFO DAGScheduler: Parents of final stage: List()
16/03/22 16:51:17 INFO DAGScheduler: Missing parents: List()
16/03/22 16:51:17 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:51:17 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=8404, maxMem=549244108
16/03/22 16:51:17 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.8 MB)
16/03/22 16:51:17 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=14220, maxMem=549244108
16/03/22 16:51:17 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.8 MB)
16/03/22 16:51:17 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:55327 (size: 3.3 KB, free: 523.8 MB)
16/03/22 16:51:17 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/22 16:51:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:51:17 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/22 16:51:17 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/22 16:51:17 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/22 16:51:17 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/22 16:51:17 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/22 16:51:17 INFO PythonRunner: Times: total = 46, boot = -232, init = 278, finish = 0
16/03/22 16:51:17 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/22 16:51:17 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 52 ms on localhost (1/2)
16/03/22 16:51:17 INFO PythonRunner: Times: total = 54, boot = -307, init = 361, finish = 0
16/03/22 16:51:17 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1336 bytes result sent to driver
16/03/22 16:51:17 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 72 ms on localhost (2/2)
16/03/22 16:51:17 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/22 16:51:17 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.073 s
16/03/22 16:51:17 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.090858 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/22 16:51:17 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/22 16:51:17 INFO DAGScheduler: Stopping DAGScheduler
16/03/22 16:51:17 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/22 16:51:17 INFO MemoryStore: MemoryStore cleared
16/03/22 16:51:17 INFO BlockManager: BlockManager stopped
16/03/22 16:51:17 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/22 16:51:17 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/22 16:51:17 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/22 16:51:17 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/22 16:51:17 INFO SparkContext: Successfully stopped SparkContext
16/03/22 16:51:17 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'set', u'None']
16/03/22 16:51:18 INFO SparkContext: Running Spark version 1.5.2
16/03/22 16:51:18 INFO SecurityManager: Changing view acls to: root
16/03/22 16:51:18 INFO SecurityManager: Changing modify acls to: root
16/03/22 16:51:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/22 16:51:18 INFO Slf4jLogger: Slf4jLogger started
16/03/22 16:51:18 INFO Remoting: Starting remoting
16/03/22 16:51:18 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:38705]
16/03/22 16:51:18 INFO Utils: Successfully started service 'sparkDriver' on port 38705.
16/03/22 16:51:18 INFO SparkEnv: Registering MapOutputTracker
16/03/22 16:51:18 INFO SparkEnv: Registering BlockManagerMaster
16/03/22 16:51:18 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9e48b1ec-7b55-47e9-82be-7d4191c5b079
16/03/22 16:51:18 INFO MemoryStore: MemoryStore started with capacity 524.2 MB
16/03/22 16:51:18 INFO HttpFileServer: HTTP File server directory is /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/httpd-65fc178c-9b69-4d47-ae9f-981db927cdf1
16/03/22 16:51:18 INFO HttpServer: Starting HTTP Server
16/03/22 16:51:18 INFO Utils: Successfully started service 'HTTP file server' on port 53823.
16/03/22 16:51:18 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/22 16:51:18 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/22 16:51:18 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/22 16:51:18 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-90ba5025-71b5-4a1c-8487-b62e5ddff74c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:51:18 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645678946
16/03/22 16:51:18 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/22 16:51:18 INFO Executor: Starting executor ID driver on host localhost
16/03/22 16:51:19 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34192.
16/03/22 16:51:19 INFO NettyBlockTransferService: Server created on 34192
16/03/22 16:51:19 INFO BlockManagerMaster: Trying to register BlockManager
16/03/22 16:51:19 INFO BlockManagerMasterEndpoint: Registering block manager localhost:34192 with 524.2 MB RAM, BlockManagerId(driver, localhost, 34192)
16/03/22 16:51:19 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): usually
16/03/22 16:51:19 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:51:19 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:51:19 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:51:19 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:51:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/22 16:51:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/22 16:51:19 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:51:19 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=549668782
16/03/22 16:51:19 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 524.2 MB)
16/03/22 16:51:19 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=549668782
16/03/22 16:51:19 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 524.2 MB)
16/03/22 16:51:19 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:34192 (size: 4.1 KB, free: 524.2 MB)
16/03/22 16:51:19 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/22 16:51:19 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:51:19 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/22 16:51:19 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/22 16:51:19 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/22 16:51:19 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/22 16:51:19 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645678946
16/03/22 16:51:19 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/22 16:51:19 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-90ba5025-71b5-4a1c-8487-b62e5ddff74c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:51:19 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/22 16:51:19 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10732, maxMem=549668782
16/03/22 16:51:19 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 524.2 MB)
16/03/22 16:51:19 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:34192 (size: 187.0 B, free: 524.2 MB)
16/03/22 16:51:19 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/22 16:51:19 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10919, maxMem=549668782
16/03/22 16:51:19 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 524.2 MB)
16/03/22 16:51:19 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:34192 (size: 177.0 B, free: 524.2 MB)
asfer_pickle_string_load(): picklef.readlines():asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: area
 usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: set
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn = mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: bend
 Synset('area.n.01') ; keyword:  usually  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: issue
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: giant
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: astatine
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: present
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: planning
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: area
mapFunction_Parents(): keyword= mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  usually  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
usually ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: permission
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: economy
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: composition
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: agency
16/03/22 16:51:31 INFO PythonRunner: Times: total = 12801, boot = 2978, init = 1330, finish = 8493
16/03/22 16:51:32 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/22 16:51:32 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 12877 ms on localhost (1/2)
16/03/22 16:51:32 INFO PythonRunner: Times: total = 12860, boot = 2973, init = 1336, finish = 8551
16/03/22 16:51:32 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/22 16:51:32 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 12945 ms on localhost (2/2)
16/03/22 16:51:32 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/22 16:51:32 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 12.947 s
16/03/22 16:51:32 INFO DAGScheduler: looking for newly runnable stages
16/03/22 16:51:32 INFO DAGScheduler: running: Set()
16/03/22 16:51:32 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/22 16:51:32 INFO DAGScheduler: failed: Set()
16/03/22 16:51:32 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/22 16:51:32 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/22 16:51:32 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=549668782
16/03/22 16:51:32 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 524.2 MB)
16/03/22 16:51:32 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=549668782
16/03/22 16:51:32 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 524.2 MB)
16/03/22 16:51:32 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:34192 (size: 3.0 KB, free: 524.2 MB)
16/03/22 16:51:32 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/22 16:51:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:51:32 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/22 16:51:32 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:51:32 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:51:32 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/22 16:51:32 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/22 16:51:32 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:51:32 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:51:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/22 16:51:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
reduceFunction_Parents(): returns= ['None', u'area', u'area']
16/03/22 16:51:32 INFO PythonRunner: Times: total = 213, boot = 212, init = 0, finish = 1
16/03/22 16:51:32 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/22 16:51:32 INFO PythonRunner: Times: total = 246, boot = 246, init = 0, finish = 0
16/03/22 16:51:32 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/22 16:51:32 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 245 ms on localhost (1/2)
16/03/22 16:51:32 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 282 ms on localhost (2/2)
16/03/22 16:51:32 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.283 s
16/03/22 16:51:32 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/22 16:51:32 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 13.256607 s
16/03/22 16:51:32 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:51:32 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:51:32 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:51:32 INFO DAGScheduler: Parents of final stage: List()
16/03/22 16:51:32 INFO DAGScheduler: Missing parents: List()
16/03/22 16:51:32 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:51:32 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=549668782
16/03/22 16:51:32 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 524.2 MB)
16/03/22 16:51:32 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24952, maxMem=549668782
16/03/22 16:51:32 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 524.2 MB)
16/03/22 16:51:32 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:34192 (size: 3.3 KB, free: 524.2 MB)
16/03/22 16:51:32 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/22 16:51:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:51:32 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/22 16:51:32 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/22 16:51:32 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/22 16:51:32 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/22 16:51:32 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/22 16:51:32 INFO PythonRunner: Times: total = 139, boot = 139, init = 0, finish = 0
16/03/22 16:51:32 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/22 16:51:32 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 150 ms on localhost (1/2)
16/03/22 16:51:32 INFO PythonRunner: Times: total = 225, boot = 224, init = 1, finish = 0
16/03/22 16:51:32 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/03/22 16:51:32 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 240 ms on localhost (2/2)
16/03/22 16:51:32 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/22 16:51:32 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.214 s
16/03/22 16:51:32 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.253127 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/22 16:51:32 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/22 16:51:32 INFO DAGScheduler: Stopping DAGScheduler
16/03/22 16:51:32 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/22 16:51:32 INFO MemoryStore: MemoryStore cleared
16/03/22 16:51:32 INFO BlockManager: BlockManager stopped
16/03/22 16:51:32 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/22 16:51:32 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/22 16:51:32 INFO SparkContext: Successfully stopped SparkContext
16/03/22 16:51:32 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/22 16:51:32 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/22 16:51:32 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'area', u'area']
16/03/22 16:51:33 INFO SparkContext: Running Spark version 1.5.2
16/03/22 16:51:33 INFO SecurityManager: Changing view acls to: root
16/03/22 16:51:33 INFO SecurityManager: Changing modify acls to: root
16/03/22 16:51:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/22 16:51:33 INFO Slf4jLogger: Slf4jLogger started
16/03/22 16:51:33 INFO Remoting: Starting remoting
16/03/22 16:51:33 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:53348]
16/03/22 16:51:33 INFO Utils: Successfully started service 'sparkDriver' on port 53348.
16/03/22 16:51:33 INFO SparkEnv: Registering MapOutputTracker
16/03/22 16:51:33 INFO SparkEnv: Registering BlockManagerMaster
16/03/22 16:51:33 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-bf5ca3ff-9c9e-47ea-8bdd-1a894578b45e
16/03/22 16:51:33 INFO MemoryStore: MemoryStore started with capacity 524.2 MB
16/03/22 16:51:33 INFO HttpFileServer: HTTP File server directory is /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/httpd-0020553c-b5dd-4641-aa84-8ca0460df537
16/03/22 16:51:33 INFO HttpServer: Starting HTTP Server
16/03/22 16:51:33 INFO Utils: Successfully started service 'HTTP file server' on port 54055.
16/03/22 16:51:34 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/22 16:51:34 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/22 16:51:34 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/22 16:51:34 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-2f7034e0-6ead-4eed-a7ec-ec91d8444431/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:51:34 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645694652
16/03/22 16:51:34 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/22 16:51:34 INFO Executor: Starting executor ID driver on host localhost
16/03/22 16:51:34 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38997.
16/03/22 16:51:34 INFO NettyBlockTransferService: Server created on 38997
16/03/22 16:51:34 INFO BlockManagerMaster: Trying to register BlockManager
16/03/22 16:51:34 INFO BlockManagerMasterEndpoint: Registering block manager localhost:38997 with 524.2 MB RAM, BlockManagerId(driver, localhost, 38997)
16/03/22 16:51:34 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): moment
16/03/22 16:51:34 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:51:34 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:51:34 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:51:34 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:51:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/22 16:51:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/22 16:51:34 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:51:34 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=549668782
16/03/22 16:51:34 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 524.2 MB)
16/03/22 16:51:34 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=549668782
16/03/22 16:51:34 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 524.2 MB)
16/03/22 16:51:34 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:38997 (size: 4.1 KB, free: 524.2 MB)
16/03/22 16:51:34 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/22 16:51:34 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:51:34 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/22 16:51:34 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/22 16:51:34 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/22 16:51:34 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/22 16:51:34 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645694652
16/03/22 16:51:34 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/22 16:51:34 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-2f7034e0-6ead-4eed-a7ec-ec91d8444431/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:51:34 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/22 16:51:34 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/22 16:51:34 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10732, maxMem=549668782
16/03/22 16:51:34 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 524.2 MB)
16/03/22 16:51:34 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:38997 (size: 187.0 B, free: 524.2 MB)
16/03/22 16:51:34 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10919, maxMem=549668782
16/03/22 16:51:34 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 524.2 MB)
16/03/22 16:51:34 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:38997 (size: 177.0 B, free: 524.2 MB)
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: area
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: bend
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: giant
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: astatine
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: present
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  moment  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: area
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/22 16:51:47 INFO PythonRunner: Times: total = 12442, boot = 710, init = 478, finish = 11254
16/03/22 16:51:47 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/22 16:51:47 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 12565 ms on localhost (1/2)
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: issue
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: planning
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: permission
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: economy
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: composition
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: agency
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/22 16:51:48 INFO PythonRunner: Times: total = 13549, boot = 695, init = 578, finish = 12276
16/03/22 16:51:48 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/22 16:51:48 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 13647 ms on localhost (2/2)
16/03/22 16:51:48 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 13.648 s
16/03/22 16:51:48 INFO DAGScheduler: looking for newly runnable stages
16/03/22 16:51:48 INFO DAGScheduler: running: Set()
16/03/22 16:51:48 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/22 16:51:48 INFO DAGScheduler: failed: Set()
16/03/22 16:51:48 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/22 16:51:48 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/22 16:51:48 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/22 16:51:48 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=549668782
16/03/22 16:51:48 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 524.2 MB)
16/03/22 16:51:48 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=549668782
16/03/22 16:51:48 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 524.2 MB)
16/03/22 16:51:48 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:38997 (size: 3.0 KB, free: 524.2 MB)
16/03/22 16:51:48 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/22 16:51:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:51:48 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/22 16:51:48 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:51:48 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:51:48 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/22 16:51:48 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:51:48 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/22 16:51:48 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:51:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/22 16:51:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
reduceFunction_Parents(): returns= ['None', u'present', 'None']
16/03/22 16:51:48 INFO PythonRunner: Times: total = 29, boot = -722, init = 750, finish = 1
16/03/22 16:51:48 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/22 16:51:48 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 113 ms on localhost (1/2)
16/03/22 16:51:48 INFO PythonRunner: Times: total = 235, boot = 235, init = 0, finish = 0
16/03/22 16:51:48 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/22 16:51:48 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.243 s
16/03/22 16:51:48 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 264 ms on localhost (2/2)
16/03/22 16:51:48 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/22 16:51:48 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 13.934393 s
16/03/22 16:51:48 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:51:48 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:51:48 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:51:48 INFO DAGScheduler: Parents of final stage: List()
16/03/22 16:51:48 INFO DAGScheduler: Missing parents: List()
16/03/22 16:51:48 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:51:48 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=549668782
16/03/22 16:51:48 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 524.2 MB)
16/03/22 16:51:48 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24952, maxMem=549668782
16/03/22 16:51:48 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 524.2 MB)
16/03/22 16:51:48 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:38997 (size: 3.3 KB, free: 524.2 MB)
16/03/22 16:51:48 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/22 16:51:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:51:48 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/22 16:51:49 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/22 16:51:49 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/22 16:51:49 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/22 16:51:49 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/22 16:51:49 INFO PythonRunner: Times: total = 35, boot = 22, init = 12, finish = 1
16/03/22 16:51:49 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1351 bytes result sent to driver
16/03/22 16:51:49 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 56 ms on localhost (1/2)
16/03/22 16:51:49 INFO PythonRunner: Times: total = 108, boot = 108, init = 0, finish = 0
16/03/22 16:51:49 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/22 16:51:49 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 125 ms on localhost (2/2)
16/03/22 16:51:49 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/22 16:51:49 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.128 s
16/03/22 16:51:49 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.140419 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/22 16:51:49 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/22 16:51:49 INFO DAGScheduler: Stopping DAGScheduler
16/03/22 16:51:49 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/22 16:51:49 INFO MemoryStore: MemoryStore cleared
16/03/22 16:51:49 INFO BlockManager: BlockManager stopped
16/03/22 16:51:49 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/22 16:51:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/22 16:51:49 INFO SparkContext: Successfully stopped SparkContext
16/03/22 16:51:49 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/22 16:51:49 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/22 16:51:49 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'present', u'None']
16/03/22 16:51:50 INFO SparkContext: Running Spark version 1.5.2
16/03/22 16:51:50 INFO SecurityManager: Changing view acls to: root
16/03/22 16:51:50 INFO SecurityManager: Changing modify acls to: root
16/03/22 16:51:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/22 16:51:50 INFO Slf4jLogger: Slf4jLogger started
16/03/22 16:51:50 INFO Remoting: Starting remoting
16/03/22 16:51:50 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:48342]
16/03/22 16:51:50 INFO Utils: Successfully started service 'sparkDriver' on port 48342.
16/03/22 16:51:50 INFO SparkEnv: Registering MapOutputTracker
16/03/22 16:51:50 INFO SparkEnv: Registering BlockManagerMaster
16/03/22 16:51:50 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0010dc74-aea3-4261-92ff-f8b8c0e76c3b
16/03/22 16:51:50 INFO MemoryStore: MemoryStore started with capacity 524.2 MB
16/03/22 16:51:50 INFO HttpFileServer: HTTP File server directory is /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/httpd-e3bc57e0-c9b2-458b-bbb3-ef8c69661acc
16/03/22 16:51:50 INFO HttpServer: Starting HTTP Server
16/03/22 16:51:50 INFO Utils: Successfully started service 'HTTP file server' on port 44736.
16/03/22 16:51:50 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/22 16:51:50 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/22 16:51:50 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/22 16:51:50 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-8dfd7a54-2f8b-49b1-ac6b-1e660c941907/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:51:50 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645710417
16/03/22 16:51:50 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/22 16:51:50 INFO Executor: Starting executor ID driver on host localhost
16/03/22 16:51:50 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59427.
16/03/22 16:51:50 INFO NettyBlockTransferService: Server created on 59427
16/03/22 16:51:50 INFO BlockManagerMaster: Trying to register BlockManager
16/03/22 16:51:50 INFO BlockManagerMasterEndpoint: Registering block manager localhost:59427 with 524.2 MB RAM, BlockManagerId(driver, localhost, 59427)
16/03/22 16:51:50 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): purpose
16/03/22 16:51:50 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:51:50 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:51:50 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:51:50 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:51:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/22 16:51:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/22 16:51:50 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:51:50 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=549668782
16/03/22 16:51:50 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 524.2 MB)
16/03/22 16:51:50 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=549668782
16/03/22 16:51:50 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 524.2 MB)
16/03/22 16:51:50 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:59427 (size: 4.1 KB, free: 524.2 MB)
16/03/22 16:51:50 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/22 16:51:50 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:51:50 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/22 16:51:50 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/22 16:51:50 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/22 16:51:50 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/22 16:51:50 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645710417
16/03/22 16:51:50 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/22 16:51:50 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-8dfd7a54-2f8b-49b1-ac6b-1e660c941907/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:51:50 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/22 16:51:50 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/22 16:51:50 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10732, maxMem=549668782
16/03/22 16:51:50 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 524.2 MB)
16/03/22 16:51:50 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:59427 (size: 177.0 B, free: 524.2 MB)
16/03/22 16:51:50 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10909, maxMem=549668782
16/03/22 16:51:50 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 524.2 MB)
16/03/22 16:51:50 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:59427 (size: 187.0 B, free: 524.2 MB)
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: area
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: bend
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: giant
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: astatine
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: present
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: area
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  purpose  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/22 16:52:00 INFO PythonRunner: Times: total = 9147, boot = 514, init = 473, finish = 8160
16/03/22 16:52:00 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/22 16:52:00 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9227 ms on localhost (1/2)
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  purpose  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: issue
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: planning
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: permission
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: economy
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: composition
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: agency
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/22 16:52:00 INFO PythonRunner: Times: total = 9451, boot = 522, init = 564, finish = 8365
16/03/22 16:52:00 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/22 16:52:00 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 9.545 s
16/03/22 16:52:00 INFO DAGScheduler: looking for newly runnable stages
16/03/22 16:52:00 INFO DAGScheduler: running: Set()
16/03/22 16:52:00 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/22 16:52:00 INFO DAGScheduler: failed: Set()
16/03/22 16:52:00 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/22 16:52:00 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/22 16:52:00 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=549668782
16/03/22 16:52:00 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 524.2 MB)
16/03/22 16:52:00 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=549668782
16/03/22 16:52:00 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9540 ms on localhost (2/2)
16/03/22 16:52:00 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/22 16:52:00 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 524.2 MB)
16/03/22 16:52:00 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:59427 (size: 3.0 KB, free: 524.2 MB)
16/03/22 16:52:00 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/22 16:52:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:52:00 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/22 16:52:00 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:52:00 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:52:00 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/22 16:52:00 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/22 16:52:00 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:52:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/22 16:52:00 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:52:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
reduceFunction_Parents(): returns= ['None', u'area', u'area']
16/03/22 16:52:00 INFO PythonRunner: Times: total = 60, boot = -125, init = 183, finish = 2
16/03/22 16:52:00 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/22 16:52:00 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 122 ms on localhost (1/2)
16/03/22 16:52:00 INFO PythonRunner: Times: total = 220, boot = 219, init = 0, finish = 1
16/03/22 16:52:00 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/22 16:52:00 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.242 s
16/03/22 16:52:00 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 9.825656 s
16/03/22 16:52:00 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 241 ms on localhost (2/2)
16/03/22 16:52:00 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/22 16:52:00 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:52:00 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:52:00 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:52:00 INFO DAGScheduler: Parents of final stage: List()
16/03/22 16:52:00 INFO DAGScheduler: Missing parents: List()
16/03/22 16:52:00 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:52:00 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=549668782
16/03/22 16:52:00 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 524.2 MB)
16/03/22 16:52:00 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24952, maxMem=549668782
16/03/22 16:52:00 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 524.2 MB)
16/03/22 16:52:00 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:59427 (size: 3.3 KB, free: 524.2 MB)
16/03/22 16:52:00 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/22 16:52:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:52:00 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/22 16:52:00 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/22 16:52:00 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/22 16:52:00 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/22 16:52:00 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/22 16:52:00 INFO PythonRunner: Times: total = 169, boot = 168, init = 1, finish = 0
16/03/22 16:52:00 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/22 16:52:00 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 179 ms on localhost (1/2)
16/03/22 16:52:00 INFO PythonRunner: Times: total = 237, boot = 237, init = 0, finish = 0
16/03/22 16:52:00 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/03/22 16:52:00 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 246 ms on localhost (2/2)
16/03/22 16:52:00 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/22 16:52:00 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.232 s
16/03/22 16:52:00 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.263542 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/22 16:52:01 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/22 16:52:01 INFO DAGScheduler: Stopping DAGScheduler
16/03/22 16:52:01 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/22 16:52:01 INFO MemoryStore: MemoryStore cleared
16/03/22 16:52:01 INFO BlockManager: BlockManager stopped
16/03/22 16:52:01 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/22 16:52:01 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/22 16:52:01 INFO SparkContext: Successfully stopped SparkContext
16/03/22 16:52:01 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/22 16:52:01 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/22 16:52:01 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'area', u'area']
16/03/22 16:52:01 INFO SparkContext: Running Spark version 1.5.2
16/03/22 16:52:01 INFO SecurityManager: Changing view acls to: root
16/03/22 16:52:01 INFO SecurityManager: Changing modify acls to: root
16/03/22 16:52:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/22 16:52:02 INFO Slf4jLogger: Slf4jLogger started
16/03/22 16:52:02 INFO Remoting: Starting remoting
16/03/22 16:52:02 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:54464]
16/03/22 16:52:02 INFO Utils: Successfully started service 'sparkDriver' on port 54464.
16/03/22 16:52:02 INFO SparkEnv: Registering MapOutputTracker
16/03/22 16:52:02 INFO SparkEnv: Registering BlockManagerMaster
16/03/22 16:52:02 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d172f489-8944-40e4-87da-84966f5e0702
16/03/22 16:52:02 INFO MemoryStore: MemoryStore started with capacity 523.9 MB
16/03/22 16:52:02 INFO HttpFileServer: HTTP File server directory is /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/httpd-16905909-74db-47d5-a5ba-07edd9a1994f
16/03/22 16:52:02 INFO HttpServer: Starting HTTP Server
16/03/22 16:52:02 INFO Utils: Successfully started service 'HTTP file server' on port 47620.
16/03/22 16:52:02 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/22 16:52:02 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/22 16:52:02 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/22 16:52:02 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-ef49a4be-e33f-4ca2-a8a0-2f54f044bcac/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:52:02 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645722857
16/03/22 16:52:02 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/22 16:52:02 INFO Executor: Starting executor ID driver on host localhost
16/03/22 16:52:02 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43160.
16/03/22 16:52:02 INFO NettyBlockTransferService: Server created on 43160
16/03/22 16:52:02 INFO BlockManagerMaster: Trying to register BlockManager
16/03/22 16:52:02 INFO BlockManagerMasterEndpoint: Registering block manager localhost:43160 with 523.9 MB RAM, BlockManagerId(driver, localhost, 43160)
16/03/22 16:52:02 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): segment
16/03/22 16:52:03 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:52:03 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:52:03 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:52:03 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:52:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/22 16:52:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/22 16:52:03 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:52:03 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=549385666
16/03/22 16:52:03 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.9 MB)
16/03/22 16:52:03 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=549385666
16/03/22 16:52:03 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.9 MB)
16/03/22 16:52:03 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:43160 (size: 4.1 KB, free: 523.9 MB)
16/03/22 16:52:03 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/22 16:52:03 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:52:03 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/22 16:52:03 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/22 16:52:03 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/22 16:52:03 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/22 16:52:03 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645722857
16/03/22 16:52:03 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/22 16:52:03 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-ef49a4be-e33f-4ca2-a8a0-2f54f044bcac/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:52:03 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/22 16:52:03 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10732, maxMem=549385666
16/03/22 16:52:03 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 523.9 MB)
16/03/22 16:52:03 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:43160 (size: 187.0 B, free: 523.9 MB)
16/03/22 16:52:03 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/22 16:52:03 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10919, maxMem=549385666
16/03/22 16:52:03 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 523.9 MB)
16/03/22 16:52:03 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:43160 (size: 177.0 B, free: 523.9 MB)
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: set
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: issue
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: planning
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: permission
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: economy
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: composition
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: agency
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/22 16:52:12 INFO PythonRunner: Times: total = 8909, boot = 520, init = 395, finish = 7994
16/03/22 16:52:12 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/22 16:52:12 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9013 ms on localhost (1/2)
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: bend
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): adding to parents: syn =  Synset('bend.n.01') ; keyword:  segment  in syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= [u'bend']
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: giant
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: astatine
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: present
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: area
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
16/03/22 16:52:12 INFO PythonRunner: Times: total = 9291, boot = 525, init = 477, finish = 8289
16/03/22 16:52:12 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/22 16:52:12 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 9.371 s
16/03/22 16:52:12 INFO DAGScheduler: looking for newly runnable stages
16/03/22 16:52:12 INFO DAGScheduler: running: Set()
16/03/22 16:52:12 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/22 16:52:12 INFO DAGScheduler: failed: Set()
16/03/22 16:52:12 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/22 16:52:12 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/22 16:52:12 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=549385666
16/03/22 16:52:12 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.9 MB)
16/03/22 16:52:12 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=549385666
16/03/22 16:52:12 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.9 MB)
16/03/22 16:52:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:43160 (size: 3.0 KB, free: 523.9 MB)
16/03/22 16:52:12 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/22 16:52:12 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:52:12 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9374 ms on localhost (2/2)
16/03/22 16:52:12 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/22 16:52:12 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/22 16:52:12 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:52:12 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:52:12 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/22 16:52:12 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/22 16:52:12 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:52:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/03/22 16:52:12 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:52:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
16/03/22 16:52:12 INFO PythonRunner: Times: total = 69, boot = -123, init = 192, finish = 0
16/03/22 16:52:12 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/22 16:52:12 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 94 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'bend', 'None']
16/03/22 16:52:12 INFO PythonRunner: Times: total = 207, boot = 206, init = 1, finish = 0
16/03/22 16:52:12 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1272 bytes result sent to driver
16/03/22 16:52:12 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.217 s
16/03/22 16:52:12 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 237 ms on localhost (2/2)
16/03/22 16:52:12 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 9.645799 s
16/03/22 16:52:12 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/22 16:52:12 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:52:12 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:52:12 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:52:12 INFO DAGScheduler: Parents of final stage: List()
16/03/22 16:52:12 INFO DAGScheduler: Missing parents: List()
16/03/22 16:52:12 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:52:12 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=549385666
16/03/22 16:52:12 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.9 MB)
16/03/22 16:52:12 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24952, maxMem=549385666
16/03/22 16:52:12 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.9 MB)
16/03/22 16:52:12 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:43160 (size: 3.3 KB, free: 523.9 MB)
16/03/22 16:52:12 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/22 16:52:12 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:52:12 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/22 16:52:12 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/22 16:52:12 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2353 bytes)
16/03/22 16:52:12 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/22 16:52:12 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/22 16:52:12 INFO PythonRunner: Times: total = 84, boot = 83, init = 1, finish = 0
16/03/22 16:52:12 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1337 bytes result sent to driver
16/03/22 16:52:12 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 93 ms on localhost (1/2)
16/03/22 16:52:13 INFO PythonRunner: Times: total = 179, boot = 179, init = 0, finish = 0
16/03/22 16:52:13 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/22 16:52:13 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 190 ms on localhost (2/2)
16/03/22 16:52:13 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/22 16:52:13 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.171 s
16/03/22 16:52:13 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.205645 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/22 16:52:13 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/22 16:52:13 INFO DAGScheduler: Stopping DAGScheduler
16/03/22 16:52:13 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/22 16:52:13 INFO MemoryStore: MemoryStore cleared
16/03/22 16:52:13 INFO BlockManager: BlockManager stopped
16/03/22 16:52:13 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/22 16:52:13 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/22 16:52:13 INFO SparkContext: Successfully stopped SparkContext
16/03/22 16:52:13 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/22 16:52:13 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/22 16:52:13 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'bend', u'None']
16/03/22 16:52:14 INFO SparkContext: Running Spark version 1.5.2
16/03/22 16:52:14 INFO SecurityManager: Changing view acls to: root
16/03/22 16:52:14 INFO SecurityManager: Changing modify acls to: root
16/03/22 16:52:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/22 16:52:14 INFO Slf4jLogger: Slf4jLogger started
16/03/22 16:52:14 INFO Remoting: Starting remoting
16/03/22 16:52:14 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:43109]
16/03/22 16:52:14 INFO Utils: Successfully started service 'sparkDriver' on port 43109.
16/03/22 16:52:14 INFO SparkEnv: Registering MapOutputTracker
16/03/22 16:52:14 INFO SparkEnv: Registering BlockManagerMaster
16/03/22 16:52:14 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-43d62b5d-7872-4fbc-83c8-2c20aeef83a4
16/03/22 16:52:14 INFO MemoryStore: MemoryStore started with capacity 523.9 MB
16/03/22 16:52:14 INFO HttpFileServer: HTTP File server directory is /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/httpd-d37decd0-b523-4507-9a2f-2bb5590e3b38
16/03/22 16:52:14 INFO HttpServer: Starting HTTP Server
16/03/22 16:52:14 INFO Utils: Successfully started service 'HTTP file server' on port 55499.
16/03/22 16:52:14 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/22 16:52:14 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/22 16:52:14 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/22 16:52:14 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-49311f1e-f969-4a1c-9280-1b2e672b688f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:52:14 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645734900
16/03/22 16:52:14 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/22 16:52:14 INFO Executor: Starting executor ID driver on host localhost
16/03/22 16:52:14 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33937.
16/03/22 16:52:14 INFO NettyBlockTransferService: Server created on 33937
16/03/22 16:52:14 INFO BlockManagerMaster: Trying to register BlockManager
16/03/22 16:52:14 INFO BlockManagerMasterEndpoint: Registering block manager localhost:33937 with 523.9 MB RAM, BlockManagerId(driver, localhost, 33937)
16/03/22 16:52:14 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): radioactive
16/03/22 16:52:15 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:52:15 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:52:15 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:52:15 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:52:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/22 16:52:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/22 16:52:15 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:52:15 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=549385666
16/03/22 16:52:15 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.9 MB)
16/03/22 16:52:15 INFO MemoryStore: ensureFreeSpace(4154) called with curMem=6576, maxMem=549385666
16/03/22 16:52:15 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.9 MB)
16/03/22 16:52:15 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:33937 (size: 4.1 KB, free: 523.9 MB)
16/03/22 16:52:15 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/22 16:52:15 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:52:15 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/22 16:52:15 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/22 16:52:15 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/22 16:52:15 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/22 16:52:15 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645734900
16/03/22 16:52:15 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/22 16:52:15 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-49311f1e-f969-4a1c-9280-1b2e672b688f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:52:15 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/22 16:52:15 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10730, maxMem=549385666
16/03/22 16:52:15 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 523.9 MB)
16/03/22 16:52:15 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:33937 (size: 177.0 B, free: 523.9 MB)
16/03/22 16:52:15 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/22 16:52:15 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10907, maxMem=549385666
16/03/22 16:52:15 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 523.9 MB)
16/03/22 16:52:15 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:33937 (size: 187.0 B, free: 523.9 MB)
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: set
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: issue
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: planning
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: permission
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: economy
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: composition
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: agency
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/22 16:52:24 INFO PythonRunner: Times: total = 8869, boot = 472, init = 381, finish = 8016
16/03/22 16:52:24 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/22 16:52:24 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8987 ms on localhost (1/2)
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: bend
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: giant
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: astatine
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  radioactive  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: present
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: area
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/22 16:52:24 INFO PythonRunner: Times: total = 9277, boot = 476, init = 474, finish = 8327
16/03/22 16:52:24 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/22 16:52:24 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 9.356 s
16/03/22 16:52:24 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9383 ms on localhost (2/2)
16/03/22 16:52:24 INFO DAGScheduler: looking for newly runnable stages
16/03/22 16:52:24 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/22 16:52:24 INFO DAGScheduler: running: Set()
16/03/22 16:52:24 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/22 16:52:24 INFO DAGScheduler: failed: Set()
16/03/22 16:52:24 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/22 16:52:24 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/22 16:52:24 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11094, maxMem=549385666
16/03/22 16:52:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.9 MB)
16/03/22 16:52:24 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16078, maxMem=549385666
16/03/22 16:52:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.9 MB)
16/03/22 16:52:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:33937 (size: 3.0 KB, free: 523.9 MB)
16/03/22 16:52:24 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/22 16:52:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:52:24 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/22 16:52:24 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:52:24 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:52:24 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/22 16:52:24 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/22 16:52:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:52:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/22 16:52:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:52:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/22 16:52:24 INFO PythonRunner: Times: total = 49, boot = -197, init = 246, finish = 0
16/03/22 16:52:24 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/22 16:52:24 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 101 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'astatine', 'None']
16/03/22 16:52:24 INFO PythonRunner: Times: total = 201, boot = 200, init = 1, finish = 0
16/03/22 16:52:24 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/03/22 16:52:24 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.229 s
16/03/22 16:52:24 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 9.632804 s
16/03/22 16:52:24 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 228 ms on localhost (2/2)
16/03/22 16:52:24 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/22 16:52:24 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:52:24 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:52:24 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:52:24 INFO DAGScheduler: Parents of final stage: List()
16/03/22 16:52:24 INFO DAGScheduler: Missing parents: List()
16/03/22 16:52:24 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:52:24 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19134, maxMem=549385666
16/03/22 16:52:24 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.9 MB)
16/03/22 16:52:24 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24950, maxMem=549385666
16/03/22 16:52:24 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.9 MB)
16/03/22 16:52:24 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:33937 (size: 3.3 KB, free: 523.9 MB)
16/03/22 16:52:24 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/22 16:52:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:52:24 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/22 16:52:24 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/22 16:52:24 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/03/22 16:52:24 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/22 16:52:24 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/22 16:52:24 INFO PythonRunner: Times: total = 28, boot = 11, init = 17, finish = 0
16/03/22 16:52:25 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/22 16:52:25 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 93 ms on localhost (1/2)
16/03/22 16:52:25 INFO PythonRunner: Times: total = 123, boot = 115, init = 8, finish = 0
16/03/22 16:52:25 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/03/22 16:52:25 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 134 ms on localhost (2/2)
16/03/22 16:52:25 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/22 16:52:25 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.119 s
16/03/22 16:52:25 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.165903 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/22 16:52:25 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/22 16:52:25 INFO DAGScheduler: Stopping DAGScheduler
16/03/22 16:52:25 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/22 16:52:25 INFO MemoryStore: MemoryStore cleared
16/03/22 16:52:25 INFO BlockManager: BlockManager stopped
16/03/22 16:52:25 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/22 16:52:25 INFO SparkContext: Successfully stopped SparkContext
16/03/22 16:52:25 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/22 16:52:25 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/22 16:52:25 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/22 16:52:25 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'astatine', u'None']
16/03/22 16:52:26 INFO SparkContext: Running Spark version 1.5.2
16/03/22 16:52:26 INFO SecurityManager: Changing view acls to: root
16/03/22 16:52:26 INFO SecurityManager: Changing modify acls to: root
16/03/22 16:52:26 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/22 16:52:26 INFO Slf4jLogger: Slf4jLogger started
16/03/22 16:52:26 INFO Remoting: Starting remoting
16/03/22 16:52:26 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:60459]
16/03/22 16:52:26 INFO Utils: Successfully started service 'sparkDriver' on port 60459.
16/03/22 16:52:26 INFO SparkEnv: Registering MapOutputTracker
16/03/22 16:52:26 INFO SparkEnv: Registering BlockManagerMaster
16/03/22 16:52:26 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5c6e3da1-ff96-4d0f-9174-34eb808ab13a
16/03/22 16:52:26 INFO MemoryStore: MemoryStore started with capacity 525.7 MB
16/03/22 16:52:26 INFO HttpFileServer: HTTP File server directory is /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/httpd-9c887daa-1360-4d45-8efb-71c189ff1dd1
16/03/22 16:52:26 INFO HttpServer: Starting HTTP Server
16/03/22 16:52:26 INFO Utils: Successfully started service 'HTTP file server' on port 52405.
16/03/22 16:52:26 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/22 16:52:26 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/22 16:52:26 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/22 16:52:26 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-4f8d1d8c-0e6e-4fae-a2a0-5a54975baed3/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:52:26 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645746915
16/03/22 16:52:26 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/22 16:52:26 INFO Executor: Starting executor ID driver on host localhost
16/03/22 16:52:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50716.
16/03/22 16:52:26 INFO NettyBlockTransferService: Server created on 50716
16/03/22 16:52:26 INFO BlockManagerMaster: Trying to register BlockManager
16/03/22 16:52:26 INFO BlockManagerMasterEndpoint: Registering block manager localhost:50716 with 525.7 MB RAM, BlockManagerId(driver, localhost, 50716)
16/03/22 16:52:26 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): happening
16/03/22 16:52:27 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:52:27 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:52:27 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:52:27 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:52:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/22 16:52:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/22 16:52:27 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:52:27 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=551225917
16/03/22 16:52:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 525.7 MB)
16/03/22 16:52:27 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=551225917
16/03/22 16:52:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 525.7 MB)
16/03/22 16:52:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:50716 (size: 4.1 KB, free: 525.7 MB)
16/03/22 16:52:27 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/22 16:52:27 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:52:27 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/22 16:52:27 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/22 16:52:27 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/22 16:52:27 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/22 16:52:27 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645746915
16/03/22 16:52:27 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/22 16:52:27 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-4f8d1d8c-0e6e-4fae-a2a0-5a54975baed3/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:52:27 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/22 16:52:27 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10732, maxMem=551225917
16/03/22 16:52:27 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 525.7 MB)
16/03/22 16:52:27 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/22 16:52:27 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10909, maxMem=551225917
16/03/22 16:52:27 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 525.7 MB)
16/03/22 16:52:27 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:50716 (size: 177.0 B, free: 525.7 MB)
16/03/22 16:52:27 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:50716 (size: 187.0 B, free: 525.7 MB)
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: set
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: issue
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: planning
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: permission
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: economy
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: composition
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: agency
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/22 16:52:36 INFO PythonRunner: Times: total = 9017, boot = 489, init = 418, finish = 8110
16/03/22 16:52:36 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/22 16:52:36 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9105 ms on localhost (1/2)
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: bend
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: giant
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: astatine
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: present
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  happening  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: area
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/22 16:52:36 INFO PythonRunner: Times: total = 9394, boot = 478, init = 439, finish = 8477
16/03/22 16:52:36 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/22 16:52:36 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 9.480 s
16/03/22 16:52:36 INFO DAGScheduler: looking for newly runnable stages
16/03/22 16:52:36 INFO DAGScheduler: running: Set()
16/03/22 16:52:36 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/22 16:52:36 INFO DAGScheduler: failed: Set()
16/03/22 16:52:36 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/22 16:52:36 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/22 16:52:36 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=551225917
16/03/22 16:52:36 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 525.7 MB)
16/03/22 16:52:36 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=551225917
16/03/22 16:52:36 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 525.7 MB)
16/03/22 16:52:36 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9469 ms on localhost (2/2)
16/03/22 16:52:36 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:50716 (size: 3.0 KB, free: 525.7 MB)
16/03/22 16:52:36 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/22 16:52:36 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/22 16:52:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:52:36 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/22 16:52:36 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:52:36 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:52:36 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/22 16:52:36 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/22 16:52:36 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:52:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/22 16:52:36 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:52:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/03/22 16:52:36 INFO PythonRunner: Times: total = 45, boot = -127, init = 171, finish = 1
16/03/22 16:52:36 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/22 16:52:36 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 88 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'present', 'None']
16/03/22 16:52:36 INFO PythonRunner: Times: total = 274, boot = 273, init = 1, finish = 0
16/03/22 16:52:36 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/22 16:52:36 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.272 s
16/03/22 16:52:36 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 9.791090 s
16/03/22 16:52:36 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 291 ms on localhost (2/2)
16/03/22 16:52:36 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/22 16:52:36 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:52:36 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:52:36 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:52:36 INFO DAGScheduler: Parents of final stage: List()
16/03/22 16:52:36 INFO DAGScheduler: Missing parents: List()
16/03/22 16:52:36 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:52:36 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=551225917
16/03/22 16:52:36 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 525.7 MB)
16/03/22 16:52:36 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24952, maxMem=551225917
16/03/22 16:52:36 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 525.7 MB)
16/03/22 16:52:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:50716 (size: 3.3 KB, free: 525.7 MB)
16/03/22 16:52:36 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/22 16:52:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:52:36 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/22 16:52:36 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/22 16:52:36 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/22 16:52:36 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/22 16:52:36 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/22 16:52:37 INFO PythonRunner: Times: total = 75, boot = -135, init = 210, finish = 0
16/03/22 16:52:37 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/22 16:52:37 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 83 ms on localhost (1/2)
16/03/22 16:52:37 INFO PythonRunner: Times: total = 169, boot = 169, init = 0, finish = 0
16/03/22 16:52:37 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1351 bytes result sent to driver
16/03/22 16:52:37 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 179 ms on localhost (2/2)
16/03/22 16:52:37 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/22 16:52:37 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.178 s
16/03/22 16:52:37 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.199566 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/22 16:52:37 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/22 16:52:37 INFO DAGScheduler: Stopping DAGScheduler
16/03/22 16:52:37 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/22 16:52:37 INFO MemoryStore: MemoryStore cleared
16/03/22 16:52:37 INFO BlockManager: BlockManager stopped
16/03/22 16:52:37 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/22 16:52:37 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/22 16:52:37 INFO SparkContext: Successfully stopped SparkContext
16/03/22 16:52:37 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/22 16:52:37 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/22 16:52:37 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'present', u'None']
16/03/22 16:52:38 INFO SparkContext: Running Spark version 1.5.2
16/03/22 16:52:38 INFO SecurityManager: Changing view acls to: root
16/03/22 16:52:38 INFO SecurityManager: Changing modify acls to: root
16/03/22 16:52:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/22 16:52:38 INFO Slf4jLogger: Slf4jLogger started
16/03/22 16:52:38 INFO Remoting: Starting remoting
16/03/22 16:52:38 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:52009]
16/03/22 16:52:38 INFO Utils: Successfully started service 'sparkDriver' on port 52009.
16/03/22 16:52:38 INFO SparkEnv: Registering MapOutputTracker
16/03/22 16:52:38 INFO SparkEnv: Registering BlockManagerMaster
16/03/22 16:52:38 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-6900cdd0-8e0c-40d1-84fb-69a4eaed2b79
16/03/22 16:52:38 INFO MemoryStore: MemoryStore started with capacity 525.7 MB
16/03/22 16:52:38 INFO HttpFileServer: HTTP File server directory is /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/httpd-0ffa4e9c-df5a-410a-a23a-499171e37afc
16/03/22 16:52:38 INFO HttpServer: Starting HTTP Server
16/03/22 16:52:38 INFO Utils: Successfully started service 'HTTP file server' on port 43056.
16/03/22 16:52:38 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/22 16:52:38 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/22 16:52:38 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/22 16:52:38 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-052a5626-c293-4236-87cd-213e1d863d6b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:52:39 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645758979
16/03/22 16:52:39 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/22 16:52:39 INFO Executor: Starting executor ID driver on host localhost
16/03/22 16:52:39 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53849.
16/03/22 16:52:39 INFO NettyBlockTransferService: Server created on 53849
16/03/22 16:52:39 INFO BlockManagerMaster: Trying to register BlockManager
16/03/22 16:52:39 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53849 with 525.7 MB RAM, BlockManagerId(driver, localhost, 53849)
16/03/22 16:52:39 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): curve
16/03/22 16:52:39 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:52:39 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:52:39 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:52:39 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:52:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/22 16:52:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/22 16:52:39 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:52:39 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=551225917
16/03/22 16:52:39 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 525.7 MB)
16/03/22 16:52:39 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=551225917
16/03/22 16:52:39 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 525.7 MB)
16/03/22 16:52:39 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53849 (size: 4.1 KB, free: 525.7 MB)
16/03/22 16:52:39 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/22 16:52:39 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:52:39 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/22 16:52:39 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/22 16:52:39 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/22 16:52:39 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/22 16:52:39 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645758979
16/03/22 16:52:39 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/22 16:52:39 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-052a5626-c293-4236-87cd-213e1d863d6b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:52:39 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/22 16:52:39 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/22 16:52:39 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10732, maxMem=551225917
16/03/22 16:52:39 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 525.7 MB)
16/03/22 16:52:39 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:53849 (size: 177.0 B, free: 525.7 MB)
16/03/22 16:52:39 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10909, maxMem=551225917
16/03/22 16:52:39 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 525.7 MB)
16/03/22 16:52:39 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:53849 (size: 187.0 B, free: 525.7 MB)
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: area
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: bend
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): adding to parents: syn =  Synset('bend.n.01') ; keyword:  curve  in syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= [u'bend']
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: giant
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: astatine
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: present
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: area
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
16/03/22 16:52:48 INFO PythonRunner: Times: total = 8967, boot = 507, init = 409, finish = 8051
16/03/22 16:52:48 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/22 16:52:48 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9043 ms on localhost (1/2)
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: issue
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: planning
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: permission
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: economy
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: composition
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: agency
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/22 16:52:48 INFO PythonRunner: Times: total = 9216, boot = 509, init = 415, finish = 8292
16/03/22 16:52:48 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/22 16:52:48 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9293 ms on localhost (2/2)
16/03/22 16:52:48 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 9.296 s
16/03/22 16:52:48 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/22 16:52:48 INFO DAGScheduler: looking for newly runnable stages
16/03/22 16:52:48 INFO DAGScheduler: running: Set()
16/03/22 16:52:48 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/22 16:52:48 INFO DAGScheduler: failed: Set()
16/03/22 16:52:48 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/22 16:52:48 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/22 16:52:48 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=551225917
16/03/22 16:52:48 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 525.7 MB)
16/03/22 16:52:48 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=551225917
16/03/22 16:52:48 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 525.7 MB)
16/03/22 16:52:48 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53849 (size: 3.0 KB, free: 525.7 MB)
16/03/22 16:52:48 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/22 16:52:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:52:48 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/22 16:52:48 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:52:48 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:52:48 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/22 16:52:48 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/22 16:52:48 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:52:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/22 16:52:48 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:52:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= [u'bend', 'None']
16/03/22 16:52:48 INFO PythonRunner: Times: total = 53, boot = 49, init = 3, finish = 1
16/03/22 16:52:48 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1272 bytes result sent to driver
16/03/22 16:52:48 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 93 ms on localhost (1/2)
16/03/22 16:52:48 INFO PythonRunner: Times: total = 245, boot = 244, init = 1, finish = 0
16/03/22 16:52:48 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/22 16:52:48 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 270 ms on localhost (2/2)
16/03/22 16:52:48 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/22 16:52:48 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.272 s
16/03/22 16:52:48 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 9.603426 s
16/03/22 16:52:48 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:52:48 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:52:48 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:52:48 INFO DAGScheduler: Parents of final stage: List()
16/03/22 16:52:48 INFO DAGScheduler: Missing parents: List()
16/03/22 16:52:48 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:52:48 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=551225917
16/03/22 16:52:48 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 525.7 MB)
16/03/22 16:52:48 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24952, maxMem=551225917
16/03/22 16:52:48 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 525.7 MB)
16/03/22 16:52:48 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53849 (size: 3.3 KB, free: 525.7 MB)
16/03/22 16:52:48 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/22 16:52:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:52:48 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/22 16:52:48 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/22 16:52:48 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2353 bytes)
16/03/22 16:52:48 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/22 16:52:48 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/22 16:52:49 INFO PythonRunner: Times: total = 77, boot = -6, init = 83, finish = 0
16/03/22 16:52:49 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1337 bytes result sent to driver
16/03/22 16:52:49 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 84 ms on localhost (1/2)
16/03/22 16:52:49 INFO PythonRunner: Times: total = 223, boot = 223, init = 0, finish = 0
16/03/22 16:52:49 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/22 16:52:49 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 229 ms on localhost (2/2)
16/03/22 16:52:49 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/22 16:52:49 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.227 s
16/03/22 16:52:49 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.259467 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/22 16:52:49 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/22 16:52:49 INFO DAGScheduler: Stopping DAGScheduler
16/03/22 16:52:49 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/22 16:52:49 INFO MemoryStore: MemoryStore cleared
16/03/22 16:52:49 INFO BlockManager: BlockManager stopped
16/03/22 16:52:49 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/22 16:52:49 INFO SparkContext: Successfully stopped SparkContext
16/03/22 16:52:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/22 16:52:49 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/22 16:52:49 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/22 16:52:49 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'bend', u'None']
16/03/22 16:52:50 INFO SparkContext: Running Spark version 1.5.2
16/03/22 16:52:50 INFO SecurityManager: Changing view acls to: root
16/03/22 16:52:50 INFO SecurityManager: Changing modify acls to: root
16/03/22 16:52:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/22 16:52:50 INFO Slf4jLogger: Slf4jLogger started
16/03/22 16:52:50 INFO Remoting: Starting remoting
16/03/22 16:52:50 INFO Utils: Successfully started service 'sparkDriver' on port 45661.
16/03/22 16:52:50 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:45661]
16/03/22 16:52:50 INFO SparkEnv: Registering MapOutputTracker
16/03/22 16:52:50 INFO SparkEnv: Registering BlockManagerMaster
16/03/22 16:52:50 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-40d07ddd-1c0d-4315-8693-466622619cd5
16/03/22 16:52:50 INFO MemoryStore: MemoryStore started with capacity 525.7 MB
16/03/22 16:52:50 INFO HttpFileServer: HTTP File server directory is /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/httpd-e3402b07-2dcd-4e79-a108-2de2deb08274
16/03/22 16:52:50 INFO HttpServer: Starting HTTP Server
16/03/22 16:52:50 INFO Utils: Successfully started service 'HTTP file server' on port 56941.
16/03/22 16:52:50 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/22 16:52:51 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/22 16:52:51 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/22 16:52:51 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-50c825c6-65bc-4f04-abda-40b0e576835f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:52:51 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645771066
16/03/22 16:52:51 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/22 16:52:51 INFO Executor: Starting executor ID driver on host localhost
16/03/22 16:52:51 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36981.
16/03/22 16:52:51 INFO NettyBlockTransferService: Server created on 36981
16/03/22 16:52:51 INFO BlockManagerMaster: Trying to register BlockManager
16/03/22 16:52:51 INFO BlockManagerMasterEndpoint: Registering block manager localhost:36981 with 525.7 MB RAM, BlockManagerId(driver, localhost, 36981)
16/03/22 16:52:51 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): together
16/03/22 16:52:51 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:52:51 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:52:51 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:52:51 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:52:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/22 16:52:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/22 16:52:51 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:52:51 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=551225917
16/03/22 16:52:51 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 525.7 MB)
16/03/22 16:52:51 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=551225917
16/03/22 16:52:51 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 525.7 MB)
16/03/22 16:52:51 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:36981 (size: 4.1 KB, free: 525.7 MB)
16/03/22 16:52:51 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/22 16:52:51 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:52:51 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/22 16:52:51 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/22 16:52:51 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/22 16:52:51 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/22 16:52:51 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645771066
16/03/22 16:52:51 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/22 16:52:51 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-50c825c6-65bc-4f04-abda-40b0e576835f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:52:51 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/22 16:52:51 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10732, maxMem=551225917
16/03/22 16:52:51 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 525.7 MB)
16/03/22 16:52:51 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:36981 (size: 177.0 B, free: 525.7 MB)
16/03/22 16:52:51 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/22 16:52:51 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10909, maxMem=551225917
16/03/22 16:52:51 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 525.7 MB)
16/03/22 16:52:51 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:36981 (size: 187.0 B, free: 525.7 MB)
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: area
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  Synset('set.n.01') ; keyword:  together  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: bend
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: giant
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: astatine
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: present
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: area
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
16/03/22 16:53:00 INFO PythonRunner: Times: total = 8820, boot = 517, init = 397, finish = 7906
16/03/22 16:53:00 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/22 16:53:00 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8913 ms on localhost (1/2)
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: issue
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: planning
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: permission
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: economy
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: composition
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: agency
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/22 16:53:01 INFO PythonRunner: Times: total = 10016, boot = 507, init = 488, finish = 9021
16/03/22 16:53:01 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/22 16:53:01 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 10134 ms on localhost (2/2)
16/03/22 16:53:01 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/22 16:53:01 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 10.136 s
16/03/22 16:53:01 INFO DAGScheduler: looking for newly runnable stages
16/03/22 16:53:01 INFO DAGScheduler: running: Set()
16/03/22 16:53:01 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/22 16:53:01 INFO DAGScheduler: failed: Set()
16/03/22 16:53:01 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/22 16:53:01 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/22 16:53:01 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=551225917
16/03/22 16:53:01 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 525.7 MB)
16/03/22 16:53:01 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=551225917
16/03/22 16:53:01 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 525.7 MB)
16/03/22 16:53:01 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:36981 (size: 3.0 KB, free: 525.7 MB)
16/03/22 16:53:01 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/22 16:53:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:53:01 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/22 16:53:01 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:53:01 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:53:01 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/22 16:53:01 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:53:01 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/22 16:53:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/22 16:53:01 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:53:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/22 16:53:01 INFO PythonRunner: Times: total = 67, boot = -1016, init = 1083, finish = 0
reduceFunction_Parents(): returns= [u'set', 'None']
16/03/22 16:53:01 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1271 bytes result sent to driver
16/03/22 16:53:01 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 106 ms on localhost (1/2)
16/03/22 16:53:01 INFO PythonRunner: Times: total = 316, boot = 316, init = 0, finish = 0
16/03/22 16:53:01 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/22 16:53:01 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.346 s
16/03/22 16:53:01 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 10.737249 s
16/03/22 16:53:01 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 342 ms on localhost (2/2)
16/03/22 16:53:01 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/22 16:53:02 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:53:02 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:53:02 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:53:02 INFO DAGScheduler: Parents of final stage: List()
16/03/22 16:53:02 INFO DAGScheduler: Missing parents: List()
16/03/22 16:53:02 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:53:02 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=551225917
16/03/22 16:53:02 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 525.7 MB)
16/03/22 16:53:02 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24952, maxMem=551225917
16/03/22 16:53:02 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 525.7 MB)
16/03/22 16:53:02 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:36981 (size: 3.3 KB, free: 525.7 MB)
16/03/22 16:53:02 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/22 16:53:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:53:02 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/22 16:53:02 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/22 16:53:02 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/22 16:53:02 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/22 16:53:02 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/22 16:53:02 INFO PythonRunner: Times: total = 75, boot = -21, init = 96, finish = 0
16/03/22 16:53:02 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1336 bytes result sent to driver
16/03/22 16:53:02 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 83 ms on localhost (1/2)
16/03/22 16:53:02 INFO PythonRunner: Times: total = 180, boot = 179, init = 1, finish = 0
16/03/22 16:53:02 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/22 16:53:02 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 190 ms on localhost (2/2)
16/03/22 16:53:02 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/22 16:53:02 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.175 s
16/03/22 16:53:02 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.200472 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/22 16:53:02 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/22 16:53:02 INFO DAGScheduler: Stopping DAGScheduler
16/03/22 16:53:02 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/22 16:53:02 INFO MemoryStore: MemoryStore cleared
16/03/22 16:53:02 INFO BlockManager: BlockManager stopped
16/03/22 16:53:02 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/22 16:53:02 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/22 16:53:02 INFO SparkContext: Successfully stopped SparkContext
16/03/22 16:53:02 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/22 16:53:02 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/22 16:53:02 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'set', u'None']
16/03/22 16:53:03 INFO SparkContext: Running Spark version 1.5.2
16/03/22 16:53:03 INFO SecurityManager: Changing view acls to: root
16/03/22 16:53:03 INFO SecurityManager: Changing modify acls to: root
16/03/22 16:53:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/22 16:53:03 INFO Slf4jLogger: Slf4jLogger started
16/03/22 16:53:03 INFO Remoting: Starting remoting
16/03/22 16:53:03 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:44380]
16/03/22 16:53:03 INFO Utils: Successfully started service 'sparkDriver' on port 44380.
16/03/22 16:53:03 INFO SparkEnv: Registering MapOutputTracker
16/03/22 16:53:03 INFO SparkEnv: Registering BlockManagerMaster
16/03/22 16:53:03 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d9747a79-9c74-4c57-8c76-1c5311c0d4cc
16/03/22 16:53:03 INFO MemoryStore: MemoryStore started with capacity 524.7 MB
16/03/22 16:53:03 INFO HttpFileServer: HTTP File server directory is /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/httpd-87fe53a4-337b-46d8-be86-4b1d894cb022
16/03/22 16:53:03 INFO HttpServer: Starting HTTP Server
16/03/22 16:53:03 INFO Utils: Successfully started service 'HTTP file server' on port 36511.
16/03/22 16:53:03 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/22 16:53:04 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/22 16:53:04 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/22 16:53:04 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-3598df16-7460-4fd1-ad8c-e656619dbf41/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:53:04 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645784229
16/03/22 16:53:04 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/22 16:53:04 INFO Executor: Starting executor ID driver on host localhost
16/03/22 16:53:04 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37435.
16/03/22 16:53:04 INFO NettyBlockTransferService: Server created on 37435
16/03/22 16:53:04 INFO BlockManagerMaster: Trying to register BlockManager
16/03/22 16:53:04 INFO BlockManagerMasterEndpoint: Registering block manager localhost:37435 with 524.7 MB RAM, BlockManagerId(driver, localhost, 37435)
16/03/22 16:53:04 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): element
16/03/22 16:53:04 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:53:04 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:53:04 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:53:04 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:53:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/22 16:53:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/22 16:53:04 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:53:04 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=550235013
16/03/22 16:53:04 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 524.7 MB)
16/03/22 16:53:04 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=550235013
16/03/22 16:53:04 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 524.7 MB)
16/03/22 16:53:04 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:37435 (size: 4.1 KB, free: 524.7 MB)
16/03/22 16:53:04 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/22 16:53:04 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:53:04 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/22 16:53:04 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/22 16:53:04 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/22 16:53:04 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/22 16:53:04 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645784229
16/03/22 16:53:04 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/22 16:53:04 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-3598df16-7460-4fd1-ad8c-e656619dbf41/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:53:04 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/22 16:53:04 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10732, maxMem=550235013
16/03/22 16:53:04 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 524.7 MB)
16/03/22 16:53:04 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:37435 (size: 187.0 B, free: 524.7 MB)
16/03/22 16:53:04 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/22 16:53:04 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10919, maxMem=550235013
16/03/22 16:53:04 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 524.7 MB)
16/03/22 16:53:04 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:37435 (size: 177.0 B, free: 524.7 MB)
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: set
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: issue
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: planning
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: permission
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: economy
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: composition
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: agency
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/22 16:53:13 INFO PythonRunner: Times: total = 8803, boot = 471, init = 398, finish = 7934
16/03/22 16:53:13 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/22 16:53:13 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8895 ms on localhost (1/2)
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: bend
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: giant
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: astatine
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  element  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: present
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: area
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/22 16:53:13 INFO PythonRunner: Times: total = 9288, boot = 468, init = 477, finish = 8343
16/03/22 16:53:13 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/22 16:53:13 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9380 ms on localhost (2/2)
16/03/22 16:53:13 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/22 16:53:13 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 9.385 s
16/03/22 16:53:13 INFO DAGScheduler: looking for newly runnable stages
16/03/22 16:53:13 INFO DAGScheduler: running: Set()
16/03/22 16:53:13 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/22 16:53:13 INFO DAGScheduler: failed: Set()
16/03/22 16:53:13 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/22 16:53:13 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/22 16:53:13 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=550235013
16/03/22 16:53:13 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 524.7 MB)
16/03/22 16:53:13 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=550235013
16/03/22 16:53:13 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 524.7 MB)
16/03/22 16:53:13 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:37435 (size: 3.0 KB, free: 524.7 MB)
16/03/22 16:53:13 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/22 16:53:13 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:53:13 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/22 16:53:13 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:53:13 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:53:13 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/22 16:53:13 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/22 16:53:13 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:53:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/22 16:53:13 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:53:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/22 16:53:13 INFO PythonRunner: Times: total = 25, boot = -311, init = 336, finish = 0
16/03/22 16:53:13 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/22 16:53:13 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 67 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'astatine', 'None']
16/03/22 16:53:14 INFO PythonRunner: Times: total = 240, boot = 239, init = 0, finish = 1
16/03/22 16:53:14 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/03/22 16:53:14 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.260 s
16/03/22 16:53:14 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 9.680867 s
16/03/22 16:53:14 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 272 ms on localhost (2/2)
16/03/22 16:53:14 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/22 16:53:14 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:53:14 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:53:14 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:53:14 INFO DAGScheduler: Parents of final stage: List()
16/03/22 16:53:14 INFO DAGScheduler: Missing parents: List()
16/03/22 16:53:14 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:53:14 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=550235013
16/03/22 16:53:14 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 524.7 MB)
16/03/22 16:53:14 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24952, maxMem=550235013
16/03/22 16:53:14 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 524.7 MB)
16/03/22 16:53:14 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:37435 (size: 3.3 KB, free: 524.7 MB)
16/03/22 16:53:14 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/22 16:53:14 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:53:14 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/22 16:53:14 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/22 16:53:14 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/03/22 16:53:14 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/22 16:53:14 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/22 16:53:14 INFO PythonRunner: Times: total = 74, boot = -37, init = 111, finish = 0
16/03/22 16:53:14 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/22 16:53:14 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 92 ms on localhost (1/2)
16/03/22 16:53:14 INFO PythonRunner: Times: total = 138, boot = 138, init = 0, finish = 0
16/03/22 16:53:14 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/03/22 16:53:14 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 157 ms on localhost (2/2)
16/03/22 16:53:14 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/22 16:53:14 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.134 s
16/03/22 16:53:14 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.170024 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/22 16:53:14 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/22 16:53:14 INFO DAGScheduler: Stopping DAGScheduler
16/03/22 16:53:14 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/22 16:53:14 INFO MemoryStore: MemoryStore cleared
16/03/22 16:53:14 INFO BlockManager: BlockManager stopped
16/03/22 16:53:14 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/22 16:53:14 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/22 16:53:14 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/22 16:53:14 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/22 16:53:14 INFO SparkContext: Successfully stopped SparkContext
16/03/22 16:53:14 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'astatine', u'None']
16/03/22 16:53:15 INFO SparkContext: Running Spark version 1.5.2
16/03/22 16:53:15 INFO SecurityManager: Changing view acls to: root
16/03/22 16:53:15 INFO SecurityManager: Changing modify acls to: root
16/03/22 16:53:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/22 16:53:15 INFO Slf4jLogger: Slf4jLogger started
16/03/22 16:53:15 INFO Remoting: Starting remoting
16/03/22 16:53:15 INFO Utils: Successfully started service 'sparkDriver' on port 52655.
16/03/22 16:53:15 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:52655]
16/03/22 16:53:15 INFO SparkEnv: Registering MapOutputTracker
16/03/22 16:53:15 INFO SparkEnv: Registering BlockManagerMaster
16/03/22 16:53:15 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b2a26095-bb4b-450d-adef-fed62139bad2
16/03/22 16:53:15 INFO MemoryStore: MemoryStore started with capacity 524.7 MB
16/03/22 16:53:15 INFO HttpFileServer: HTTP File server directory is /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/httpd-06e2d0e2-ef27-48c0-98e0-00723395ada5
16/03/22 16:53:15 INFO HttpServer: Starting HTTP Server
16/03/22 16:53:15 INFO Utils: Successfully started service 'HTTP file server' on port 33504.
16/03/22 16:53:15 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/22 16:53:16 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/22 16:53:16 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/22 16:53:16 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-b9e73f0f-3d4e-488e-b641-ce7549a996e6/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:53:16 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645796220
16/03/22 16:53:16 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/22 16:53:16 INFO Executor: Starting executor ID driver on host localhost
16/03/22 16:53:16 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44348.
16/03/22 16:53:16 INFO NettyBlockTransferService: Server created on 44348
16/03/22 16:53:16 INFO BlockManagerMaster: Trying to register BlockManager
16/03/22 16:53:16 INFO BlockManagerMasterEndpoint: Registering block manager localhost:44348 with 524.7 MB RAM, BlockManagerId(driver, localhost, 44348)
16/03/22 16:53:16 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): person
16/03/22 16:53:16 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:53:16 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:53:16 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:53:16 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:53:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/22 16:53:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/22 16:53:16 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:53:16 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=550235013
16/03/22 16:53:16 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 524.7 MB)
16/03/22 16:53:16 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=550235013
16/03/22 16:53:16 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 524.7 MB)
16/03/22 16:53:16 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:44348 (size: 4.1 KB, free: 524.7 MB)
16/03/22 16:53:16 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/22 16:53:16 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:53:16 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/22 16:53:16 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/22 16:53:16 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/22 16:53:16 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/22 16:53:16 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645796220
16/03/22 16:53:16 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/22 16:53:16 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-b9e73f0f-3d4e-488e-b641-ce7549a996e6/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:53:16 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/22 16:53:16 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10732, maxMem=550235013
16/03/22 16:53:16 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 524.7 MB)
16/03/22 16:53:16 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:44348 (size: 187.0 B, free: 524.7 MB)
16/03/22 16:53:16 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/22 16:53:16 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10919, maxMem=550235013
16/03/22 16:53:16 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 524.7 MB)
16/03/22 16:53:16 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:44348 (size: 177.0 B, free: 524.7 MB)
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: set
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: bend
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: giant
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): adding to parents: syn =  Synset('colossus.n.02') ; keyword:  person  in syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= [u'giant']
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: astatine
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: present
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: area
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
16/03/22 16:53:25 INFO PythonRunner: Times: total = 9049, boot = 492, init = 497, finish = 8060
16/03/22 16:53:25 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/22 16:53:25 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9137 ms on localhost (1/2)
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: issue
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: planning
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: permission
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: economy
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: composition
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: agency
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/22 16:53:26 INFO PythonRunner: Times: total = 9610, boot = 482, init = 435, finish = 8693
16/03/22 16:53:26 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/22 16:53:26 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 9.691 s
16/03/22 16:53:26 INFO DAGScheduler: looking for newly runnable stages
16/03/22 16:53:26 INFO DAGScheduler: running: Set()
16/03/22 16:53:26 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/22 16:53:26 INFO DAGScheduler: failed: Set()
16/03/22 16:53:26 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/22 16:53:26 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/22 16:53:26 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=550235013
16/03/22 16:53:26 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 524.7 MB)
16/03/22 16:53:26 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=550235013
16/03/22 16:53:26 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 524.7 MB)
16/03/22 16:53:26 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9697 ms on localhost (2/2)
16/03/22 16:53:26 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:44348 (size: 3.0 KB, free: 524.7 MB)
16/03/22 16:53:26 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/22 16:53:26 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/22 16:53:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:53:26 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/22 16:53:26 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:53:26 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:53:26 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/22 16:53:26 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/22 16:53:26 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:53:26 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:53:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/22 16:53:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/22 16:53:26 INFO PythonRunner: Times: total = 49, boot = -351, init = 399, finish = 1
16/03/22 16:53:26 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1281 bytes result sent to driver
reduceFunction_Parents(): returns= ['None', u'giant', 'None']
16/03/22 16:53:26 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 112 ms on localhost (1/2)
16/03/22 16:53:26 INFO PythonRunner: Times: total = 241, boot = 240, init = 0, finish = 1
16/03/22 16:53:26 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/22 16:53:26 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 272 ms on localhost (2/2)
16/03/22 16:53:26 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.264 s
16/03/22 16:53:26 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/22 16:53:26 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 10.017988 s
16/03/22 16:53:26 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:53:26 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:53:26 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:53:26 INFO DAGScheduler: Parents of final stage: List()
16/03/22 16:53:26 INFO DAGScheduler: Missing parents: List()
16/03/22 16:53:26 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:53:26 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=550235013
16/03/22 16:53:26 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 524.7 MB)
16/03/22 16:53:26 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24952, maxMem=550235013
16/03/22 16:53:26 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 524.7 MB)
16/03/22 16:53:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:44348 (size: 3.3 KB, free: 524.7 MB)
16/03/22 16:53:26 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/22 16:53:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:53:26 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/22 16:53:26 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/22 16:53:26 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2362 bytes)
16/03/22 16:53:26 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/22 16:53:26 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/22 16:53:26 INFO PythonRunner: Times: total = 57, boot = -38, init = 95, finish = 0
16/03/22 16:53:26 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1349 bytes result sent to driver
16/03/22 16:53:26 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 69 ms on localhost (1/2)
16/03/22 16:53:26 INFO PythonRunner: Times: total = 114, boot = 113, init = 1, finish = 0
16/03/22 16:53:26 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/22 16:53:26 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 124 ms on localhost (2/2)
16/03/22 16:53:26 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/22 16:53:26 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.116 s
16/03/22 16:53:26 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.174334 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/22 16:53:26 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/22 16:53:26 INFO DAGScheduler: Stopping DAGScheduler
16/03/22 16:53:26 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/22 16:53:26 INFO MemoryStore: MemoryStore cleared
16/03/22 16:53:26 INFO BlockManager: BlockManager stopped
16/03/22 16:53:26 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/22 16:53:26 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/22 16:53:26 INFO SparkContext: Successfully stopped SparkContext
16/03/22 16:53:26 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/22 16:53:26 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/22 16:53:26 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'giant', u'None']
16/03/22 16:53:27 INFO SparkContext: Running Spark version 1.5.2
16/03/22 16:53:27 INFO SecurityManager: Changing view acls to: root
16/03/22 16:53:27 INFO SecurityManager: Changing modify acls to: root
16/03/22 16:53:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/22 16:53:27 INFO Slf4jLogger: Slf4jLogger started
16/03/22 16:53:27 INFO Remoting: Starting remoting
16/03/22 16:53:28 INFO Utils: Successfully started service 'sparkDriver' on port 46121.
16/03/22 16:53:28 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:46121]
16/03/22 16:53:28 INFO SparkEnv: Registering MapOutputTracker
16/03/22 16:53:28 INFO SparkEnv: Registering BlockManagerMaster
16/03/22 16:53:28 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-64d3cd82-00a9-4e17-a16c-b0962625f675
16/03/22 16:53:28 INFO MemoryStore: MemoryStore started with capacity 527.2 MB
16/03/22 16:53:28 INFO HttpFileServer: HTTP File server directory is /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/httpd-a7ab40e1-4a82-4e1d-b739-49bb687a607e
16/03/22 16:53:28 INFO HttpServer: Starting HTTP Server
16/03/22 16:53:28 INFO Utils: Successfully started service 'HTTP file server' on port 34139.
16/03/22 16:53:28 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/22 16:53:28 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/22 16:53:28 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/22 16:53:28 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-d381f052-0361-43b5-99d9-c5e625a97837/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:53:28 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645808253
16/03/22 16:53:28 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/22 16:53:28 INFO Executor: Starting executor ID driver on host localhost
16/03/22 16:53:28 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41069.
16/03/22 16:53:28 INFO NettyBlockTransferService: Server created on 41069
16/03/22 16:53:28 INFO BlockManagerMaster: Trying to register BlockManager
16/03/22 16:53:28 INFO BlockManagerMasterEndpoint: Registering block manager localhost:41069 with 527.2 MB RAM, BlockManagerId(driver, localhost, 41069)
16/03/22 16:53:28 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): reputation
16/03/22 16:53:28 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:53:28 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:53:28 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:53:28 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:53:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/22 16:53:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/22 16:53:28 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:53:28 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=552783052
16/03/22 16:53:28 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 527.2 MB)
16/03/22 16:53:28 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=552783052
16/03/22 16:53:28 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 527.2 MB)
16/03/22 16:53:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:41069 (size: 4.1 KB, free: 527.2 MB)
16/03/22 16:53:28 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/22 16:53:28 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:53:28 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/22 16:53:28 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/22 16:53:28 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/22 16:53:28 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/22 16:53:28 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645808253
16/03/22 16:53:28 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/22 16:53:28 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-d381f052-0361-43b5-99d9-c5e625a97837/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:53:28 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/22 16:53:28 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/22 16:53:28 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10732, maxMem=552783052
16/03/22 16:53:28 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 527.2 MB)
16/03/22 16:53:28 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10919, maxMem=552783052
16/03/22 16:53:28 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:41069 (size: 187.0 B, free: 527.2 MB)
16/03/22 16:53:28 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 527.2 MB)
16/03/22 16:53:28 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:41069 (size: 177.0 B, free: 527.2 MB)
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: area
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: bend
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: giant
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): adding to parents: syn =  Synset('colossus.n.02') ; keyword:  reputation  in syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= [u'giant']
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: astatine
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: present
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: area
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
16/03/22 16:53:37 INFO PythonRunner: Times: total = 9233, boot = 482, init = 421, finish = 8330
16/03/22 16:53:37 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/22 16:53:37 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9313 ms on localhost (1/2)
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: issue
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: planning
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: permission
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: economy
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: composition
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: agency
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/22 16:53:38 INFO PythonRunner: Times: total = 9720, boot = 472, init = 563, finish = 8685
16/03/22 16:53:38 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/22 16:53:38 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 9.796 s
16/03/22 16:53:38 INFO DAGScheduler: looking for newly runnable stages
16/03/22 16:53:38 INFO DAGScheduler: running: Set()
16/03/22 16:53:38 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/22 16:53:38 INFO DAGScheduler: failed: Set()
16/03/22 16:53:38 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/22 16:53:38 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9802 ms on localhost (2/2)
16/03/22 16:53:38 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/22 16:53:38 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/22 16:53:38 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=552783052
16/03/22 16:53:38 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 527.2 MB)
16/03/22 16:53:38 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=552783052
16/03/22 16:53:38 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 527.2 MB)
16/03/22 16:53:38 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:41069 (size: 3.0 KB, free: 527.2 MB)
16/03/22 16:53:38 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/22 16:53:38 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:53:38 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/22 16:53:38 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:53:38 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:53:38 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/22 16:53:38 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/22 16:53:38 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:53:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/22 16:53:38 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:53:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
reduceFunction_Parents(): returns= ['None', u'giant', 'None']
16/03/22 16:53:38 INFO PythonRunner: Times: total = 43, boot = -259, init = 301, finish = 1
16/03/22 16:53:38 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1281 bytes result sent to driver
16/03/22 16:53:38 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 120 ms on localhost (1/2)
16/03/22 16:53:38 INFO PythonRunner: Times: total = 309, boot = 308, init = 0, finish = 1
16/03/22 16:53:38 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/22 16:53:38 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.313 s
16/03/22 16:53:38 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 10.159747 s
16/03/22 16:53:38 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 327 ms on localhost (2/2)
16/03/22 16:53:38 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/22 16:53:38 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:53:38 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:53:38 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:53:38 INFO DAGScheduler: Parents of final stage: List()
16/03/22 16:53:38 INFO DAGScheduler: Missing parents: List()
16/03/22 16:53:38 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:53:38 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=552783052
16/03/22 16:53:38 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 527.2 MB)
16/03/22 16:53:38 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24952, maxMem=552783052
16/03/22 16:53:38 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 527.1 MB)
16/03/22 16:53:38 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:41069 (size: 3.3 KB, free: 527.2 MB)
16/03/22 16:53:38 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/22 16:53:38 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:53:38 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/22 16:53:38 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/22 16:53:38 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2362 bytes)
16/03/22 16:53:38 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/22 16:53:38 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/22 16:53:38 INFO PythonRunner: Times: total = 78, boot = -151, init = 229, finish = 0
16/03/22 16:53:38 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1349 bytes result sent to driver
16/03/22 16:53:38 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 90 ms on localhost (1/2)
16/03/22 16:53:38 INFO PythonRunner: Times: total = 193, boot = 193, init = 0, finish = 0
16/03/22 16:53:38 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/22 16:53:38 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 203 ms on localhost (2/2)
16/03/22 16:53:38 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/22 16:53:38 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.188 s
16/03/22 16:53:38 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.213309 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/22 16:53:38 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/22 16:53:38 INFO DAGScheduler: Stopping DAGScheduler
16/03/22 16:53:39 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/22 16:53:39 INFO MemoryStore: MemoryStore cleared
16/03/22 16:53:39 INFO BlockManager: BlockManager stopped
16/03/22 16:53:39 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/22 16:53:39 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/22 16:53:39 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/22 16:53:39 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/22 16:53:39 INFO SparkContext: Successfully stopped SparkContext
16/03/22 16:53:39 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'giant', u'None']
16/03/22 16:53:39 INFO SparkContext: Running Spark version 1.5.2
16/03/22 16:53:39 INFO SecurityManager: Changing view acls to: root
16/03/22 16:53:39 INFO SecurityManager: Changing modify acls to: root
16/03/22 16:53:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/22 16:53:39 INFO Slf4jLogger: Slf4jLogger started
16/03/22 16:53:39 INFO Remoting: Starting remoting
16/03/22 16:53:40 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:53848]
16/03/22 16:53:40 INFO Utils: Successfully started service 'sparkDriver' on port 53848.
16/03/22 16:53:40 INFO SparkEnv: Registering MapOutputTracker
16/03/22 16:53:40 INFO SparkEnv: Registering BlockManagerMaster
16/03/22 16:53:40 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-6aa9f2db-6716-416f-bfed-7815c7e27dfe
16/03/22 16:53:40 INFO MemoryStore: MemoryStore started with capacity 527.2 MB
16/03/22 16:53:40 INFO HttpFileServer: HTTP File server directory is /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/httpd-199daa45-0c6f-43a8-8812-d226ddad880f
16/03/22 16:53:40 INFO HttpServer: Starting HTTP Server
16/03/22 16:53:40 INFO Utils: Successfully started service 'HTTP file server' on port 42550.
16/03/22 16:53:40 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/22 16:53:40 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/22 16:53:40 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/22 16:53:40 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-924ade7d-3517-4ca6-aecb-bd8fc80df64b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:53:40 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645820219
16/03/22 16:53:40 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/22 16:53:40 INFO Executor: Starting executor ID driver on host localhost
16/03/22 16:53:40 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60455.
16/03/22 16:53:40 INFO NettyBlockTransferService: Server created on 60455
16/03/22 16:53:40 INFO BlockManagerMaster: Trying to register BlockManager
16/03/22 16:53:40 INFO BlockManagerMasterEndpoint: Registering block manager localhost:60455 with 527.2 MB RAM, BlockManagerId(driver, localhost, 60455)
16/03/22 16:53:40 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): time
16/03/22 16:53:40 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:53:40 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:53:40 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:53:40 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:53:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/22 16:53:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/22 16:53:40 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:53:40 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=552783052
16/03/22 16:53:40 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 527.2 MB)
16/03/22 16:53:40 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=552783052
16/03/22 16:53:40 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 527.2 MB)
16/03/22 16:53:40 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:60455 (size: 4.1 KB, free: 527.2 MB)
16/03/22 16:53:40 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/22 16:53:40 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:53:40 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/22 16:53:40 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/22 16:53:40 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/22 16:53:40 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/22 16:53:40 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645820219
16/03/22 16:53:40 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/22 16:53:40 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-924ade7d-3517-4ca6-aecb-bd8fc80df64b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:53:40 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/22 16:53:40 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10732, maxMem=552783052
16/03/22 16:53:40 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 527.2 MB)
16/03/22 16:53:40 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/22 16:53:40 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10909, maxMem=552783052
16/03/22 16:53:40 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:60455 (size: 177.0 B, free: 527.2 MB)
16/03/22 16:53:40 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 527.2 MB)
16/03/22 16:53:40 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:60455 (size: 187.0 B, free: 527.2 MB)
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: area
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: bend
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: giant
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: astatine
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: present
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  time  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: area
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/22 16:53:50 INFO PythonRunner: Times: total = 9702, boot = 503, init = 430, finish = 8769
16/03/22 16:53:50 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/22 16:53:50 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9887 ms on localhost (1/2)
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: issue
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: planning
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: permission
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: economy
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: composition
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: agency
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/22 16:53:51 INFO PythonRunner: Times: total = 10551, boot = 517, init = 526, finish = 9508
16/03/22 16:53:51 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/22 16:53:51 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 10.731 s
16/03/22 16:53:51 INFO DAGScheduler: looking for newly runnable stages
16/03/22 16:53:51 INFO DAGScheduler: running: Set()
16/03/22 16:53:51 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/22 16:53:51 INFO DAGScheduler: failed: Set()
16/03/22 16:53:51 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/22 16:53:51 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/22 16:53:51 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=552783052
16/03/22 16:53:51 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 527.2 MB)
16/03/22 16:53:51 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=552783052
16/03/22 16:53:51 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 527.2 MB)
16/03/22 16:53:51 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:60455 (size: 3.0 KB, free: 527.2 MB)
16/03/22 16:53:51 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/22 16:53:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:53:51 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/22 16:53:51 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 10728 ms on localhost (2/2)
16/03/22 16:53:51 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/22 16:53:51 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:53:51 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:53:51 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/22 16:53:51 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:53:51 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/22 16:53:51 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:53:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/22 16:53:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
reduceFunction_Parents(): returns= ['None', u'present', 'None']
16/03/22 16:53:51 INFO PythonRunner: Times: total = 35, boot = -615, init = 649, finish = 1
16/03/22 16:53:51 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/22 16:53:51 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 107 ms on localhost (1/2)
16/03/22 16:53:51 INFO PythonRunner: Times: total = 288, boot = 287, init = 0, finish = 1
16/03/22 16:53:51 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/22 16:53:51 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.295 s
16/03/22 16:53:51 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 11.057337 s
16/03/22 16:53:51 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 306 ms on localhost (2/2)
16/03/22 16:53:51 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/22 16:53:51 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:53:51 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:53:51 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:53:51 INFO DAGScheduler: Parents of final stage: List()
16/03/22 16:53:51 INFO DAGScheduler: Missing parents: List()
16/03/22 16:53:51 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:53:51 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=552783052
16/03/22 16:53:51 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 527.2 MB)
16/03/22 16:53:51 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24952, maxMem=552783052
16/03/22 16:53:51 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 527.1 MB)
16/03/22 16:53:51 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:60455 (size: 3.3 KB, free: 527.2 MB)
16/03/22 16:53:51 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/22 16:53:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:53:51 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/22 16:53:51 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/22 16:53:51 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/22 16:53:51 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/22 16:53:51 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/22 16:53:51 INFO PythonRunner: Times: total = 51, boot = -135, init = 186, finish = 0
16/03/22 16:53:51 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1351 bytes result sent to driver
16/03/22 16:53:51 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 76 ms on localhost (1/2)
16/03/22 16:53:51 INFO PythonRunner: Times: total = 234, boot = 232, init = 2, finish = 0
16/03/22 16:53:51 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/22 16:53:51 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 242 ms on localhost (2/2)
16/03/22 16:53:51 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/22 16:53:51 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.231 s
16/03/22 16:53:51 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.277443 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/22 16:53:51 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/22 16:53:51 INFO DAGScheduler: Stopping DAGScheduler
16/03/22 16:53:51 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/22 16:53:51 INFO MemoryStore: MemoryStore cleared
16/03/22 16:53:51 INFO BlockManager: BlockManager stopped
16/03/22 16:53:51 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/22 16:53:51 INFO SparkContext: Successfully stopped SparkContext
16/03/22 16:53:51 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/22 16:53:51 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/22 16:53:51 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/22 16:53:51 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'present', u'None']
16/03/22 16:53:52 INFO SparkContext: Running Spark version 1.5.2
16/03/22 16:53:52 INFO SecurityManager: Changing view acls to: root
16/03/22 16:53:52 INFO SecurityManager: Changing modify acls to: root
16/03/22 16:53:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/22 16:53:52 INFO Slf4jLogger: Slf4jLogger started
16/03/22 16:53:52 INFO Remoting: Starting remoting
16/03/22 16:53:52 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:48388]
16/03/22 16:53:52 INFO Utils: Successfully started service 'sparkDriver' on port 48388.
16/03/22 16:53:52 INFO SparkEnv: Registering MapOutputTracker
16/03/22 16:53:52 INFO SparkEnv: Registering BlockManagerMaster
16/03/22 16:53:52 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c7cdd7c2-1311-4d6b-b47f-5c99584552d0
16/03/22 16:53:52 INFO MemoryStore: MemoryStore started with capacity 527.2 MB
16/03/22 16:53:52 INFO HttpFileServer: HTTP File server directory is /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/httpd-274bcbb4-175c-4c12-9080-f8f32f5c54be
16/03/22 16:53:52 INFO HttpServer: Starting HTTP Server
16/03/22 16:53:53 INFO Utils: Successfully started service 'HTTP file server' on port 60922.
16/03/22 16:53:53 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/22 16:53:53 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/22 16:53:53 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/22 16:53:53 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-73be638d-21f6-4d1c-820f-1641c956ca28/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:53:53 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645833662
16/03/22 16:53:53 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/22 16:53:53 INFO Executor: Starting executor ID driver on host localhost
16/03/22 16:53:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42701.
16/03/22 16:53:53 INFO NettyBlockTransferService: Server created on 42701
16/03/22 16:53:53 INFO BlockManagerMaster: Trying to register BlockManager
16/03/22 16:53:53 INFO BlockManagerMasterEndpoint: Registering block manager localhost:42701 with 527.2 MB RAM, BlockManagerId(driver, localhost, 42701)
16/03/22 16:53:53 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): position
16/03/22 16:53:53 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:53:53 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:53:53 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:53:53 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:53:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/22 16:53:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/22 16:53:53 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:53:53 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=552783052
16/03/22 16:53:53 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 527.2 MB)
16/03/22 16:53:54 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=552783052
16/03/22 16:53:54 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 527.2 MB)
16/03/22 16:53:54 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:42701 (size: 4.1 KB, free: 527.2 MB)
16/03/22 16:53:54 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/22 16:53:54 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:53:54 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/22 16:53:54 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/22 16:53:54 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/22 16:53:54 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/22 16:53:54 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645833662
16/03/22 16:53:54 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/22 16:53:54 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-73be638d-21f6-4d1c-820f-1641c956ca28/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:53:54 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/22 16:53:54 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10732, maxMem=552783052
16/03/22 16:53:54 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 527.2 MB)
16/03/22 16:53:54 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:42701 (size: 177.0 B, free: 527.2 MB)
16/03/22 16:53:54 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/22 16:53:54 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10909, maxMem=552783052
16/03/22 16:53:54 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 527.2 MB)
16/03/22 16:53:54 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:42701 (size: 187.0 B, free: 527.2 MB)
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: set
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: issue
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: planning
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: permission
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: economy
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: composition
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: agency
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/22 16:54:03 INFO PythonRunner: Times: total = 9522, boot = 489, init = 432, finish = 8601
16/03/22 16:54:03 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/22 16:54:03 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9642 ms on localhost (1/2)
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: bend
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: giant
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: astatine
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: present
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  position  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: area
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
16/03/22 16:54:03 INFO PythonRunner: Times: total = 9826, boot = 488, init = 508, finish = 8830
16/03/22 16:54:03 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/22 16:54:03 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9949 ms on localhost (2/2)
16/03/22 16:54:03 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/22 16:54:03 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 9.951 s
16/03/22 16:54:03 INFO DAGScheduler: looking for newly runnable stages
16/03/22 16:54:03 INFO DAGScheduler: running: Set()
16/03/22 16:54:03 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/22 16:54:03 INFO DAGScheduler: failed: Set()
16/03/22 16:54:03 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/22 16:54:03 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/22 16:54:03 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=552783052
16/03/22 16:54:03 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 527.2 MB)
16/03/22 16:54:03 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=552783052
16/03/22 16:54:03 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 527.2 MB)
16/03/22 16:54:03 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:42701 (size: 3.0 KB, free: 527.2 MB)
16/03/22 16:54:03 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/22 16:54:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:54:03 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/22 16:54:03 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:54:03 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:54:03 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/22 16:54:03 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/22 16:54:03 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:54:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/22 16:54:03 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:54:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
reduceFunction_Parents(): returns= ['None', u'metropolitan', 'None']
16/03/22 16:54:04 INFO PythonRunner: Times: total = 55, boot = -117, init = 172, finish = 0
16/03/22 16:54:04 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1288 bytes result sent to driver
16/03/22 16:54:04 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 98 ms on localhost (1/2)
16/03/22 16:54:04 INFO PythonRunner: Times: total = 221, boot = 220, init = 1, finish = 0
16/03/22 16:54:04 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/22 16:54:04 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.238 s
16/03/22 16:54:04 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 10.420926 s
16/03/22 16:54:04 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 255 ms on localhost (2/2)
16/03/22 16:54:04 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/22 16:54:04 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:54:04 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:54:04 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:54:04 INFO DAGScheduler: Parents of final stage: List()
16/03/22 16:54:04 INFO DAGScheduler: Missing parents: List()
16/03/22 16:54:04 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:54:04 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=552783052
16/03/22 16:54:04 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 527.2 MB)
16/03/22 16:54:04 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24952, maxMem=552783052
16/03/22 16:54:04 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 527.1 MB)
16/03/22 16:54:04 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:42701 (size: 3.3 KB, free: 527.2 MB)
16/03/22 16:54:04 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/22 16:54:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:54:04 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/22 16:54:04 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/22 16:54:04 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2369 bytes)
16/03/22 16:54:04 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/22 16:54:04 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/22 16:54:04 INFO PythonRunner: Times: total = 66, boot = -37, init = 103, finish = 0
16/03/22 16:54:04 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/22 16:54:04 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 73 ms on localhost (1/2)
16/03/22 16:54:04 INFO PythonRunner: Times: total = 120, boot = 120, init = 0, finish = 0
16/03/22 16:54:04 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1356 bytes result sent to driver
16/03/22 16:54:04 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 134 ms on localhost (2/2)
16/03/22 16:54:04 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/22 16:54:04 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.116 s
16/03/22 16:54:04 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.159139 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/22 16:54:04 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/22 16:54:04 INFO DAGScheduler: Stopping DAGScheduler
16/03/22 16:54:04 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/22 16:54:04 INFO MemoryStore: MemoryStore cleared
16/03/22 16:54:04 INFO BlockManager: BlockManager stopped
16/03/22 16:54:04 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/22 16:54:04 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/22 16:54:04 INFO SparkContext: Successfully stopped SparkContext
16/03/22 16:54:04 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/22 16:54:04 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/22 16:54:04 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'metropolitan', u'None']
16/03/22 16:54:05 INFO SparkContext: Running Spark version 1.5.2
16/03/22 16:54:05 INFO SecurityManager: Changing view acls to: root
16/03/22 16:54:05 INFO SecurityManager: Changing modify acls to: root
16/03/22 16:54:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/22 16:54:05 INFO Slf4jLogger: Slf4jLogger started
16/03/22 16:54:05 INFO Remoting: Starting remoting
16/03/22 16:54:05 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:34540]
16/03/22 16:54:05 INFO Utils: Successfully started service 'sparkDriver' on port 34540.
16/03/22 16:54:05 INFO SparkEnv: Registering MapOutputTracker
16/03/22 16:54:05 INFO SparkEnv: Registering BlockManagerMaster
16/03/22 16:54:05 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ace2ec96-d16c-4589-9df5-d8edab5bb633
16/03/22 16:54:05 INFO MemoryStore: MemoryStore started with capacity 526.5 MB
16/03/22 16:54:05 INFO HttpFileServer: HTTP File server directory is /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/httpd-cea4bec4-026a-4f9e-9611-eb18a970a37c
16/03/22 16:54:05 INFO HttpServer: Starting HTTP Server
16/03/22 16:54:05 INFO Utils: Successfully started service 'HTTP file server' on port 53317.
16/03/22 16:54:05 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/22 16:54:05 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/22 16:54:05 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/22 16:54:05 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-548a1c11-01bb-427c-b5ff-179fa5252855/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:54:05 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645845915
16/03/22 16:54:05 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/22 16:54:05 INFO Executor: Starting executor ID driver on host localhost
16/03/22 16:54:06 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55489.
16/03/22 16:54:06 INFO NettyBlockTransferService: Server created on 55489
16/03/22 16:54:06 INFO BlockManagerMaster: Trying to register BlockManager
16/03/22 16:54:06 INFO BlockManagerMasterEndpoint: Registering block manager localhost:55489 with 526.5 MB RAM, BlockManagerId(driver, localhost, 55489)
16/03/22 16:54:06 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): quantity
16/03/22 16:54:06 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:54:06 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:54:06 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:54:06 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:54:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/22 16:54:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/22 16:54:06 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:54:06 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=552075264
16/03/22 16:54:06 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 526.5 MB)
16/03/22 16:54:06 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=552075264
16/03/22 16:54:06 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 526.5 MB)
16/03/22 16:54:06 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:55489 (size: 4.1 KB, free: 526.5 MB)
16/03/22 16:54:06 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/22 16:54:06 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:54:06 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/22 16:54:06 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/22 16:54:06 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/22 16:54:06 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/22 16:54:06 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645845915
16/03/22 16:54:06 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/22 16:54:06 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-548a1c11-01bb-427c-b5ff-179fa5252855/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:54:06 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/22 16:54:06 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10732, maxMem=552075264
16/03/22 16:54:06 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 526.5 MB)
16/03/22 16:54:06 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:55489 (size: 177.0 B, free: 526.5 MB)
16/03/22 16:54:06 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/22 16:54:06 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10909, maxMem=552075264
16/03/22 16:54:06 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 526.5 MB)
16/03/22 16:54:06 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:55489 (size: 187.0 B, free: 526.5 MB)
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: area
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: issue
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: planning
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: permission
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: economy
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: composition
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: agency
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/22 16:54:15 INFO PythonRunner: Times: total = 9343, boot = 496, init = 588, finish = 8259
16/03/22 16:54:15 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/22 16:54:15 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9448 ms on localhost (1/2)
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: bend
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: giant
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: astatine
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: present
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: area
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/22 16:54:16 INFO PythonRunner: Times: total = 9944, boot = 490, init = 417, finish = 9037
16/03/22 16:54:16 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/22 16:54:16 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 10035 ms on localhost (2/2)
16/03/22 16:54:16 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 10.041 s
16/03/22 16:54:16 INFO DAGScheduler: looking for newly runnable stages
16/03/22 16:54:16 INFO DAGScheduler: running: Set()
16/03/22 16:54:16 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/22 16:54:16 INFO DAGScheduler: failed: Set()
16/03/22 16:54:16 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/22 16:54:16 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/22 16:54:16 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=552075264
16/03/22 16:54:16 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 526.5 MB)
16/03/22 16:54:16 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=552075264
16/03/22 16:54:16 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 526.5 MB)
16/03/22 16:54:16 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/22 16:54:16 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:55489 (size: 3.0 KB, free: 526.5 MB)
16/03/22 16:54:16 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/22 16:54:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:54:16 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/22 16:54:16 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:54:16 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:54:16 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/22 16:54:16 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:54:16 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/22 16:54:16 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:54:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/22 16:54:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
reduceFunction_Parents(): returns= ['None', 'None']
16/03/22 16:54:16 INFO PythonRunner: Times: total = 34, boot = -405, init = 439, finish = 0
16/03/22 16:54:16 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1269 bytes result sent to driver
16/03/22 16:54:16 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 123 ms on localhost (1/2)
16/03/22 16:54:16 INFO PythonRunner: Times: total = 282, boot = 281, init = 0, finish = 1
16/03/22 16:54:16 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/22 16:54:16 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 300 ms on localhost (2/2)
16/03/22 16:54:16 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/22 16:54:16 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.280 s
16/03/22 16:54:16 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 10.366687 s
16/03/22 16:54:16 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/22 16:54:16 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/22 16:54:16 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:54:16 INFO DAGScheduler: Parents of final stage: List()
16/03/22 16:54:16 INFO DAGScheduler: Missing parents: List()
16/03/22 16:54:16 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/22 16:54:16 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=552075264
16/03/22 16:54:16 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 526.5 MB)
16/03/22 16:54:16 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24952, maxMem=552075264
16/03/22 16:54:16 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 526.5 MB)
16/03/22 16:54:16 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:55489 (size: 3.3 KB, free: 526.5 MB)
16/03/22 16:54:16 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/22 16:54:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/22 16:54:16 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/22 16:54:16 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/22 16:54:16 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2350 bytes)
16/03/22 16:54:16 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/22 16:54:16 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/22 16:54:16 INFO PythonRunner: Times: total = 73, boot = -134, init = 207, finish = 0
16/03/22 16:54:16 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/22 16:54:16 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 80 ms on localhost (1/2)
16/03/22 16:54:16 INFO PythonRunner: Times: total = 102, boot = 102, init = 0, finish = 0
16/03/22 16:54:16 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1337 bytes result sent to driver
16/03/22 16:54:16 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 120 ms on localhost (2/2)
16/03/22 16:54:16 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/22 16:54:16 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.103 s
16/03/22 16:54:16 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.139209 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/22 16:54:16 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/22 16:54:16 INFO DAGScheduler: Stopping DAGScheduler
16/03/22 16:54:16 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/22 16:54:16 INFO MemoryStore: MemoryStore cleared
16/03/22 16:54:16 INFO BlockManager: BlockManager stopped
16/03/22 16:54:16 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/22 16:54:16 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/22 16:54:16 INFO SparkContext: Successfully stopped SparkContext
16/03/22 16:54:16 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/22 16:54:16 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/22 16:54:16 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None']
InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:freqterms1= [u'serving', u'Madras', u'Bengal', u'course', u'relation', u'geography', u'group', u'decay', u'program', u'Tamil', u'exceptional', u'Bay', u'formulating', u'serves', u'item', u'miles', u'unstable', u'including', u'people', u'series', u'Christianity', u'culture', u'meters', u'special', u'0.621371', u'Orthodox', u'definite', u'boundary', u'business', u'importance', u'equivalent', u'thorium', u'approval', u'providing', u'region', u'title', u'equal', u'length', u'resulting', u'act', u'action', u'whole', u'businesses', u'1000', u'formerly', u'period', u'highly', u'production', u'indefinite', u'unit', u'city', u'use', u'consumption', u'Eastern', u'stretch', u'archbishop', u'system', u'halogen', u'continuous', u'western', u'particular', u'given', u'kind', u'official', u'patriarch', u'Church', u'distribution', u'property', u'distinguished', u'metric', u'heaviest', u'purposes', u'general', u'something', u'bishop', u'things', u'belong', u'uranium', u'arrangement', u'parts', u'speech', u'geographical', u'spatial', u'Nadu', u'circular', u'product', u'used', u'usually', u'moment', u'purpose', u'segment', u'radioactive', u'happening', u'curve', u'together', u'element', u'person', u'reputation', u'time', u'position', u'quantity']
16/03/22 16:54:17 INFO SparkContext: Running Spark version 1.5.2
16/03/22 16:54:17 INFO SecurityManager: Changing view acls to: root
16/03/22 16:54:17 INFO SecurityManager: Changing modify acls to: root
16/03/22 16:54:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/22 16:54:17 INFO Slf4jLogger: Slf4jLogger started
16/03/22 16:54:17 INFO Remoting: Starting remoting
16/03/22 16:54:17 INFO Utils: Successfully started service 'sparkDriver' on port 42406.
16/03/22 16:54:17 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:42406]
16/03/22 16:54:17 INFO SparkEnv: Registering MapOutputTracker
16/03/22 16:54:17 INFO SparkEnv: Registering BlockManagerMaster
16/03/22 16:54:17 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-26a6afe2-4b79-455c-9811-ca06146bd860
16/03/22 16:54:17 INFO MemoryStore: MemoryStore started with capacity 526.5 MB
16/03/22 16:54:17 INFO HttpFileServer: HTTP File server directory is /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/httpd-c0c8e686-bd9c-4dac-91d9-a55e7386ffe6
16/03/22 16:54:17 INFO HttpServer: Starting HTTP Server
16/03/22 16:54:17 INFO Utils: Successfully started service 'HTTP file server' on port 34259.
16/03/22 16:54:17 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/22 16:54:18 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/22 16:54:18 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/22 16:54:18 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-2384dce8-5b2a-43ac-948e-0fffb0190209/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:54:18 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645858072
16/03/22 16:54:18 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/22 16:54:18 INFO Executor: Starting executor ID driver on host localhost
16/03/22 16:54:18 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42465.
16/03/22 16:54:18 INFO NettyBlockTransferService: Server created on 42465
16/03/22 16:54:18 INFO BlockManagerMaster: Trying to register BlockManager
16/03/22 16:54:18 INFO BlockManagerMasterEndpoint: Registering block manager localhost:42465 with 526.5 MB RAM, BlockManagerId(driver, localhost, 42465)
16/03/22 16:54:18 INFO BlockManagerMaster: Registered BlockManager
Spark_MapReduce(): wordsatthislevel: [u'serving', u'Madras', u'Bengal', u'course', u'relation', u'geography', u'group', u'decay', u'program', u'Tamil', u'exceptional', u'Bay', u'formulating', u'serves', u'item', u'miles', u'unstable', u'including', u'people', u'series', u'Christianity', u'culture', u'meters', u'special', u'0.621371', u'Orthodox', u'definite', u'boundary', u'business', u'importance', u'equivalent', u'thorium', u'approval', u'providing', u'region', u'title', u'equal', u'length', u'resulting', u'act', u'action', u'whole', u'businesses', u'1000', u'formerly', u'period', u'highly', u'production', u'indefinite', u'unit', u'city', u'use', u'consumption', u'Eastern', u'stretch', u'archbishop', u'system', u'halogen', u'continuous', u'western', u'particular', u'given', u'kind', u'official', u'patriarch', u'Church', u'distribution', u'property', u'distinguished', u'metric', u'heaviest', u'purposes', u'general', u'something', u'bishop', u'things', u'belong', u'uranium', u'arrangement', u'parts', u'speech', u'geographical', u'spatial', u'Nadu', u'circular', u'product', u'used', u'usually', u'moment', u'purpose', u'segment', u'radioactive', u'happening', u'curve', u'together', u'element', u'person', u'reputation', u'time', u'position', u'quantity']
16/03/22 16:54:18 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234
16/03/22 16:54:18 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234)
16/03/22 16:54:18 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234) with 2 output partitions
16/03/22 16:54:18 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234)
16/03/22 16:54:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/22 16:54:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/22 16:54:18 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234), which has no missing parents
16/03/22 16:54:18 INFO MemoryStore: ensureFreeSpace(6560) called with curMem=0, maxMem=552075264
16/03/22 16:54:18 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 526.5 MB)
16/03/22 16:54:18 INFO MemoryStore: ensureFreeSpace(4147) called with curMem=6560, maxMem=552075264
16/03/22 16:54:18 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 526.5 MB)
16/03/22 16:54:18 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:42465 (size: 4.0 KB, free: 526.5 MB)
16/03/22 16:54:18 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/22 16:54:18 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234)
16/03/22 16:54:18 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/22 16:54:18 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 3016 bytes)
16/03/22 16:54:18 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 3065 bytes)
16/03/22 16:54:18 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/22 16:54:18 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458645858072
16/03/22 16:54:18 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/22 16:54:18 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/userFiles-2384dce8-5b2a-43ac-948e-0fffb0190209/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/22 16:54:18 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/22 16:54:18 INFO MemoryStore: ensureFreeSpace(662) called with curMem=10707, maxMem=552075264
16/03/22 16:54:18 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 662.0 B, free 526.5 MB)
16/03/22 16:54:18 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:42465 (size: 662.0 B, free: 526.5 MB)
16/03/22 16:54:18 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/22 16:54:18 INFO MemoryStore: ensureFreeSpace(692) called with curMem=11369, maxMem=552075264
16/03/22 16:54:18 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 692.0 B, free 526.5 MB)
16/03/22 16:54:18 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:42465 (size: 692.0 B, free: 526.5 MB)
mapFunction(): freqterms1: city
mapFunction(): freqterms1: serving
mapFunction(): freqterms1: use
mapFunction(): freqterms1: consumption
mapFunction(): freqterms1: Eastern
mapFunction(): freqterms1: Madras
mapFunction(): freqterms1: stretch
mapFunction(): freqterms1: Bengal
mapFunction(): freqterms1: course
mapFunction(): freqterms1: archbishop
mapFunction(): freqterms1: system
mapFunction(): freqterms1: halogen
mapFunction(): freqterms1: continuous
mapFunction(): freqterms1: relation
mapFunction(): freqterms1: western
mapFunction(): freqterms1: particular
mapFunction(): freqterms1: geography
mapFunction(): freqterms1: group
mapFunction(): freqterms1: given
mapFunction(): freqterms1: decay
mapFunction(): freqterms1: program
mapFunction(): freqterms1: Tamil
mapFunction(): freqterms1: exceptional
mapFunction(): freqterms1: Bay
mapFunction(): freqterms1: kind
mapFunction(): freqterms1: official
mapFunction(): freqterms1: patriarch
mapFunction(): freqterms1: formulating
mapFunction(): freqterms1: Church
mapFunction(): freqterms1: serves
mapFunction(): freqterms1: item
mapFunction(): freqterms1: distribution
mapFunction(): freqterms1: property
mapFunction(): freqterms1: miles
mapFunction(): freqterms1: unstable
mapFunction(): freqterms1: distinguished
mapFunction(): freqterms1: metric
mapFunction(): freqterms1: including
mapFunction(): freqterms1: heaviest
mapFunction(): freqterms1: people
mapFunction(): freqterms1: series
mapFunction(): freqterms1: Christianity
mapFunction(): freqterms1: purposes
mapFunction(): freqterms1: culture
mapFunction(): freqterms1: general
mapFunction(): freqterms1: meters
mapFunction(): freqterms1: something
mapFunction(): freqterms1: bishop
mapFunction(): freqterms1: things
mapFunction(): freqterms1: special
mapFunction(): freqterms1: 0.621371
mapFunction(): freqterms1: Orthodox
mapFunction(): freqterms1: definite
mapFunction(): freqterms1: belong
mapFunction(): freqterms1: boundary
mapFunction(): freqterms1: uranium
mapFunction(): freqterms1: arrangement
mapFunction(): freqterms1: parts
mapFunction(): freqterms1: business
mapFunction(): freqterms1: importance
mapFunction(): freqterms1: equivalent
mapFunction(): freqterms1: thorium
mapFunction(): freqterms1: approval
mapFunction(): freqterms1: providing
mapFunction(): freqterms1: speech
mapFunction(): freqterms1: region
mapFunction(): freqterms1: geographical
mapFunction(): freqterms1: title
mapFunction(): freqterms1: spatial
mapFunction(): freqterms1: Nadu
mapFunction(): freqterms1: circular
mapFunction(): freqterms1: equal
mapFunction(): freqterms1: product
mapFunction(): freqterms1: used
mapFunction(): freqterms1: length
mapFunction(): freqterms1: usually
mapFunction(): freqterms1: moment
mapFunction(): freqterms1: resulting
mapFunction(): freqterms1: act
mapFunction(): freqterms1: purpose
mapFunction(): freqterms1: segment
mapFunction(): freqterms1: radioactive
mapFunction(): freqterms1: happening
mapFunction(): freqterms1: action
mapFunction(): freqterms1: curve
mapFunction(): freqterms1: together
mapFunction(): freqterms1: whole
mapFunction(): freqterms1: businesses
mapFunction(): freqterms1: 1000
mapFunction(): freqterms1: element
mapFunction(): freqterms1: person
mapFunction(): freqterms1: reputation
mapFunction(): freqterms1: time
mapFunction(): freqterms1: formerly
mapFunction(): freqterms1: period
mapFunction(): freqterms1: position
mapFunction(): freqterms1: highly
mapFunction(): freqterms1: production
mapFunction(): freqterms1: indefinite
mapFunction(): freqterms1: quantity
mapFunction(): freqterms1: unit
16/03/22 16:54:31 INFO PythonRunner: Times: total = 13450, boot = 504, init = 446, finish = 12500
16/03/22 16:54:31 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/22 16:54:31 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 13567 ms on localhost (1/2)
16/03/22 16:54:31 INFO PythonRunner: Times: total = 13544, boot = 496, init = 573, finish = 12475
16/03/22 16:54:31 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/22 16:54:31 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234) finished in 13.639 s
16/03/22 16:54:31 INFO DAGScheduler: looking for newly runnable stages
16/03/22 16:54:31 INFO DAGScheduler: running: Set()
16/03/22 16:54:31 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/22 16:54:31 INFO DAGScheduler: failed: Set()
16/03/22 16:54:31 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/22 16:54:31 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234), which is now runnable
16/03/22 16:54:31 INFO MemoryStore: ensureFreeSpace(4976) called with curMem=12061, maxMem=552075264
16/03/22 16:54:31 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 526.5 MB)
16/03/22 16:54:31 INFO MemoryStore: ensureFreeSpace(3049) called with curMem=17037, maxMem=552075264
16/03/22 16:54:31 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 526.5 MB)
16/03/22 16:54:31 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:42465 (size: 3.0 KB, free: 526.5 MB)
16/03/22 16:54:31 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/22 16:54:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234)
16/03/22 16:54:31 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/22 16:54:31 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 13635 ms on localhost (2/2)
16/03/22 16:54:31 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/22 16:54:31 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:54:31 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/22 16:54:31 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/22 16:54:31 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:54:31 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/22 16:54:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/22 16:54:31 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/22 16:54:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/22 16:54:32 INFO PythonRunner: Times: total = 267, boot = 266, init = 1, finish = 0
16/03/22 16:54:32 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/22 16:54:32 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 302 ms on localhost (1/2)
16/03/22 16:54:32 INFO PythonRunner: Times: total = 385, boot = 381, init = 0, finish = 4
16/03/22 16:54:32 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 11013 bytes result sent to driver
16/03/22 16:54:32 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234) finished in 0.394 s
16/03/22 16:54:32 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234, took 14.071590 s
16/03/22 16:54:32 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 404 ms on localhost (2/2)
16/03/22 16:54:32 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/22 16:54:32 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234
16/03/22 16:54:32 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234) with 2 output partitions
16/03/22 16:54:32 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234)
16/03/22 16:54:32 INFO DAGScheduler: Parents of final stage: List()
16/03/22 16:54:32 INFO DAGScheduler: Missing parents: List()
16/03/22 16:54:32 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234), which has no missing parents
16/03/22 16:54:32 INFO MemoryStore: ensureFreeSpace(5872) called with curMem=20086, maxMem=552075264
16/03/22 16:54:32 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 526.5 MB)
16/03/22 16:54:32 INFO MemoryStore: ensureFreeSpace(3419) called with curMem=25958, maxMem=552075264
16/03/22 16:54:32 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 526.5 MB)
16/03/22 16:54:32 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:42465 (size: 3.3 KB, free: 526.5 MB)
16/03/22 16:54:32 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/22 16:54:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234)
16/03/22 16:54:32 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/22 16:54:32 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/22 16:54:32 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 11962 bytes)
16/03/22 16:54:32 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/22 16:54:32 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/22 16:54:32 INFO PythonRunner: Times: total = 52, boot = -24, init = 76, finish = 0
16/03/22 16:54:32 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/22 16:54:32 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 97 ms on localhost (1/2)
16/03/22 16:54:32 INFO PythonRunner: Times: total = 136, boot = 134, init = 1, finish = 1
16/03/22 16:54:32 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 11320 bytes result sent to driver
16/03/22 16:54:32 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 169 ms on localhost (2/2)
16/03/22 16:54:32 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/22 16:54:32 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234) finished in 0.150 s
16/03/22 16:54:32 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234, took 0.189717 s
Spark_MapReduce() - SparkSQL DataFrame query results:
Row(tokensatthislevel=[u'individual', u'quantity', u'food', u'drink', u'taken', u'part', u'meal', u'state', u'southeastern', u'India', u'Bay', u'Bengal', u'south', u'Andhra', u'Pradesh', u'formerly', u'Madras', u'region', u'whose', u'eastern', u'part', u'Bangladesh', u'whose', u'western', u'part', u'included', u'India', u'education', u'imparted', u'series', u'lessons', u'meetings', u'act', u'sexual', u'procreation', u'man', u'woman', u'man', u'penis', u'inserted', u'woman', u'vagina', u'excited', u'orgasm', u'ejaculation', u'occur', u'study', u'earth', u'surface', u'includes', u'people', u'responses', u'topography', u'climate', u'soil', u'vegetation', u'number', u'entities', u'members', u'considered', u'unit', u'gradual', u'decrease', u'stored', u'charge', u'current', u'series', u'steps', u'carried', u'goals', u'accomplished', u'member', u'mixed', u'Dravidian', u'Caucasian', u'people', u'southern', u'India', u'Sri', u'Lanka', u'deviating', u'widely', u'norm', u'physical', u'mental', u'ability', u'used', u'especially', u'children', u'normal', u'intelligence', u'indentation', u'shoreline', u'larger', u'cove', u'smaller', u'gulf', u'come', u'idea', u'plan', u'explanation', u'theory', u'principle', u'mental', u'effort', u'sports', u'stroke', u'puts', u'ball', u'play', u'distinct', u'part', u'specified', u'separately', u'group', u'things', u'could', u'enumerated', u'list', u'unit', u'length', u'equal', u'1,760', u'yards', u'5,280', u'feet', u'exactly', u'1609.344', u'meters', u'lacking', u'stability', u'fixity', u'firmness', u'part', u'made', u'plural', u'group', u'human', u'beings', u'men', u'women', u'children', u'collectively', u'similar', u'things', u'placed', u'order', u'happening', u'one', u'another', u'monotheistic', u'system', u'beliefs', u'practices', u'based', u'Old', u'Testament', u'teachings', u'Jesus', u'embodied', u'New', u'Testament', u'emphasizing', u'role', u'Jesus', u'savior', u'particular', u'society', u'particular', u'time', u'place', u'basic', u'unit', u'length', u'adopted', u'Systeme', u'International', u"d'Unites", u'approximately', u'1.094', u'yards', u'special', u'offering', u'usually', u'temporary', u'reduced', u'price', u'featured', u'advertising', u'pertaining', u'characteristic', u'Judaism', u'precise', u'explicit', u'clearly', u'defined', u'line', u'determining', u'limits', u'area', u'commercial', u'industrial', u'enterprise', u'people', u'constitute', u'prominent', u'status', u'person', u'thing', u'equal', u'another', u'value', u'measure', u'force', u'effect', u'significance', u'etc', u'soft', u'silvery-white', u'tetravalent', u'radioactive', u'metallic', u'element', u'isotope', u'232', u'used', u'power', u'source', u'nuclear', u'reactors', u'occurs', u'thorite', u'monazite', u'sands', u'feeling', u'liking', u'something', u'someone', u'good', u'give', u'something', u'useful', u'necessary', u'extended', u'spatial', u'location', u'something', u'heading', u'names', u'statute', u'legislative', u'bill', u'give', u'brief', u'summary', u'matters', u'deals', u'person', u'equal', u'standing', u'another', u'group', u'linear', u'extent', u'space', u'one', u'end', u'longest', u'dimension', u'something', u'fixed', u'place', u'issue', u'terminate', u'specified', u'way', u'state', u'etc', u'end', u'legal', u'document', u'codifying', u'result', u'deliberations', u'committee', u'society', u'legislative', u'body', u'military', u'engagement', u'something', u'including', u'component', u'elements', u'parts', u'commercial', u'industrial', u'enterprise', u'people', u'constitute', u'cardinal', u'number', u'product', u'10', u'100', u'previous', u'time', u'amount', u'time', u'high', u'degree', u'extent', u'favorably', u'much', u'respect', u'act', u'process', u'producing', u'something', u'vague', u'clearly', u'defined', u'stated', u'division', u'quantity', u'accepted', u'standard', u'measurement', u'exchange', u'large', u'densely', u'populated', u'urban', u'area', u'include', u'several', u'independent', u'administrative', u'districts', u'act', u'using', u'process', u'taking', u'food', u'body', u'mouth', u'eating', u'lying', u'toward', u'situated', u'east', u'large', u'unbroken', u'expanse', u'distance', u'bishop', u'highest', u'rank', u'instrumentality', u'combines', u'interrelated', u'interacting', u'artifacts', u'designed', u'work', u'coherent', u'entity', u'five', u'related', u'nonmetallic', u'elements', u'fluorine', u'chlorine', u'bromine', u'iodine', u'astatine', u'monovalent', u'readily', u'form', u'negative', u'ions', u'continuing', u'time', u'space', u'without', u'interruption', u'film', u'life', u'western', u'United', u'States', u'period', u'exploration', u'development', u'fact', u'part', u'opposed', u'general', u'assumption', u'taken', u'granted', u'category', u'things', u'distinguished', u'common', u'characteristic', u'quality', u'worker', u'holds', u'invested', u'office', u'man', u'older', u'higher', u'rank', u'one', u'groups', u'Christians', u'beliefs', u'forms', u'worship', u'statistics', u'arrangement', u'values', u'variable', u'showing', u'observed', u'theoretical', u'frequency', u'occurrence', u'something', u'owned', u'tangible', u'intangible', u'possession', u'owned', u'someone', u'mark', u'different', u'function', u'topological', u'space', u'gives', u'two', u'points', u'space', u'value', u'equal', u'distance', u'usually', u'describes', u'large', u'person', u'fat', u'large', u'frame', u'carry', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions', u'general', u'officer', u'highest', u'rank', u'senior', u'member', u'Christian', u'clergy', u'spiritual', u'administrative', u'authority', u'appointed', u'Christian', u'churches', u'oversee', u'priests', u'ministers', u'considered', u'churches', u'successors', u'twelve', u'Apostles', u'Christ', u'movable', u'possession', u'especially', u'articles', u'clothing', u'owned', u'possession', u'heavy', u'toxic', u'silvery-white', u'radioactive', u'metallic', u'element', u'occurs', u'many', u'isotopes', u'used', u'nuclear', u'fuels', u'nuclear', u'weapons', u'orderly', u'grouping', u'things', u'persons', u'considered', u'unit', u'result', u'arranging', u'something', u'less', u'whole', u'human', u'artifact', u'act', u'delivering', u'formal', u'spoken', u'communication', u'audience', u'relating', u'science', u'geography', u'pertaining', u'involving', u'nature', u'space', u'advertisement', u'usually', u'printed', u'page', u'leaflet', u'intended', u'wide', u'distribution', u'commodities', u'offered', u'sale', u'put', u'service', u'make', u'work', u'employ', u'particular', u'purpose', u'inherent', u'natural', u'purpose', u'normal', u'conditions', u'particular', u'point', u'time', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions', u'one', u'several', u'parts', u'pieces', u'fit', u'others', u'constitute', u'whole', u'object', u'exhibiting', u'caused', u'radioactivity', u'event', u'happens', u'trace', u'point', u'whose', u'direction', u'motion', u'changes', u'mentally', u'emotionally', u'stable', u'abstract', u'part', u'something', u'human', u'general', u'estimation', u'public', u'person', u'instance', u'single', u'occasion', u'event', u'particular', u'portion', u'space', u'occupied', u'something', u'concept', u'something', u'magnitude', u'represented', u'mathematical', u'expressions', u'constant', u'variable'])
16/03/22 16:54:32 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/22 16:54:32 INFO DAGScheduler: Stopping DAGScheduler
16/03/22 16:54:32 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/22 16:54:32 INFO MemoryStore: MemoryStore cleared
16/03/22 16:54:32 INFO BlockManager: BlockManager stopped
16/03/22 16:54:32 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/22 16:54:32 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/22 16:54:32 INFO SparkContext: Successfully stopped SparkContext
16/03/22 16:54:33 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/22 16:54:33 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/22 16:54:33 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:tokensofthislevel: [u'individual', u'quantity', u'food', u'drink', u'taken', u'part', u'meal', u'state', u'southeastern', u'India', u'Bay', u'Bengal', u'south', u'Andhra', u'Pradesh', u'formerly', u'Madras', u'region', u'whose', u'eastern', u'part', u'Bangladesh', u'whose', u'western', u'part', u'included', u'India', u'education', u'imparted', u'series', u'lessons', u'meetings', u'act', u'sexual', u'procreation', u'man', u'woman', u'man', u'penis', u'inserted', u'woman', u'vagina', u'excited', u'orgasm', u'ejaculation', u'occur', u'study', u'earth', u'surface', u'includes', u'people', u'responses', u'topography', u'climate', u'soil', u'vegetation', u'number', u'entities', u'members', u'considered', u'unit', u'gradual', u'decrease', u'stored', u'charge', u'current', u'series', u'steps', u'carried', u'goals', u'accomplished', u'member', u'mixed', u'Dravidian', u'Caucasian', u'people', u'southern', u'India', u'Sri', u'Lanka', u'deviating', u'widely', u'norm', u'physical', u'mental', u'ability', u'used', u'especially', u'children', u'normal', u'intelligence', u'indentation', u'shoreline', u'larger', u'cove', u'smaller', u'gulf', u'come', u'idea', u'plan', u'explanation', u'theory', u'principle', u'mental', u'effort', u'sports', u'stroke', u'puts', u'ball', u'play', u'distinct', u'part', u'specified', u'separately', u'group', u'things', u'could', u'enumerated', u'list', u'unit', u'length', u'equal', u'1,760', u'yards', u'5,280', u'feet', u'exactly', u'1609.344', u'meters', u'lacking', u'stability', u'fixity', u'firmness', u'part', u'made', u'plural', u'group', u'human', u'beings', u'men', u'women', u'children', u'collectively', u'similar', u'things', u'placed', u'order', u'happening', u'one', u'another', u'monotheistic', u'system', u'beliefs', u'practices', u'based', u'Old', u'Testament', u'teachings', u'Jesus', u'embodied', u'New', u'Testament', u'emphasizing', u'role', u'Jesus', u'savior', u'particular', u'society', u'particular', u'time', u'place', u'basic', u'unit', u'length', u'adopted', u'Systeme', u'International', u"d'Unites", u'approximately', u'1.094', u'yards', u'special', u'offering', u'usually', u'temporary', u'reduced', u'price', u'featured', u'advertising', u'pertaining', u'characteristic', u'Judaism', u'precise', u'explicit', u'clearly', u'defined', u'line', u'determining', u'limits', u'area', u'commercial', u'industrial', u'enterprise', u'people', u'constitute', u'prominent', u'status', u'person', u'thing', u'equal', u'another', u'value', u'measure', u'force', u'effect', u'significance', u'etc', u'soft', u'silvery-white', u'tetravalent', u'radioactive', u'metallic', u'element', u'isotope', u'232', u'used', u'power', u'source', u'nuclear', u'reactors', u'occurs', u'thorite', u'monazite', u'sands', u'feeling', u'liking', u'something', u'someone', u'good', u'give', u'something', u'useful', u'necessary', u'extended', u'spatial', u'location', u'something', u'heading', u'names', u'statute', u'legislative', u'bill', u'give', u'brief', u'summary', u'matters', u'deals', u'person', u'equal', u'standing', u'another', u'group', u'linear', u'extent', u'space', u'one', u'end', u'longest', u'dimension', u'something', u'fixed', u'place', u'issue', u'terminate', u'specified', u'way', u'state', u'etc', u'end', u'legal', u'document', u'codifying', u'result', u'deliberations', u'committee', u'society', u'legislative', u'body', u'military', u'engagement', u'something', u'including', u'component', u'elements', u'parts', u'commercial', u'industrial', u'enterprise', u'people', u'constitute', u'cardinal', u'number', u'product', u'10', u'100', u'previous', u'time', u'amount', u'time', u'high', u'degree', u'extent', u'favorably', u'much', u'respect', u'act', u'process', u'producing', u'something', u'vague', u'clearly', u'defined', u'stated', u'division', u'quantity', u'accepted', u'standard', u'measurement', u'exchange', u'large', u'densely', u'populated', u'urban', u'area', u'include', u'several', u'independent', u'administrative', u'districts', u'act', u'using', u'process', u'taking', u'food', u'body', u'mouth', u'eating', u'lying', u'toward', u'situated', u'east', u'large', u'unbroken', u'expanse', u'distance', u'bishop', u'highest', u'rank', u'instrumentality', u'combines', u'interrelated', u'interacting', u'artifacts', u'designed', u'work', u'coherent', u'entity', u'five', u'related', u'nonmetallic', u'elements', u'fluorine', u'chlorine', u'bromine', u'iodine', u'astatine', u'monovalent', u'readily', u'form', u'negative', u'ions', u'continuing', u'time', u'space', u'without', u'interruption', u'film', u'life', u'western', u'United', u'States', u'period', u'exploration', u'development', u'fact', u'part', u'opposed', u'general', u'assumption', u'taken', u'granted', u'category', u'things', u'distinguished', u'common', u'characteristic', u'quality', u'worker', u'holds', u'invested', u'office', u'man', u'older', u'higher', u'rank', u'one', u'groups', u'Christians', u'beliefs', u'forms', u'worship', u'statistics', u'arrangement', u'values', u'variable', u'showing', u'observed', u'theoretical', u'frequency', u'occurrence', u'something', u'owned', u'tangible', u'intangible', u'possession', u'owned', u'someone', u'mark', u'different', u'function', u'topological', u'space', u'gives', u'two', u'points', u'space', u'value', u'equal', u'distance', u'usually', u'describes', u'large', u'person', u'fat', u'large', u'frame', u'carry', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions', u'general', u'officer', u'highest', u'rank', u'senior', u'member', u'Christian', u'clergy', u'spiritual', u'administrative', u'authority', u'appointed', u'Christian', u'churches', u'oversee', u'priests', u'ministers', u'considered', u'churches', u'successors', u'twelve', u'Apostles', u'Christ', u'movable', u'possession', u'especially', u'articles', u'clothing', u'owned', u'possession', u'heavy', u'toxic', u'silvery-white', u'radioactive', u'metallic', u'element', u'occurs', u'many', u'isotopes', u'used', u'nuclear', u'fuels', u'nuclear', u'weapons', u'orderly', u'grouping', u'things', u'persons', u'considered', u'unit', u'result', u'arranging', u'something', u'less', u'whole', u'human', u'artifact', u'act', u'delivering', u'formal', u'spoken', u'communication', u'audience', u'relating', u'science', u'geography', u'pertaining', u'involving', u'nature', u'space', u'advertisement', u'usually', u'printed', u'page', u'leaflet', u'intended', u'wide', u'distribution', u'commodities', u'offered', u'sale', u'put', u'service', u'make', u'work', u'employ', u'particular', u'purpose', u'inherent', u'natural', u'purpose', u'normal', u'conditions', u'particular', u'point', u'time', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions', u'one', u'several', u'parts', u'pieces', u'fit', u'others', u'constitute', u'whole', u'object', u'exhibiting', u'caused', u'radioactivity', u'event', u'happens', u'trace', u'point', u'whose', u'direction', u'motion', u'changes', u'mentally', u'emotionally', u'stable', u'abstract', u'part', u'something', u'human', u'general', u'estimation', u'public', u'person', u'instance', u'single', u'occasion', u'event', u'particular', u'portion', u'space', u'occupied', u'something', u'concept', u'something', u'magnitude', u'represented', u'mathematical', u'expressions', u'constant', u'variable']
prevlevelsynsets: [Synset('city.n.01'), Synset('use.n.01'), Synset('consumption.n.01'), Synset('helping.n.01'), Synset('eastern.s.01'), Synset('tamil_nadu.n.01'), Synset('bengal.n.01'), Synset('stretch.n.01'), Synset('archbishop.n.01'), Synset('system.n.01'), Synset('halogen.n.01'), Synset('course.n.01'), Synset('continuous.a.01'), Synset('western.n.01'), Synset('sexual_intercourse.n.01'), Synset('geography.n.01'), Synset('particular.n.01'), Synset('group.n.01'), Synset('decay.n.01'), Synset('plan.n.01'), Synset('tamil.n.01'), Synset('exceeding.s.01'), Synset('given.n.01'), Synset('kind.n.01'), Synset('official.n.01'), Synset('bay.n.01'), Synset('patriarch.n.01'), Synset('invent.v.01'), Synset('serve.n.01'), Synset('church.n.01'), Synset('distribution.n.01'), Synset('item.n.01'), Synset('mile.n.01'), Synset('property.n.01'), Synset('distinguish.v.01'), Synset('unstable.a.01'), Synset('metric_function.n.01'), Synset('include.v.01'), Synset('people.n.01'), Synset('series.n.01'), Synset('fleshy.s.01'), Synset('christianity.n.01'), Synset('purpose.n.01'), Synset('culture.n.01'), Synset('general.n.01'), Synset('bishop.n.01'), Synset('meter.n.01'), Synset('special.n.01'), Synset('orthodox.a.01'), Synset('things.n.01'), Synset('definite.a.01'), Synset('belong.v.01'), Synset('uranium.n.01'), Synset('agreement.n.04'), Synset('boundary.n.01'), Synset('business.n.01'), Synset('importance.n.01'), Synset('equivalent.n.01'), Synset('thorium.n.01'), Synset('blessing.n.01'), Synset('part.n.01'), Synset('supply.n.01'), Synset('address.n.01'), Synset('region.n.01'), Synset('geographic.a.01'), Synset('spatial.a.01'), Synset('title.n.01'), Synset('circular.n.01'), Synset('merchandise.n.01'), Synset('peer.n.01'), Synset('use.n.01'), Synset('normally.r.01'), Synset('length.n.01'), Synset('consequence.n.01'), Synset('moment.n.01'), Synset('purpose.n.01'), Synset('section.n.01'), Synset('radioactive.a.01'), Synset('act.n.01'), Synset('happening.n.01'), Synset('curve.n.01'), Synset('military_action.n.01'), Synset('whole.n.01'), Synset('business.n.01'), Synset('together.s.01'), Synset('component.n.01'), Synset('person.n.01'), Synset('repute.n.01'), Synset('thousand.n.01'), Synset('once.r.01'), Synset('time.n.01'), Synset('time_period.n.01'), Synset('highly.r.01'), Synset('production.n.01'), Synset('position.n.01'), Synset('indefinite.a.01'), Synset('measure.n.02'), Synset('unit_of_measurement.n.01')]
defaultdict(<type 'list'>, {u'serving': [u'None', u'area', u'area'], u'Madras': [u'None', u'Chennai', u'None', u'Chennai'], u'Bengal': [u'None', u'Chennai', u'None', u'Chennai'], u'course': [u'None', u'None', u'planning'], u'relation': [u'None', u'None', u'composition'], u'geography': [u'None', u'area', u'area'], u'group': [u'set', u'None'], u'decay': [u'None', u'astatine', u'None'], u'halogen': [u'None', u'astatine', u'None'], u'Tamil': [u'None', u'Chennai', u'None', u'Chennai'], u'exceptional': [u'None', u'giant', u'None'], u'Bay': [u'None', u'Chennai', u'None', u'Chennai'], u'formulating': [u'None', u'None', u'planning'], u'serves': [u'None', u'None', u'agency'], u'item': [u'None', u'None'], u'miles': [u'None', u'kilometer', u'None', u'kilometer'], u'unstable': [u'None', u'astatine', u'None'], u'including': [u'None', u'present', u'None'], u'people': [u'None', u'area', u'area'], u'series': [u'None', u'astatine', u'None'], u'Christianity': [u'None', u'metropolitan', u'None'], u'culture': [u'None', u'area', u'area'], u'meters': [u'None', u'kilometer', u'None', u'kilometer'], u'special': [u'None', u'area', u'area'], u'0.621371': [u'None', u'kilometer', u'None', u'kilometer'], u'Orthodox': [u'None', u'metropolitan', u'None'], u'definite': [u'None', u'None', u'planning'], u'boundary': [u'None', u'area', u'area'], u'business': [u'None', u'None', u'agency'], u'importance': [u'None', u'giant', u'None'], u'equivalent': [u'None', u'metropolitan', u'None'], u'thorium': [u'None', u'astatine', u'None'], u'approval': [u'None', u'None', u'permission'], u'providing': [u'None', u'None'], u'region': [u'None', u'area', u'area'], u'title': [u'None', u'metropolitan', u'None'], u'equal': [u'None', u'kilometer', u'None', u'kilometer'], u'length': [u'None', u'kilometer', u'None', u'kilometer'], u'resulting': [u'None', u'None', u'composition'], u'act': [u'None', u'None', u'planning'], u'action': [u'None', u'None', u'planning'], u'whole': [u'None', u'None', u'composition'], u'businesses': [u'None', u'None', u'agency'], u'1000': [u'None', u'kilometer', u'None', u'kilometer'], u'formerly': [u'None', u'Chennai', u'None', u'Chennai'], u'period': [u'None', u'present', u'None'], u'highly': [u'None', u'astatine', u'None'], u'production': [u'None', u'None', u'economy'], u'indefinite': [u'None', u'area', u'area'], u'unit': [u'None', u'kilometer', u'None', u'kilometer'], u'city': [u'None', u'Chennai', u'None', u'Chennai'], u'use': [u'None', u'None'], u'consumption': [u'None', u'None', u'economy'], u'Eastern': [u'None', u'metropolitan', u'None'], u'stretch': [u'None', u'present', u'None'], u'archbishop': [u'None', u'metropolitan', u'None'], u'system': [u'None', u'None', u'economy'], u'program': [u'None', u'None', u'planning'], u'continuous': [u'None', u'present', u'None'], u'western': [u'None', u'metropolitan', u'None'], u'particular': [u'None', u'area', u'area'], u'given': [u'None', u'metropolitan', u'None'], u'kind': [u'set', u'None'], u'official': [u'None', u'None'], u'patriarch': [u'None', u'metropolitan', u'None'], u'Church': [u'None', u'metropolitan', u'None'], u'distribution': [u'None', u'None', u'economy'], u'property': [u'None', u'None', u'composition'], u'distinguished': [u'None', u'area', u'area'], u'metric': [u'None', u'kilometer', u'None', u'kilometer'], u'heaviest': [u'None', u'astatine', u'None'], u'purposes': [u'None', u'None'], u'general': [u'None', u'None'], u'something': [u'None', u'None', u'permission'], u'bishop': [u'None', u'metropolitan', u'None'], u'things': [u'set', u'None'], u'belong': [u'set', u'None'], u'uranium': [u'None', u'astatine', u'None'], u'arrangement': [u'None', u'None', u'composition'], u'parts': [u'None', u'None', u'composition'], u'speech': [u'None', u'present', u'None'], u'geographical': [u'None', u'area', u'area'], u'spatial': [u'None', u'None', u'composition'], u'Nadu': [u'None', u'Chennai', u'None', u'Chennai'], u'circular': [u'bend', u'None'], u'product': [u'None', u'astatine', u'None'], u'used': [u'set', u'None'], u'usually': [u'None', u'area', u'area'], u'moment': [u'None', u'present', u'None'], u'purpose': [u'None', u'area', u'area'], u'segment': [u'bend', u'None'], u'radioactive': [u'None', u'astatine', u'None'], u'happening': [u'None', u'present', u'None'], u'curve': [u'bend', u'None'], u'together': [u'set', u'None'], u'element': [u'None', u'astatine', u'None'], u'person': [u'None', u'giant', u'None'], u'reputation': [u'None', u'giant', u'None'], u'time': [u'None', u'present', u'None'], u'position': [u'None', u'metropolitan', u'None'], u'quantity': [u'None', u'None']})
ksynset= Synset('helping.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('helping.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('helping.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('course.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('course.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('course.n.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('relation.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('relation.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('relation.n.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('group.n.01')
lsynset= Synset('set.n.01')
ksynset= Synset('group.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('decay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('decay.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('decay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('halogen.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('halogen.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('halogen.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('exceeding.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('exceeding.s.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('exceeding.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('explicate.v.02')
lsynset= Synset('none.n.01')
ksynset= Synset('explicate.v.02')
lsynset= Synset('none.n.01')
ksynset= Synset('explicate.v.02')
lsynset= Synset('planning.n.01')
ksynset= Synset('serve.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('serve.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('serve.n.01')
lsynset= Synset('agency.n.01')
ksynset= Synset('item.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('item.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('unstable.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unstable.a.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('unstable.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('include.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('include.v.01')
lsynset= Synset('present.n.01')
ksynset= Synset('include.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('series.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('series.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('series.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('definite.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('definite.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('definite.a.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('agency.n.01')
ksynset= Synset('importance.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('importance.n.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('importance.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thorium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thorium.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('thorium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('blessing.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('blessing.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('blessing.n.01')
lsynset= Synset('permission.n.01')
ksynset= Synset('supply.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('supply.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('result.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('result.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('result.v.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('act.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('act.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('act.n.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('action.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('action.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('action.n.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('whole.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('whole.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('whole.n.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('agency.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('none.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('chennai.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('none.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('chennai.n.01')
ksynset= Synset('time_period.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time_period.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('time_period.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('highly.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('highly.r.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('highly.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('production.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('production.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('production.n.01')
lsynset= Synset('economy.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('use.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('use.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('consumption.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('consumption.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('consumption.n.01')
lsynset= Synset('economy.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('stretch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('stretch.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('stretch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('system.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('system.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('system.n.01')
lsynset= Synset('economy.n.01')
ksynset= Synset('plan.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('plan.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('plan.n.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('continuous.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('continuous.a.01')
lsynset= Synset('present.n.01')
ksynset= Synset('continuous.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('kind.n.01')
lsynset= Synset('set.n.01')
ksynset= Synset('kind.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('official.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('official.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distribution.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distribution.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distribution.n.01')
lsynset= Synset('economy.n.01')
ksynset= Synset('property.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('property.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('property.n.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('area.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('area.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('heavy.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('heavy.a.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('heavy.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('general.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('general.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('things.n.01')
lsynset= Synset('set.n.01')
ksynset= Synset('things.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('belong.v.01')
lsynset= Synset('set.n.01')
ksynset= Synset('belong.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('uranium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('uranium.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('uranium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('agreement.n.04')
lsynset= Synset('none.n.01')
ksynset= Synset('agreement.n.04')
lsynset= Synset('none.n.01')
ksynset= Synset('agreement.n.04')
lsynset= Synset('composition.n.01')
ksynset= Synset('parts.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('parts.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('parts.n.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('address.n.03')
lsynset= Synset('none.n.01')
ksynset= Synset('address.n.03')
lsynset= Synset('present.n.01')
ksynset= Synset('address.n.03')
lsynset= Synset('none.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('spatial.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('spatial.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('spatial.a.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('circular.n.01')
lsynset= Synset('bend.n.01')
ksynset= Synset('circular.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('use.v.01')
lsynset= Synset('set.n.01')
ksynset= Synset('use.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('area.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('area.n.01')
ksynset= Synset('moment.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('moment.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('moment.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('section.n.04')
lsynset= Synset('bend.n.01')
ksynset= Synset('section.n.04')
lsynset= Synset('none.n.01')
ksynset= Synset('radioactive.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('radioactive.a.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('radioactive.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('happening.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('happening.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('happening.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('curve.n.01')
lsynset= Synset('bend.n.01')
ksynset= Synset('curve.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('together.s.01')
lsynset= Synset('set.n.01')
ksynset= Synset('together.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('repute.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('repute.n.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('repute.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('time.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('measure.n.02')
lsynset= Synset('none.n.01')
ksynset= Synset('measure.n.02')
lsynset= Synset('none.n.01')
Core number (sorted) : [(u'area', 13), (u'metropolitan', 12), (u'astatine', 11), (u'kilometer', 8), (u'present', 8), (u'Chennai', 7), (u'composition', 7), (u'planning', 6), (u'set', 6), (u'giant', 4), (u'economy', 4), (u'bend', 3), (u'agency', 3), (u'serving', 2), (u'Madras', 2), (u'Bengal', 2), (u'course', 2), (u'relation', 2), (u'geography', 2), (u'group', 2), (u'title', 2), (u'halogen', 2), (u'Tamil', 2), (u'permission', 2), (u'Bay', 2), (u'formulating', 2), (u'serves', 2), (u'miles', 2), (u'unstable', 2), (u'including', 2), (u'people', 2), (u'series', 2), (u'Christianity', 2), (u'culture', 2), (u'meters', 2), (u'special', 2), (u'0.621371', 2), (u'Orthodox', 2), (u'definite', 2), (u'boundary', 2), (u'business', 2), (u'importance', 2), (u'equivalent', 2), (u'thorium', 2), (u'approval', 2), (u'region', 2), (u'decay', 2), (u'equal', 2), (u'length', 2), (u'resulting', 2), (u'act', 2), (u'action', 2), (u'whole', 2), (u'businesses', 2), (u'1000', 2), (u'formerly', 2), (u'period', 2), (u'highly', 2), (u'production', 2), (u'indefinite', 2), (u'unit', 2), (u'city', 2), (u'given', 2), (u'consumption', 2), (u'stretch', 2), (u'archbishop', 2), (u'system', 2), (u'program', 2), (u'exceptional', 2), (u'continuous', 2), (u'western', 2), (u'particular', 2), (u'kind', 2), (u'patriarch', 2), (u'Eastern', 2), (u'Church', 2), (u'distribution', 2), (u'property', 2), (u'distinguished', 2), (u'something', 2), (u'metric', 2), (u'heaviest', 2), (u'bishop', 2), (u'things', 2), (u'belong', 2), (u'uranium', 2), (u'arrangement', 2), (u'parts', 2), (u'speech', 2), (u'geographical', 2), (u'spatial', 2), (u'Nadu', 2), (u'circular', 2), (u'product', 2), (u'used', 2), (u'usually', 2), (u'moment', 2), (u'purpose', 2), (u'segment', 2), (u'radioactive', 2), (u'happening', 2), (u'curve', 2), (u'together', 2), (u'element', 2), (u'person', 2), (u'reputation', 2), (u'time', 2), (u'position', 2), (u'item', 0), (u'None', 0), (u'use', 0), (u'providing', 0), (u'official', 0), (u'purposes', 0), (u'general', 0), (u'quantity', 0)]
=============================================================================================================
Unsupervised Classification based on top percentile Core numbers of the definition graph(subgraph of WordNet)
=============================================================================================================
This document belongs to class: area ,core number= 13
This document belongs to class: metropolitan ,core number= 12
This document belongs to class: astatine ,core number= 11
This document belongs to class: kilometer ,core number= 8
This document belongs to class: present ,core number= 8
This document belongs to class: Chennai ,core number= 7
This document belongs to class: composition ,core number= 7
This document belongs to class: planning ,core number= 6
This document belongs to class: set ,core number= 6
This document belongs to class: giant ,core number= 4
This document belongs to class: economy ,core number= 4
This document belongs to class: bend ,core number= 3
This document belongs to class: agency ,core number= 3
max_core_number 13
===================================================================
Page Rank of the vertices of RGO Definition Graph
===================================================================
[(u'area', 0.05964397617197671), (u'metropolitan', 0.05543677058743772), (u'astatine', 0.051229565002898755), (u'kilometer', 0.03860794824928188), (u'present', 0.03860794824928188), (u'Chennai', 0.034400742664742925), (u'composition', 0.034400742664742925), (u'planning', 0.030193537080203968), (u'set', 0.030193537080203968), (u'giant', 0.021779125911126046), (u'economy', 0.02177912591112604), (u'agency', 0.01757192032658708), (u'bend', 0.017571920326587075), (u'permission', 0.013364714742048119), (u'approval', 0.0070539063652396775), (u'something', 0.0070539063652396775), (u'serves', 0.006352705434483184), (u'business', 0.006352705434483184), (u'businesses', 0.006352705434483184), (u'circular', 0.006352705434483183), (u'segment', 0.006352705434483183), (u'curve', 0.006352705434483183), (u'importance', 0.006002104969104938), (u'production', 0.006002104969104938), (u'consumption', 0.006002104969104938), (u'system', 0.006002104969104938), (u'distribution', 0.006002104969104938), (u'exceptional', 0.006002104969104938), (u'person', 0.006002104969104938), (u'reputation', 0.006002104969104938), (u'course', 0.0056515045037266905), (u'group', 0.0056515045037266905), (u'program', 0.0056515045037266905), (u'formulating', 0.0056515045037266905), (u'definite', 0.0056515045037266905), (u'act', 0.0056515045037266905), (u'action', 0.0056515045037266905), (u'belong', 0.0056515045037266905), (u'kind', 0.0056515045037266905), (u'things', 0.0056515045037266905), (u'used', 0.0056515045037266905), (u'together', 0.0056515045037266905), (u'Madras', 0.005551332942190048), (u'Bengal', 0.005551332942190048), (u'relation', 0.005551332942190048), (u'Tamil', 0.005551332942190048), (u'Bay', 0.005551332942190048), (u'resulting', 0.005551332942190048), (u'whole', 0.005551332942190048), (u'formerly', 0.005551332942190048), (u'city', 0.005551332942190048), (u'property', 0.005551332942190048), (u'arrangement', 0.005551332942190048), (u'parts', 0.005551332942190048), (u'spatial', 0.005551332942190048), (u'Nadu', 0.005551332942190048), (u'miles', 0.0054762042710375675), (u'including', 0.0054762042710375675), (u'meters', 0.0054762042710375675), (u'0.621371', 0.0054762042710375675), (u'equal', 0.0054762042710375675), (u'length', 0.0054762042710375675), (u'1000', 0.0054762042710375675), (u'period', 0.0054762042710375675), (u'unit', 0.0054762042710375675), (u'stretch', 0.0054762042710375675), (u'continuous', 0.0054762042710375675), (u'metric', 0.0054762042710375675), (u'speech', 0.0054762042710375675), (u'moment', 0.0054762042710375675), (u'happening', 0.0054762042710375675), (u'time', 0.0054762042710375675), (u'unstable', 0.005332776807928284), (u'series', 0.005332776807928284), (u'thorium', 0.005332776807928284), (u'decay', 0.005332776807928284), (u'highly', 0.005332776807928284), (u'halogen', 0.005332776807928284), (u'heaviest', 0.005332776807928284), (u'uranium', 0.005332776807928284), (u'product', 0.005332776807928284), (u'radioactive', 0.005332776807928284), (u'element', 0.005332776807928284), (u'title', 0.005300904038348444), (u'Christianity', 0.005300904038348444), (u'Orthodox', 0.005300904038348444), (u'equivalent', 0.005300904038348444), (u'given', 0.005300904038348444), (u'archbishop', 0.005300904038348444), (u'western', 0.005300904038348444), (u'patriarch', 0.005300904038348444), (u'Eastern', 0.005300904038348444), (u'Church', 0.005300904038348444), (u'bishop', 0.005300904038348444), (u'position', 0.005300904038348444), (u'serving', 0.005273934771780889), (u'geography', 0.005273934771780889), (u'people', 0.005273934771780889), (u'culture', 0.005273934771780889), (u'special', 0.005273934771780889), (u'boundary', 0.005273934771780889), (u'region', 0.005273934771780889), (u'indefinite', 0.005273934771780889), (u'particular', 0.005273934771780889), (u'distinguished', 0.005273934771780889), (u'geographical', 0.005273934771780889), (u'usually', 0.005273934771780889), (u'purpose', 0.005273934771780889), (u'item', 0.001373626373626374), (u'None', 0.001373626373626374), (u'use', 0.001373626373626374), (u'providing', 0.001373626373626374), (u'official', 0.001373626373626374), (u'purposes', 0.001373626373626374), (u'general', 0.001373626373626374), (u'quantity', 0.001373626373626374)]
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - connectivity of RGO Definition Graph - Mengers Theorem
==========================================================================================================
0
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - Maxflow-Mincut of RGO Definition Graph - Minimum Edge Cut
==========================================================================================================
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - Maxflow-Mincut of RGO Definition Graph - Stoer-Wagner
==========================================================================================================
16/03/22 16:56:42 INFO ShutdownHookManager: Shutdown hook called
16/03/22 16:56:42 INFO ShutdownHookManager: Deleting directory /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/pyspark-ff999438-872e-402a-9aa4-92059e9b958f
16/03/22 16:56:42 INFO ShutdownHookManager: Deleting directory /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/pyspark-c4d980e8-a5db-462d-ad93-1d1dfff2b733
16/03/22 16:56:42 INFO ShutdownHookManager: Deleting directory /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/pyspark-fca04162-5c3e-4cf1-8484-ccd8ec38e991
16/03/22 16:56:42 INFO ShutdownHookManager: Deleting directory /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/pyspark-2c2f06ca-eb0a-4d58-8d00-2eafc2b30202
16/03/22 16:56:42 INFO ShutdownHookManager: Deleting directory /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/pyspark-4c955bcd-ed31-4376-bb75-f643f846c30b
16/03/22 16:56:42 INFO ShutdownHookManager: Deleting directory /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/pyspark-dc077f28-bd4e-41ba-8509-e2d78684cbcd
16/03/22 16:56:42 INFO ShutdownHookManager: Deleting directory /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/pyspark-5b9fa6a5-2d39-4118-9275-3736b8534301
16/03/22 16:56:42 INFO ShutdownHookManager: Deleting directory /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/pyspark-e058ba43-4088-44c3-939b-f4cedc5f0444
16/03/22 16:56:42 INFO ShutdownHookManager: Deleting directory /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/pyspark-8e030167-86b2-4742-a227-cf390fffa0a4
16/03/22 16:56:42 INFO ShutdownHookManager: Deleting directory /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/pyspark-b3cc41fb-4491-425a-9243-296002f3df56
16/03/22 16:56:42 INFO ShutdownHookManager: Deleting directory /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/pyspark-0fbe1f3e-f233-4241-bb0d-9e5547460e36
16/03/22 16:56:42 INFO ShutdownHookManager: Deleting directory /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/pyspark-13dc9775-c38e-4b91-a503-08e14f86faa2
16/03/22 16:56:42 INFO ShutdownHookManager: Deleting directory /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/pyspark-825ff4bc-31fd-452c-a3e2-ab1e9b5ad001
16/03/22 16:56:42 INFO ShutdownHookManager: Deleting directory /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/pyspark-6e3b18dd-48a3-40b6-b29f-676dc277ef16
16/03/22 16:56:42 INFO ShutdownHookManager: Deleting directory /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/pyspark-ec93ec93-2d57-4570-937c-514d92fae40c
16/03/22 16:56:42 INFO ShutdownHookManager: Deleting directory /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a/pyspark-3f41841f-9ff6-4547-ac4f-b0dd46293d76
16/03/22 16:56:42 INFO ShutdownHookManager: Deleting directory /tmp/spark-01b3110e-4217-40cf-a702-ee9f3097bf4a

