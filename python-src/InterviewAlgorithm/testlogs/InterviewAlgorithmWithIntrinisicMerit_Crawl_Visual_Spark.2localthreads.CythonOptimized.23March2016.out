16/03/23 14:12:45 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/23 14:12:45 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/23 14:12:45 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/23 14:12:45 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/23 14:12:45 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722565773
16/03/23 14:12:45 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/23 14:12:45 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-8b8680e8-3c42-4a62-afea-1026288d27f2/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:12:45 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/23 14:12:45 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10732, maxMem=547686973
16/03/23 14:12:45 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 522.3 MB)
16/03/23 14:12:45 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:41894 (size: 187.0 B, free: 522.3 MB)
16/03/23 14:12:45 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/23 14:12:45 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10919, maxMem=547686973
16/03/23 14:12:45 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 522.3 MB)
16/03/23 14:12:45 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:41894 (size: 177.0 B, free: 522.3 MB)
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: set
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: issue
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: planning
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: permission
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: economy
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: composition
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: agency
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/23 14:12:54 INFO PythonRunner: Times: total = 8023, boot = 452, init = 367, finish = 7204
16/03/23 14:12:54 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/23 14:12:54 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8097 ms on localhost (1/2)
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: bend
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: giant
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: astatine
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  uranium  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: present
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: area
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/23 14:12:54 INFO PythonRunner: Times: total = 8424, boot = 455, init = 468, finish = 7501
16/03/23 14:12:54 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/23 14:12:54 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 8.502 s
16/03/23 14:12:54 INFO DAGScheduler: looking for newly runnable stages
16/03/23 14:12:54 INFO DAGScheduler: running: Set()
16/03/23 14:12:54 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/23 14:12:54 INFO DAGScheduler: failed: Set()
16/03/23 14:12:54 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/23 14:12:54 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/23 14:12:54 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=547686973
16/03/23 14:12:54 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 522.3 MB)
16/03/23 14:12:54 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=547686973
16/03/23 14:12:54 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 522.3 MB)
16/03/23 14:12:54 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8493 ms on localhost (2/2)
16/03/23 14:12:54 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/23 14:12:54 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:41894 (size: 3.0 KB, free: 522.3 MB)
16/03/23 14:12:54 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/23 14:12:54 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:12:54 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/23 14:12:54 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:12:54 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:12:54 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/23 14:12:54 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/23 14:12:54 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:12:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/23 14:12:54 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:12:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
16/03/23 14:12:54 INFO PythonRunner: Times: total = 33, boot = -239, init = 272, finish = 0
16/03/23 14:12:54 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/23 14:12:54 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 65 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'astatine', 'None']
16/03/23 14:12:54 INFO PythonRunner: Times: total = 200, boot = 199, init = 1, finish = 0
16/03/23 14:12:54 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/03/23 14:12:54 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.222 s
16/03/23 14:12:54 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 8.746045 s
16/03/23 14:12:54 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 222 ms on localhost (2/2)
16/03/23 14:12:54 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/23 14:12:54 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:12:54 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:12:54 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:12:54 INFO DAGScheduler: Parents of final stage: List()
16/03/23 14:12:54 INFO DAGScheduler: Missing parents: List()
16/03/23 14:12:54 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:12:54 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=547686973
16/03/23 14:12:54 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 522.3 MB)
16/03/23 14:12:54 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24952, maxMem=547686973
16/03/23 14:12:54 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 522.3 MB)
16/03/23 14:12:54 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:41894 (size: 3.3 KB, free: 522.3 MB)
16/03/23 14:12:54 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/23 14:12:54 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:12:54 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/23 14:12:54 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/23 14:12:54 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/03/23 14:12:54 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/23 14:12:54 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/23 14:12:54 INFO PythonRunner: Times: total = 78, boot = 78, init = 0, finish = 0
16/03/23 14:12:54 INFO PythonRunner: Times: total = 58, boot = 49, init = 9, finish = 0
16/03/23 14:12:54 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/03/23 14:12:54 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/23 14:12:54 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 113 ms on localhost (1/2)
16/03/23 14:12:54 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 115 ms on localhost (2/2)
16/03/23 14:12:54 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/23 14:12:54 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.108 s
16/03/23 14:12:54 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.124138 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/23 14:12:55 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/23 14:12:55 INFO DAGScheduler: Stopping DAGScheduler
16/03/23 14:12:55 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/23 14:12:55 INFO MemoryStore: MemoryStore cleared
16/03/23 14:12:55 INFO BlockManager: BlockManager stopped
16/03/23 14:12:55 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/23 14:12:55 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/23 14:12:55 INFO SparkContext: Successfully stopped SparkContext
16/03/23 14:12:55 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/23 14:12:55 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/23 14:12:55 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'astatine', u'None']
16/03/23 14:12:55 INFO SparkContext: Running Spark version 1.5.2
16/03/23 14:12:55 INFO SecurityManager: Changing view acls to: root
16/03/23 14:12:55 INFO SecurityManager: Changing modify acls to: root
16/03/23 14:12:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/23 14:12:55 INFO Slf4jLogger: Slf4jLogger started
16/03/23 14:12:55 INFO Remoting: Starting remoting
16/03/23 14:12:56 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:37694]
16/03/23 14:12:56 INFO Utils: Successfully started service 'sparkDriver' on port 37694.
16/03/23 14:12:56 INFO SparkEnv: Registering MapOutputTracker
16/03/23 14:12:56 INFO SparkEnv: Registering BlockManagerMaster
16/03/23 14:12:56 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-debe9f32-6c4f-4e00-aca1-db85da1cbcb6
16/03/23 14:12:56 INFO MemoryStore: MemoryStore started with capacity 522.3 MB
16/03/23 14:12:56 INFO HttpFileServer: HTTP File server directory is /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/httpd-472cd3e2-601b-46ec-b03f-9afbc40fdfdf
16/03/23 14:12:56 INFO HttpServer: Starting HTTP Server
16/03/23 14:12:56 INFO Utils: Successfully started service 'HTTP file server' on port 43162.
16/03/23 14:12:56 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/23 14:12:56 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/23 14:12:56 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/23 14:12:56 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-90857fcf-4eef-4e3b-a28a-d4f8a69c2593/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:12:56 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722576166
16/03/23 14:12:56 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/23 14:12:56 INFO Executor: Starting executor ID driver on host localhost
16/03/23 14:12:56 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44082.
16/03/23 14:12:56 INFO NettyBlockTransferService: Server created on 44082
16/03/23 14:12:56 INFO BlockManagerMaster: Trying to register BlockManager
16/03/23 14:12:56 INFO BlockManagerMasterEndpoint: Registering block manager localhost:44082 with 522.3 MB RAM, BlockManagerId(driver, localhost, 44082)
16/03/23 14:12:56 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): arrangement
16/03/23 14:12:56 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:12:56 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:12:56 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:12:56 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:12:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/23 14:12:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/23 14:12:56 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:12:56 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=547686973
16/03/23 14:12:56 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 522.3 MB)
16/03/23 14:12:56 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=547686973
16/03/23 14:12:56 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 522.3 MB)
16/03/23 14:12:56 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:44082 (size: 4.1 KB, free: 522.3 MB)
16/03/23 14:12:56 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/23 14:12:56 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:12:56 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/23 14:12:56 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/23 14:12:56 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/23 14:12:56 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/23 14:12:56 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722576166
16/03/23 14:12:56 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/23 14:12:56 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-90857fcf-4eef-4e3b-a28a-d4f8a69c2593/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:12:56 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/23 14:12:56 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10732, maxMem=547686973
16/03/23 14:12:56 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 522.3 MB)
16/03/23 14:12:56 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:44082 (size: 177.0 B, free: 522.3 MB)
16/03/23 14:12:56 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/23 14:12:56 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10909, maxMem=547686973
16/03/23 14:12:56 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 522.3 MB)
16/03/23 14:12:56 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:44082 (size: 187.0 B, free: 522.3 MB)
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: set
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: bend
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: giant
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: astatine
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: present
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: area
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/23 14:13:04 INFO PythonRunner: Times: total = 8132, boot = 642, init = 474, finish = 7016
16/03/23 14:13:04 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/23 14:13:04 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8199 ms on localhost (1/2)
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: issue
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: planning
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: permission
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: economy
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: composition
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  arrangement  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: agency
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/23 14:13:04 INFO PythonRunner: Times: total = 8604, boot = 651, init = 377, finish = 7576
16/03/23 14:13:04 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/23 14:13:04 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 8.678 s
16/03/23 14:13:04 INFO DAGScheduler: looking for newly runnable stages
16/03/23 14:13:04 INFO DAGScheduler: running: Set()
16/03/23 14:13:04 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/23 14:13:04 INFO DAGScheduler: failed: Set()
16/03/23 14:13:04 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/23 14:13:04 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/23 14:13:04 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=547686973
16/03/23 14:13:04 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 522.3 MB)
16/03/23 14:13:04 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=547686973
16/03/23 14:13:04 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 522.3 MB)
16/03/23 14:13:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:44082 (size: 3.0 KB, free: 522.3 MB)
16/03/23 14:13:04 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8661 ms on localhost (2/2)
16/03/23 14:13:04 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/23 14:13:04 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/23 14:13:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:04 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/23 14:13:04 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:13:04 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:13:05 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/23 14:13:05 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/23 14:13:05 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:13:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/23 14:13:05 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:13:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', 'None', u'composition']
16/03/23 14:13:05 INFO PythonRunner: Times: total = 44, boot = -318, init = 362, finish = 0
16/03/23 14:13:05 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1287 bytes result sent to driver
16/03/23 14:13:05 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 88 ms on localhost (1/2)
16/03/23 14:13:05 INFO PythonRunner: Times: total = 181, boot = 180, init = 0, finish = 1
16/03/23 14:13:05 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/23 14:13:05 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 204 ms on localhost (2/2)
16/03/23 14:13:05 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/23 14:13:05 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.194 s
16/03/23 14:13:05 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 8.916702 s
16/03/23 14:13:05 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:13:05 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:13:05 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:05 INFO DAGScheduler: Parents of final stage: List()
16/03/23 14:13:05 INFO DAGScheduler: Missing parents: List()
16/03/23 14:13:05 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:13:05 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=547686973
16/03/23 14:13:05 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 522.3 MB)
16/03/23 14:13:05 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24952, maxMem=547686973
16/03/23 14:13:05 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 522.3 MB)
16/03/23 14:13:05 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:44082 (size: 3.3 KB, free: 522.3 MB)
16/03/23 14:13:05 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/23 14:13:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:05 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/23 14:13:05 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/23 14:13:05 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2368 bytes)
16/03/23 14:13:05 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/23 14:13:05 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/23 14:13:05 INFO PythonRunner: Times: total = 85, boot = 76, init = 9, finish = 0
16/03/23 14:13:05 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1355 bytes result sent to driver
16/03/23 14:13:05 INFO PythonRunner: Times: total = 86, boot = 86, init = 0, finish = 0
16/03/23 14:13:05 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 92 ms on localhost (1/2)
16/03/23 14:13:05 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/23 14:13:05 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 95 ms on localhost (2/2)
16/03/23 14:13:05 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/23 14:13:05 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.092 s
16/03/23 14:13:05 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.155032 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/23 14:13:05 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/23 14:13:05 INFO DAGScheduler: Stopping DAGScheduler
16/03/23 14:13:05 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/23 14:13:05 INFO MemoryStore: MemoryStore cleared
16/03/23 14:13:05 INFO BlockManager: BlockManager stopped
16/03/23 14:13:05 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/23 14:13:05 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/23 14:13:05 INFO SparkContext: Successfully stopped SparkContext
16/03/23 14:13:05 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/23 14:13:05 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/23 14:13:05 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'composition']
16/03/23 14:13:06 INFO SparkContext: Running Spark version 1.5.2
16/03/23 14:13:06 INFO SecurityManager: Changing view acls to: root
16/03/23 14:13:06 INFO SecurityManager: Changing modify acls to: root
16/03/23 14:13:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/23 14:13:06 INFO Slf4jLogger: Slf4jLogger started
16/03/23 14:13:06 INFO Remoting: Starting remoting
16/03/23 14:13:06 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:38468]
16/03/23 14:13:06 INFO Utils: Successfully started service 'sparkDriver' on port 38468.
16/03/23 14:13:06 INFO SparkEnv: Registering MapOutputTracker
16/03/23 14:13:06 INFO SparkEnv: Registering BlockManagerMaster
16/03/23 14:13:06 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-55d18202-20bb-4a3b-8395-bf1fc82492fc
16/03/23 14:13:06 INFO MemoryStore: MemoryStore started with capacity 516.8 MB
16/03/23 14:13:06 INFO HttpFileServer: HTTP File server directory is /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/httpd-58724c2f-4e57-4d3c-87dc-6b1c60f70ebb
16/03/23 14:13:06 INFO HttpServer: Starting HTTP Server
16/03/23 14:13:06 INFO Utils: Successfully started service 'HTTP file server' on port 39830.
16/03/23 14:13:06 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/23 14:13:06 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/23 14:13:06 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/23 14:13:06 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-8e74bc1c-4e9e-4ec4-8c5a-88052a5a2747/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:13:06 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722586772
16/03/23 14:13:06 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/23 14:13:06 INFO Executor: Starting executor ID driver on host localhost
16/03/23 14:13:06 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39076.
16/03/23 14:13:06 INFO NettyBlockTransferService: Server created on 39076
16/03/23 14:13:06 INFO BlockManagerMaster: Trying to register BlockManager
16/03/23 14:13:06 INFO BlockManagerMasterEndpoint: Registering block manager localhost:39076 with 516.8 MB RAM, BlockManagerId(driver, localhost, 39076)
16/03/23 14:13:06 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): parts
16/03/23 14:13:06 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:13:06 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:06 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:13:06 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/23 14:13:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/23 14:13:06 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:13:06 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=541883105
16/03/23 14:13:06 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 516.8 MB)
16/03/23 14:13:06 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=541883105
16/03/23 14:13:06 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 516.8 MB)
16/03/23 14:13:06 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:39076 (size: 4.1 KB, free: 516.8 MB)
16/03/23 14:13:06 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/23 14:13:06 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:06 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/23 14:13:06 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/23 14:13:06 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/23 14:13:06 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/23 14:13:06 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722586772
16/03/23 14:13:06 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/23 14:13:06 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-8e74bc1c-4e9e-4ec4-8c5a-88052a5a2747/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:13:07 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/23 14:13:07 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/23 14:13:07 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10732, maxMem=541883105
16/03/23 14:13:07 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 516.8 MB)
16/03/23 14:13:07 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:39076 (size: 187.0 B, free: 516.8 MB)
16/03/23 14:13:07 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10919, maxMem=541883105
16/03/23 14:13:07 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 516.8 MB)
16/03/23 14:13:07 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:39076 (size: 177.0 B, free: 516.8 MB)
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: set
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: issue
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: planning
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: permission
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: economy
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: composition
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  parts  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: agency
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/23 14:13:15 INFO PythonRunner: Times: total = 7996, boot = 459, init = 365, finish = 7172
16/03/23 14:13:15 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/23 14:13:15 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8060 ms on localhost (1/2)
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: bend
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: giant
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: astatine
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: present
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: area
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/23 14:13:15 INFO PythonRunner: Times: total = 8438, boot = 460, init = 402, finish = 7576
16/03/23 14:13:15 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/23 14:13:15 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8513 ms on localhost (2/2)
16/03/23 14:13:15 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 8.530 s
16/03/23 14:13:15 INFO DAGScheduler: looking for newly runnable stages
16/03/23 14:13:15 INFO DAGScheduler: running: Set()
16/03/23 14:13:15 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/23 14:13:15 INFO DAGScheduler: failed: Set()
16/03/23 14:13:15 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/23 14:13:15 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/23 14:13:15 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/23 14:13:15 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=541883105
16/03/23 14:13:15 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 516.8 MB)
16/03/23 14:13:15 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=541883105
16/03/23 14:13:15 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 516.8 MB)
16/03/23 14:13:15 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:39076 (size: 3.0 KB, free: 516.8 MB)
16/03/23 14:13:15 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/23 14:13:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:15 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/23 14:13:15 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:13:15 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:13:15 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/23 14:13:15 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/23 14:13:15 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:13:15 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:13:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/23 14:13:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', 'None', u'composition']
16/03/23 14:13:15 INFO PythonRunner: Times: total = 71, boot = -283, init = 353, finish = 1
16/03/23 14:13:15 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1287 bytes result sent to driver
16/03/23 14:13:15 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 105 ms on localhost (1/2)
16/03/23 14:13:15 INFO PythonRunner: Times: total = 274, boot = 273, init = 0, finish = 1
16/03/23 14:13:15 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/23 14:13:15 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.289 s
16/03/23 14:13:15 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 8.837755 s
16/03/23 14:13:15 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 289 ms on localhost (2/2)
16/03/23 14:13:15 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/23 14:13:15 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:13:15 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:13:15 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:15 INFO DAGScheduler: Parents of final stage: List()
16/03/23 14:13:15 INFO DAGScheduler: Missing parents: List()
16/03/23 14:13:15 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:13:15 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=541883105
16/03/23 14:13:15 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 516.8 MB)
16/03/23 14:13:15 INFO MemoryStore: ensureFreeSpace(3379) called with curMem=24952, maxMem=541883105
16/03/23 14:13:15 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 516.8 MB)
16/03/23 14:13:15 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:39076 (size: 3.3 KB, free: 516.8 MB)
16/03/23 14:13:15 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/23 14:13:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:15 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/23 14:13:15 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/23 14:13:15 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2368 bytes)
16/03/23 14:13:15 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/23 14:13:15 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/23 14:13:15 INFO PythonRunner: Times: total = 48, boot = -14, init = 62, finish = 0
16/03/23 14:13:15 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/23 14:13:15 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 57 ms on localhost (1/2)
16/03/23 14:13:15 INFO PythonRunner: Times: total = 58, boot = 58, init = 0, finish = 0
16/03/23 14:13:15 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1355 bytes result sent to driver
16/03/23 14:13:15 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 68 ms on localhost (2/2)
16/03/23 14:13:15 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/23 14:13:15 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.023 s
16/03/23 14:13:15 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.089501 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/23 14:13:16 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/23 14:13:16 INFO DAGScheduler: Stopping DAGScheduler
16/03/23 14:13:16 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/23 14:13:16 INFO MemoryStore: MemoryStore cleared
16/03/23 14:13:16 INFO BlockManager: BlockManager stopped
16/03/23 14:13:16 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/23 14:13:16 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/23 14:13:16 INFO SparkContext: Successfully stopped SparkContext
16/03/23 14:13:16 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/23 14:13:16 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/23 14:13:16 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'composition']
16/03/23 14:13:17 INFO SparkContext: Running Spark version 1.5.2
16/03/23 14:13:17 INFO SecurityManager: Changing view acls to: root
16/03/23 14:13:17 INFO SecurityManager: Changing modify acls to: root
16/03/23 14:13:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/23 14:13:17 INFO Slf4jLogger: Slf4jLogger started
16/03/23 14:13:17 INFO Remoting: Starting remoting
16/03/23 14:13:17 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:39380]
16/03/23 14:13:17 INFO Utils: Successfully started service 'sparkDriver' on port 39380.
16/03/23 14:13:17 INFO SparkEnv: Registering MapOutputTracker
16/03/23 14:13:17 INFO SparkEnv: Registering BlockManagerMaster
16/03/23 14:13:17 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-20875272-f2b2-42fe-b83b-df7972715747
16/03/23 14:13:17 INFO MemoryStore: MemoryStore started with capacity 516.8 MB
16/03/23 14:13:17 INFO HttpFileServer: HTTP File server directory is /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/httpd-5c7e4cfb-2c04-42ce-9bee-a416cdde99d0
16/03/23 14:13:17 INFO HttpServer: Starting HTTP Server
16/03/23 14:13:17 INFO Utils: Successfully started service 'HTTP file server' on port 45364.
16/03/23 14:13:17 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/23 14:13:17 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/23 14:13:17 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/23 14:13:17 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-85ba03fb-f90d-4173-9d90-eeb1d97fd342/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:13:17 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722597228
16/03/23 14:13:17 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/23 14:13:17 INFO Executor: Starting executor ID driver on host localhost
16/03/23 14:13:17 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56402.
16/03/23 14:13:17 INFO NettyBlockTransferService: Server created on 56402
16/03/23 14:13:17 INFO BlockManagerMaster: Trying to register BlockManager
16/03/23 14:13:17 INFO BlockManagerMasterEndpoint: Registering block manager localhost:56402 with 516.8 MB RAM, BlockManagerId(driver, localhost, 56402)
16/03/23 14:13:17 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): speech
16/03/23 14:13:17 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:13:17 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:17 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:13:17 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/23 14:13:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/23 14:13:17 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:13:17 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=541883105
16/03/23 14:13:17 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 516.8 MB)
16/03/23 14:13:17 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=541883105
16/03/23 14:13:17 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 516.8 MB)
16/03/23 14:13:17 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:56402 (size: 4.1 KB, free: 516.8 MB)
16/03/23 14:13:17 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/23 14:13:17 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:17 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/23 14:13:17 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/23 14:13:17 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/23 14:13:17 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/23 14:13:17 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722597228
16/03/23 14:13:17 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/23 14:13:17 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-85ba03fb-f90d-4173-9d90-eeb1d97fd342/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:13:17 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/23 14:13:17 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10732, maxMem=541883105
16/03/23 14:13:17 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 516.8 MB)
16/03/23 14:13:17 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:56402 (size: 187.0 B, free: 516.8 MB)
16/03/23 14:13:17 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/23 14:13:17 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10919, maxMem=541883105
16/03/23 14:13:17 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 516.8 MB)
16/03/23 14:13:17 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:56402 (size: 177.0 B, free: 516.8 MB)
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: area
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: issue
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: planning
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: permission
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: economy
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: composition
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: agency
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
mapFunction_Parents(): keyword= speech16/03/23 14:13:25 INFO PythonRunner: Times: total = 8135, boot = 450, init = 382, finish = 7303
 ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so'16/03/23 14:13:25 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
, u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: bend
16/03/23 14:13:25 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8203 ms on localhost (1/2)
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: giant
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: astatine
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: present
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  speech  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: area
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/23 14:13:25 INFO PythonRunner: Times: total = 8313, boot = 431, init = 366, finish = 7516
16/03/23 14:13:25 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/23 14:13:25 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8411 ms on localhost (2/2)
16/03/23 14:13:25 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/23 14:13:25 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 8.418 s
16/03/23 14:13:25 INFO DAGScheduler: looking for newly runnable stages
16/03/23 14:13:25 INFO DAGScheduler: running: Set()
16/03/23 14:13:25 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/23 14:13:25 INFO DAGScheduler: failed: Set()
16/03/23 14:13:25 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/23 14:13:25 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/23 14:13:25 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=541883105
16/03/23 14:13:25 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 516.8 MB)
16/03/23 14:13:25 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=541883105
16/03/23 14:13:25 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 516.8 MB)
16/03/23 14:13:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:56402 (size: 3.0 KB, free: 516.8 MB)
16/03/23 14:13:25 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/23 14:13:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:25 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/23 14:13:25 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:13:25 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:13:25 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/23 14:13:25 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/23 14:13:25 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:13:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/23 14:13:25 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:13:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/23 14:13:25 INFO PythonRunner: Times: total = 43, boot = -17, init = 59, finish = 1
16/03/23 14:13:25 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
reduceFunction_Parents(): returns= ['None', u'present', 'None']
16/03/23 14:13:25 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 67 ms on localhost (1/2)
16/03/23 14:13:25 INFO PythonRunner: Times: total = 192, boot = 192, init = 0, finish = 0
16/03/23 14:13:25 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/23 14:13:25 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 211 ms on localhost (2/2)
16/03/23 14:13:25 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/23 14:13:26 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.219 s
16/03/23 14:13:26 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 8.666630 s
16/03/23 14:13:26 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:13:26 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:13:26 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:26 INFO DAGScheduler: Parents of final stage: List()
16/03/23 14:13:26 INFO DAGScheduler: Missing parents: List()
16/03/23 14:13:26 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:13:26 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=541883105
16/03/23 14:13:26 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 516.8 MB)
16/03/23 14:13:26 INFO MemoryStore: ensureFreeSpace(3379) called with curMem=24952, maxMem=541883105
16/03/23 14:13:26 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 516.8 MB)
16/03/23 14:13:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:56402 (size: 3.3 KB, free: 516.8 MB)
16/03/23 14:13:26 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/23 14:13:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:26 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/23 14:13:26 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/23 14:13:26 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/23 14:13:26 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/23 14:13:26 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/23 14:13:26 INFO PythonRunner: Times: total = 58, boot = -38, init = 96, finish = 0
16/03/23 14:13:26 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1351 bytes result sent to driver
16/03/23 14:13:26 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 77 ms on localhost (1/2)
16/03/23 14:13:26 INFO PythonRunner: Times: total = 119, boot = 115, init = 4, finish = 0
16/03/23 14:13:26 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/23 14:13:26 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 131 ms on localhost (2/2)
16/03/23 14:13:26 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/23 14:13:26 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.128 s
16/03/23 14:13:26 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.150028 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/23 14:13:26 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/23 14:13:26 INFO DAGScheduler: Stopping DAGScheduler
16/03/23 14:13:26 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/23 14:13:26 INFO MemoryStore: MemoryStore cleared
16/03/23 14:13:26 INFO BlockManager: BlockManager stopped
16/03/23 14:13:26 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/23 14:13:26 INFO SparkContext: Successfully stopped SparkContext
16/03/23 14:13:26 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/23 14:13:26 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/23 14:13:26 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/23 14:13:26 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'present', u'None']
16/03/23 14:13:27 INFO SparkContext: Running Spark version 1.5.2
16/03/23 14:13:27 INFO SecurityManager: Changing view acls to: root
16/03/23 14:13:27 INFO SecurityManager: Changing modify acls to: root
16/03/23 14:13:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/23 14:13:27 INFO Slf4jLogger: Slf4jLogger started
16/03/23 14:13:27 INFO Remoting: Starting remoting
16/03/23 14:13:27 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:53038]
16/03/23 14:13:27 INFO Utils: Successfully started service 'sparkDriver' on port 53038.
16/03/23 14:13:27 INFO SparkEnv: Registering MapOutputTracker
16/03/23 14:13:27 INFO SparkEnv: Registering BlockManagerMaster
16/03/23 14:13:27 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0c42fb2a-cbce-446c-8fbf-9f122ecb8fe7
16/03/23 14:13:27 INFO MemoryStore: MemoryStore started with capacity 516.8 MB
16/03/23 14:13:27 INFO HttpFileServer: HTTP File server directory is /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/httpd-a458ae76-9a6e-48d2-8edd-9a3c5b55a666
16/03/23 14:13:27 INFO HttpServer: Starting HTTP Server
16/03/23 14:13:27 INFO Utils: Successfully started service 'HTTP file server' on port 56189.
16/03/23 14:13:27 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/23 14:13:27 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/23 14:13:27 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/23 14:13:27 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-08edb0ef-202e-49fa-887c-390bb95e4252/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:13:27 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722607531
16/03/23 14:13:27 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/23 14:13:27 INFO Executor: Starting executor ID driver on host localhost
16/03/23 14:13:27 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33350.
16/03/23 14:13:27 INFO NettyBlockTransferService: Server created on 33350
16/03/23 14:13:27 INFO BlockManagerMaster: Trying to register BlockManager
16/03/23 14:13:27 INFO BlockManagerMasterEndpoint: Registering block manager localhost:33350 with 516.8 MB RAM, BlockManagerId(driver, localhost, 33350)
16/03/23 14:13:27 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): geographical
16/03/23 14:13:27 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:13:27 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:27 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:13:27 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/23 14:13:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/23 14:13:27 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:13:27 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=541883105
16/03/23 14:13:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 516.8 MB)
16/03/23 14:13:27 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=541883105
16/03/23 14:13:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 516.8 MB)
16/03/23 14:13:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:33350 (size: 4.1 KB, free: 516.8 MB)
16/03/23 14:13:27 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/23 14:13:27 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:27 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/23 14:13:27 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/23 14:13:27 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/23 14:13:27 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/23 14:13:27 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722607531
16/03/23 14:13:27 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/23 14:13:27 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-08edb0ef-202e-49fa-887c-390bb95e4252/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:13:27 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/23 14:13:27 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10732, maxMem=541883105
16/03/23 14:13:27 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 516.8 MB)
16/03/23 14:13:27 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:33350 (size: 177.0 B, free: 516.8 MB)
16/03/23 14:13:27 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/23 14:13:27 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10909, maxMem=541883105
16/03/23 14:13:27 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 516.8 MB)
16/03/23 14:13:27 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:33350 (size: 187.0 B, free: 516.8 MB)
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: set
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  geographical  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: issue
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: planning
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: permission
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: economy
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: composition
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: agency
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/23 14:13:35 INFO PythonRunner: Times: total = 7830, boot = 453, init = 367, finish = 7010
16/03/23 14:13:35 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/23 14:13:35 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 7917 ms on localhost (1/2)
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: bend
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: giant
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: astatine
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: present
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: area
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  geographical  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/23 14:13:36 INFO PythonRunner: Times: total = 8385, boot = 451, init = 395, finish = 7539
16/03/23 14:13:36 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/23 14:13:36 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8457 ms on localhost (2/2)
16/03/23 14:13:36 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/23 14:13:36 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 8.459 s
16/03/23 14:13:36 INFO DAGScheduler: looking for newly runnable stages
16/03/23 14:13:36 INFO DAGScheduler: running: Set()
16/03/23 14:13:36 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/23 14:13:36 INFO DAGScheduler: failed: Set()
16/03/23 14:13:36 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/23 14:13:36 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/23 14:13:36 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=541883105
16/03/23 14:13:36 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 516.8 MB)
16/03/23 14:13:36 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=541883105
16/03/23 14:13:36 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 516.8 MB)
16/03/23 14:13:36 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:33350 (size: 3.0 KB, free: 516.8 MB)
16/03/23 14:13:36 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/23 14:13:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:36 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/23 14:13:36 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:13:36 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:13:36 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/23 14:13:36 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:13:36 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/23 14:13:36 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:13:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/23 14:13:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
reduceFunction_Parents(): returns= ['None', u'area', u'area']
16/03/23 14:13:36 INFO PythonRunner: Times: total = 33, boot = -368, init = 400, finish = 1
16/03/23 14:13:36 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/23 14:13:36 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 91 ms on localhost (1/2)
16/03/23 14:13:36 INFO PythonRunner: Times: total = 191, boot = 190, init = 0, finish = 1
16/03/23 14:13:36 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/23 14:13:36 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 212 ms on localhost (2/2)
16/03/23 14:13:36 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/23 14:13:36 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.199 s
16/03/23 14:13:36 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 8.702312 s
16/03/23 14:13:36 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:13:36 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:13:36 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:36 INFO DAGScheduler: Parents of final stage: List()
16/03/23 14:13:36 INFO DAGScheduler: Missing parents: List()
16/03/23 14:13:36 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:13:36 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=541883105
16/03/23 14:13:36 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 516.8 MB)
16/03/23 14:13:36 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24952, maxMem=541883105
16/03/23 14:13:36 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 516.8 MB)
16/03/23 14:13:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:33350 (size: 3.3 KB, free: 516.8 MB)
16/03/23 14:13:36 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/23 14:13:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:36 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/23 14:13:36 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/23 14:13:36 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/23 14:13:36 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/23 14:13:36 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/23 14:13:36 INFO PythonRunner: Times: total = 106, boot = 105, init = 1, finish = 0
16/03/23 14:13:36 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/23 14:13:36 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 114 ms on localhost (1/2)
16/03/23 14:13:36 INFO PythonRunner: Times: total = 119, boot = 119, init = 0, finish = 0
16/03/23 14:13:36 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/03/23 14:13:36 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 131 ms on localhost (2/2)
16/03/23 14:13:36 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/23 14:13:36 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.113 s
16/03/23 14:13:36 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.151783 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/23 14:13:36 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/23 14:13:36 INFO DAGScheduler: Stopping DAGScheduler
16/03/23 14:13:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/23 14:13:37 INFO MemoryStore: MemoryStore cleared
16/03/23 14:13:37 INFO BlockManager: BlockManager stopped
16/03/23 14:13:37 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/23 14:13:37 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/23 14:13:37 INFO SparkContext: Successfully stopped SparkContext
16/03/23 14:13:37 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/23 14:13:37 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/23 14:13:37 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'area', u'area']
16/03/23 14:13:37 INFO SparkContext: Running Spark version 1.5.2
16/03/23 14:13:37 INFO SecurityManager: Changing view acls to: root
16/03/23 14:13:37 INFO SecurityManager: Changing modify acls to: root
16/03/23 14:13:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/23 14:13:37 INFO Slf4jLogger: Slf4jLogger started
16/03/23 14:13:37 INFO Remoting: Starting remoting
16/03/23 14:13:37 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:46129]
16/03/23 14:13:37 INFO Utils: Successfully started service 'sparkDriver' on port 46129.
16/03/23 14:13:37 INFO SparkEnv: Registering MapOutputTracker
16/03/23 14:13:37 INFO SparkEnv: Registering BlockManagerMaster
16/03/23 14:13:37 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-85ec24d0-46c3-4996-bfb6-4fd8985d0309
16/03/23 14:13:37 INFO MemoryStore: MemoryStore started with capacity 522.0 MB
16/03/23 14:13:37 INFO HttpFileServer: HTTP File server directory is /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/httpd-7137da63-6502-4339-ae52-d9993e082b0d
16/03/23 14:13:37 INFO HttpServer: Starting HTTP Server
16/03/23 14:13:38 INFO Utils: Successfully started service 'HTTP file server' on port 55410.
16/03/23 14:13:38 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/23 14:13:38 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/23 14:13:38 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/23 14:13:38 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-9d0599fd-0709-4b9b-b220-6ac6a740d83a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:13:38 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722618172
16/03/23 14:13:38 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/23 14:13:38 INFO Executor: Starting executor ID driver on host localhost
16/03/23 14:13:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39022.
16/03/23 14:13:38 INFO NettyBlockTransferService: Server created on 39022
16/03/23 14:13:38 INFO BlockManagerMaster: Trying to register BlockManager
16/03/23 14:13:38 INFO BlockManagerMasterEndpoint: Registering block manager localhost:39022 with 522.0 MB RAM, BlockManagerId(driver, localhost, 39022)
16/03/23 14:13:38 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): spatial
16/03/23 14:13:38 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:13:38 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:38 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:13:38 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/23 14:13:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/23 14:13:38 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:13:38 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=547403857
16/03/23 14:13:38 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 522.0 MB)
16/03/23 14:13:38 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=547403857
16/03/23 14:13:38 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 522.0 MB)
16/03/23 14:13:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:39022 (size: 4.1 KB, free: 522.0 MB)
16/03/23 14:13:38 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/23 14:13:38 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:38 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/23 14:13:38 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/23 14:13:38 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/23 14:13:38 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/23 14:13:38 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722618172
16/03/23 14:13:38 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/23 14:13:38 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-9d0599fd-0709-4b9b-b220-6ac6a740d83a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:13:38 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/23 14:13:38 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/23 14:13:38 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10732, maxMem=547403857
16/03/23 14:13:38 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 522.0 MB)
16/03/23 14:13:38 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10919, maxMem=547403857
16/03/23 14:13:38 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:39022 (size: 187.0 B, free: 522.0 MB)
16/03/23 14:13:38 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 522.0 MB)
16/03/23 14:13:38 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:39022 (size: 177.0 B, free: 522.0 MB)
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: set
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: issue
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: planning
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: permission
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: economy
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: composition
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  spatial  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: agency
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/23 14:13:46 INFO PythonRunner: Times: total = 8058, boot = 463, init = 365, finish = 7230
16/03/23 14:13:46 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/23 14:13:46 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8130 ms on localhost (1/2)
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: bend
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: giant
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: astatine
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: present
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: area
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/23 14:13:46 INFO PythonRunner: Times: total = 8427, boot = 464, init = 397, finish = 7566
16/03/23 14:13:46 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/23 14:13:46 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8510 ms on localhost (2/2)
16/03/23 14:13:46 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 8.518 s
16/03/23 14:13:46 INFO DAGScheduler: looking for newly runnable stages
16/03/23 14:13:46 INFO DAGScheduler: running: Set()
16/03/23 14:13:46 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/23 14:13:46 INFO DAGScheduler: failed: Set()
16/03/23 14:13:46 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/23 14:13:46 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/23 14:13:46 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/23 14:13:46 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=547403857
16/03/23 14:13:46 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 522.0 MB)
16/03/23 14:13:46 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=547403857
16/03/23 14:13:46 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 522.0 MB)
16/03/23 14:13:46 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:39022 (size: 3.0 KB, free: 522.0 MB)
16/03/23 14:13:46 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/23 14:13:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:46 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/23 14:13:46 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:13:46 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:13:46 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/23 14:13:46 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/23 14:13:46 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:13:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/23 14:13:46 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:13:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
16/03/23 14:13:46 INFO PythonRunner: Times: total = 35, boot = -216, init = 251, finish = 0
16/03/23 14:13:46 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/23 14:13:46 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 62 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'composition']
16/03/23 14:13:47 INFO PythonRunner: Times: total = 204, boot = 203, init = 0, finish = 1
16/03/23 14:13:47 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1287 bytes result sent to driver
16/03/23 14:13:47 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.223 s
16/03/23 14:13:47 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 222 ms on localhost (2/2)
16/03/23 14:13:47 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/23 14:13:47 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 8.765640 s
16/03/23 14:13:47 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:13:47 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:13:47 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:47 INFO DAGScheduler: Parents of final stage: List()
16/03/23 14:13:47 INFO DAGScheduler: Missing parents: List()
16/03/23 14:13:47 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:13:47 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=547403857
16/03/23 14:13:47 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 522.0 MB)
16/03/23 14:13:47 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24952, maxMem=547403857
16/03/23 14:13:47 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 522.0 MB)
16/03/23 14:13:47 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:39022 (size: 3.3 KB, free: 522.0 MB)
16/03/23 14:13:47 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/23 14:13:47 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:47 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/23 14:13:47 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/23 14:13:47 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2368 bytes)
16/03/23 14:13:47 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/23 14:13:47 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/23 14:13:47 INFO PythonRunner: Times: total = 148, boot = 147, init = 1, finish = 0
16/03/23 14:13:47 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1355 bytes result sent to driver
16/03/23 14:13:47 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 158 ms on localhost (1/2)
16/03/23 14:13:47 INFO PythonRunner: Times: total = 177, boot = 177, init = 0, finish = 0
16/03/23 14:13:47 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/23 14:13:47 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 183 ms on localhost (2/2)
16/03/23 14:13:47 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/23 14:13:47 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.175 s
16/03/23 14:13:47 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.191086 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/23 14:13:47 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/23 14:13:47 INFO DAGScheduler: Stopping DAGScheduler
16/03/23 14:13:47 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/23 14:13:47 INFO MemoryStore: MemoryStore cleared
16/03/23 14:13:47 INFO BlockManager: BlockManager stopped
16/03/23 14:13:47 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/23 14:13:47 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/23 14:13:47 INFO SparkContext: Successfully stopped SparkContext
16/03/23 14:13:47 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/23 14:13:47 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/23 14:13:47 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'composition']
16/03/23 14:13:48 INFO SparkContext: Running Spark version 1.5.2
16/03/23 14:13:48 INFO SecurityManager: Changing view acls to: root
16/03/23 14:13:48 INFO SecurityManager: Changing modify acls to: root
16/03/23 14:13:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/23 14:13:48 INFO Slf4jLogger: Slf4jLogger started
16/03/23 14:13:48 INFO Remoting: Starting remoting
16/03/23 14:13:48 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:37572]
16/03/23 14:13:48 INFO Utils: Successfully started service 'sparkDriver' on port 37572.
16/03/23 14:13:48 INFO SparkEnv: Registering MapOutputTracker
16/03/23 14:13:48 INFO SparkEnv: Registering BlockManagerMaster
16/03/23 14:13:48 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3eb67b8b-c7b8-4c65-9798-03258dfbdce1
16/03/23 14:13:48 INFO MemoryStore: MemoryStore started with capacity 522.0 MB
16/03/23 14:13:48 INFO HttpFileServer: HTTP File server directory is /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/httpd-3cd16dfe-f6a5-4e3b-8b87-40dd6dac24d1
16/03/23 14:13:48 INFO HttpServer: Starting HTTP Server
16/03/23 14:13:48 INFO Utils: Successfully started service 'HTTP file server' on port 34804.
16/03/23 14:13:48 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/23 14:13:48 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/23 14:13:48 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/23 14:13:48 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-dffdc697-f881-4639-a081-46499b7b7e05/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:13:48 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722628639
16/03/23 14:13:48 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/23 14:13:48 INFO Executor: Starting executor ID driver on host localhost
16/03/23 14:13:48 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43778.
16/03/23 14:13:48 INFO NettyBlockTransferService: Server created on 43778
16/03/23 14:13:48 INFO BlockManagerMaster: Trying to register BlockManager
16/03/23 14:13:48 INFO BlockManagerMasterEndpoint: Registering block manager localhost:43778 with 522.0 MB RAM, BlockManagerId(driver, localhost, 43778)
16/03/23 14:13:48 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): Nadu
16/03/23 14:13:48 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:13:48 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:48 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:13:48 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/23 14:13:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/23 14:13:48 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:13:48 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=547403857
16/03/23 14:13:48 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 522.0 MB)
16/03/23 14:13:48 INFO MemoryStore: ensureFreeSpace(4155) called with curMem=6576, maxMem=547403857
16/03/23 14:13:48 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 522.0 MB)
16/03/23 14:13:48 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:43778 (size: 4.1 KB, free: 522.0 MB)
16/03/23 14:13:48 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/23 14:13:48 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:48 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/23 14:13:48 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/23 14:13:48 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/23 14:13:48 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/23 14:13:48 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722628639
16/03/23 14:13:48 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/23 14:13:48 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-dffdc697-f881-4639-a081-46499b7b7e05/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:13:48 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/23 14:13:48 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10731, maxMem=547403857
16/03/23 14:13:48 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 522.0 MB)
16/03/23 14:13:48 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/23 14:13:48 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10918, maxMem=547403857
16/03/23 14:13:48 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:43778 (size: 187.0 B, free: 522.0 MB)
16/03/23 14:13:48 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 522.0 MB)
16/03/23 14:13:48 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:43778 (size: 177.0 B, free: 522.0 MB)
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: area
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: issue
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: planning
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: permission
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: economy
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: composition
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: agency
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Nadu  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/23 14:13:56 INFO PythonRunner: Times: total = 8071, boot = 472, init = 378, finish = 7221
16/03/23 14:13:56 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: bend
16/03/23 14:13:56 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8161 ms on localhost (1/2)
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: giant
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: astatine
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: present
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Nadu  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: area
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/23 14:13:57 INFO PythonRunner: Times: total = 8272, boot = 473, init = 362, finish = 7437
16/03/23 14:13:57 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/23 14:13:57 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8365 ms on localhost (2/2)
16/03/23 14:13:57 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/23 14:13:57 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 8.363 s
16/03/23 14:13:57 INFO DAGScheduler: looking for newly runnable stages
16/03/23 14:13:57 INFO DAGScheduler: running: Set()
16/03/23 14:13:57 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/23 14:13:57 INFO DAGScheduler: failed: Set()
16/03/23 14:13:57 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/23 14:13:57 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/23 14:13:57 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11095, maxMem=547403857
16/03/23 14:13:57 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 522.0 MB)
16/03/23 14:13:57 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16079, maxMem=547403857
16/03/23 14:13:57 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 522.0 MB)
16/03/23 14:13:57 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:43778 (size: 3.0 KB, free: 522.0 MB)
16/03/23 14:13:57 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/23 14:13:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:57 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/23 14:13:57 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:13:57 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:13:57 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/23 14:13:57 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/23 14:13:57 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:13:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/23 14:13:57 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:13:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
reduceFunction_Parents(): returns= ['None', u'Chennai', 'None', u'Chennai']
16/03/23 14:13:57 INFO PythonRunner: Times: total = 39, boot = -8, init = 46, finish = 1
16/03/23 14:13:57 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1297 bytes result sent to driver
16/03/23 14:13:57 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 56 ms on localhost (1/2)
16/03/23 14:13:57 INFO PythonRunner: Times: total = 221, boot = 221, init = 0, finish = 0
16/03/23 14:13:57 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/23 14:13:57 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.248 s
16/03/23 14:13:57 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 8.640323 s
16/03/23 14:13:57 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 247 ms on localhost (2/2)
16/03/23 14:13:57 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/23 14:13:57 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:13:57 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:13:57 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:57 INFO DAGScheduler: Parents of final stage: List()
16/03/23 14:13:57 INFO DAGScheduler: Missing parents: List()
16/03/23 14:13:57 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:13:57 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19135, maxMem=547403857
16/03/23 14:13:57 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 522.0 MB)
16/03/23 14:13:57 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24951, maxMem=547403857
16/03/23 14:13:57 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 522.0 MB)
16/03/23 14:13:57 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:43778 (size: 3.3 KB, free: 522.0 MB)
16/03/23 14:13:57 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/23 14:13:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:57 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/23 14:13:57 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/23 14:13:57 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2378 bytes)
16/03/23 14:13:57 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/23 14:13:57 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/23 14:13:57 INFO PythonRunner: Times: total = 41, boot = 40, init = 1, finish = 0
16/03/23 14:13:57 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1365 bytes result sent to driver
16/03/23 14:13:57 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 60 ms on localhost (1/2)
16/03/23 14:13:57 INFO PythonRunner: Times: total = 75, boot = -171, init = 246, finish = 0
16/03/23 14:13:57 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/23 14:13:57 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 82 ms on localhost (2/2)
16/03/23 14:13:57 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/23 14:13:57 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.083 s
16/03/23 14:13:57 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.098385 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/23 14:13:57 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/23 14:13:57 INFO DAGScheduler: Stopping DAGScheduler
16/03/23 14:13:57 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/23 14:13:57 INFO MemoryStore: MemoryStore cleared
16/03/23 14:13:57 INFO BlockManager: BlockManager stopped
16/03/23 14:13:57 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/23 14:13:57 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/23 14:13:57 INFO SparkContext: Successfully stopped SparkContext
16/03/23 14:13:57 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/23 14:13:57 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/23 14:13:57 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'Chennai', u'None', u'Chennai']
16/03/23 14:13:58 INFO SparkContext: Running Spark version 1.5.2
16/03/23 14:13:58 INFO SecurityManager: Changing view acls to: root
16/03/23 14:13:58 INFO SecurityManager: Changing modify acls to: root
16/03/23 14:13:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/23 14:13:58 INFO Slf4jLogger: Slf4jLogger started
16/03/23 14:13:58 INFO Remoting: Starting remoting
16/03/23 14:13:58 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:59208]
16/03/23 14:13:58 INFO Utils: Successfully started service 'sparkDriver' on port 59208.
16/03/23 14:13:58 INFO SparkEnv: Registering MapOutputTracker
16/03/23 14:13:58 INFO SparkEnv: Registering BlockManagerMaster
16/03/23 14:13:58 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-49bb3430-8f4a-44a0-854f-fcfb68a773f9
16/03/23 14:13:58 INFO MemoryStore: MemoryStore started with capacity 522.4 MB
16/03/23 14:13:59 INFO HttpFileServer: HTTP File server directory is /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/httpd-ea75e02a-d045-4042-b4f6-07721905f58f
16/03/23 14:13:59 INFO HttpServer: Starting HTTP Server
16/03/23 14:13:59 INFO Utils: Successfully started service 'HTTP file server' on port 52041.
16/03/23 14:13:59 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/23 14:13:59 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/23 14:13:59 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/23 14:13:59 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-9bc92afe-27e8-41ea-8822-ea5c620ee21e/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:13:59 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722639129
16/03/23 14:13:59 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/23 14:13:59 INFO Executor: Starting executor ID driver on host localhost
16/03/23 14:13:59 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36330.
16/03/23 14:13:59 INFO NettyBlockTransferService: Server created on 36330
16/03/23 14:13:59 INFO BlockManagerMaster: Trying to register BlockManager
16/03/23 14:13:59 INFO BlockManagerMasterEndpoint: Registering block manager localhost:36330 with 522.4 MB RAM, BlockManagerId(driver, localhost, 36330)
16/03/23 14:13:59 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): circular
16/03/23 14:13:59 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:13:59 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:59 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:13:59 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/23 14:13:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/23 14:13:59 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:13:59 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=547828531
16/03/23 14:13:59 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 522.4 MB)
16/03/23 14:13:59 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=547828531
16/03/23 14:13:59 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 522.4 MB)
16/03/23 14:13:59 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:36330 (size: 4.1 KB, free: 522.4 MB)
16/03/23 14:13:59 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/23 14:13:59 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:13:59 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/23 14:13:59 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/23 14:13:59 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/23 14:13:59 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/23 14:13:59 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722639129
16/03/23 14:13:59 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/23 14:13:59 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-9bc92afe-27e8-41ea-8822-ea5c620ee21e/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:13:59 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/23 14:13:59 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10732, maxMem=547828531
16/03/23 14:13:59 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 522.4 MB)
16/03/23 14:13:59 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:36330 (size: 187.0 B, free: 522.4 MB)
16/03/23 14:13:59 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/23 14:13:59 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10919, maxMem=547828531
16/03/23 14:13:59 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 522.4 MB)
16/03/23 14:13:59 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:36330 (size: 177.0 B, free: 522.4 MB)
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: set
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: bend
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): adding to parents: syn =  Synset('bend.n.01') ; keyword:  circular  in syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= [u'bend']
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: giant
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: astatine
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: present
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: issue
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: area
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: planning
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
16/03/23 14:14:07 INFO PythonRunner: Times: total = 8153, boot = 460, init = 502, finish = 7191
16/03/23 14:14:07 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: permission
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: economy
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: composition
16/03/23 14:14:07 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8295 ms on localhost (1/2)
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: agency
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/23 14:14:07 INFO PythonRunner: Times: total = 8247, boot = 461, init = 394, finish = 7392
16/03/23 14:14:07 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/23 14:14:07 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 8.373 s
16/03/23 14:14:07 INFO DAGScheduler: looking for newly runnable stages
16/03/23 14:14:07 INFO DAGScheduler: running: Set()
16/03/23 14:14:07 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/23 14:14:07 INFO DAGScheduler: failed: Set()
16/03/23 14:14:07 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/23 14:14:07 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/23 14:14:07 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=547828531
16/03/23 14:14:07 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 522.4 MB)
16/03/23 14:14:07 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=547828531
16/03/23 14:14:07 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 522.4 MB)
16/03/23 14:14:07 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8375 ms on localhost (2/2)
16/03/23 14:14:07 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/23 14:14:07 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:36330 (size: 3.0 KB, free: 522.4 MB)
16/03/23 14:14:07 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/23 14:14:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:14:07 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/23 14:14:07 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:14:07 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:14:07 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/23 14:14:07 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:14:07 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/23 14:14:07 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:14:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/23 14:14:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
reduceFunction_Parents(): returns= [u'bend', 'None']
16/03/23 14:14:07 INFO PythonRunner: Times: total = 259, boot = 258, init = 0, finish = 1
16/03/23 14:14:07 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1272 bytes result sent to driver
16/03/23 14:14:08 INFO PythonRunner: Times: total = 263, boot = 262, init = 0, finish = 1
16/03/23 14:14:08 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/23 14:14:08 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 292 ms on localhost (1/2)
16/03/23 14:14:08 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 307 ms on localhost (2/2)
16/03/23 14:14:08 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.318 s
16/03/23 14:14:08 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/23 14:14:08 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 8.728056 s
16/03/23 14:14:08 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:14:08 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:14:08 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:14:08 INFO DAGScheduler: Parents of final stage: List()
16/03/23 14:14:08 INFO DAGScheduler: Missing parents: List()
16/03/23 14:14:08 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:14:08 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=547828531
16/03/23 14:14:08 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 522.4 MB)
16/03/23 14:14:08 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24952, maxMem=547828531
16/03/23 14:14:08 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 522.4 MB)
16/03/23 14:14:08 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:36330 (size: 3.3 KB, free: 522.4 MB)
16/03/23 14:14:08 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/23 14:14:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:14:08 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/23 14:14:08 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/23 14:14:08 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2353 bytes)
16/03/23 14:14:08 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/23 14:14:08 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/23 14:14:08 INFO PythonRunner: Times: total = 168, boot = 167, init = 1, finish = 0
16/03/23 14:14:08 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/23 14:14:08 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 174 ms on localhost (1/2)
16/03/23 14:14:08 INFO PythonRunner: Times: total = 263, boot = 262, init = 1, finish = 0
16/03/23 14:14:08 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1337 bytes result sent to driver
16/03/23 14:14:08 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 275 ms on localhost (2/2)
16/03/23 14:14:08 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/23 14:14:08 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.260 s
16/03/23 14:14:08 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.285713 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/23 14:14:08 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/23 14:14:08 INFO DAGScheduler: Stopping DAGScheduler
16/03/23 14:14:08 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/23 14:14:08 INFO MemoryStore: MemoryStore cleared
16/03/23 14:14:08 INFO BlockManager: BlockManager stopped
16/03/23 14:14:08 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/23 14:14:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/23 14:14:08 INFO SparkContext: Successfully stopped SparkContext
16/03/23 14:14:08 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/23 14:14:08 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/23 14:14:08 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'bend', u'None']
16/03/23 14:14:09 INFO SparkContext: Running Spark version 1.5.2
16/03/23 14:14:09 INFO SecurityManager: Changing view acls to: root
16/03/23 14:14:09 INFO SecurityManager: Changing modify acls to: root
16/03/23 14:14:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/23 14:14:09 INFO Slf4jLogger: Slf4jLogger started
16/03/23 14:14:09 INFO Remoting: Starting remoting
16/03/23 14:14:09 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:37108]
16/03/23 14:14:09 INFO Utils: Successfully started service 'sparkDriver' on port 37108.
16/03/23 14:14:09 INFO SparkEnv: Registering MapOutputTracker
16/03/23 14:14:09 INFO SparkEnv: Registering BlockManagerMaster
16/03/23 14:14:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a08af72c-f057-4e5d-aa19-b0c077262c41
16/03/23 14:14:09 INFO MemoryStore: MemoryStore started with capacity 522.4 MB
16/03/23 14:14:09 INFO HttpFileServer: HTTP File server directory is /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/httpd-dc8695a1-b7e2-4c8f-9992-238c9f3b551c
16/03/23 14:14:09 INFO HttpServer: Starting HTTP Server
16/03/23 14:14:09 INFO Utils: Successfully started service 'HTTP file server' on port 58236.
16/03/23 14:14:09 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/23 14:14:09 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/23 14:14:09 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/23 14:14:09 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-ef57a749-34f8-4c8a-a220-4b2c424cd254/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:14:09 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722649702
16/03/23 14:14:09 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/23 14:14:09 INFO Executor: Starting executor ID driver on host localhost
16/03/23 14:14:09 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42623.
16/03/23 14:14:09 INFO NettyBlockTransferService: Server created on 42623
16/03/23 14:14:09 INFO BlockManagerMaster: Trying to register BlockManager
16/03/23 14:14:09 INFO BlockManagerMasterEndpoint: Registering block manager localhost:42623 with 522.4 MB RAM, BlockManagerId(driver, localhost, 42623)
16/03/23 14:14:09 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): product
16/03/23 14:14:09 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:14:09 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:14:09 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:14:09 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:14:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/23 14:14:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/23 14:14:09 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:14:09 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=547828531
16/03/23 14:14:09 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 522.4 MB)
16/03/23 14:14:09 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=547828531
16/03/23 14:14:09 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 522.4 MB)
16/03/23 14:14:09 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:42623 (size: 4.1 KB, free: 522.4 MB)
16/03/23 14:14:09 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/23 14:14:09 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:14:09 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/23 14:14:09 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/23 14:14:09 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/23 14:14:09 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/23 14:14:09 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722649702
16/03/23 14:14:09 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/23 14:14:09 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-ef57a749-34f8-4c8a-a220-4b2c424cd254/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:14:09 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/23 14:14:09 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10732, maxMem=547828531
16/03/23 14:14:09 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 522.4 MB)
16/03/23 14:14:09 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:42623 (size: 177.0 B, free: 522.4 MB)
16/03/23 14:14:09 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/23 14:14:09 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10909, maxMem=547828531
16/03/23 14:14:09 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 522.4 MB)
16/03/23 14:14:09 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:42623 (size: 187.0 B, free: 522.4 MB)
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: set
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: issue
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: planning
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: permission
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: economy
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: composition
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: agency
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/23 14:14:17 INFO PythonRunner: Times: total = 8076, boot = 453, init = 368, finish = 7255
16/03/23 14:14:17 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/23 14:14:17 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8144 ms on localhost (1/2)
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: bend
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: giant
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: astatine
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  product  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: present
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: area
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/23 14:14:18 INFO PythonRunner: Times: total = 8424, boot = 449, init = 385, finish = 7590
16/03/23 14:14:18 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/23 14:14:18 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8496 ms on localhost (2/2)
16/03/23 14:14:18 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 8.498 s
16/03/23 14:14:18 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/23 14:14:18 INFO DAGScheduler: looking for newly runnable stages
16/03/23 14:14:18 INFO DAGScheduler: running: Set()
16/03/23 14:14:18 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/23 14:14:18 INFO DAGScheduler: failed: Set()
16/03/23 14:14:18 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/23 14:14:18 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/23 14:14:18 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=547828531
16/03/23 14:14:18 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 522.4 MB)
16/03/23 14:14:18 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=547828531
16/03/23 14:14:18 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 522.4 MB)
16/03/23 14:14:18 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:42623 (size: 3.0 KB, free: 522.4 MB)
16/03/23 14:14:18 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/23 14:14:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:14:18 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/23 14:14:18 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:14:18 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:14:18 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/23 14:14:18 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/23 14:14:18 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:14:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/23 14:14:18 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:14:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/03/23 14:14:18 INFO PythonRunner: Times: total = 42, boot = -199, init = 241, finish = 0
16/03/23 14:14:18 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/23 14:14:18 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 76 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'astatine', 'None']
16/03/23 14:14:18 INFO PythonRunner: Times: total = 191, boot = 190, init = 1, finish = 0
16/03/23 14:14:18 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/03/23 14:14:18 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.218 s
16/03/23 14:14:18 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 8.742035 s
16/03/23 14:14:18 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 222 ms on localhost (2/2)
16/03/23 14:14:18 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/23 14:14:18 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:14:18 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:14:18 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:14:18 INFO DAGScheduler: Parents of final stage: List()
16/03/23 14:14:18 INFO DAGScheduler: Missing parents: List()
16/03/23 14:14:18 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:14:18 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=547828531
16/03/23 14:14:18 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 522.4 MB)
16/03/23 14:14:18 INFO MemoryStore: ensureFreeSpace(3377) called with curMem=24952, maxMem=547828531
16/03/23 14:14:18 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 522.4 MB)
16/03/23 14:14:18 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:42623 (size: 3.3 KB, free: 522.4 MB)
16/03/23 14:14:18 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/23 14:14:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:14:18 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/23 14:14:18 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/23 14:14:18 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/03/23 14:14:18 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/23 14:14:18 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/23 14:14:18 INFO PythonRunner: Times: total = 29, boot = 23, init = 6, finish = 0
16/03/23 14:14:18 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/23 14:14:18 INFO PythonRunner: Times: total = 91, boot = 64, init = 27, finish = 0
16/03/23 14:14:18 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/03/23 14:14:18 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 100 ms on localhost (1/2)
16/03/23 14:14:18 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 104 ms on localhost (2/2)
16/03/23 14:14:18 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/23 14:14:18 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.102 s
16/03/23 14:14:18 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.124653 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/23 14:14:18 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/23 14:14:18 INFO DAGScheduler: Stopping DAGScheduler
16/03/23 14:14:19 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/23 14:14:19 INFO MemoryStore: MemoryStore cleared
16/03/23 14:14:19 INFO BlockManager: BlockManager stopped
16/03/23 14:14:19 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/23 14:14:19 INFO SparkContext: Successfully stopped SparkContext
16/03/23 14:14:19 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/23 14:14:19 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/23 14:14:19 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/23 14:14:19 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'astatine', u'None']
16/03/23 14:14:19 INFO SparkContext: Running Spark version 1.5.2
16/03/23 14:14:19 INFO SecurityManager: Changing view acls to: root
16/03/23 14:14:19 INFO SecurityManager: Changing modify acls to: root
16/03/23 14:14:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/23 14:14:19 INFO Slf4jLogger: Slf4jLogger started
16/03/23 14:14:19 INFO Remoting: Starting remoting
16/03/23 14:14:19 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:32924]
16/03/23 14:14:19 INFO Utils: Successfully started service 'sparkDriver' on port 32924.
16/03/23 14:14:19 INFO SparkEnv: Registering MapOutputTracker
16/03/23 14:14:19 INFO SparkEnv: Registering BlockManagerMaster
16/03/23 14:14:19 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-cca911b6-1272-4a32-9215-3e502828c779
16/03/23 14:14:19 INFO MemoryStore: MemoryStore started with capacity 522.4 MB
16/03/23 14:14:19 INFO HttpFileServer: HTTP File server directory is /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/httpd-2b6bdea8-9f14-450e-8bdc-0622868f02e7
16/03/23 14:14:19 INFO HttpServer: Starting HTTP Server
16/03/23 14:14:20 INFO Utils: Successfully started service 'HTTP file server' on port 43303.
16/03/23 14:14:20 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/23 14:14:20 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/23 14:14:20 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/23 14:14:20 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-667fa196-a25a-4d33-9c2c-659cb3779e7d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:14:20 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722660121
16/03/23 14:14:20 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/23 14:14:20 INFO Executor: Starting executor ID driver on host localhost
16/03/23 14:14:20 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56529.
16/03/23 14:14:20 INFO NettyBlockTransferService: Server created on 56529
16/03/23 14:14:20 INFO BlockManagerMaster: Trying to register BlockManager
16/03/23 14:14:20 INFO BlockManagerMasterEndpoint: Registering block manager localhost:56529 with 522.4 MB RAM, BlockManagerId(driver, localhost, 56529)
16/03/23 14:14:20 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): used
16/03/23 14:14:20 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:14:20 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:14:20 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:14:20 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:14:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/23 14:14:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/23 14:14:20 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:14:20 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=547828531
16/03/23 14:14:20 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 522.4 MB)
16/03/23 14:14:20 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=547828531
16/03/23 14:14:20 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 522.4 MB)
16/03/23 14:14:20 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:56529 (size: 4.1 KB, free: 522.4 MB)
16/03/23 14:14:20 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/23 14:14:20 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:14:20 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/23 14:14:20 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/23 14:14:20 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/23 14:14:20 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/23 14:14:20 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722660121
16/03/23 14:14:20 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/23 14:14:20 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-667fa196-a25a-4d33-9c2c-659cb3779e7d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:14:20 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/23 14:14:20 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/23 14:14:20 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10732, maxMem=547828531
16/03/23 14:14:20 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 522.4 MB)
16/03/23 14:14:20 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10909, maxMem=547828531
16/03/23 14:14:20 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:56529 (size: 177.0 B, free: 522.4 MB)
16/03/23 14:14:20 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 522.4 MB)
16/03/23 14:14:20 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:56529 (size: 187.0 B, free: 522.4 MB)
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: area
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  Synset('set.n.01') ; keyword:  used  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: bend
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: giant
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: astatine
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: present
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: area
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
16/03/23 14:14:28 INFO PythonRunner: Times: total = 7911, boot = 449, init = 366, finish = 7096
16/03/23 14:14:28 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/23 14:14:28 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8367 ms on localhost (1/2)
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: issue
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: planning
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: permission
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: economy
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: composition
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: agency
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/23 14:14:28 INFO PythonRunner: Times: total = 8437, boot = 454, init = 383, finish = 7600
16/03/23 14:14:28 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/23 14:14:28 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8519 ms on localhost (2/2)
16/03/23 14:14:28 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/23 14:14:28 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 8.523 s
16/03/23 14:14:28 INFO DAGScheduler: looking for newly runnable stages
16/03/23 14:14:28 INFO DAGScheduler: running: Set()
16/03/23 14:14:28 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/23 14:14:28 INFO DAGScheduler: failed: Set()
16/03/23 14:14:28 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/23 14:14:28 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/23 14:14:28 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=547828531
16/03/23 14:14:28 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 522.4 MB)
16/03/23 14:14:28 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=547828531
16/03/23 14:14:28 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 522.4 MB)
16/03/23 14:14:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:56529 (size: 3.0 KB, free: 522.4 MB)
16/03/23 14:14:28 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/23 14:14:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:14:28 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/23 14:14:28 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:14:28 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:14:28 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/23 14:14:28 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:14:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/23 14:14:28 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/23 14:14:28 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:14:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
reduceFunction_Parents(): returns= [u'set', 'None']
16/03/23 14:14:28 INFO PythonRunner: Times: total = 28, boot = -154, init = 181, finish = 1
16/03/23 14:14:28 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1271 bytes result sent to driver
16/03/23 14:14:28 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 91 ms on localhost (1/2)
16/03/23 14:14:29 INFO PythonRunner: Times: total = 196, boot = 195, init = 1, finish = 0
16/03/23 14:14:29 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/23 14:14:29 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 221 ms on localhost (2/2)
16/03/23 14:14:29 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/23 14:14:29 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.222 s
16/03/23 14:14:29 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 8.782683 s
16/03/23 14:14:29 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:14:29 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:14:29 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:14:29 INFO DAGScheduler: Parents of final stage: List()
16/03/23 14:14:29 INFO DAGScheduler: Missing parents: List()
16/03/23 14:14:29 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:14:29 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=547828531
16/03/23 14:14:29 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 522.4 MB)
16/03/23 14:14:29 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24952, maxMem=547828531
16/03/23 14:14:29 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 522.4 MB)
16/03/23 14:14:29 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:56529 (size: 3.3 KB, free: 522.4 MB)
16/03/23 14:14:29 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/23 14:14:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:14:29 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/23 14:14:29 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/23 14:14:29 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/23 14:14:29 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/23 14:14:29 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/23 14:14:29 INFO PythonRunner: Times: total = 77, boot = 38, init = 39, finish = 0
16/03/23 14:14:29 INFO PythonRunner: Times: total = 63, boot = 63, init = 0, finish = 0
16/03/23 14:14:29 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/23 14:14:29 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1336 bytes result sent to driver
16/03/23 14:14:29 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 94 ms on localhost (1/2)
16/03/23 14:14:29 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 95 ms on localhost (2/2)
16/03/23 14:14:29 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/23 14:14:29 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.069 s
16/03/23 14:14:29 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.125883 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/23 14:14:29 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/23 14:14:29 INFO DAGScheduler: Stopping DAGScheduler
16/03/23 14:14:29 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/23 14:14:29 INFO MemoryStore: MemoryStore cleared
16/03/23 14:14:29 INFO BlockManager: BlockManager stopped
16/03/23 14:14:29 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/23 14:14:29 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/23 14:14:29 INFO SparkContext: Successfully stopped SparkContext
16/03/23 14:14:29 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/23 14:14:29 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/23 14:14:29 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'set', u'None']
16/03/23 14:14:30 INFO SparkContext: Running Spark version 1.5.2
16/03/23 14:14:30 INFO SecurityManager: Changing view acls to: root
16/03/23 14:14:30 INFO SecurityManager: Changing modify acls to: root
16/03/23 14:14:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/23 14:14:30 INFO Slf4jLogger: Slf4jLogger started
16/03/23 14:14:30 INFO Remoting: Starting remoting
16/03/23 14:14:30 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:43190]
16/03/23 14:14:30 INFO Utils: Successfully started service 'sparkDriver' on port 43190.
16/03/23 14:14:30 INFO SparkEnv: Registering MapOutputTracker
16/03/23 14:14:30 INFO SparkEnv: Registering BlockManagerMaster
16/03/23 14:14:30 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-61960a56-65c2-4611-91e3-95b576406ea6
16/03/23 14:14:30 INFO MemoryStore: MemoryStore started with capacity 523.3 MB
16/03/23 14:14:30 INFO HttpFileServer: HTTP File server directory is /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/httpd-b2efe9f7-0e3d-4ce7-88a0-8d12f28e61ae
16/03/23 14:14:30 INFO HttpServer: Starting HTTP Server
16/03/23 14:14:30 INFO Utils: Successfully started service 'HTTP file server' on port 33001.
16/03/23 14:14:30 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/23 14:14:30 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/23 14:14:30 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/23 14:14:30 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-893d839b-0851-41e4-a4c4-8967be9f3f07/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:14:30 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722670582
16/03/23 14:14:30 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/23 14:14:30 INFO Executor: Starting executor ID driver on host localhost
16/03/23 14:14:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42376.
16/03/23 14:14:30 INFO NettyBlockTransferService: Server created on 42376
16/03/23 14:14:30 INFO BlockManagerMaster: Trying to register BlockManager
16/03/23 14:14:30 INFO BlockManagerMasterEndpoint: Registering block manager localhost:42376 with 523.3 MB RAM, BlockManagerId(driver, localhost, 42376)
16/03/23 14:14:30 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): usually
16/03/23 14:14:30 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:14:30 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:14:30 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:14:30 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:14:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/23 14:14:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/23 14:14:30 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:14:30 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=548677877
16/03/23 14:14:30 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.3 MB)
16/03/23 14:14:30 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=548677877
16/03/23 14:14:30 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.2 MB)
16/03/23 14:14:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:42376 (size: 4.1 KB, free: 523.3 MB)
16/03/23 14:14:30 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/23 14:14:30 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:14:30 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/23 14:14:30 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/23 14:14:30 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/23 14:14:30 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/23 14:14:30 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722670582
16/03/23 14:14:30 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/23 14:14:30 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-893d839b-0851-41e4-a4c4-8967be9f3f07/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:14:30 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/23 14:14:30 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10732, maxMem=548677877
16/03/23 14:14:30 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 523.2 MB)
16/03/23 14:14:30 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:42376 (size: 187.0 B, free: 523.3 MB)
16/03/23 14:14:30 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/23 14:14:30 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10919, maxMem=548677877
16/03/23 14:14:30 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 523.2 MB)
16/03/23 14:14:30 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:42376 (size: 177.0 B, free: 523.3 MB)
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: set
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  usually  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: issue
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: planning
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: permission
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: economy
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: composition
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: agency
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/23 14:14:38 INFO PythonRunner: Times: total = 7965, boot = 458, init = 359, finish = 7148
16/03/23 14:14:38 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', 16/03/23 14:14:38 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8037 ms on localhost (1/2)
u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: bend
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: giant
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: astatine
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: present
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: area
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  usually  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/23 14:14:38 INFO PythonRunner: Times: total = 8097, boot = 460, init = 414, finish = 7223
16/03/23 14:14:38 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/23 14:14:38 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8182 ms on localhost (2/2)
16/03/23 14:14:38 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/23 14:14:38 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 8.175 s
16/03/23 14:14:38 INFO DAGScheduler: looking for newly runnable stages
16/03/23 14:14:38 INFO DAGScheduler: running: Set()
16/03/23 14:14:38 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/23 14:14:38 INFO DAGScheduler: failed: Set()
16/03/23 14:14:38 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/23 14:14:38 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/23 14:14:38 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=548677877
16/03/23 14:14:38 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.2 MB)
16/03/23 14:14:38 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=548677877
16/03/23 14:14:38 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.2 MB)
16/03/23 14:14:38 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:42376 (size: 3.0 KB, free: 523.3 MB)
16/03/23 14:14:38 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/23 14:14:38 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:14:38 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/23 14:14:38 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:14:38 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:14:38 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/23 14:14:38 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:14:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/23 14:14:38 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/23 14:14:38 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:14:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
reduceFunction_Parents(): returns= ['None', u'area', u'area']
16/03/23 14:14:39 INFO PythonRunner: Times: total = 181, boot = 180, init = 0, finish = 1
16/03/23 14:14:39 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/23 14:14:39 INFO PythonRunner: Times: total = 196, boot = 195, init = 0, finish = 1
16/03/23 14:14:39 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/23 14:14:39 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 215 ms on localhost (1/2)
16/03/23 14:14:39 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.219 s
16/03/23 14:14:39 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 232 ms on localhost (2/2)
16/03/23 14:14:39 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 8.470825 s
16/03/23 14:14:39 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/23 14:14:39 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:14:39 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:14:39 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:14:39 INFO DAGScheduler: Parents of final stage: List()
16/03/23 14:14:39 INFO DAGScheduler: Missing parents: List()
16/03/23 14:14:39 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:14:39 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=548677877
16/03/23 14:14:39 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.2 MB)
16/03/23 14:14:39 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24952, maxMem=548677877
16/03/23 14:14:39 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.2 MB)
16/03/23 14:14:39 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:42376 (size: 3.3 KB, free: 523.2 MB)
16/03/23 14:14:39 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/23 14:14:39 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:14:39 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/23 14:14:39 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/23 14:14:39 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/23 14:14:39 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/23 14:14:39 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/23 14:14:39 INFO PythonRunner: Times: total = 34, boot = -30, init = 64, finish = 0
16/03/23 14:14:39 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/23 14:14:39 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 57 ms on localhost (1/2)
16/03/23 14:14:39 INFO PythonRunner: Times: total = 136, boot = 135, init = 1, finish = 0
16/03/23 14:14:39 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/03/23 14:14:39 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 148 ms on localhost (2/2)
16/03/23 14:14:39 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/23 14:14:39 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.149 s
16/03/23 14:14:39 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.173451 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/23 14:14:39 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/23 14:14:39 INFO DAGScheduler: Stopping DAGScheduler
16/03/23 14:14:39 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/23 14:14:39 INFO MemoryStore: MemoryStore cleared
16/03/23 14:14:39 INFO BlockManager: BlockManager stopped
16/03/23 14:14:39 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/23 14:14:39 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/23 14:14:39 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/23 14:14:39 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/23 14:14:39 INFO SparkContext: Successfully stopped SparkContext
16/03/23 14:14:39 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'area', u'area']
16/03/23 14:14:40 INFO SparkContext: Running Spark version 1.5.2
16/03/23 14:14:40 INFO SecurityManager: Changing view acls to: root
16/03/23 14:14:40 INFO SecurityManager: Changing modify acls to: root
16/03/23 14:14:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/23 14:14:40 INFO Slf4jLogger: Slf4jLogger started
16/03/23 14:14:40 INFO Remoting: Starting remoting
16/03/23 14:14:40 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:52920]
16/03/23 14:14:40 INFO Utils: Successfully started service 'sparkDriver' on port 52920.
16/03/23 14:14:40 INFO SparkEnv: Registering MapOutputTracker
16/03/23 14:14:40 INFO SparkEnv: Registering BlockManagerMaster
16/03/23 14:14:40 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-dd65616a-2f76-49dc-bbc5-1e70edd80ed0
16/03/23 14:14:40 INFO MemoryStore: MemoryStore started with capacity 523.3 MB
16/03/23 14:14:40 INFO HttpFileServer: HTTP File server directory is /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/httpd-a4f6d434-8465-493a-b4b4-f247b611dfa9
16/03/23 14:14:40 INFO HttpServer: Starting HTTP Server
16/03/23 14:14:40 INFO Utils: Successfully started service 'HTTP file server' on port 36258.
16/03/23 14:14:40 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/23 14:14:40 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/23 14:14:40 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/23 14:14:40 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-536e612e-10f5-4bd2-b808-1ffc9b1d843b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:14:40 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722680802
16/03/23 14:14:40 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/23 14:14:40 INFO Executor: Starting executor ID driver on host localhost
16/03/23 14:14:40 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52117.
16/03/23 14:14:40 INFO NettyBlockTransferService: Server created on 52117
16/03/23 14:14:40 INFO BlockManagerMaster: Trying to register BlockManager
16/03/23 14:14:40 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52117 with 523.3 MB RAM, BlockManagerId(driver, localhost, 52117)
16/03/23 14:14:40 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): moment
16/03/23 14:14:40 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:14:40 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:14:40 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:14:40 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:14:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/23 14:14:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/23 14:14:40 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:14:40 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=548677877
16/03/23 14:14:40 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.3 MB)
16/03/23 14:14:40 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=548677877
16/03/23 14:14:40 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.2 MB)
16/03/23 14:14:40 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52117 (size: 4.1 KB, free: 523.3 MB)
16/03/23 14:14:40 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/23 14:14:40 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:14:40 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/23 14:14:40 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/23 14:14:40 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/23 14:14:40 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/23 14:14:40 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722680802
16/03/23 14:14:40 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/23 14:14:40 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-536e612e-10f5-4bd2-b808-1ffc9b1d843b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:14:41 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/23 14:14:41 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10732, maxMem=548677877
16/03/23 14:14:41 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 523.2 MB)
16/03/23 14:14:41 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:52117 (size: 187.0 B, free: 523.3 MB)
16/03/23 14:14:41 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/23 14:14:41 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10919, maxMem=548677877
16/03/23 14:14:41 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 523.2 MB)
16/03/23 14:14:41 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:52117 (size: 177.0 B, free: 523.3 MB)
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: area
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: bend
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: giant
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: astatine
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: present
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  moment  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: area
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/23 14:14:49 INFO PythonRunner: Times: total = 8122, boot = 466, init = 362, finish = 7294
16/03/23 14:14:49 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/23 14:14:49 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8239 ms on localhost (1/2)
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: issue
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: planning
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: permission
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: economy
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: composition
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: agency
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/23 14:14:49 INFO PythonRunner: Times: total = 8265, boot = 462, init = 394, finish = 7409
16/03/23 14:14:49 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/23 14:14:49 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 8.385 s
16/03/23 14:14:49 INFO DAGScheduler: looking for newly runnable stages
16/03/23 14:14:49 INFO DAGScheduler: running: Set()
16/03/23 14:14:49 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/23 14:14:49 INFO DAGScheduler: failed: Set()
16/03/23 14:14:49 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/23 14:14:49 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/23 14:14:49 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=548677877
16/03/23 14:14:49 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.2 MB)
16/03/23 14:14:49 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=548677877
16/03/23 14:14:49 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.2 MB)
16/03/23 14:14:49 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52117 (size: 3.0 KB, free: 523.3 MB)
16/03/23 14:14:49 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/23 14:14:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:14:49 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/23 14:14:49 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8384 ms on localhost (2/2)
16/03/23 14:14:49 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/23 14:14:49 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:14:49 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:14:49 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/23 14:14:49 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/23 14:14:49 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:14:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/23 14:14:49 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:14:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/23 14:14:49 INFO PythonRunner: Times: total = 138, boot = 137, init = 1, finish = 0
16/03/23 14:14:49 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/23 14:14:49 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 160 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'present', 'None']
16/03/23 14:14:49 INFO PythonRunner: Times: total = 201, boot = 200, init = 0, finish = 1
16/03/23 14:14:49 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/23 14:14:49 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.224 s
16/03/23 14:14:49 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 8.627555 s
16/03/23 14:14:49 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 223 ms on localhost (2/2)
16/03/23 14:14:49 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/23 14:14:49 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:14:49 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:14:49 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:14:49 INFO DAGScheduler: Parents of final stage: List()
16/03/23 14:14:49 INFO DAGScheduler: Missing parents: List()
16/03/23 14:14:49 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:14:49 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=548677877
16/03/23 14:14:49 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.2 MB)
16/03/23 14:14:49 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24952, maxMem=548677877
16/03/23 14:14:49 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.2 MB)
16/03/23 14:14:49 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:52117 (size: 3.3 KB, free: 523.2 MB)
16/03/23 14:14:49 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/23 14:14:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:14:49 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/23 14:14:49 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/23 14:14:49 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/23 14:14:49 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/23 14:14:49 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/23 14:14:49 INFO PythonRunner: Times: total = 132, boot = 132, init = 0, finish = 0
16/03/23 14:14:49 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/23 14:14:49 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 138 ms on localhost (1/2)
16/03/23 14:14:49 INFO PythonRunner: Times: total = 146, boot = 145, init = 0, finish = 1
16/03/23 14:14:49 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1351 bytes result sent to driver
16/03/23 14:14:49 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 151 ms on localhost (2/2)
16/03/23 14:14:49 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/23 14:14:49 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.153 s
16/03/23 14:14:49 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.164623 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/23 14:14:49 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/23 14:14:49 INFO DAGScheduler: Stopping DAGScheduler
16/03/23 14:14:49 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/23 14:14:49 INFO MemoryStore: MemoryStore cleared
16/03/23 14:14:49 INFO BlockManager: BlockManager stopped
16/03/23 14:14:49 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/23 14:14:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/23 14:14:50 INFO SparkContext: Successfully stopped SparkContext
16/03/23 14:14:50 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/23 14:14:50 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/23 14:14:50 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'present', u'None']
16/03/23 14:14:50 INFO SparkContext: Running Spark version 1.5.2
16/03/23 14:14:50 INFO SecurityManager: Changing view acls to: root
16/03/23 14:14:50 INFO SecurityManager: Changing modify acls to: root
16/03/23 14:14:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/23 14:14:50 INFO Slf4jLogger: Slf4jLogger started
16/03/23 14:14:50 INFO Remoting: Starting remoting
16/03/23 14:14:50 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:39689]
16/03/23 14:14:50 INFO Utils: Successfully started service 'sparkDriver' on port 39689.
16/03/23 14:14:50 INFO SparkEnv: Registering MapOutputTracker
16/03/23 14:14:50 INFO SparkEnv: Registering BlockManagerMaster
16/03/23 14:14:50 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1669ce53-9c8e-4537-8d48-776a35ade683
16/03/23 14:14:50 INFO MemoryStore: MemoryStore started with capacity 523.3 MB
16/03/23 14:14:50 INFO HttpFileServer: HTTP File server directory is /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/httpd-830cd68d-17f1-47f6-8fb1-c294fa30a4e4
16/03/23 14:14:50 INFO HttpServer: Starting HTTP Server
16/03/23 14:14:51 INFO Utils: Successfully started service 'HTTP file server' on port 47692.
16/03/23 14:14:51 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/23 14:14:51 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/23 14:14:51 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/23 14:14:51 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-ae9f3d33-c66a-42e6-8116-371147e9daaa/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:14:51 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722691302
16/03/23 14:14:51 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/23 14:14:51 INFO Executor: Starting executor ID driver on host localhost
16/03/23 14:14:51 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54626.
16/03/23 14:14:51 INFO NettyBlockTransferService: Server created on 54626
16/03/23 14:14:51 INFO BlockManagerMaster: Trying to register BlockManager
16/03/23 14:14:51 INFO BlockManagerMasterEndpoint: Registering block manager localhost:54626 with 523.3 MB RAM, BlockManagerId(driver, localhost, 54626)
16/03/23 14:14:51 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): purpose
16/03/23 14:14:51 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:14:51 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:14:51 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:14:51 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:14:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/23 14:14:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/23 14:14:51 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:14:51 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=548677877
16/03/23 14:14:51 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.3 MB)
16/03/23 14:14:51 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=548677877
16/03/23 14:14:51 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.2 MB)
16/03/23 14:14:51 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:54626 (size: 4.1 KB, free: 523.3 MB)
16/03/23 14:14:51 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/23 14:14:51 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:14:51 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/23 14:14:51 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/23 14:14:51 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/23 14:14:51 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/23 14:14:51 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722691302
16/03/23 14:14:51 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/23 14:14:51 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-ae9f3d33-c66a-42e6-8116-371147e9daaa/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:14:51 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/23 14:14:51 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10732, maxMem=548677877
16/03/23 14:14:51 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 523.2 MB)
16/03/23 14:14:51 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:54626 (size: 177.0 B, free: 523.3 MB)
16/03/23 14:14:51 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/23 14:14:51 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10909, maxMem=548677877
16/03/23 14:14:51 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 523.2 MB)
16/03/23 14:14:51 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:54626 (size: 187.0 B, free: 523.3 MB)
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: area
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: bend
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: giant
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: astatine
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: present
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: area
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  purpose  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/23 14:14:59 INFO PythonRunner: Times: total = 8054, boot = 452, init = 360, finish = 7242
16/03/23 14:14:59 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/23 14:14:59 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8130 ms on localhost (1/2)
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  purpose  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: issue
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: planning
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: permission
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: economy
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: composition
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: agency
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/23 14:14:59 INFO PythonRunner: Times: total = 8371, boot = 459, init = 413, finish = 7499
16/03/23 14:14:59 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/23 14:14:59 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 8.462 s
16/03/23 14:14:59 INFO DAGScheduler: looking for newly runnable stages
16/03/23 14:14:59 INFO DAGScheduler: running: Set()
16/03/23 14:14:59 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/23 14:14:59 INFO DAGScheduler: failed: Set()
16/03/23 14:14:59 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/23 14:14:59 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/23 14:14:59 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=548677877
16/03/23 14:14:59 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.2 MB)
16/03/23 14:14:59 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=548677877
16/03/23 14:14:59 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.2 MB)
16/03/23 14:14:59 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8450 ms on localhost (2/2)
16/03/23 14:14:59 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/23 14:14:59 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:54626 (size: 3.0 KB, free: 523.3 MB)
16/03/23 14:14:59 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/23 14:14:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:14:59 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/23 14:14:59 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:14:59 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:14:59 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/23 14:14:59 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/23 14:14:59 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:14:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/23 14:14:59 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:14:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
reduceFunction_Parents(): returns= ['None', u'area', u'area']
16/03/23 14:14:59 INFO PythonRunner: Times: total = 39, boot = -122, init = 160, finish = 1
16/03/23 14:14:59 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/23 14:15:00 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 120 ms on localhost (1/2)
16/03/23 14:15:00 INFO PythonRunner: Times: total = 271, boot = 270, init = 1, finish = 0
16/03/23 14:15:00 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/23 14:15:00 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.288 s
16/03/23 14:15:00 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 8.766919 s
16/03/23 14:15:00 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 288 ms on localhost (2/2)
16/03/23 14:15:00 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/23 14:15:00 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:15:00 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:15:00 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:00 INFO DAGScheduler: Parents of final stage: List()
16/03/23 14:15:00 INFO DAGScheduler: Missing parents: List()
16/03/23 14:15:00 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:15:00 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=548677877
16/03/23 14:15:00 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.2 MB)
16/03/23 14:15:00 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24952, maxMem=548677877
16/03/23 14:15:00 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.2 MB)
16/03/23 14:15:00 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:54626 (size: 3.3 KB, free: 523.2 MB)
16/03/23 14:15:00 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/23 14:15:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:00 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/23 14:15:00 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/23 14:15:00 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/23 14:15:00 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/23 14:15:00 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/23 14:15:00 INFO PythonRunner: Times: total = 69, boot = -72, init = 141, finish = 0
16/03/23 14:15:00 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/23 14:15:00 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 76 ms on localhost (1/2)
16/03/23 14:15:00 INFO PythonRunner: Times: total = 224, boot = 224, init = 0, finish = 0
16/03/23 14:15:00 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/03/23 14:15:00 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 234 ms on localhost (2/2)
16/03/23 14:15:00 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/23 14:15:00 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.226 s
16/03/23 14:15:00 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.246036 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/23 14:15:00 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/23 14:15:00 INFO DAGScheduler: Stopping DAGScheduler
16/03/23 14:15:00 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/23 14:15:00 INFO MemoryStore: MemoryStore cleared
16/03/23 14:15:00 INFO BlockManager: BlockManager stopped
16/03/23 14:15:00 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/23 14:15:00 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/23 14:15:00 INFO SparkContext: Successfully stopped SparkContext
16/03/23 14:15:00 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/23 14:15:00 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/23 14:15:00 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'area', u'area']
16/03/23 14:15:01 INFO SparkContext: Running Spark version 1.5.2
16/03/23 14:15:01 INFO SecurityManager: Changing view acls to: root
16/03/23 14:15:01 INFO SecurityManager: Changing modify acls to: root
16/03/23 14:15:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/23 14:15:01 INFO Slf4jLogger: Slf4jLogger started
16/03/23 14:15:01 INFO Remoting: Starting remoting
16/03/23 14:15:01 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:60444]
16/03/23 14:15:01 INFO Utils: Successfully started service 'sparkDriver' on port 60444.
16/03/23 14:15:01 INFO SparkEnv: Registering MapOutputTracker
16/03/23 14:15:01 INFO SparkEnv: Registering BlockManagerMaster
16/03/23 14:15:01 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-4c05d54b-4c98-4491-b81b-594e6ef4e2ad
16/03/23 14:15:01 INFO MemoryStore: MemoryStore started with capacity 522.9 MB
16/03/23 14:15:01 INFO HttpFileServer: HTTP File server directory is /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/httpd-96436360-2149-4009-96ca-2503c8f7fffd
16/03/23 14:15:01 INFO HttpServer: Starting HTTP Server
16/03/23 14:15:01 INFO Utils: Successfully started service 'HTTP file server' on port 47400.
16/03/23 14:15:01 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/23 14:15:01 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/23 14:15:01 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/23 14:15:01 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-f4c08da5-9883-4182-b3fa-28aab11f05e0/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:15:01 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722701768
16/03/23 14:15:01 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/23 14:15:01 INFO Executor: Starting executor ID driver on host localhost
16/03/23 14:15:01 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45188.
16/03/23 14:15:01 INFO NettyBlockTransferService: Server created on 45188
16/03/23 14:15:01 INFO BlockManagerMaster: Trying to register BlockManager
16/03/23 14:15:01 INFO BlockManagerMasterEndpoint: Registering block manager localhost:45188 with 522.9 MB RAM, BlockManagerId(driver, localhost, 45188)
16/03/23 14:15:01 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): segment
16/03/23 14:15:01 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:15:01 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:01 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:15:01 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/23 14:15:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/23 14:15:01 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:15:01 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=548253204
16/03/23 14:15:01 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 522.8 MB)
16/03/23 14:15:01 INFO MemoryStore: ensureFreeSpace(4155) called with curMem=6576, maxMem=548253204
16/03/23 14:15:01 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 522.8 MB)
16/03/23 14:15:01 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:45188 (size: 4.1 KB, free: 522.9 MB)
16/03/23 14:15:01 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/23 14:15:01 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:01 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/23 14:15:01 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/23 14:15:01 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/23 14:15:01 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/23 14:15:01 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722701768
16/03/23 14:15:01 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/23 14:15:01 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-f4c08da5-9883-4182-b3fa-28aab11f05e0/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:15:01 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/23 14:15:01 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10731, maxMem=548253204
16/03/23 14:15:01 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 522.8 MB)
16/03/23 14:15:01 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:45188 (size: 187.0 B, free: 522.9 MB)
16/03/23 14:15:02 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/23 14:15:02 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10918, maxMem=548253204
16/03/23 14:15:02 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 522.8 MB)
16/03/23 14:15:02 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:45188 (size: 177.0 B, free: 522.9 MB)
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: area
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: issue
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: bend
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): adding to parents: syn =  Synset('bend.n.01') ; keyword:  segment  in syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= [u'bend']
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: giant
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: planning
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: astatine
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: present
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: permission
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: economy
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: composition
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: area
mapFunction_Parents(): keyword= mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: kilometer
segment ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each'mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
, u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: agency
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= [16/03/23 14:15:10 INFO PythonRunner: Times: total = 8200, boot = 492, init = 365, finish = 7343
16/03/23 14:15:10 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/23 14:15:10 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8280 ms on localhost (1/2)
]
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/23 14:15:10 INFO PythonRunner: Times: total = 8272, boot = 486, init = 412, finish = 7374
16/03/23 14:15:10 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/23 14:15:10 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8346 ms on localhost (2/2)
16/03/23 14:15:10 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 8.349 s
16/03/23 14:15:10 INFO DAGScheduler: looking for newly runnable stages
16/03/23 14:15:10 INFO DAGScheduler: running: Set()
16/03/23 14:15:10 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/23 14:15:10 INFO DAGScheduler: failed: Set()
16/03/23 14:15:10 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/23 14:15:10 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/23 14:15:10 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11095, maxMem=548253204
16/03/23 14:15:10 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 522.8 MB)
16/03/23 14:15:10 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16079, maxMem=548253204
16/03/23 14:15:10 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 522.8 MB)
16/03/23 14:15:10 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/23 14:15:10 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:45188 (size: 3.0 KB, free: 522.8 MB)
16/03/23 14:15:10 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/23 14:15:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:10 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/23 14:15:10 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:15:10 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:15:10 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/23 14:15:10 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/23 14:15:10 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:15:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/23 14:15:10 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:15:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/23 14:15:10 INFO PythonRunner: Times: total = 156, boot = 155, init = 0, finish = 1
16/03/23 14:15:10 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/23 14:15:10 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 172 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'bend', 'None']
16/03/23 14:15:10 INFO PythonRunner: Times: total = 232, boot = 231, init = 0, finish = 1
16/03/23 14:15:10 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1272 bytes result sent to driver
16/03/23 14:15:10 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 248 ms on localhost (2/2)
16/03/23 14:15:10 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/23 14:15:10 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.248 s
16/03/23 14:15:10 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 8.622063 s
16/03/23 14:15:10 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:15:10 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:15:10 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:10 INFO DAGScheduler: Parents of final stage: List()
16/03/23 14:15:10 INFO DAGScheduler: Missing parents: List()
16/03/23 14:15:10 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:15:10 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19135, maxMem=548253204
16/03/23 14:15:10 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 522.8 MB)
16/03/23 14:15:10 INFO MemoryStore: ensureFreeSpace(3377) called with curMem=24951, maxMem=548253204
16/03/23 14:15:10 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 522.8 MB)
16/03/23 14:15:10 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:45188 (size: 3.3 KB, free: 522.8 MB)
16/03/23 14:15:10 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/23 14:15:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:10 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/23 14:15:10 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/23 14:15:10 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2353 bytes)
16/03/23 14:15:10 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/23 14:15:10 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/23 14:15:10 INFO PythonRunner: Times: total = 113, boot = 113, init = 0, finish = 0
16/03/23 14:15:10 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1337 bytes result sent to driver
16/03/23 14:15:10 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 120 ms on localhost (1/2)
16/03/23 14:15:10 INFO PythonRunner: Times: total = 236, boot = 235, init = 0, finish = 1
16/03/23 14:15:10 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/23 14:15:10 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 242 ms on localhost (2/2)
16/03/23 14:15:10 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/23 14:15:10 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.240 s
16/03/23 14:15:10 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.266984 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/23 14:15:11 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/23 14:15:11 INFO DAGScheduler: Stopping DAGScheduler
16/03/23 14:15:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/23 14:15:11 INFO MemoryStore: MemoryStore cleared
16/03/23 14:15:11 INFO BlockManager: BlockManager stopped
16/03/23 14:15:11 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/23 14:15:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/23 14:15:11 INFO SparkContext: Successfully stopped SparkContext
16/03/23 14:15:11 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/23 14:15:11 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/23 14:15:11 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'bend', u'None']
16/03/23 14:15:11 INFO SparkContext: Running Spark version 1.5.2
16/03/23 14:15:11 INFO SecurityManager: Changing view acls to: root
16/03/23 14:15:11 INFO SecurityManager: Changing modify acls to: root
16/03/23 14:15:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/23 14:15:12 INFO Slf4jLogger: Slf4jLogger started
16/03/23 14:15:12 INFO Remoting: Starting remoting
16/03/23 14:15:12 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:48266]
16/03/23 14:15:12 INFO Utils: Successfully started service 'sparkDriver' on port 48266.
16/03/23 14:15:12 INFO SparkEnv: Registering MapOutputTracker
16/03/23 14:15:12 INFO SparkEnv: Registering BlockManagerMaster
16/03/23 14:15:12 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9f1703ef-a4ac-469e-a956-8de450ebd20e
16/03/23 14:15:12 INFO MemoryStore: MemoryStore started with capacity 522.9 MB
16/03/23 14:15:12 INFO HttpFileServer: HTTP File server directory is /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/httpd-dc752207-e3e6-44d2-b2be-a6cead0cf756
16/03/23 14:15:12 INFO HttpServer: Starting HTTP Server
16/03/23 14:15:12 INFO Utils: Successfully started service 'HTTP file server' on port 49284.
16/03/23 14:15:12 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/23 14:15:12 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/23 14:15:12 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/23 14:15:12 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-4adc478d-4911-4486-a91b-ea96999c4a32/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:15:12 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722712232
16/03/23 14:15:12 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/23 14:15:12 INFO Executor: Starting executor ID driver on host localhost
16/03/23 14:15:12 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45426.
16/03/23 14:15:12 INFO NettyBlockTransferService: Server created on 45426
16/03/23 14:15:12 INFO BlockManagerMaster: Trying to register BlockManager
16/03/23 14:15:12 INFO BlockManagerMasterEndpoint: Registering block manager localhost:45426 with 522.9 MB RAM, BlockManagerId(driver, localhost, 45426)
16/03/23 14:15:12 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): radioactive
16/03/23 14:15:12 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:15:12 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:12 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:15:12 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/23 14:15:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/23 14:15:12 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:15:12 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=548253204
16/03/23 14:15:12 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 522.8 MB)
16/03/23 14:15:12 INFO MemoryStore: ensureFreeSpace(4153) called with curMem=6576, maxMem=548253204
16/03/23 14:15:12 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 522.8 MB)
16/03/23 14:15:12 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:45426 (size: 4.1 KB, free: 522.9 MB)
16/03/23 14:15:12 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/23 14:15:12 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:12 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/23 14:15:12 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/23 14:15:12 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/23 14:15:12 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/23 14:15:12 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722712232
16/03/23 14:15:12 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/23 14:15:12 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-4adc478d-4911-4486-a91b-ea96999c4a32/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:15:12 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/23 14:15:12 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10729, maxMem=548253204
16/03/23 14:15:12 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 522.8 MB)
16/03/23 14:15:12 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:45426 (size: 177.0 B, free: 522.9 MB)
16/03/23 14:15:12 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/23 14:15:12 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10906, maxMem=548253204
16/03/23 14:15:12 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 522.8 MB)
16/03/23 14:15:12 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:45426 (size: 187.0 B, free: 522.9 MB)
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: area
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: issue
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: planning
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: permission
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: economy
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: composition
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: agency
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/23 14:15:20 INFO PythonRunner: Times: total = 7949, boot = 451, init = 376, finish = 7122
16/03/23 14:15:20 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/23 14:15:20 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8040 ms on localhost (1/2)
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: bend
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: giant
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: astatine
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  radioactive  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: present
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: area
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/23 14:15:20 INFO PythonRunner: Times: total = 8226, boot = 461, init = 379, finish = 7386
16/03/23 14:15:20 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/23 14:15:20 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8294 ms on localhost (2/2)
16/03/23 14:15:20 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/23 14:15:20 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 8.295 s
16/03/23 14:15:20 INFO DAGScheduler: looking for newly runnable stages
16/03/23 14:15:20 INFO DAGScheduler: running: Set()
16/03/23 14:15:20 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/23 14:15:20 INFO DAGScheduler: failed: Set()
16/03/23 14:15:20 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/23 14:15:20 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/23 14:15:20 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11093, maxMem=548253204
16/03/23 14:15:20 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 522.8 MB)
16/03/23 14:15:20 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16077, maxMem=548253204
16/03/23 14:15:20 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 522.8 MB)
16/03/23 14:15:20 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:45426 (size: 3.0 KB, free: 522.8 MB)
16/03/23 14:15:20 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/23 14:15:20 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:20 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/23 14:15:20 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:15:20 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:15:20 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/23 14:15:20 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:15:20 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/23 14:15:20 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:15:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/03/23 14:15:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
reduceFunction_Parents(): returns= ['None', u'astatine', 'None']
16/03/23 14:15:20 INFO PythonRunner: Times: total = 26, boot = -101, init = 127, finish = 0
16/03/23 14:15:20 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/03/23 14:15:21 INFO PythonRunner: Times: total = 388, boot = 387, init = 1, finish = 0
16/03/23 14:15:21 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/23 14:15:21 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:45426 in memory (size: 4.1 KB, free: 522.9 MB)
16/03/23 14:15:21 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 405 ms on localhost (1/2)
16/03/23 14:15:21 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 424 ms on localhost (2/2)
16/03/23 14:15:21 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/23 14:15:21 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.406 s
16/03/23 14:15:21 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 8.743088 s
16/03/23 14:15:21 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:15:21 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:15:21 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:21 INFO DAGScheduler: Parents of final stage: List()
16/03/23 14:15:21 INFO DAGScheduler: Missing parents: List()
16/03/23 14:15:21 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:15:21 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=8403, maxMem=548253204
16/03/23 14:15:21 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 522.8 MB)
16/03/23 14:15:21 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=14219, maxMem=548253204
16/03/23 14:15:21 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 522.8 MB)
16/03/23 14:15:21 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:45426 (size: 3.3 KB, free: 522.8 MB)
16/03/23 14:15:21 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/23 14:15:21 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:21 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/23 14:15:21 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/23 14:15:21 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/03/23 14:15:21 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/23 14:15:21 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/23 14:15:21 INFO PythonRunner: Times: total = 46, boot = -225, init = 271, finish = 0
16/03/23 14:15:21 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/03/23 14:15:21 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 55 ms on localhost (1/2)
16/03/23 14:15:21 INFO PythonRunner: Times: total = 56, boot = 37, init = 19, finish = 0
16/03/23 14:15:21 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/23 14:15:21 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 63 ms on localhost (2/2)
16/03/23 14:15:21 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/23 14:15:21 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.051 s
16/03/23 14:15:21 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.086757 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/23 14:15:21 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/23 14:15:21 INFO DAGScheduler: Stopping DAGScheduler
16/03/23 14:15:21 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/23 14:15:21 INFO MemoryStore: MemoryStore cleared
16/03/23 14:15:21 INFO BlockManager: BlockManager stopped
16/03/23 14:15:21 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/23 14:15:21 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/23 14:15:21 INFO SparkContext: Successfully stopped SparkContext
16/03/23 14:15:21 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/23 14:15:21 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/23 14:15:21 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'astatine', u'None']
16/03/23 14:15:22 INFO SparkContext: Running Spark version 1.5.2
16/03/23 14:15:22 INFO SecurityManager: Changing view acls to: root
16/03/23 14:15:22 INFO SecurityManager: Changing modify acls to: root
16/03/23 14:15:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/23 14:15:22 INFO Slf4jLogger: Slf4jLogger started
16/03/23 14:15:22 INFO Remoting: Starting remoting
16/03/23 14:15:22 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:56522]
16/03/23 14:15:22 INFO Utils: Successfully started service 'sparkDriver' on port 56522.
16/03/23 14:15:22 INFO SparkEnv: Registering MapOutputTracker
16/03/23 14:15:22 INFO SparkEnv: Registering BlockManagerMaster
16/03/23 14:15:22 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-6c708627-b16e-4688-9876-3a21afa7d71b
16/03/23 14:15:22 INFO MemoryStore: MemoryStore started with capacity 524.9 MB
16/03/23 14:15:22 INFO HttpFileServer: HTTP File server directory is /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/httpd-bdf8d495-8592-4380-813a-a987006237ed
16/03/23 14:15:22 INFO HttpServer: Starting HTTP Server
16/03/23 14:15:22 INFO Utils: Successfully started service 'HTTP file server' on port 58311.
16/03/23 14:15:22 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/23 14:15:22 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/23 14:15:22 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/23 14:15:22 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-2e1865a1-c561-4457-af28-75075f16bc1a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:15:22 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722722595
16/03/23 14:15:22 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/23 14:15:22 INFO Executor: Starting executor ID driver on host localhost
16/03/23 14:15:22 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34620.
16/03/23 14:15:22 INFO NettyBlockTransferService: Server created on 34620
16/03/23 14:15:22 INFO BlockManagerMaster: Trying to register BlockManager
16/03/23 14:15:22 INFO BlockManagerMasterEndpoint: Registering block manager localhost:34620 with 524.9 MB RAM, BlockManagerId(driver, localhost, 34620)
16/03/23 14:15:22 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): happening
16/03/23 14:15:22 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:15:22 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:22 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:15:22 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/23 14:15:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/23 14:15:22 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:15:22 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=550376570
16/03/23 14:15:22 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 524.9 MB)
16/03/23 14:15:22 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=550376570
16/03/23 14:15:22 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 524.9 MB)
16/03/23 14:15:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:34620 (size: 4.1 KB, free: 524.9 MB)
16/03/23 14:15:22 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/23 14:15:22 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:22 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/23 14:15:22 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/23 14:15:22 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/23 14:15:22 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/23 14:15:22 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722722595
16/03/23 14:15:22 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-2e1865a1-c561-4457-af28-75075f16bc1a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:15:22 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/23 14:15:22 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/23 14:15:22 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10732, maxMem=550376570
16/03/23 14:15:22 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 524.9 MB)
16/03/23 14:15:22 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/23 14:15:22 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:34620 (size: 177.0 B, free: 524.9 MB)
16/03/23 14:15:22 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10909, maxMem=550376570
16/03/23 14:15:22 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 524.9 MB)
16/03/23 14:15:22 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:34620 (size: 187.0 B, free: 524.9 MB)
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: area
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: bend
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: giant
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: astatine
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: present
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  happening  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: area
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/23 14:15:30 INFO PythonRunner: Times: total = 8020, boot = 452, init = 370, finish = 7198
16/03/23 14:15:30 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/23 14:15:30 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8092 ms on localhost (1/2)
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: issue
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: planning
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: permission
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: economy
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: composition
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: agency
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/23 14:15:31 INFO PythonRunner: Times: total = 8484, boot = 460, init = 460, finish = 7564
16/03/23 14:15:31 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/23 14:15:31 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8550 ms on localhost (2/2)
16/03/23 14:15:31 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 8.556 s
16/03/23 14:15:31 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/23 14:15:31 INFO DAGScheduler: looking for newly runnable stages
16/03/23 14:15:31 INFO DAGScheduler: running: Set()
16/03/23 14:15:31 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/23 14:15:31 INFO DAGScheduler: failed: Set()
16/03/23 14:15:31 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/23 14:15:31 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/23 14:15:31 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=550376570
16/03/23 14:15:31 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 524.9 MB)
16/03/23 14:15:31 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=550376570
16/03/23 14:15:31 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 524.9 MB)
16/03/23 14:15:31 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:34620 (size: 3.0 KB, free: 524.9 MB)
16/03/23 14:15:31 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/23 14:15:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:31 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/23 14:15:31 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:15:31 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:15:31 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/23 14:15:31 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:15:31 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/23 14:15:31 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:15:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/23 14:15:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
reduceFunction_Parents(): returns= ['None', u'present', 'None']
16/03/23 14:15:31 INFO PythonRunner: Times: total = 24, boot = -317, init = 341, finish = 0
16/03/23 14:15:31 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/23 14:15:31 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 110 ms on localhost (1/2)
16/03/23 14:15:31 INFO PythonRunner: Times: total = 192, boot = 191, init = 1, finish = 0
16/03/23 14:15:31 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/23 14:15:31 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.214 s
16/03/23 14:15:31 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 8.807259 s
16/03/23 14:15:31 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 213 ms on localhost (2/2)
16/03/23 14:15:31 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/23 14:15:31 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:15:31 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:15:31 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:31 INFO DAGScheduler: Parents of final stage: List()
16/03/23 14:15:31 INFO DAGScheduler: Missing parents: List()
16/03/23 14:15:31 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:15:31 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=550376570
16/03/23 14:15:31 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 524.9 MB)
16/03/23 14:15:31 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24952, maxMem=550376570
16/03/23 14:15:31 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 524.9 MB)
16/03/23 14:15:31 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:34620 (size: 3.3 KB, free: 524.9 MB)
16/03/23 14:15:31 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/23 14:15:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:31 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/23 14:15:31 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/23 14:15:31 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/23 14:15:31 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/23 14:15:31 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/23 14:15:31 INFO PythonRunner: Times: total = 58, boot = 58, init = 0, finish = 0
16/03/23 14:15:31 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1351 bytes result sent to driver
16/03/23 14:15:31 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 86 ms on localhost (1/2)
16/03/23 14:15:31 INFO PythonRunner: Times: total = 216, boot = 216, init = 0, finish = 0
16/03/23 14:15:31 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/23 14:15:31 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 224 ms on localhost (2/2)
16/03/23 14:15:31 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/23 14:15:31 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.208 s
16/03/23 14:15:31 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.242982 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/23 14:15:32 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/23 14:15:32 INFO DAGScheduler: Stopping DAGScheduler
16/03/23 14:15:32 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/23 14:15:32 INFO MemoryStore: MemoryStore cleared
16/03/23 14:15:32 INFO BlockManager: BlockManager stopped
16/03/23 14:15:32 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/23 14:15:32 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/23 14:15:32 INFO SparkContext: Successfully stopped SparkContext
16/03/23 14:15:32 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/23 14:15:32 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/23 14:15:32 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'present', u'None']
16/03/23 14:15:32 INFO SparkContext: Running Spark version 1.5.2
16/03/23 14:15:32 INFO SecurityManager: Changing view acls to: root
16/03/23 14:15:32 INFO SecurityManager: Changing modify acls to: root
16/03/23 14:15:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/23 14:15:32 INFO Slf4jLogger: Slf4jLogger started
16/03/23 14:15:32 INFO Remoting: Starting remoting
16/03/23 14:15:33 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:53502]
16/03/23 14:15:33 INFO Utils: Successfully started service 'sparkDriver' on port 53502.
16/03/23 14:15:33 INFO SparkEnv: Registering MapOutputTracker
16/03/23 14:15:33 INFO SparkEnv: Registering BlockManagerMaster
16/03/23 14:15:33 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-4eb83611-fd82-40ce-8e36-8d2ececa8bee
16/03/23 14:15:33 INFO MemoryStore: MemoryStore started with capacity 524.9 MB
16/03/23 14:15:33 INFO HttpFileServer: HTTP File server directory is /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/httpd-07882567-a3e9-4059-8f62-f0bf77b67556
16/03/23 14:15:33 INFO HttpServer: Starting HTTP Server
16/03/23 14:15:33 INFO Utils: Successfully started service 'HTTP file server' on port 56175.
16/03/23 14:15:33 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/23 14:15:33 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/23 14:15:33 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/23 14:15:33 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-6e978024-f164-43aa-9384-fa55b9a8cf27/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:15:33 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722733207
16/03/23 14:15:33 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/23 14:15:33 INFO Executor: Starting executor ID driver on host localhost
16/03/23 14:15:33 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51046.
16/03/23 14:15:33 INFO NettyBlockTransferService: Server created on 51046
16/03/23 14:15:33 INFO BlockManagerMaster: Trying to register BlockManager
16/03/23 14:15:33 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51046 with 524.9 MB RAM, BlockManagerId(driver, localhost, 51046)
16/03/23 14:15:33 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): curve
16/03/23 14:15:33 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:15:33 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:33 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:15:33 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/23 14:15:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/23 14:15:33 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:15:33 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=550376570
16/03/23 14:15:33 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 524.9 MB)
16/03/23 14:15:33 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=550376570
16/03/23 14:15:33 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 524.9 MB)
16/03/23 14:15:33 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51046 (size: 4.1 KB, free: 524.9 MB)
16/03/23 14:15:33 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/23 14:15:33 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:33 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/23 14:15:33 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/23 14:15:33 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/23 14:15:33 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/23 14:15:33 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722733207
16/03/23 14:15:33 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/23 14:15:33 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-6e978024-f164-43aa-9384-fa55b9a8cf27/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:15:33 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/23 14:15:33 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10732, maxMem=550376570
16/03/23 14:15:33 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 524.9 MB)
16/03/23 14:15:33 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:51046 (size: 187.0 B, free: 524.9 MB)
16/03/23 14:15:33 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/23 14:15:33 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10919, maxMem=550376570
16/03/23 14:15:33 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 524.9 MB)
16/03/23 14:15:33 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:51046 (size: 177.0 B, free: 524.9 MB)
asfer_pickle_string_load(): picklef.readlines():asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: area
 curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: set
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: bend
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): adding to parents: syn =  Synset('bend.n.01') ; keyword:  curve  in syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= [u'bend']
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: giant
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: astatine
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: present
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: issue
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: planning
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: area
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= curve mapFunction_Parents(): keyword= curve; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or' ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
, u'unit'asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword:,  curve ; prevleveltokens: permission
u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: economy
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: composition
16/03/23 14:15:41 INFO PythonRunner: Times: total = 8172, boot = 463, init = 359, finish = 7350
16/03/23 14:15:41 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: agency
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/23 14:15:41 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8241 ms on localhost (1/2)
16/03/23 14:15:41 INFO PythonRunner: Times: total = 8216, boot = 451, init = 372, finish = 7393
16/03/23 14:15:41 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/23 14:15:41 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 8.296 s
16/03/23 14:15:41 INFO DAGScheduler: looking for newly runnable stages
16/03/23 14:15:41 INFO DAGScheduler: running: Set()
16/03/23 14:15:41 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/23 14:15:41 INFO DAGScheduler: failed: Set()
16/03/23 14:15:41 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/23 14:15:41 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/23 14:15:41 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=550376570
16/03/23 14:15:41 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 524.9 MB)
16/03/23 14:15:41 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=550376570
16/03/23 14:15:41 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 524.9 MB)
16/03/23 14:15:41 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8299 ms on localhost (2/2)
16/03/23 14:15:41 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/23 14:15:41 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51046 (size: 3.0 KB, free: 524.9 MB)
16/03/23 14:15:41 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/23 14:15:41 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:41 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/23 14:15:41 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:15:41 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:15:41 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/23 14:15:41 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:15:41 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/23 14:15:41 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:15:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/23 14:15:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
reduceFunction_Parents(): returns= [u'bend', 'None']
16/03/23 14:15:41 INFO PythonRunner: Times: total = 136, boot = 134, init = 0, finish = 2
16/03/23 14:15:41 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1272 bytes result sent to driver
16/03/23 14:15:41 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 157 ms on localhost (1/2)
16/03/23 14:15:41 INFO PythonRunner: Times: total = 282, boot = 281, init = 1, finish = 0
16/03/23 14:15:41 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/23 14:15:41 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.309 s
16/03/23 14:15:41 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 8.641424 s
16/03/23 14:15:41 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 309 ms on localhost (2/2)
16/03/23 14:15:41 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/23 14:15:42 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:15:42 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:15:42 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:42 INFO DAGScheduler: Parents of final stage: List()
16/03/23 14:15:42 INFO DAGScheduler: Missing parents: List()
16/03/23 14:15:42 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:15:42 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=550376570
16/03/23 14:15:42 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 524.9 MB)
16/03/23 14:15:42 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24952, maxMem=550376570
16/03/23 14:15:42 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 524.9 MB)
16/03/23 14:15:42 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:51046 (size: 3.3 KB, free: 524.9 MB)
16/03/23 14:15:42 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/23 14:15:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:42 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/23 14:15:42 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/23 14:15:42 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2353 bytes)
16/03/23 14:15:42 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/23 14:15:42 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/23 14:15:42 INFO PythonRunner: Times: total = 51, boot = -5, init = 56, finish = 0
16/03/23 14:15:42 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/23 14:15:42 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 62 ms on localhost (1/2)
16/03/23 14:15:42 INFO PythonRunner: Times: total = 54, boot = 54, init = 0, finish = 0
16/03/23 14:15:42 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1337 bytes result sent to driver
16/03/23 14:15:42 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 66 ms on localhost (2/2)
16/03/23 14:15:42 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/23 14:15:42 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.053 s
16/03/23 14:15:42 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.077882 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/23 14:15:42 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/23 14:15:42 INFO DAGScheduler: Stopping DAGScheduler
16/03/23 14:15:42 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/23 14:15:42 INFO MemoryStore: MemoryStore cleared
16/03/23 14:15:42 INFO BlockManager: BlockManager stopped
16/03/23 14:15:42 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/23 14:15:42 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/23 14:15:42 INFO SparkContext: Successfully stopped SparkContext
16/03/23 14:15:42 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/23 14:15:42 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/23 14:15:42 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'bend', u'None']
16/03/23 14:15:43 INFO SparkContext: Running Spark version 1.5.2
16/03/23 14:15:43 INFO SecurityManager: Changing view acls to: root
16/03/23 14:15:43 INFO SecurityManager: Changing modify acls to: root
16/03/23 14:15:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/23 14:15:43 INFO Slf4jLogger: Slf4jLogger started
16/03/23 14:15:43 INFO Remoting: Starting remoting
16/03/23 14:15:43 INFO Utils: Successfully started service 'sparkDriver' on port 39020.
16/03/23 14:15:43 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:39020]
16/03/23 14:15:43 INFO SparkEnv: Registering MapOutputTracker
16/03/23 14:15:43 INFO SparkEnv: Registering BlockManagerMaster
16/03/23 14:15:43 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8d1f3a07-57ab-4bb2-a121-50a317a0d90c
16/03/23 14:15:43 INFO MemoryStore: MemoryStore started with capacity 524.9 MB
16/03/23 14:15:43 INFO HttpFileServer: HTTP File server directory is /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/httpd-b23c72dc-b410-486e-ae36-92ad90615dea
16/03/23 14:15:43 INFO HttpServer: Starting HTTP Server
16/03/23 14:15:43 INFO Utils: Successfully started service 'HTTP file server' on port 34025.
16/03/23 14:15:43 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/23 14:15:43 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/23 14:15:43 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/23 14:15:43 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-1546038a-ee5f-4ed9-b913-3264b3f1972d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:15:43 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722743657
16/03/23 14:15:43 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/23 14:15:43 INFO Executor: Starting executor ID driver on host localhost
16/03/23 14:15:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34386.
16/03/23 14:15:43 INFO NettyBlockTransferService: Server created on 34386
16/03/23 14:15:43 INFO BlockManagerMaster: Trying to register BlockManager
16/03/23 14:15:43 INFO BlockManagerMasterEndpoint: Registering block manager localhost:34386 with 524.9 MB RAM, BlockManagerId(driver, localhost, 34386)
16/03/23 14:15:43 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): together
16/03/23 14:15:43 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:15:43 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:43 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:15:43 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/23 14:15:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/23 14:15:43 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:15:43 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=550376570
16/03/23 14:15:43 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 524.9 MB)
16/03/23 14:15:43 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=550376570
16/03/23 14:15:43 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 524.9 MB)
16/03/23 14:15:43 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:34386 (size: 4.1 KB, free: 524.9 MB)
16/03/23 14:15:43 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/23 14:15:43 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:43 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/23 14:15:43 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/23 14:15:43 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/23 14:15:43 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/23 14:15:43 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722743657
16/03/23 14:15:43 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/23 14:15:43 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-1546038a-ee5f-4ed9-b913-3264b3f1972d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:15:43 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/23 14:15:43 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10732, maxMem=550376570
16/03/23 14:15:43 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 524.9 MB)
16/03/23 14:15:43 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:34386 (size: 187.0 B, free: 524.9 MB)
16/03/23 14:15:43 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/23 14:15:43 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10919, maxMem=550376570
16/03/23 14:15:43 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 524.9 MB)
16/03/23 14:15:43 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:34386 (size: 177.0 B, free: 524.9 MB)
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: set
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: issue
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: planning
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: permission
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: economy
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: composition
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: agency
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/23 14:15:52 INFO PythonRunner: Times: total = 8150, boot = 506, init = 371, finish = 7273
16/03/23 14:15:52 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/23 14:15:52 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8223 ms on localhost (1/2)
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  Synset('set.n.01') ; keyword:  together  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: bend
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: giant
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: astatine
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: present
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: area
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
16/03/23 14:15:52 INFO PythonRunner: Times: total = 8515, boot = 509, init = 386, finish = 7620
16/03/23 14:15:52 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/23 14:15:52 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 8.614 s
16/03/23 14:15:52 INFO DAGScheduler: looking for newly runnable stages
16/03/23 14:15:52 INFO DAGScheduler: running: Set()
16/03/23 14:15:52 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/23 14:15:52 INFO DAGScheduler: failed: Set()
16/03/23 14:15:52 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/23 14:15:52 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/23 14:15:52 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8622 ms on localhost (2/2)
16/03/23 14:15:52 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/23 14:15:52 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=550376570
16/03/23 14:15:52 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 524.9 MB)
16/03/23 14:15:52 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=550376570
16/03/23 14:15:52 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 524.9 MB)
16/03/23 14:15:52 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:34386 (size: 3.0 KB, free: 524.9 MB)
16/03/23 14:15:52 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/23 14:15:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:52 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/23 14:15:52 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:15:52 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:15:52 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/23 14:15:52 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:15:52 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/23 14:15:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
16/03/23 14:15:52 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:15:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
16/03/23 14:15:52 INFO PythonRunner: Times: total = 51, boot = -246, init = 297, finish = 0
16/03/23 14:15:52 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/23 14:15:52 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 102 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'set', 'None']
16/03/23 14:15:52 INFO PythonRunner: Times: total = 186, boot = 185, init = 0, finish = 1
16/03/23 14:15:52 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1271 bytes result sent to driver
16/03/23 14:15:52 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.211 s
16/03/23 14:15:52 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 8.857583 s
16/03/23 14:15:52 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 208 ms on localhost (2/2)
16/03/23 14:15:52 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/23 14:15:52 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:15:52 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:15:52 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:52 INFO DAGScheduler: Parents of final stage: List()
16/03/23 14:15:52 INFO DAGScheduler: Missing parents: List()
16/03/23 14:15:52 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:15:52 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=550376570
16/03/23 14:15:52 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 524.9 MB)
16/03/23 14:15:52 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24952, maxMem=550376570
16/03/23 14:15:52 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 524.9 MB)
16/03/23 14:15:52 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:34386 (size: 3.3 KB, free: 524.9 MB)
16/03/23 14:15:52 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/23 14:15:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:52 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/23 14:15:52 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/23 14:15:52 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/23 14:15:52 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/23 14:15:52 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/23 14:15:52 INFO PythonRunner: Times: total = 80, boot = 69, init = 11, finish = 0
16/03/23 14:15:52 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/23 14:15:52 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 95 ms on localhost (1/2)
16/03/23 14:15:52 INFO PythonRunner: Times: total = 145, boot = 145, init = 0, finish = 0
16/03/23 14:15:52 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1336 bytes result sent to driver
16/03/23 14:15:52 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 165 ms on localhost (2/2)
16/03/23 14:15:52 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/23 14:15:52 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.144 s
16/03/23 14:15:52 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.182945 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/23 14:15:53 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/23 14:15:53 INFO DAGScheduler: Stopping DAGScheduler
16/03/23 14:15:53 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/23 14:15:53 INFO MemoryStore: MemoryStore cleared
16/03/23 14:15:53 INFO BlockManager: BlockManager stopped
16/03/23 14:15:53 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/23 14:15:53 INFO SparkContext: Successfully stopped SparkContext
16/03/23 14:15:53 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/23 14:15:53 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/23 14:15:53 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/23 14:15:53 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'set', u'None']
16/03/23 14:15:53 INFO SparkContext: Running Spark version 1.5.2
16/03/23 14:15:53 INFO SecurityManager: Changing view acls to: root
16/03/23 14:15:53 INFO SecurityManager: Changing modify acls to: root
16/03/23 14:15:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/23 14:15:54 INFO Slf4jLogger: Slf4jLogger started
16/03/23 14:15:54 INFO Remoting: Starting remoting
16/03/23 14:15:54 INFO Utils: Successfully started service 'sparkDriver' on port 40429.
16/03/23 14:15:54 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:40429]
16/03/23 14:15:54 INFO SparkEnv: Registering MapOutputTracker
16/03/23 14:15:54 INFO SparkEnv: Registering BlockManagerMaster
16/03/23 14:15:54 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-aa56bdd5-f4b2-4597-b36b-1c9c6185ad3e
16/03/23 14:15:54 INFO MemoryStore: MemoryStore started with capacity 524.1 MB
16/03/23 14:15:54 INFO HttpFileServer: HTTP File server directory is /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/httpd-519305ec-e8fb-44a6-9b7e-6999acfc7668
16/03/23 14:15:54 INFO HttpServer: Starting HTTP Server
16/03/23 14:15:54 INFO Utils: Successfully started service 'HTTP file server' on port 34178.
16/03/23 14:15:54 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/23 14:15:54 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/23 14:15:54 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/23 14:15:54 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-033f5355-e01c-4fab-8d49-afd607f0765a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:15:54 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722754246
16/03/23 14:15:54 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/23 14:15:54 INFO Executor: Starting executor ID driver on host localhost
16/03/23 14:15:54 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56016.
16/03/23 14:15:54 INFO NettyBlockTransferService: Server created on 56016
16/03/23 14:15:54 INFO BlockManagerMaster: Trying to register BlockManager
16/03/23 14:15:54 INFO BlockManagerMasterEndpoint: Registering block manager localhost:56016 with 524.1 MB RAM, BlockManagerId(driver, localhost, 56016)
16/03/23 14:15:54 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): element
16/03/23 14:15:54 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:15:54 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:54 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:15:54 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/23 14:15:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/23 14:15:54 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:15:54 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=549527224
16/03/23 14:15:54 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 524.1 MB)
16/03/23 14:15:54 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=549527224
16/03/23 14:15:54 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 524.1 MB)
16/03/23 14:15:54 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:56016 (size: 4.1 KB, free: 524.1 MB)
16/03/23 14:15:54 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/23 14:15:54 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:15:54 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/23 14:15:54 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/23 14:15:54 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/23 14:15:54 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/23 14:15:54 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722754246
16/03/23 14:15:54 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/23 14:15:54 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-033f5355-e01c-4fab-8d49-afd607f0765a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:15:54 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/23 14:15:54 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10732, maxMem=549527224
16/03/23 14:15:54 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 524.1 MB)
16/03/23 14:15:54 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:56016 (size: 187.0 B, free: 524.1 MB)
16/03/23 14:15:54 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/23 14:15:54 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10919, maxMem=549527224
16/03/23 14:15:54 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 524.1 MB)
16/03/23 14:15:54 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:56016 (size: 177.0 B, free: 524.1 MB)
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: set
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: issue
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: planning
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: permission
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: economy
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: composition
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: agency
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/23 14:16:02 INFO PythonRunner: Times: total = 7825, boot = 466, init = 358, finish = 7001
16/03/23 14:16:02 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/23 14:16:02 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 7904 ms on localhost (1/2)
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: bend
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: giant
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: astatine
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  element  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: present
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: area
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/23 14:16:02 INFO PythonRunner: Times: total = 8470, boot = 462, init = 411, finish = 7597
16/03/23 14:16:02 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/23 14:16:02 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8563 ms on localhost (2/2)
16/03/23 14:16:02 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 8.565 s
16/03/23 14:16:02 INFO DAGScheduler: looking for newly runnable stages
16/03/23 14:16:02 INFO DAGScheduler: running: Set()
16/03/23 14:16:02 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/23 14:16:02 INFO DAGScheduler: failed: Set()
16/03/23 14:16:02 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/23 14:16:02 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/23 14:16:02 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/23 14:16:02 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=549527224
16/03/23 14:16:02 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 524.1 MB)
16/03/23 14:16:02 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=549527224
16/03/23 14:16:02 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 524.1 MB)
16/03/23 14:16:02 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:56016 (size: 3.0 KB, free: 524.1 MB)
16/03/23 14:16:02 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/23 14:16:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:16:02 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/23 14:16:02 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:16:02 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:16:02 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/23 14:16:02 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:16:02 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/23 14:16:02 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:16:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/23 14:16:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
reduceFunction_Parents(): returns= ['None', u'astatine', 'None']
16/03/23 14:16:03 INFO PythonRunner: Times: total = 23, boot = -474, init = 496, finish = 1
16/03/23 14:16:03 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/03/23 14:16:03 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 80 ms on localhost (1/2)
16/03/23 14:16:03 INFO PythonRunner: Times: total = 265, boot = 264, init = 1, finish = 0
16/03/23 14:16:03 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/23 14:16:03 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.279 s
16/03/23 14:16:03 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 8.873685 s
16/03/23 14:16:03 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 289 ms on localhost (2/2)
16/03/23 14:16:03 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/23 14:16:03 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:16:03 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:16:03 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:16:03 INFO DAGScheduler: Parents of final stage: List()
16/03/23 14:16:03 INFO DAGScheduler: Missing parents: List()
16/03/23 14:16:03 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:16:03 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=549527224
16/03/23 14:16:03 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 524.0 MB)
16/03/23 14:16:03 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24952, maxMem=549527224
16/03/23 14:16:03 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 524.0 MB)
16/03/23 14:16:03 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:56016 (size: 3.3 KB, free: 524.1 MB)
16/03/23 14:16:03 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/23 14:16:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:16:03 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/23 14:16:03 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/23 14:16:03 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/03/23 14:16:03 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/23 14:16:03 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/23 14:16:03 INFO PythonRunner: Times: total = 63, boot = -144, init = 207, finish = 0
16/03/23 14:16:03 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/23 14:16:03 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 74 ms on localhost (1/2)
16/03/23 14:16:03 INFO PythonRunner: Times: total = 144, boot = 143, init = 1, finish = 0
16/03/23 14:16:03 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/03/23 14:16:03 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 156 ms on localhost (2/2)
16/03/23 14:16:03 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/23 14:16:03 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.139 s
16/03/23 14:16:03 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.166074 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/23 14:16:03 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/23 14:16:03 INFO DAGScheduler: Stopping DAGScheduler
16/03/23 14:16:03 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/23 14:16:03 INFO MemoryStore: MemoryStore cleared
16/03/23 14:16:03 INFO BlockManager: BlockManager stopped
16/03/23 14:16:03 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/23 14:16:03 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/23 14:16:03 INFO SparkContext: Successfully stopped SparkContext
16/03/23 14:16:03 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/23 14:16:03 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/23 14:16:03 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'astatine', u'None']
16/03/23 14:16:04 INFO SparkContext: Running Spark version 1.5.2
16/03/23 14:16:04 INFO SecurityManager: Changing view acls to: root
16/03/23 14:16:04 INFO SecurityManager: Changing modify acls to: root
16/03/23 14:16:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/23 14:16:04 INFO Slf4jLogger: Slf4jLogger started
16/03/23 14:16:04 INFO Remoting: Starting remoting
16/03/23 14:16:04 INFO Utils: Successfully started service 'sparkDriver' on port 37874.
16/03/23 14:16:04 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:37874]
16/03/23 14:16:04 INFO SparkEnv: Registering MapOutputTracker
16/03/23 14:16:04 INFO SparkEnv: Registering BlockManagerMaster
16/03/23 14:16:04 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e9638ddd-951c-426c-9848-63b3859a36ee
16/03/23 14:16:04 INFO MemoryStore: MemoryStore started with capacity 524.1 MB
16/03/23 14:16:04 INFO HttpFileServer: HTTP File server directory is /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/httpd-66194bfc-312a-4f39-a3c5-5b523c8c1622
16/03/23 14:16:04 INFO HttpServer: Starting HTTP Server
16/03/23 14:16:04 INFO Utils: Successfully started service 'HTTP file server' on port 41163.
16/03/23 14:16:04 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/23 14:16:04 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/23 14:16:04 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/23 14:16:04 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-95f5770b-cad5-4237-a33b-3e7260f2c22d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:16:04 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722764828
16/03/23 14:16:04 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/23 14:16:04 INFO Executor: Starting executor ID driver on host localhost
16/03/23 14:16:04 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46228.
16/03/23 14:16:04 INFO NettyBlockTransferService: Server created on 46228
16/03/23 14:16:04 INFO BlockManagerMaster: Trying to register BlockManager
16/03/23 14:16:04 INFO BlockManagerMasterEndpoint: Registering block manager localhost:46228 with 524.1 MB RAM, BlockManagerId(driver, localhost, 46228)
16/03/23 14:16:04 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): person
16/03/23 14:16:04 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:16:04 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:16:04 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:16:04 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:16:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/23 14:16:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/23 14:16:04 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:16:04 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=549527224
16/03/23 14:16:04 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 524.1 MB)
16/03/23 14:16:04 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=549527224
16/03/23 14:16:04 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 524.1 MB)
16/03/23 14:16:04 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:46228 (size: 4.1 KB, free: 524.1 MB)
16/03/23 14:16:04 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/23 14:16:04 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:16:04 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/23 14:16:04 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/23 14:16:04 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/23 14:16:04 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/23 14:16:04 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722764828
16/03/23 14:16:04 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/23 14:16:05 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-95f5770b-cad5-4237-a33b-3e7260f2c22d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:16:05 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/23 14:16:05 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10732, maxMem=549527224
16/03/23 14:16:05 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 524.1 MB)
16/03/23 14:16:05 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:46228 (size: 187.0 B, free: 524.1 MB)
16/03/23 14:16:05 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/23 14:16:05 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10919, maxMem=549527224
16/03/23 14:16:05 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 524.1 MB)
16/03/23 14:16:05 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:46228 (size: 177.0 B, free: 524.1 MB)
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: set
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: issue
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: planning
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: permission
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: economy
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: composition
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: agency
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/23 14:16:13 INFO PythonRunner: Times: total = 8066, boot = 451, init = 362, finish = 7253
16/03/23 14:16:13 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/23 14:16:13 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8135 ms on localhost (1/2)
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: bend
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: giant
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): adding to parents: syn =  Synset('colossus.n.02') ; keyword:  person  in syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= [u'giant']
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: astatine
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: present
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: area
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
16/03/23 14:16:13 INFO PythonRunner: Times: total = 8323, boot = 444, init = 411, finish = 7468
16/03/23 14:16:13 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/23 14:16:13 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8426 ms on localhost (2/2)
16/03/23 14:16:13 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/23 14:16:13 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 8.436 s
16/03/23 14:16:13 INFO DAGScheduler: looking for newly runnable stages
16/03/23 14:16:13 INFO DAGScheduler: running: Set()
16/03/23 14:16:13 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/23 14:16:13 INFO DAGScheduler: failed: Set()
16/03/23 14:16:13 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/23 14:16:13 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/23 14:16:13 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=549527224
16/03/23 14:16:13 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 524.1 MB)
16/03/23 14:16:13 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=549527224
16/03/23 14:16:13 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 524.1 MB)
16/03/23 14:16:13 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:46228 (size: 3.0 KB, free: 524.1 MB)
16/03/23 14:16:13 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/23 14:16:13 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:16:13 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/23 14:16:13 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:16:13 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:16:13 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/23 14:16:13 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/23 14:16:13 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:16:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
16/03/23 14:16:13 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:16:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
reduceFunction_Parents(): returns= ['None', u'giant', 'None']
16/03/23 14:16:13 INFO PythonRunner: Times: total = 28, boot = -28, init = 56, finish = 0
16/03/23 14:16:13 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1281 bytes result sent to driver
16/03/23 14:16:13 INFO PythonRunner: Times: total = 384, boot = 383, init = 0, finish = 1
16/03/23 14:16:13 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/23 14:16:13 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:46228 in memory (size: 4.1 KB, free: 524.1 MB)
16/03/23 14:16:13 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 578 ms on localhost (1/2)
16/03/23 14:16:13 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.581 s
16/03/23 14:16:13 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 9.034222 s
16/03/23 14:16:13 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 581 ms on localhost (2/2)
16/03/23 14:16:13 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/23 14:16:14 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:16:14 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:16:14 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:16:14 INFO DAGScheduler: Parents of final stage: List()
16/03/23 14:16:14 INFO DAGScheduler: Missing parents: List()
16/03/23 14:16:14 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:16:14 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=8404, maxMem=549527224
16/03/23 14:16:14 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 524.1 MB)
16/03/23 14:16:14 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=14220, maxMem=549527224
16/03/23 14:16:14 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 524.1 MB)
16/03/23 14:16:14 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:46228 (size: 3.3 KB, free: 524.1 MB)
16/03/23 14:16:14 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/23 14:16:14 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:16:14 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/23 14:16:14 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/23 14:16:14 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2362 bytes)
16/03/23 14:16:14 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/23 14:16:14 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/23 14:16:14 INFO PythonRunner: Times: total = 26, boot = 26, init = 0, finish = 0
16/03/23 14:16:14 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1349 bytes result sent to driver
16/03/23 14:16:14 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 37 ms on localhost (1/2)
16/03/23 14:16:14 INFO PythonRunner: Times: total = 63, boot = -315, init = 378, finish = 0
16/03/23 14:16:14 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/23 14:16:14 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 71 ms on localhost (2/2)
16/03/23 14:16:14 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/23 14:16:14 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.055 s
16/03/23 14:16:14 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.084301 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/23 14:16:14 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/23 14:16:14 INFO DAGScheduler: Stopping DAGScheduler
16/03/23 14:16:14 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/23 14:16:14 INFO MemoryStore: MemoryStore cleared
16/03/23 14:16:14 INFO BlockManager: BlockManager stopped
16/03/23 14:16:14 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/23 14:16:14 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/23 14:16:14 INFO SparkContext: Successfully stopped SparkContext
16/03/23 14:16:14 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/23 14:16:14 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'giant', u'None']
16/03/23 14:16:15 INFO SparkContext: Running Spark version 1.5.2
16/03/23 14:16:15 INFO SecurityManager: Changing view acls to: root
16/03/23 14:16:15 INFO SecurityManager: Changing modify acls to: root
16/03/23 14:16:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/23 14:16:15 INFO Slf4jLogger: Slf4jLogger started
16/03/23 14:16:15 INFO Remoting: Starting remoting
16/03/23 14:16:15 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:54060]
16/03/23 14:16:15 INFO Utils: Successfully started service 'sparkDriver' on port 54060.
16/03/23 14:16:15 INFO SparkEnv: Registering MapOutputTracker
16/03/23 14:16:15 INFO SparkEnv: Registering BlockManagerMaster
16/03/23 14:16:15 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-457c2726-2c3b-44d5-9a35-6e6c53839f39
16/03/23 14:16:15 INFO MemoryStore: MemoryStore started with capacity 526.6 MB
16/03/23 14:16:15 INFO HttpFileServer: HTTP File server directory is /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/httpd-22dbe2e6-94b9-4a47-8ce4-efb498598ecb
16/03/23 14:16:15 INFO HttpServer: Starting HTTP Server
16/03/23 14:16:15 INFO Utils: Successfully started service 'HTTP file server' on port 36887.
16/03/23 14:16:15 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/23 14:16:15 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/23 14:16:15 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/23 14:16:15 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-a140bc3f-7182-4dfe-8e97-ede676fea2ca/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:16:15 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722775424
16/03/23 14:16:15 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/23 14:16:15 INFO Executor: Starting executor ID driver on host localhost
16/03/23 14:16:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38837.
16/03/23 14:16:15 INFO NettyBlockTransferService: Server created on 38837
16/03/23 14:16:15 INFO BlockManagerMaster: Trying to register BlockManager
16/03/23 14:16:15 INFO BlockManagerMasterEndpoint: Registering block manager localhost:38837 with 526.6 MB RAM, BlockManagerId(driver, localhost, 38837)
16/03/23 14:16:15 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): reputation
16/03/23 14:16:15 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:16:15 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:16:15 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:16:15 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:16:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/23 14:16:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/23 14:16:15 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:16:15 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=552216821
16/03/23 14:16:15 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 526.6 MB)
16/03/23 14:16:15 INFO MemoryStore: ensureFreeSpace(4155) called with curMem=6576, maxMem=552216821
16/03/23 14:16:15 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 526.6 MB)
16/03/23 14:16:15 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:38837 (size: 4.1 KB, free: 526.6 MB)
16/03/23 14:16:15 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/23 14:16:15 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:16:15 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/23 14:16:15 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/23 14:16:15 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/23 14:16:15 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/23 14:16:15 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722775424
16/03/23 14:16:15 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/23 14:16:15 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-a140bc3f-7182-4dfe-8e97-ede676fea2ca/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:16:15 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/23 14:16:15 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/23 14:16:15 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10731, maxMem=552216821
16/03/23 14:16:15 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 526.6 MB)
16/03/23 14:16:15 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:38837 (size: 177.0 B, free: 526.6 MB)
16/03/23 14:16:15 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10908, maxMem=552216821
16/03/23 14:16:15 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 526.6 MB)
16/03/23 14:16:15 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:38837 (size: 187.0 B, free: 526.6 MB)
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: area
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: bend
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: giant
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): adding to parents: syn =  Synset('colossus.n.02') ; keyword:  reputation  in syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= [u'giant']
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: astatine
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: present
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: area
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
16/03/23 14:16:23 INFO PythonRunner: Times: total = 7974, boot = 452, init = 366, finish = 7156
16/03/23 14:16:23 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/23 14:16:23 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8061 ms on localhost (1/2)
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: issue
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: planning
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: permission
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: economy
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: composition
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: agency
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/23 14:16:24 INFO PythonRunner: Times: total = 8409, boot = 457, init = 399, finish = 7553
16/03/23 14:16:24 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/23 14:16:24 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8496 ms on localhost (2/2)
16/03/23 14:16:24 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/23 14:16:24 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 8.498 s
16/03/23 14:16:24 INFO DAGScheduler: looking for newly runnable stages
16/03/23 14:16:24 INFO DAGScheduler: running: Set()
16/03/23 14:16:24 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/23 14:16:24 INFO DAGScheduler: failed: Set()
16/03/23 14:16:24 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/23 14:16:24 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/23 14:16:24 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11095, maxMem=552216821
16/03/23 14:16:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 526.6 MB)
16/03/23 14:16:24 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16079, maxMem=552216821
16/03/23 14:16:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 526.6 MB)
16/03/23 14:16:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:38837 (size: 3.0 KB, free: 526.6 MB)
16/03/23 14:16:24 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/23 14:16:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:16:24 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/23 14:16:24 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:16:24 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:16:24 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/23 14:16:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:16:24 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/23 14:16:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:16:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/23 14:16:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
reduceFunction_Parents(): returns= ['None', u'giant', 'None']
16/03/23 14:16:24 INFO PythonRunner: Times: total = 50, boot = -279, init = 328, finish = 1
16/03/23 14:16:24 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1281 bytes result sent to driver
16/03/23 14:16:24 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 76 ms on localhost (1/2)
16/03/23 14:16:24 INFO PythonRunner: Times: total = 229, boot = 228, init = 0, finish = 1
16/03/23 14:16:24 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/23 14:16:24 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 252 ms on localhost (2/2)
16/03/23 14:16:24 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/23 14:16:24 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.244 s
16/03/23 14:16:24 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 8.773257 s
16/03/23 14:16:24 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:16:24 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:16:24 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:16:24 INFO DAGScheduler: Parents of final stage: List()
16/03/23 14:16:24 INFO DAGScheduler: Missing parents: List()
16/03/23 14:16:24 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:16:24 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19135, maxMem=552216821
16/03/23 14:16:24 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 526.6 MB)
16/03/23 14:16:24 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24951, maxMem=552216821
16/03/23 14:16:24 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 526.6 MB)
16/03/23 14:16:24 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:38837 (size: 3.3 KB, free: 526.6 MB)
16/03/23 14:16:24 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/23 14:16:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:16:24 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/23 14:16:24 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/23 14:16:24 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2362 bytes)
16/03/23 14:16:24 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/23 14:16:24 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/23 14:16:24 INFO PythonRunner: Times: total = 58, boot = -67, init = 125, finish = 0
16/03/23 14:16:24 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1349 bytes result sent to driver
16/03/23 14:16:24 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 77 ms on localhost (1/2)
16/03/23 14:16:24 INFO PythonRunner: Times: total = 161, boot = 161, init = 0, finish = 0
16/03/23 14:16:24 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/23 14:16:24 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 172 ms on localhost (2/2)
16/03/23 14:16:24 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/23 14:16:24 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.170 s
16/03/23 14:16:24 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.190669 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/23 14:16:24 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/23 14:16:24 INFO DAGScheduler: Stopping DAGScheduler
16/03/23 14:16:24 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/23 14:16:24 INFO MemoryStore: MemoryStore cleared
16/03/23 14:16:24 INFO BlockManager: BlockManager stopped
16/03/23 14:16:24 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/23 14:16:24 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/23 14:16:24 INFO SparkContext: Successfully stopped SparkContext
16/03/23 14:16:24 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/23 14:16:24 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/23 14:16:24 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'giant', u'None']
16/03/23 14:16:25 INFO SparkContext: Running Spark version 1.5.2
16/03/23 14:16:25 INFO SecurityManager: Changing view acls to: root
16/03/23 14:16:25 INFO SecurityManager: Changing modify acls to: root
16/03/23 14:16:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/23 14:16:25 INFO Slf4jLogger: Slf4jLogger started
16/03/23 14:16:25 INFO Remoting: Starting remoting
16/03/23 14:16:25 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:60839]
16/03/23 14:16:25 INFO Utils: Successfully started service 'sparkDriver' on port 60839.
16/03/23 14:16:25 INFO SparkEnv: Registering MapOutputTracker
16/03/23 14:16:25 INFO SparkEnv: Registering BlockManagerMaster
16/03/23 14:16:25 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-fb05b715-e603-45af-9d78-4a5ead2d72c8
16/03/23 14:16:25 INFO MemoryStore: MemoryStore started with capacity 526.6 MB
16/03/23 14:16:25 INFO HttpFileServer: HTTP File server directory is /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/httpd-598b7c19-6557-4d56-8bf7-ed56e240469f
16/03/23 14:16:25 INFO HttpServer: Starting HTTP Server
16/03/23 14:16:25 INFO Utils: Successfully started service 'HTTP file server' on port 46847.
16/03/23 14:16:25 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/23 14:16:25 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/23 14:16:25 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/23 14:16:25 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-7eea43d5-f4a3-4382-b7aa-ef5a25218907/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:16:25 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722785882
16/03/23 14:16:25 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/23 14:16:25 INFO Executor: Starting executor ID driver on host localhost
16/03/23 14:16:25 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38187.
16/03/23 14:16:25 INFO NettyBlockTransferService: Server created on 38187
16/03/23 14:16:25 INFO BlockManagerMaster: Trying to register BlockManager
16/03/23 14:16:25 INFO BlockManagerMasterEndpoint: Registering block manager localhost:38187 with 526.6 MB RAM, BlockManagerId(driver, localhost, 38187)
16/03/23 14:16:25 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): time
16/03/23 14:16:26 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:16:26 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:16:26 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:16:26 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:16:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/23 14:16:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/23 14:16:26 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:16:26 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=552216821
16/03/23 14:16:26 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 526.6 MB)
16/03/23 14:16:26 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=552216821
16/03/23 14:16:26 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 526.6 MB)
16/03/23 14:16:26 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:38187 (size: 4.1 KB, free: 526.6 MB)
16/03/23 14:16:26 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/23 14:16:26 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:16:26 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/23 14:16:26 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/23 14:16:26 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/23 14:16:26 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/23 14:16:26 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722785882
16/03/23 14:16:26 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/23 14:16:26 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-7eea43d5-f4a3-4382-b7aa-ef5a25218907/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:16:26 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/23 14:16:26 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10732, maxMem=552216821
16/03/23 14:16:26 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 526.6 MB)
16/03/23 14:16:26 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/23 14:16:26 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10919, maxMem=552216821
16/03/23 14:16:26 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 526.6 MB)
16/03/23 14:16:26 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:38187 (size: 187.0 B, free: 526.6 MB)
16/03/23 14:16:26 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:38187 (size: 177.0 B, free: 526.6 MB)
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: set
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: issue
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: planning
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: permission
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: economy
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: composition
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: agency
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/23 14:16:34 INFO PythonRunner: Times: total = 8044, boot = 468, init = 365, finish = 7211
16/03/23 14:16:34 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/23 14:16:34 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8159 ms on localhost (1/2)
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: bend
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: giant
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: astatine
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: present
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  time  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: area
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/23 14:16:34 INFO PythonRunner: Times: total = 8308, boot = 470, init = 365, finish = 7473
16/03/23 14:16:34 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/23 14:16:34 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8420 ms on localhost (2/2)
16/03/23 14:16:34 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 8.411 s
16/03/23 14:16:34 INFO DAGScheduler: looking for newly runnable stages
16/03/23 14:16:34 INFO DAGScheduler: running: Set()
16/03/23 14:16:34 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/23 14:16:34 INFO DAGScheduler: failed: Set()
16/03/23 14:16:34 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/23 14:16:34 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/23 14:16:34 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/23 14:16:34 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=552216821
16/03/23 14:16:34 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 526.6 MB)
16/03/23 14:16:34 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=552216821
16/03/23 14:16:34 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 526.6 MB)
16/03/23 14:16:34 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:38187 (size: 3.0 KB, free: 526.6 MB)
16/03/23 14:16:34 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/23 14:16:34 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:16:34 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/23 14:16:34 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:16:34 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:16:34 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/23 14:16:34 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:16:34 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/23 14:16:34 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:16:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/23 14:16:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
reduceFunction_Parents(): returns= ['None', u'present', 'None']
16/03/23 14:16:34 INFO PythonRunner: Times: total = 15, boot = -102, init = 116, finish = 1
16/03/23 14:16:34 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/03/23 14:16:34 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 68 ms on localhost (1/2)
16/03/23 14:16:34 INFO PythonRunner: Times: total = 234, boot = 234, init = 0, finish = 0
16/03/23 14:16:34 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/23 14:16:34 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 252 ms on localhost (2/2)
16/03/23 14:16:34 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.236 s
16/03/23 14:16:34 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/23 14:16:34 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 8.716616 s
16/03/23 14:16:34 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:16:34 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:16:34 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:16:34 INFO DAGScheduler: Parents of final stage: List()
16/03/23 14:16:34 INFO DAGScheduler: Missing parents: List()
16/03/23 14:16:34 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:16:34 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=552216821
16/03/23 14:16:34 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 526.6 MB)
16/03/23 14:16:34 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24952, maxMem=552216821
16/03/23 14:16:34 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 526.6 MB)
16/03/23 14:16:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:38187 (size: 3.3 KB, free: 526.6 MB)
16/03/23 14:16:34 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/23 14:16:34 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:16:34 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/23 14:16:34 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/23 14:16:34 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/03/23 14:16:34 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/23 14:16:34 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/23 14:16:34 INFO PythonRunner: Times: total = 72, boot = -121, init = 193, finish = 0
16/03/23 14:16:34 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/23 14:16:34 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 80 ms on localhost (1/2)
16/03/23 14:16:35 INFO PythonRunner: Times: total = 165, boot = 164, init = 0, finish = 1
16/03/23 14:16:35 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1351 bytes result sent to driver
16/03/23 14:16:35 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 176 ms on localhost (2/2)
16/03/23 14:16:35 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/23 14:16:35 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.160 s
16/03/23 14:16:35 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.194700 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/23 14:16:35 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/23 14:16:35 INFO DAGScheduler: Stopping DAGScheduler
16/03/23 14:16:35 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/23 14:16:35 INFO MemoryStore: MemoryStore cleared
16/03/23 14:16:35 INFO BlockManager: BlockManager stopped
16/03/23 14:16:35 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/23 14:16:35 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/23 14:16:35 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/23 14:16:35 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/23 14:16:35 INFO SparkContext: Successfully stopped SparkContext
16/03/23 14:16:35 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'present', u'None']
16/03/23 14:16:36 INFO SparkContext: Running Spark version 1.5.2
16/03/23 14:16:36 INFO SecurityManager: Changing view acls to: root
16/03/23 14:16:36 INFO SecurityManager: Changing modify acls to: root
16/03/23 14:16:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/23 14:16:36 INFO Slf4jLogger: Slf4jLogger started
16/03/23 14:16:36 INFO Remoting: Starting remoting
16/03/23 14:16:36 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:40331]
16/03/23 14:16:36 INFO Utils: Successfully started service 'sparkDriver' on port 40331.
16/03/23 14:16:36 INFO SparkEnv: Registering MapOutputTracker
16/03/23 14:16:36 INFO SparkEnv: Registering BlockManagerMaster
16/03/23 14:16:36 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c061de8f-6a4a-4803-9875-bbc6e937e104
16/03/23 14:16:36 INFO MemoryStore: MemoryStore started with capacity 526.6 MB
16/03/23 14:16:36 INFO HttpFileServer: HTTP File server directory is /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/httpd-dd7bdbb3-9313-4294-b12e-6f6184e8e168
16/03/23 14:16:36 INFO HttpServer: Starting HTTP Server
16/03/23 14:16:36 INFO Utils: Successfully started service 'HTTP file server' on port 36267.
16/03/23 14:16:36 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/23 14:16:36 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/23 14:16:36 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/23 14:16:36 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-5a2ea218-fe40-41e1-9d7b-70ec9ca604e9/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:16:36 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722796492
16/03/23 14:16:36 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/23 14:16:36 INFO Executor: Starting executor ID driver on host localhost
16/03/23 14:16:36 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37153.
16/03/23 14:16:36 INFO NettyBlockTransferService: Server created on 37153
16/03/23 14:16:36 INFO BlockManagerMaster: Trying to register BlockManager
16/03/23 14:16:36 INFO BlockManagerMasterEndpoint: Registering block manager localhost:37153 with 526.6 MB RAM, BlockManagerId(driver, localhost, 37153)
16/03/23 14:16:36 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): position
16/03/23 14:16:36 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:16:36 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:16:36 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:16:36 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:16:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/23 14:16:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/23 14:16:36 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:16:36 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=552216821
16/03/23 14:16:36 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 526.6 MB)
16/03/23 14:16:36 INFO MemoryStore: ensureFreeSpace(4155) called with curMem=6576, maxMem=552216821
16/03/23 14:16:36 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 526.6 MB)
16/03/23 14:16:36 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:37153 (size: 4.1 KB, free: 526.6 MB)
16/03/23 14:16:36 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/23 14:16:36 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:16:36 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/23 14:16:36 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/23 14:16:36 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/23 14:16:36 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/23 14:16:36 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722796492
16/03/23 14:16:36 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/23 14:16:36 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-5a2ea218-fe40-41e1-9d7b-70ec9ca604e9/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:16:36 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/23 14:16:36 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10731, maxMem=552216821
16/03/23 14:16:36 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 526.6 MB)
16/03/23 14:16:36 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:37153 (size: 187.0 B, free: 526.6 MB)
16/03/23 14:16:36 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/23 14:16:36 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10918, maxMem=552216821
16/03/23 14:16:36 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 526.6 MB)
16/03/23 14:16:36 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:37153 (size: 177.0 B, free: 526.6 MB)
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: area
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: set
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: issue
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: planning
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: permission
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: economy
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: composition
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: agency
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/23 14:16:44 INFO PythonRunner: Times: total = 7819, boot = 459, init = 370, finish = 6990
16/03/23 14:16:44 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/23 14:16:44 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 7900 ms on localhost (1/2)
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: bend
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: giant
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: astatine
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: present
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  position  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: area
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
16/03/23 14:16:45 INFO PythonRunner: Times: total = 8407, boot = 455, init = 416, finish = 7536
16/03/23 14:16:45 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/23 14:16:45 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8503 ms on localhost (2/2)
16/03/23 14:16:45 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/23 14:16:45 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 8.495 s
16/03/23 14:16:45 INFO DAGScheduler: looking for newly runnable stages
16/03/23 14:16:45 INFO DAGScheduler: running: Set()
16/03/23 14:16:45 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/23 14:16:45 INFO DAGScheduler: failed: Set()
16/03/23 14:16:45 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/23 14:16:45 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/23 14:16:45 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11095, maxMem=552216821
16/03/23 14:16:45 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 526.6 MB)
16/03/23 14:16:45 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16079, maxMem=552216821
16/03/23 14:16:45 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 526.6 MB)
16/03/23 14:16:45 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:37153 (size: 3.0 KB, free: 526.6 MB)
16/03/23 14:16:45 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/23 14:16:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:16:45 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/23 14:16:45 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:16:45 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:16:45 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/23 14:16:45 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/23 14:16:45 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:16:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/23 14:16:45 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:16:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
16/03/23 14:16:45 INFO PythonRunner: Times: total = 32, boot = -437, init = 469, finish = 0
16/03/23 14:16:45 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/23 14:16:45 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 84 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'metropolitan', 'None']
16/03/23 14:16:45 INFO PythonRunner: Times: total = 222, boot = 219, init = 1, finish = 2
16/03/23 14:16:45 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1288 bytes result sent to driver
16/03/23 14:16:45 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.236 s
16/03/23 14:16:45 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 8.772734 s
16/03/23 14:16:45 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 245 ms on localhost (2/2)
16/03/23 14:16:45 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/23 14:16:45 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:16:45 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:16:45 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:16:45 INFO DAGScheduler: Parents of final stage: List()
16/03/23 14:16:45 INFO DAGScheduler: Missing parents: List()
16/03/23 14:16:45 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:16:45 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19134, maxMem=552216821
16/03/23 14:16:45 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 526.6 MB)
16/03/23 14:16:45 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24950, maxMem=552216821
16/03/23 14:16:45 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 526.6 MB)
16/03/23 14:16:45 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:37153 (size: 3.3 KB, free: 526.6 MB)
16/03/23 14:16:45 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/23 14:16:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:16:45 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/23 14:16:45 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/23 14:16:45 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2369 bytes)
16/03/23 14:16:45 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/23 14:16:45 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/23 14:16:45 INFO PythonRunner: Times: total = 66, boot = -100, init = 166, finish = 0
16/03/23 14:16:45 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1356 bytes result sent to driver
16/03/23 14:16:45 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 78 ms on localhost (1/2)
16/03/23 14:16:45 INFO PythonRunner: Times: total = 167, boot = 166, init = 1, finish = 0
16/03/23 14:16:45 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/23 14:16:45 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 176 ms on localhost (2/2)
16/03/23 14:16:45 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/23 14:16:45 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.161 s
16/03/23 14:16:45 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.189982 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/23 14:16:45 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/23 14:16:45 INFO DAGScheduler: Stopping DAGScheduler
16/03/23 14:16:45 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/23 14:16:45 INFO MemoryStore: MemoryStore cleared
16/03/23 14:16:45 INFO BlockManager: BlockManager stopped
16/03/23 14:16:45 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/23 14:16:45 INFO SparkContext: Successfully stopped SparkContext
16/03/23 14:16:45 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/23 14:16:45 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/23 14:16:45 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/23 14:16:45 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'metropolitan', u'None']
16/03/23 14:16:46 INFO SparkContext: Running Spark version 1.5.2
16/03/23 14:16:46 INFO SecurityManager: Changing view acls to: root
16/03/23 14:16:46 INFO SecurityManager: Changing modify acls to: root
16/03/23 14:16:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/23 14:16:46 INFO Slf4jLogger: Slf4jLogger started
16/03/23 14:16:46 INFO Remoting: Starting remoting
16/03/23 14:16:46 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:56326]
16/03/23 14:16:46 INFO Utils: Successfully started service 'sparkDriver' on port 56326.
16/03/23 14:16:46 INFO SparkEnv: Registering MapOutputTracker
16/03/23 14:16:46 INFO SparkEnv: Registering BlockManagerMaster
16/03/23 14:16:46 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e337cd74-950c-4211-99c1-158d5518c207
16/03/23 14:16:46 INFO MemoryStore: MemoryStore started with capacity 525.7 MB
16/03/23 14:16:46 INFO HttpFileServer: HTTP File server directory is /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/httpd-86afae44-ce3e-4121-8f70-037aa588e7b9
16/03/23 14:16:46 INFO HttpServer: Starting HTTP Server
16/03/23 14:16:46 INFO Utils: Successfully started service 'HTTP file server' on port 32834.
16/03/23 14:16:46 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/23 14:16:47 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/23 14:16:47 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/23 14:16:47 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-fa48b898-8992-4aa5-ba58-044b6b334c14/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:16:47 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722807025
16/03/23 14:16:47 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/23 14:16:47 INFO Executor: Starting executor ID driver on host localhost
16/03/23 14:16:47 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41264.
16/03/23 14:16:47 INFO NettyBlockTransferService: Server created on 41264
16/03/23 14:16:47 INFO BlockManagerMaster: Trying to register BlockManager
16/03/23 14:16:47 INFO BlockManagerMasterEndpoint: Registering block manager localhost:41264 with 525.7 MB RAM, BlockManagerId(driver, localhost, 41264)
16/03/23 14:16:47 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): quantity
16/03/23 14:16:47 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:16:47 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:16:47 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:16:47 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:16:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/23 14:16:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/23 14:16:47 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:16:47 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=551225917
16/03/23 14:16:47 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 525.7 MB)
16/03/23 14:16:47 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=551225917
16/03/23 14:16:47 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 525.7 MB)
16/03/23 14:16:47 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:41264 (size: 4.1 KB, free: 525.7 MB)
16/03/23 14:16:47 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/23 14:16:47 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:16:47 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/23 14:16:47 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/23 14:16:47 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2444 bytes)
16/03/23 14:16:47 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/23 14:16:47 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722807025
16/03/23 14:16:47 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/23 14:16:47 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-fa48b898-8992-4aa5-ba58-044b6b334c14/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:16:47 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/23 14:16:47 INFO MemoryStore: ensureFreeSpace(177) called with curMem=10732, maxMem=551225917
16/03/23 14:16:47 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 177.0 B, free 525.7 MB)
16/03/23 14:16:47 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:41264 (size: 177.0 B, free: 525.7 MB)
16/03/23 14:16:47 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/23 14:16:47 INFO MemoryStore: ensureFreeSpace(187) called with curMem=10909, maxMem=551225917
16/03/23 14:16:47 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 187.0 B, free 525.7 MB)
16/03/23 14:16:47 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:41264 (size: 187.0 B, free: 525.7 MB)
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: set
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: area
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: bend
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: giant
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: astatine
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: present
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: area
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/23 14:16:55 INFO PythonRunner: Times: total = 8098, boot = 464, init = 411, finish = 7223
16/03/23 14:16:55 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/23 14:16:55 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8203 ms on localhost (1/2)
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: issue
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: planning
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: permission
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: economy
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: composition
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: agency
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/23 14:16:55 INFO PythonRunner: Times: total = 8334, boot = 472, init = 425, finish = 7437
16/03/23 14:16:55 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/23 14:16:55 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 8.416 s
16/03/23 14:16:55 INFO DAGScheduler: looking for newly runnable stages
16/03/23 14:16:55 INFO DAGScheduler: running: Set()
16/03/23 14:16:55 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/23 14:16:55 INFO DAGScheduler: failed: Set()
16/03/23 14:16:55 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8415 ms on localhost (2/2)
16/03/23 14:16:55 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/23 14:16:55 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/23 14:16:55 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which is now runnable
16/03/23 14:16:55 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11096, maxMem=551225917
16/03/23 14:16:55 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 525.7 MB)
16/03/23 14:16:55 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16080, maxMem=551225917
16/03/23 14:16:55 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 525.7 MB)
16/03/23 14:16:55 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:41264 (size: 3.0 KB, free: 525.7 MB)
16/03/23 14:16:55 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/23 14:16:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:16:55 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/23 14:16:55 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:16:55 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:16:55 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/23 14:16:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:16:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/23 14:16:55 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/23 14:16:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:16:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/23 14:16:55 INFO PythonRunner: Times: total = 36, boot = -46, init = 82, finish = 0
16/03/23 14:16:55 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/23 14:16:55 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 76 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None']
16/03/23 14:16:55 INFO PythonRunner: Times: total = 248, boot = 248, init = 0, finish = 0
16/03/23 14:16:55 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1269 bytes result sent to driver
16/03/23 14:16:55 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.256 s
16/03/23 14:16:55 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 8.708410 s
16/03/23 14:16:55 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 272 ms on localhost (2/2)
16/03/23 14:16:55 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/23 14:16:55 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211
16/03/23 14:16:55 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) with 2 output partitions
16/03/23 14:16:55 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:16:55 INFO DAGScheduler: Parents of final stage: List()
16/03/23 14:16:55 INFO DAGScheduler: Missing parents: List()
16/03/23 14:16:55 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211), which has no missing parents
16/03/23 14:16:55 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19136, maxMem=551225917
16/03/23 14:16:55 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 525.7 MB)
16/03/23 14:16:55 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24952, maxMem=551225917
16/03/23 14:16:55 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 525.7 MB)
16/03/23 14:16:55 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:41264 (size: 3.3 KB, free: 525.7 MB)
16/03/23 14:16:55 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/23 14:16:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211)
16/03/23 14:16:55 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/23 14:16:55 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/23 14:16:55 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2350 bytes)
16/03/23 14:16:55 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/23 14:16:55 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/23 14:16:56 INFO PythonRunner: Times: total = 61, boot = -103, init = 164, finish = 0
16/03/23 14:16:56 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1337 bytes result sent to driver
16/03/23 14:16:56 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 74 ms on localhost (1/2)
16/03/23 14:16:56 INFO PythonRunner: Times: total = 212, boot = 212, init = 0, finish = 0
16/03/23 14:16:56 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/23 14:16:56 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 221 ms on localhost (2/2)
16/03/23 14:16:56 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/23 14:16:56 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211) finished in 0.210 s
16/03/23 14:16:56 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:211, took 0.236107 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/23 14:16:56 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/23 14:16:56 INFO DAGScheduler: Stopping DAGScheduler
16/03/23 14:16:56 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/23 14:16:56 INFO MemoryStore: MemoryStore cleared
16/03/23 14:16:56 INFO BlockManager: BlockManager stopped
16/03/23 14:16:56 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/23 14:16:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/23 14:16:56 INFO SparkContext: Successfully stopped SparkContext
16/03/23 14:16:56 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/23 14:16:56 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/23 14:16:56 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None']
InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:freqterms1= [u'serving', u'Madras', u'Bengal', u'course', u'relation', u'geography', u'group', u'decay', u'program', u'Tamil', u'exceptional', u'Bay', u'formulating', u'serves', u'item', u'miles', u'unstable', u'including', u'people', u'series', u'Christianity', u'culture', u'meters', u'special', u'0.621371', u'Orthodox', u'definite', u'boundary', u'business', u'importance', u'equivalent', u'thorium', u'approval', u'providing', u'region', u'title', u'equal', u'length', u'resulting', u'act', u'action', u'whole', u'businesses', u'1000', u'formerly', u'period', u'highly', u'production', u'indefinite', u'unit', u'city', u'use', u'consumption', u'Eastern', u'stretch', u'archbishop', u'system', u'halogen', u'continuous', u'western', u'particular', u'given', u'kind', u'official', u'patriarch', u'Church', u'distribution', u'property', u'distinguished', u'metric', u'heaviest', u'purposes', u'general', u'something', u'bishop', u'things', u'belong', u'uranium', u'arrangement', u'parts', u'speech', u'geographical', u'spatial', u'Nadu', u'circular', u'product', u'used', u'usually', u'moment', u'purpose', u'segment', u'radioactive', u'happening', u'curve', u'together', u'element', u'person', u'reputation', u'time', u'position', u'quantity']
16/03/23 14:16:57 INFO SparkContext: Running Spark version 1.5.2
16/03/23 14:16:57 INFO SecurityManager: Changing view acls to: root
16/03/23 14:16:57 INFO SecurityManager: Changing modify acls to: root
16/03/23 14:16:57 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/23 14:16:57 INFO Slf4jLogger: Slf4jLogger started
16/03/23 14:16:57 INFO Remoting: Starting remoting
16/03/23 14:16:57 INFO Utils: Successfully started service 'sparkDriver' on port 51126.
16/03/23 14:16:57 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:51126]
16/03/23 14:16:57 INFO SparkEnv: Registering MapOutputTracker
16/03/23 14:16:57 INFO SparkEnv: Registering BlockManagerMaster
16/03/23 14:16:57 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c41612f6-8271-469a-a686-e3c9e68a9279
16/03/23 14:16:57 INFO MemoryStore: MemoryStore started with capacity 525.7 MB
16/03/23 14:16:57 INFO HttpFileServer: HTTP File server directory is /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/httpd-0315fc10-955e-4ef1-bee1-fb45ac0feeb8
16/03/23 14:16:57 INFO HttpServer: Starting HTTP Server
16/03/23 14:16:57 INFO Utils: Successfully started service 'HTTP file server' on port 39083.
16/03/23 14:16:57 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/23 14:16:57 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/23 14:16:57 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/23 14:16:57 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-e5a0b1c0-d296-4a1e-9630-6bb947fe3cc9/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:16:57 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722817460
16/03/23 14:16:57 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/23 14:16:57 INFO Executor: Starting executor ID driver on host localhost
16/03/23 14:16:57 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54043.
16/03/23 14:16:57 INFO NettyBlockTransferService: Server created on 54043
16/03/23 14:16:57 INFO BlockManagerMaster: Trying to register BlockManager
16/03/23 14:16:57 INFO BlockManagerMasterEndpoint: Registering block manager localhost:54043 with 525.7 MB RAM, BlockManagerId(driver, localhost, 54043)
16/03/23 14:16:57 INFO BlockManagerMaster: Registered BlockManager
Spark_MapReduce(): wordsatthislevel: [u'serving', u'Madras', u'Bengal', u'course', u'relation', u'geography', u'group', u'decay', u'program', u'Tamil', u'exceptional', u'Bay', u'formulating', u'serves', u'item', u'miles', u'unstable', u'including', u'people', u'series', u'Christianity', u'culture', u'meters', u'special', u'0.621371', u'Orthodox', u'definite', u'boundary', u'business', u'importance', u'equivalent', u'thorium', u'approval', u'providing', u'region', u'title', u'equal', u'length', u'resulting', u'act', u'action', u'whole', u'businesses', u'1000', u'formerly', u'period', u'highly', u'production', u'indefinite', u'unit', u'city', u'use', u'consumption', u'Eastern', u'stretch', u'archbishop', u'system', u'halogen', u'continuous', u'western', u'particular', u'given', u'kind', u'official', u'patriarch', u'Church', u'distribution', u'property', u'distinguished', u'metric', u'heaviest', u'purposes', u'general', u'something', u'bishop', u'things', u'belong', u'uranium', u'arrangement', u'parts', u'speech', u'geographical', u'spatial', u'Nadu', u'circular', u'product', u'used', u'usually', u'moment', u'purpose', u'segment', u'radioactive', u'happening', u'curve', u'together', u'element', u'person', u'reputation', u'time', u'position', u'quantity']
16/03/23 14:16:57 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234
16/03/23 14:16:57 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234)
16/03/23 14:16:57 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234) with 2 output partitions
16/03/23 14:16:57 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234)
16/03/23 14:16:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/23 14:16:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/23 14:16:57 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234), which has no missing parents
16/03/23 14:16:57 INFO MemoryStore: ensureFreeSpace(6560) called with curMem=0, maxMem=551225917
16/03/23 14:16:57 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 525.7 MB)
16/03/23 14:16:57 INFO MemoryStore: ensureFreeSpace(4147) called with curMem=6560, maxMem=551225917
16/03/23 14:16:57 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 525.7 MB)
16/03/23 14:16:57 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:54043 (size: 4.0 KB, free: 525.7 MB)
16/03/23 14:16:57 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/23 14:16:57 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234)
16/03/23 14:16:57 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/23 14:16:57 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 3016 bytes)
16/03/23 14:16:57 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 3065 bytes)
16/03/23 14:16:57 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/23 14:16:57 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458722817460
16/03/23 14:16:57 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/23 14:16:57 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/userFiles-e5a0b1c0-d296-4a1e-9630-6bb947fe3cc9/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/23 14:16:57 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/23 14:16:57 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/23 14:16:57 INFO MemoryStore: ensureFreeSpace(692) called with curMem=10707, maxMem=551225917
16/03/23 14:16:57 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 692.0 B, free 525.7 MB)
16/03/23 14:16:57 INFO MemoryStore: ensureFreeSpace(662) called with curMem=11399, maxMem=551225917
16/03/23 14:16:57 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:54043 (size: 692.0 B, free: 525.7 MB)
16/03/23 14:16:57 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 662.0 B, free 525.7 MB)
16/03/23 14:16:57 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:54043 (size: 662.0 B, free: 525.7 MB)
mapFunction(): freqterms1: city
mapFunction(): freqterms1: serving
mapFunction(): freqterms1: use
mapFunction(): freqterms1: consumption
mapFunction(): freqterms1: Eastern
mapFunction(): freqterms1: stretch
mapFunction(): freqterms1: archbishop
mapFunction(): freqterms1: Madras
mapFunction(): freqterms1: system
mapFunction(): freqterms1: Bengal
mapFunction(): freqterms1: course
mapFunction(): freqterms1: halogen
mapFunction(): freqterms1: continuous
mapFunction(): freqterms1: western
mapFunction(): freqterms1: particular
mapFunction(): freqterms1: relation
mapFunction(): freqterms1: geography
mapFunction(): freqterms1: group
mapFunction(): freqterms1: given
mapFunction(): freqterms1: decay
mapFunction(): freqterms1: program
mapFunction(): freqterms1: kind
mapFunction(): freqterms1: Tamil
mapFunction(): freqterms1: official
mapFunction(): freqterms1: exceptional
mapFunction(): freqterms1: Bay
mapFunction(): freqterms1: patriarch
mapFunction(): freqterms1: Church
mapFunction(): freqterms1: distribution
mapFunction(): freqterms1: property
mapFunction(): freqterms1: formulating
mapFunction(): freqterms1: serves
mapFunction(): freqterms1: distinguished
mapFunction(): freqterms1: metric
mapFunction(): freqterms1: item
mapFunction(): freqterms1: heaviest
mapFunction(): freqterms1: miles
mapFunction(): freqterms1: unstable
mapFunction(): freqterms1: including
mapFunction(): freqterms1: people
mapFunction(): freqterms1: purposes
mapFunction(): freqterms1: series
mapFunction(): freqterms1: general
mapFunction(): freqterms1: something
mapFunction(): freqterms1: bishop
mapFunction(): freqterms1: Christianity
mapFunction(): freqterms1: culture
mapFunction(): freqterms1: things
mapFunction(): freqterms1: meters
mapFunction(): freqterms1: special
mapFunction(): freqterms1: belong
mapFunction(): freqterms1: 0.621371
mapFunction(): freqterms1: Orthodox
mapFunction(): freqterms1: uranium
mapFunction(): freqterms1: arrangement
mapFunction(): freqterms1: parts
mapFunction(): freqterms1: definite
mapFunction(): freqterms1: boundary
mapFunction(): freqterms1: business
mapFunction(): freqterms1: speech
mapFunction(): freqterms1: importance
mapFunction(): freqterms1: geographical
mapFunction(): freqterms1: equivalent
mapFunction(): freqterms1: thorium
mapFunction(): freqterms1: approval
mapFunction(): freqterms1: providing
mapFunction(): freqterms1: spatial
mapFunction(): freqterms1: region
mapFunction(): freqterms1: Nadu
mapFunction(): freqterms1: circular
mapFunction(): freqterms1: title
mapFunction(): freqterms1: equal
mapFunction(): freqterms1: product
mapFunction(): freqterms1: used
mapFunction(): freqterms1: length
mapFunction(): freqterms1: usually
mapFunction(): freqterms1: resulting
mapFunction(): freqterms1: moment
mapFunction(): freqterms1: act
mapFunction(): freqterms1: purpose
mapFunction(): freqterms1: segment
mapFunction(): freqterms1: radioactive
mapFunction(): freqterms1: happening
mapFunction(): freqterms1: action
mapFunction(): freqterms1: curve
mapFunction(): freqterms1: together
mapFunction(): freqterms1: whole
mapFunction(): freqterms1: businesses
mapFunction(): freqterms1: 1000
mapFunction(): freqterms1: element
mapFunction(): freqterms1: person
mapFunction(): freqterms1: formerly
mapFunction(): freqterms1: period
mapFunction(): freqterms1: reputation
mapFunction(): freqterms1: time
mapFunction(): freqterms1: highly
mapFunction(): freqterms1: production
mapFunction(): freqterms1: position
mapFunction(): freqterms1: indefinite
mapFunction(): freqterms1: unit
mapFunction(): freqterms1: quantity
16/03/23 14:17:08 INFO PythonRunner: Times: total = 10368, boot = 451, init = 372, finish = 9545
16/03/23 14:17:08 INFO PythonRunner: Times: total = 10368, boot = 460, init = 382, finish = 9526
16/03/23 14:17:08 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/23 14:17:08 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/23 14:17:08 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 10489 ms on localhost (1/2)
16/03/23 14:17:08 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 10493 ms on localhost (2/2)
16/03/23 14:17:08 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234) finished in 10.493 s
16/03/23 14:17:08 INFO DAGScheduler: looking for newly runnable stages
16/03/23 14:17:08 INFO DAGScheduler: running: Set()
16/03/23 14:17:08 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/23 14:17:08 INFO DAGScheduler: failed: Set()
16/03/23 14:17:08 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/23 14:17:08 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/23 14:17:08 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234), which is now runnable
16/03/23 14:17:08 INFO MemoryStore: ensureFreeSpace(4976) called with curMem=12061, maxMem=551225917
16/03/23 14:17:08 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 525.7 MB)
16/03/23 14:17:08 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=17037, maxMem=551225917
16/03/23 14:17:08 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 525.7 MB)
16/03/23 14:17:08 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:54043 (size: 3.0 KB, free: 525.7 MB)
16/03/23 14:17:08 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/23 14:17:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234)
16/03/23 14:17:08 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/23 14:17:08 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:17:08 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/23 14:17:08 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/23 14:17:08 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:17:08 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/23 14:17:08 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/23 14:17:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/23 14:17:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
16/03/23 14:17:08 INFO PythonRunner: Times: total = 189, boot = 188, init = 0, finish = 1
16/03/23 14:17:08 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/23 14:17:08 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 206 ms on localhost (1/2)
16/03/23 14:17:08 INFO PythonRunner: Times: total = 236, boot = 233, init = 0, finish = 3
16/03/23 14:17:08 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 11013 bytes result sent to driver
16/03/23 14:17:08 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 576 ms on localhost (2/2)
16/03/23 14:17:08 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/23 14:17:08 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234) finished in 0.572 s
16/03/23 14:17:08 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234, took 11.122567 s
16/03/23 14:17:08 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:54043 in memory (size: 4.0 KB, free: 525.7 MB)
16/03/23 14:17:08 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234
16/03/23 14:17:08 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234) with 2 output partitions
16/03/23 14:17:08 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234)
16/03/23 14:17:08 INFO DAGScheduler: Parents of final stage: List()
16/03/23 14:17:08 INFO DAGScheduler: Missing parents: List()
16/03/23 14:17:08 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234), which has no missing parents
16/03/23 14:17:08 INFO MemoryStore: ensureFreeSpace(5872) called with curMem=9378, maxMem=551225917
16/03/23 14:17:08 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 525.7 MB)
16/03/23 14:17:08 INFO MemoryStore: ensureFreeSpace(3419) called with curMem=15250, maxMem=551225917
16/03/23 14:17:08 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 525.7 MB)
16/03/23 14:17:08 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:54043 (size: 3.3 KB, free: 525.7 MB)
16/03/23 14:17:08 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/23 14:17:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234)
16/03/23 14:17:08 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/23 14:17:08 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/23 14:17:08 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 11962 bytes)
16/03/23 14:17:08 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/23 14:17:08 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/23 14:17:08 INFO PythonRunner: Times: total = 17, boot = -200, init = 217, finish = 0
16/03/23 14:17:08 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/23 14:17:08 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 90 ms on localhost (1/2)
16/03/23 14:17:08 INFO PythonRunner: Times: total = 37, boot = -70, init = 106, finish = 1
16/03/23 14:17:08 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 11320 bytes result sent to driver
16/03/23 14:17:08 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 106 ms on localhost (2/2)
16/03/23 14:17:08 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/23 14:17:08 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234) finished in 0.107 s
16/03/23 14:17:08 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:234, took 0.117974 s
Spark_MapReduce() - SparkSQL DataFrame query results:
Row(tokensatthislevel=[u'individual', u'quantity', u'food', u'drink', u'taken', u'part', u'meal', u'state', u'southeastern', u'India', u'Bay', u'Bengal', u'south', u'Andhra', u'Pradesh', u'formerly', u'Madras', u'region', u'whose', u'eastern', u'part', u'Bangladesh', u'whose', u'western', u'part', u'included', u'India', u'education', u'imparted', u'series', u'lessons', u'meetings', u'act', u'sexual', u'procreation', u'man', u'woman', u'man', u'penis', u'inserted', u'woman', u'vagina', u'excited', u'orgasm', u'ejaculation', u'occur', u'study', u'earth', u'surface', u'includes', u'people', u'responses', u'topography', u'climate', u'soil', u'vegetation', u'number', u'entities', u'members', u'considered', u'unit', u'gradual', u'decrease', u'stored', u'charge', u'current', u'series', u'steps', u'carried', u'goals', u'accomplished', u'member', u'mixed', u'Dravidian', u'Caucasian', u'people', u'southern', u'India', u'Sri', u'Lanka', u'deviating', u'widely', u'norm', u'physical', u'mental', u'ability', u'used', u'especially', u'children', u'normal', u'intelligence', u'indentation', u'shoreline', u'larger', u'cove', u'smaller', u'gulf', u'come', u'idea', u'plan', u'explanation', u'theory', u'principle', u'mental', u'effort', u'sports', u'stroke', u'puts', u'ball', u'play', u'distinct', u'part', u'specified', u'separately', u'group', u'things', u'could', u'enumerated', u'list', u'unit', u'length', u'equal', u'1,760', u'yards', u'5,280', u'feet', u'exactly', u'1609.344', u'meters', u'lacking', u'stability', u'fixity', u'firmness', u'part', u'made', u'plural', u'group', u'human', u'beings', u'men', u'women', u'children', u'collectively', u'similar', u'things', u'placed', u'order', u'happening', u'one', u'another', u'monotheistic', u'system', u'beliefs', u'practices', u'based', u'Old', u'Testament', u'teachings', u'Jesus', u'embodied', u'New', u'Testament', u'emphasizing', u'role', u'Jesus', u'savior', u'particular', u'society', u'particular', u'time', u'place', u'basic', u'unit', u'length', u'adopted', u'Systeme', u'International', u"d'Unites", u'approximately', u'1.094', u'yards', u'special', u'offering', u'usually', u'temporary', u'reduced', u'price', u'featured', u'advertising', u'pertaining', u'characteristic', u'Judaism', u'precise', u'explicit', u'clearly', u'defined', u'line', u'determining', u'limits', u'area', u'commercial', u'industrial', u'enterprise', u'people', u'constitute', u'prominent', u'status', u'person', u'thing', u'equal', u'another', u'value', u'measure', u'force', u'effect', u'significance', u'etc', u'soft', u'silvery-white', u'tetravalent', u'radioactive', u'metallic', u'element', u'isotope', u'232', u'used', u'power', u'source', u'nuclear', u'reactors', u'occurs', u'thorite', u'monazite', u'sands', u'feeling', u'liking', u'something', u'someone', u'good', u'give', u'something', u'useful', u'necessary', u'extended', u'spatial', u'location', u'something', u'heading', u'names', u'statute', u'legislative', u'bill', u'give', u'brief', u'summary', u'matters', u'deals', u'person', u'equal', u'standing', u'another', u'group', u'linear', u'extent', u'space', u'one', u'end', u'longest', u'dimension', u'something', u'fixed', u'place', u'issue', u'terminate', u'specified', u'way', u'state', u'etc', u'end', u'legal', u'document', u'codifying', u'result', u'deliberations', u'committee', u'society', u'legislative', u'body', u'military', u'engagement', u'something', u'including', u'component', u'elements', u'parts', u'commercial', u'industrial', u'enterprise', u'people', u'constitute', u'cardinal', u'number', u'product', u'10', u'100', u'previous', u'time', u'amount', u'time', u'high', u'degree', u'extent', u'favorably', u'much', u'respect', u'act', u'process', u'producing', u'something', u'vague', u'clearly', u'defined', u'stated', u'division', u'quantity', u'accepted', u'standard', u'measurement', u'exchange', u'large', u'densely', u'populated', u'urban', u'area', u'include', u'several', u'independent', u'administrative', u'districts', u'act', u'using', u'process', u'taking', u'food', u'body', u'mouth', u'eating', u'lying', u'toward', u'situated', u'east', u'large', u'unbroken', u'expanse', u'distance', u'bishop', u'highest', u'rank', u'instrumentality', u'combines', u'interrelated', u'interacting', u'artifacts', u'designed', u'work', u'coherent', u'entity', u'five', u'related', u'nonmetallic', u'elements', u'fluorine', u'chlorine', u'bromine', u'iodine', u'astatine', u'monovalent', u'readily', u'form', u'negative', u'ions', u'continuing', u'time', u'space', u'without', u'interruption', u'film', u'life', u'western', u'United', u'States', u'period', u'exploration', u'development', u'fact', u'part', u'opposed', u'general', u'assumption', u'taken', u'granted', u'category', u'things', u'distinguished', u'common', u'characteristic', u'quality', u'worker', u'holds', u'invested', u'office', u'man', u'older', u'higher', u'rank', u'one', u'groups', u'Christians', u'beliefs', u'forms', u'worship', u'statistics', u'arrangement', u'values', u'variable', u'showing', u'observed', u'theoretical', u'frequency', u'occurrence', u'something', u'owned', u'tangible', u'intangible', u'possession', u'owned', u'someone', u'mark', u'different', u'function', u'topological', u'space', u'gives', u'two', u'points', u'space', u'value', u'equal', u'distance', u'usually', u'describes', u'large', u'person', u'fat', u'large', u'frame', u'carry', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions', u'general', u'officer', u'highest', u'rank', u'senior', u'member', u'Christian', u'clergy', u'spiritual', u'administrative', u'authority', u'appointed', u'Christian', u'churches', u'oversee', u'priests', u'ministers', u'considered', u'churches', u'successors', u'twelve', u'Apostles', u'Christ', u'movable', u'possession', u'especially', u'articles', u'clothing', u'owned', u'possession', u'heavy', u'toxic', u'silvery-white', u'radioactive', u'metallic', u'element', u'occurs', u'many', u'isotopes', u'used', u'nuclear', u'fuels', u'nuclear', u'weapons', u'orderly', u'grouping', u'things', u'persons', u'considered', u'unit', u'result', u'arranging', u'something', u'less', u'whole', u'human', u'artifact', u'act', u'delivering', u'formal', u'spoken', u'communication', u'audience', u'relating', u'science', u'geography', u'pertaining', u'involving', u'nature', u'space', u'advertisement', u'usually', u'printed', u'page', u'leaflet', u'intended', u'wide', u'distribution', u'commodities', u'offered', u'sale', u'put', u'service', u'make', u'work', u'employ', u'particular', u'purpose', u'inherent', u'natural', u'purpose', u'normal', u'conditions', u'particular', u'point', u'time', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions', u'one', u'several', u'parts', u'pieces', u'fit', u'others', u'constitute', u'whole', u'object', u'exhibiting', u'caused', u'radioactivity', u'event', u'happens', u'trace', u'point', u'whose', u'direction', u'motion', u'changes', u'mentally', u'emotionally', u'stable', u'abstract', u'part', u'something', u'human', u'general', u'estimation', u'public', u'person', u'instance', u'single', u'occasion', u'event', u'particular', u'portion', u'space', u'occupied', u'something', u'concept', u'something', u'magnitude', u'represented', u'mathematical', u'expressions', u'constant', u'variable'])
16/03/23 14:17:09 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/23 14:17:09 INFO DAGScheduler: Stopping DAGScheduler
16/03/23 14:17:09 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/23 14:17:09 INFO MemoryStore: MemoryStore cleared
16/03/23 14:17:09 INFO BlockManager: BlockManager stopped
16/03/23 14:17:09 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/23 14:17:09 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/23 14:17:09 INFO SparkContext: Successfully stopped SparkContext
16/03/23 14:17:09 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/23 14:17:09 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/23 14:17:09 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:tokensofthislevel: [u'individual', u'quantity', u'food', u'drink', u'taken', u'part', u'meal', u'state', u'southeastern', u'India', u'Bay', u'Bengal', u'south', u'Andhra', u'Pradesh', u'formerly', u'Madras', u'region', u'whose', u'eastern', u'part', u'Bangladesh', u'whose', u'western', u'part', u'included', u'India', u'education', u'imparted', u'series', u'lessons', u'meetings', u'act', u'sexual', u'procreation', u'man', u'woman', u'man', u'penis', u'inserted', u'woman', u'vagina', u'excited', u'orgasm', u'ejaculation', u'occur', u'study', u'earth', u'surface', u'includes', u'people', u'responses', u'topography', u'climate', u'soil', u'vegetation', u'number', u'entities', u'members', u'considered', u'unit', u'gradual', u'decrease', u'stored', u'charge', u'current', u'series', u'steps', u'carried', u'goals', u'accomplished', u'member', u'mixed', u'Dravidian', u'Caucasian', u'people', u'southern', u'India', u'Sri', u'Lanka', u'deviating', u'widely', u'norm', u'physical', u'mental', u'ability', u'used', u'especially', u'children', u'normal', u'intelligence', u'indentation', u'shoreline', u'larger', u'cove', u'smaller', u'gulf', u'come', u'idea', u'plan', u'explanation', u'theory', u'principle', u'mental', u'effort', u'sports', u'stroke', u'puts', u'ball', u'play', u'distinct', u'part', u'specified', u'separately', u'group', u'things', u'could', u'enumerated', u'list', u'unit', u'length', u'equal', u'1,760', u'yards', u'5,280', u'feet', u'exactly', u'1609.344', u'meters', u'lacking', u'stability', u'fixity', u'firmness', u'part', u'made', u'plural', u'group', u'human', u'beings', u'men', u'women', u'children', u'collectively', u'similar', u'things', u'placed', u'order', u'happening', u'one', u'another', u'monotheistic', u'system', u'beliefs', u'practices', u'based', u'Old', u'Testament', u'teachings', u'Jesus', u'embodied', u'New', u'Testament', u'emphasizing', u'role', u'Jesus', u'savior', u'particular', u'society', u'particular', u'time', u'place', u'basic', u'unit', u'length', u'adopted', u'Systeme', u'International', u"d'Unites", u'approximately', u'1.094', u'yards', u'special', u'offering', u'usually', u'temporary', u'reduced', u'price', u'featured', u'advertising', u'pertaining', u'characteristic', u'Judaism', u'precise', u'explicit', u'clearly', u'defined', u'line', u'determining', u'limits', u'area', u'commercial', u'industrial', u'enterprise', u'people', u'constitute', u'prominent', u'status', u'person', u'thing', u'equal', u'another', u'value', u'measure', u'force', u'effect', u'significance', u'etc', u'soft', u'silvery-white', u'tetravalent', u'radioactive', u'metallic', u'element', u'isotope', u'232', u'used', u'power', u'source', u'nuclear', u'reactors', u'occurs', u'thorite', u'monazite', u'sands', u'feeling', u'liking', u'something', u'someone', u'good', u'give', u'something', u'useful', u'necessary', u'extended', u'spatial', u'location', u'something', u'heading', u'names', u'statute', u'legislative', u'bill', u'give', u'brief', u'summary', u'matters', u'deals', u'person', u'equal', u'standing', u'another', u'group', u'linear', u'extent', u'space', u'one', u'end', u'longest', u'dimension', u'something', u'fixed', u'place', u'issue', u'terminate', u'specified', u'way', u'state', u'etc', u'end', u'legal', u'document', u'codifying', u'result', u'deliberations', u'committee', u'society', u'legislative', u'body', u'military', u'engagement', u'something', u'including', u'component', u'elements', u'parts', u'commercial', u'industrial', u'enterprise', u'people', u'constitute', u'cardinal', u'number', u'product', u'10', u'100', u'previous', u'time', u'amount', u'time', u'high', u'degree', u'extent', u'favorably', u'much', u'respect', u'act', u'process', u'producing', u'something', u'vague', u'clearly', u'defined', u'stated', u'division', u'quantity', u'accepted', u'standard', u'measurement', u'exchange', u'large', u'densely', u'populated', u'urban', u'area', u'include', u'several', u'independent', u'administrative', u'districts', u'act', u'using', u'process', u'taking', u'food', u'body', u'mouth', u'eating', u'lying', u'toward', u'situated', u'east', u'large', u'unbroken', u'expanse', u'distance', u'bishop', u'highest', u'rank', u'instrumentality', u'combines', u'interrelated', u'interacting', u'artifacts', u'designed', u'work', u'coherent', u'entity', u'five', u'related', u'nonmetallic', u'elements', u'fluorine', u'chlorine', u'bromine', u'iodine', u'astatine', u'monovalent', u'readily', u'form', u'negative', u'ions', u'continuing', u'time', u'space', u'without', u'interruption', u'film', u'life', u'western', u'United', u'States', u'period', u'exploration', u'development', u'fact', u'part', u'opposed', u'general', u'assumption', u'taken', u'granted', u'category', u'things', u'distinguished', u'common', u'characteristic', u'quality', u'worker', u'holds', u'invested', u'office', u'man', u'older', u'higher', u'rank', u'one', u'groups', u'Christians', u'beliefs', u'forms', u'worship', u'statistics', u'arrangement', u'values', u'variable', u'showing', u'observed', u'theoretical', u'frequency', u'occurrence', u'something', u'owned', u'tangible', u'intangible', u'possession', u'owned', u'someone', u'mark', u'different', u'function', u'topological', u'space', u'gives', u'two', u'points', u'space', u'value', u'equal', u'distance', u'usually', u'describes', u'large', u'person', u'fat', u'large', u'frame', u'carry', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions', u'general', u'officer', u'highest', u'rank', u'senior', u'member', u'Christian', u'clergy', u'spiritual', u'administrative', u'authority', u'appointed', u'Christian', u'churches', u'oversee', u'priests', u'ministers', u'considered', u'churches', u'successors', u'twelve', u'Apostles', u'Christ', u'movable', u'possession', u'especially', u'articles', u'clothing', u'owned', u'possession', u'heavy', u'toxic', u'silvery-white', u'radioactive', u'metallic', u'element', u'occurs', u'many', u'isotopes', u'used', u'nuclear', u'fuels', u'nuclear', u'weapons', u'orderly', u'grouping', u'things', u'persons', u'considered', u'unit', u'result', u'arranging', u'something', u'less', u'whole', u'human', u'artifact', u'act', u'delivering', u'formal', u'spoken', u'communication', u'audience', u'relating', u'science', u'geography', u'pertaining', u'involving', u'nature', u'space', u'advertisement', u'usually', u'printed', u'page', u'leaflet', u'intended', u'wide', u'distribution', u'commodities', u'offered', u'sale', u'put', u'service', u'make', u'work', u'employ', u'particular', u'purpose', u'inherent', u'natural', u'purpose', u'normal', u'conditions', u'particular', u'point', u'time', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions', u'one', u'several', u'parts', u'pieces', u'fit', u'others', u'constitute', u'whole', u'object', u'exhibiting', u'caused', u'radioactivity', u'event', u'happens', u'trace', u'point', u'whose', u'direction', u'motion', u'changes', u'mentally', u'emotionally', u'stable', u'abstract', u'part', u'something', u'human', u'general', u'estimation', u'public', u'person', u'instance', u'single', u'occasion', u'event', u'particular', u'portion', u'space', u'occupied', u'something', u'concept', u'something', u'magnitude', u'represented', u'mathematical', u'expressions', u'constant', u'variable']
prevlevelsynsets: [Synset('city.n.01'), Synset('use.n.01'), Synset('consumption.n.01'), Synset('eastern.s.01'), Synset('stretch.n.01'), Synset('helping.n.01'), Synset('archbishop.n.01'), Synset('tamil_nadu.n.01'), Synset('bengal.n.01'), Synset('system.n.01'), Synset('halogen.n.01'), Synset('continuous.a.01'), Synset('western.n.01'), Synset('course.n.01'), Synset('sexual_intercourse.n.01'), Synset('geography.n.01'), Synset('particular.n.01'), Synset('group.n.01'), Synset('decay.n.01'), Synset('given.n.01'), Synset('plan.n.01'), Synset('kind.n.01'), Synset('tamil.n.01'), Synset('exceeding.s.01'), Synset('official.n.01'), Synset('patriarch.n.01'), Synset('church.n.01'), Synset('distribution.n.01'), Synset('bay.n.01'), Synset('invent.v.01'), Synset('property.n.01'), Synset('distinguish.v.01'), Synset('serve.n.01'), Synset('metric_function.n.01'), Synset('item.n.01'), Synset('mile.n.01'), Synset('unstable.a.01'), Synset('include.v.01'), Synset('fleshy.s.01'), Synset('people.n.01'), Synset('purpose.n.01'), Synset('general.n.01'), Synset('series.n.01'), Synset('christianity.n.01'), Synset('bishop.n.01'), Synset('culture.n.01'), Synset('meter.n.01'), Synset('things.n.01'), Synset('special.n.01'), Synset('belong.v.01'), Synset('uranium.n.01'), Synset('agreement.n.04'), Synset('orthodox.a.01'), Synset('definite.a.01'), Synset('boundary.n.01'), Synset('part.n.01'), Synset('business.n.01'), Synset('address.n.01'), Synset('importance.n.01'), Synset('equivalent.n.01'), Synset('thorium.n.01'), Synset('blessing.n.01'), Synset('geographic.a.01'), Synset('supply.n.01'), Synset('spatial.a.01'), Synset('region.n.01'), Synset('title.n.01'), Synset('circular.n.01'), Synset('merchandise.n.01'), Synset('peer.n.01'), Synset('use.n.01'), Synset('length.n.01'), Synset('normally.r.01'), Synset('consequence.n.01'), Synset('moment.n.01'), Synset('purpose.n.01'), Synset('section.n.01'), Synset('radioactive.a.01'), Synset('act.n.01'), Synset('happening.n.01'), Synset('curve.n.01'), Synset('military_action.n.01'), Synset('whole.n.01'), Synset('business.n.01'), Synset('together.s.01'), Synset('component.n.01'), Synset('thousand.n.01'), Synset('once.r.01'), Synset('person.n.01'), Synset('repute.n.01'), Synset('time_period.n.01'), Synset('highly.r.01'), Synset('time.n.01'), Synset('production.n.01'), Synset('indefinite.a.01'), Synset('position.n.01'), Synset('unit_of_measurement.n.01'), Synset('measure.n.02')]
defaultdict(<type 'list'>, {u'serving': [u'None', u'area', u'area'], u'Madras': [u'None', u'Chennai', u'None', u'Chennai'], u'Bengal': [u'None', u'Chennai', u'None', u'Chennai'], u'course': [u'None', u'None', u'planning'], u'relation': [u'None', u'None', u'composition'], u'geography': [u'None', u'area', u'area'], u'group': [u'set', u'None'], u'decay': [u'None', u'astatine', u'None'], u'halogen': [u'None', u'astatine', u'None'], u'Tamil': [u'None', u'Chennai', u'None', u'Chennai'], u'exceptional': [u'None', u'giant', u'None'], u'Bay': [u'None', u'Chennai', u'None', u'Chennai'], u'formulating': [u'None', u'None', u'planning'], u'serves': [u'None', u'None', u'agency'], u'item': [u'None', u'None'], u'miles': [u'None', u'kilometer', u'None', u'kilometer'], u'unstable': [u'None', u'astatine', u'None'], u'including': [u'None', u'present', u'None'], u'people': [u'None', u'area', u'area'], u'series': [u'None', u'astatine', u'None'], u'Christianity': [u'None', u'metropolitan', u'None'], u'culture': [u'None', u'area', u'area'], u'meters': [u'None', u'kilometer', u'None', u'kilometer'], u'special': [u'None', u'area', u'area'], u'0.621371': [u'None', u'kilometer', u'None', u'kilometer'], u'Orthodox': [u'None', u'metropolitan', u'None'], u'definite': [u'None', u'None', u'planning'], u'boundary': [u'None', u'area', u'area'], u'business': [u'None', u'None', u'agency'], u'importance': [u'None', u'giant', u'None'], u'equivalent': [u'None', u'metropolitan', u'None'], u'thorium': [u'None', u'astatine', u'None'], u'approval': [u'None', u'None', u'permission'], u'providing': [u'None', u'None'], u'region': [u'None', u'area', u'area'], u'title': [u'None', u'metropolitan', u'None'], u'equal': [u'None', u'kilometer', u'None', u'kilometer'], u'length': [u'None', u'kilometer', u'None', u'kilometer'], u'resulting': [u'None', u'None', u'composition'], u'act': [u'None', u'None', u'planning'], u'action': [u'None', u'None', u'planning'], u'whole': [u'None', u'None', u'composition'], u'businesses': [u'None', u'None', u'agency'], u'1000': [u'None', u'kilometer', u'None', u'kilometer'], u'formerly': [u'None', u'Chennai', u'None', u'Chennai'], u'period': [u'None', u'present', u'None'], u'highly': [u'None', u'astatine', u'None'], u'production': [u'None', u'None', u'economy'], u'indefinite': [u'None', u'area', u'area'], u'unit': [u'None', u'kilometer', u'None', u'kilometer'], u'city': [u'None', u'Chennai', u'None', u'Chennai'], u'use': [u'None', u'None'], u'consumption': [u'None', u'None', u'economy'], u'Eastern': [u'None', u'metropolitan', u'None'], u'stretch': [u'None', u'present', u'None'], u'archbishop': [u'None', u'metropolitan', u'None'], u'system': [u'None', u'None', u'economy'], u'program': [u'None', u'None', u'planning'], u'continuous': [u'None', u'present', u'None'], u'western': [u'None', u'metropolitan', u'None'], u'particular': [u'None', u'area', u'area'], u'given': [u'None', u'metropolitan', u'None'], u'kind': [u'set', u'None'], u'official': [u'None', u'None'], u'patriarch': [u'None', u'metropolitan', u'None'], u'Church': [u'None', u'metropolitan', u'None'], u'distribution': [u'None', u'None', u'economy'], u'property': [u'None', u'None', u'composition'], u'distinguished': [u'None', u'area', u'area'], u'metric': [u'None', u'kilometer', u'None', u'kilometer'], u'heaviest': [u'None', u'astatine', u'None'], u'purposes': [u'None', u'None'], u'general': [u'None', u'None'], u'something': [u'None', u'None', u'permission'], u'bishop': [u'None', u'metropolitan', u'None'], u'things': [u'set', u'None'], u'belong': [u'set', u'None'], u'uranium': [u'None', u'astatine', u'None'], u'arrangement': [u'None', u'None', u'composition'], u'parts': [u'None', u'None', u'composition'], u'speech': [u'None', u'present', u'None'], u'geographical': [u'None', u'area', u'area'], u'spatial': [u'None', u'None', u'composition'], u'Nadu': [u'None', u'Chennai', u'None', u'Chennai'], u'circular': [u'bend', u'None'], u'product': [u'None', u'astatine', u'None'], u'used': [u'set', u'None'], u'usually': [u'None', u'area', u'area'], u'moment': [u'None', u'present', u'None'], u'purpose': [u'None', u'area', u'area'], u'segment': [u'bend', u'None'], u'radioactive': [u'None', u'astatine', u'None'], u'happening': [u'None', u'present', u'None'], u'curve': [u'bend', u'None'], u'together': [u'set', u'None'], u'element': [u'None', u'astatine', u'None'], u'person': [u'None', u'giant', u'None'], u'reputation': [u'None', u'giant', u'None'], u'time': [u'None', u'present', u'None'], u'position': [u'None', u'metropolitan', u'None'], u'quantity': [u'None', u'None']})
ksynset= Synset('helping.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('helping.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('helping.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('course.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('course.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('course.n.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('relation.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('relation.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('relation.n.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('group.n.01')
lsynset= Synset('set.n.01')
ksynset= Synset('group.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('decay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('decay.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('decay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('halogen.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('halogen.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('halogen.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('exceeding.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('exceeding.s.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('exceeding.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('explicate.v.02')
lsynset= Synset('none.n.01')
ksynset= Synset('explicate.v.02')
lsynset= Synset('none.n.01')
ksynset= Synset('explicate.v.02')
lsynset= Synset('planning.n.01')
ksynset= Synset('serve.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('serve.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('serve.n.01')
lsynset= Synset('agency.n.01')
ksynset= Synset('item.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('item.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('unstable.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unstable.a.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('unstable.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('include.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('include.v.01')
lsynset= Synset('present.n.01')
ksynset= Synset('include.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('series.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('series.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('series.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('definite.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('definite.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('definite.a.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('agency.n.01')
ksynset= Synset('importance.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('importance.n.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('importance.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thorium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thorium.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('thorium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('blessing.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('blessing.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('blessing.n.01')
lsynset= Synset('permission.n.01')
ksynset= Synset('supply.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('supply.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('result.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('result.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('result.v.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('act.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('act.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('act.n.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('action.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('action.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('action.n.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('whole.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('whole.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('whole.n.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('agency.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('none.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('chennai.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('none.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('chennai.n.01')
ksynset= Synset('time_period.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time_period.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('time_period.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('highly.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('highly.r.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('highly.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('production.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('production.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('production.n.01')
lsynset= Synset('economy.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('use.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('use.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('consumption.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('consumption.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('consumption.n.01')
lsynset= Synset('economy.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('stretch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('stretch.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('stretch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('system.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('system.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('system.n.01')
lsynset= Synset('economy.n.01')
ksynset= Synset('plan.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('plan.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('plan.n.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('continuous.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('continuous.a.01')
lsynset= Synset('present.n.01')
ksynset= Synset('continuous.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('kind.n.01')
lsynset= Synset('set.n.01')
ksynset= Synset('kind.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('official.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('official.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distribution.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distribution.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distribution.n.01')
lsynset= Synset('economy.n.01')
ksynset= Synset('property.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('property.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('property.n.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('area.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('area.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('heavy.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('heavy.a.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('heavy.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('general.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('general.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('things.n.01')
lsynset= Synset('set.n.01')
ksynset= Synset('things.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('belong.v.01')
lsynset= Synset('set.n.01')
ksynset= Synset('belong.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('uranium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('uranium.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('uranium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('agreement.n.04')
lsynset= Synset('none.n.01')
ksynset= Synset('agreement.n.04')
lsynset= Synset('none.n.01')
ksynset= Synset('agreement.n.04')
lsynset= Synset('composition.n.01')
ksynset= Synset('parts.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('parts.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('parts.n.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('address.n.03')
lsynset= Synset('none.n.01')
ksynset= Synset('address.n.03')
lsynset= Synset('present.n.01')
ksynset= Synset('address.n.03')
lsynset= Synset('none.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('spatial.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('spatial.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('spatial.a.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('circular.n.01')
lsynset= Synset('bend.n.01')
ksynset= Synset('circular.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('use.v.01')
lsynset= Synset('set.n.01')
ksynset= Synset('use.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('area.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('area.n.01')
ksynset= Synset('moment.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('moment.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('moment.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('section.n.04')
lsynset= Synset('bend.n.01')
ksynset= Synset('section.n.04')
lsynset= Synset('none.n.01')
ksynset= Synset('radioactive.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('radioactive.a.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('radioactive.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('happening.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('happening.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('happening.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('curve.n.01')
lsynset= Synset('bend.n.01')
ksynset= Synset('curve.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('together.s.01')
lsynset= Synset('set.n.01')
ksynset= Synset('together.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('repute.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('repute.n.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('repute.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('time.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('measure.n.02')
lsynset= Synset('none.n.01')
ksynset= Synset('measure.n.02')
lsynset= Synset('none.n.01')
Core number (sorted) : [(u'area', 13), (u'metropolitan', 12), (u'astatine', 11), (u'kilometer', 8), (u'present', 8), (u'Chennai', 7), (u'composition', 7), (u'planning', 6), (u'set', 6), (u'giant', 4), (u'economy', 4), (u'bend', 3), (u'agency', 3), (u'serving', 2), (u'Madras', 2), (u'Bengal', 2), (u'course', 2), (u'relation', 2), (u'geography', 2), (u'group', 2), (u'title', 2), (u'halogen', 2), (u'Tamil', 2), (u'permission', 2), (u'Bay', 2), (u'formulating', 2), (u'serves', 2), (u'miles', 2), (u'unstable', 2), (u'including', 2), (u'people', 2), (u'series', 2), (u'Christianity', 2), (u'culture', 2), (u'meters', 2), (u'special', 2), (u'0.621371', 2), (u'Orthodox', 2), (u'definite', 2), (u'boundary', 2), (u'business', 2), (u'importance', 2), (u'equivalent', 2), (u'thorium', 2), (u'approval', 2), (u'region', 2), (u'decay', 2), (u'equal', 2), (u'length', 2), (u'resulting', 2), (u'act', 2), (u'action', 2), (u'whole', 2), (u'businesses', 2), (u'1000', 2), (u'formerly', 2), (u'period', 2), (u'highly', 2), (u'production', 2), (u'indefinite', 2), (u'unit', 2), (u'city', 2), (u'given', 2), (u'consumption', 2), (u'stretch', 2), (u'archbishop', 2), (u'system', 2), (u'program', 2), (u'exceptional', 2), (u'continuous', 2), (u'western', 2), (u'particular', 2), (u'kind', 2), (u'patriarch', 2), (u'Eastern', 2), (u'Church', 2), (u'distribution', 2), (u'property', 2), (u'distinguished', 2), (u'something', 2), (u'metric', 2), (u'heaviest', 2), (u'bishop', 2), (u'things', 2), (u'belong', 2), (u'uranium', 2), (u'arrangement', 2), (u'parts', 2), (u'speech', 2), (u'geographical', 2), (u'spatial', 2), (u'Nadu', 2), (u'circular', 2), (u'product', 2), (u'used', 2), (u'usually', 2), (u'moment', 2), (u'purpose', 2), (u'segment', 2), (u'radioactive', 2), (u'happening', 2), (u'curve', 2), (u'together', 2), (u'element', 2), (u'person', 2), (u'reputation', 2), (u'time', 2), (u'position', 2), (u'item', 0), (u'None', 0), (u'use', 0), (u'providing', 0), (u'official', 0), (u'purposes', 0), (u'general', 0), (u'quantity', 0)]
=============================================================================================================
Unsupervised Classification based on top percentile Core numbers of the definition graph(subgraph of WordNet)
=============================================================================================================
This document belongs to class: area ,core number= 13
This document belongs to class: metropolitan ,core number= 12
This document belongs to class: astatine ,core number= 11
This document belongs to class: kilometer ,core number= 8
This document belongs to class: present ,core number= 8
This document belongs to class: Chennai ,core number= 7
This document belongs to class: composition ,core number= 7
This document belongs to class: planning ,core number= 6
This document belongs to class: set ,core number= 6
This document belongs to class: giant ,core number= 4
This document belongs to class: economy ,core number= 4
This document belongs to class: bend ,core number= 3
This document belongs to class: agency ,core number= 3
max_core_number 13
===================================================================
Page Rank of the vertices of RGO Definition Graph
===================================================================
[(u'area', 0.05964397617197671), (u'metropolitan', 0.05543677058743772), (u'astatine', 0.051229565002898755), (u'kilometer', 0.03860794824928188), (u'present', 0.03860794824928188), (u'Chennai', 0.034400742664742925), (u'composition', 0.034400742664742925), (u'planning', 0.030193537080203968), (u'set', 0.030193537080203968), (u'giant', 0.021779125911126046), (u'economy', 0.02177912591112604), (u'agency', 0.01757192032658708), (u'bend', 0.017571920326587075), (u'permission', 0.013364714742048119), (u'approval', 0.0070539063652396775), (u'something', 0.0070539063652396775), (u'serves', 0.006352705434483184), (u'business', 0.006352705434483184), (u'businesses', 0.006352705434483184), (u'circular', 0.006352705434483183), (u'segment', 0.006352705434483183), (u'curve', 0.006352705434483183), (u'importance', 0.006002104969104938), (u'production', 0.006002104969104938), (u'consumption', 0.006002104969104938), (u'system', 0.006002104969104938), (u'distribution', 0.006002104969104938), (u'exceptional', 0.006002104969104938), (u'person', 0.006002104969104938), (u'reputation', 0.006002104969104938), (u'course', 0.0056515045037266905), (u'group', 0.0056515045037266905), (u'program', 0.0056515045037266905), (u'formulating', 0.0056515045037266905), (u'definite', 0.0056515045037266905), (u'act', 0.0056515045037266905), (u'action', 0.0056515045037266905), (u'belong', 0.0056515045037266905), (u'kind', 0.0056515045037266905), (u'things', 0.0056515045037266905), (u'used', 0.0056515045037266905), (u'together', 0.0056515045037266905), (u'Madras', 0.005551332942190048), (u'Bengal', 0.005551332942190048), (u'relation', 0.005551332942190048), (u'Tamil', 0.005551332942190048), (u'Bay', 0.005551332942190048), (u'resulting', 0.005551332942190048), (u'whole', 0.005551332942190048), (u'formerly', 0.005551332942190048), (u'city', 0.005551332942190048), (u'property', 0.005551332942190048), (u'arrangement', 0.005551332942190048), (u'parts', 0.005551332942190048), (u'spatial', 0.005551332942190048), (u'Nadu', 0.005551332942190048), (u'miles', 0.0054762042710375675), (u'including', 0.0054762042710375675), (u'meters', 0.0054762042710375675), (u'0.621371', 0.0054762042710375675), (u'equal', 0.0054762042710375675), (u'length', 0.0054762042710375675), (u'1000', 0.0054762042710375675), (u'period', 0.0054762042710375675), (u'unit', 0.0054762042710375675), (u'stretch', 0.0054762042710375675), (u'continuous', 0.0054762042710375675), (u'metric', 0.0054762042710375675), (u'speech', 0.0054762042710375675), (u'moment', 0.0054762042710375675), (u'happening', 0.0054762042710375675), (u'time', 0.0054762042710375675), (u'unstable', 0.005332776807928284), (u'series', 0.005332776807928284), (u'thorium', 0.005332776807928284), (u'decay', 0.005332776807928284), (u'highly', 0.005332776807928284), (u'halogen', 0.005332776807928284), (u'heaviest', 0.005332776807928284), (u'uranium', 0.005332776807928284), (u'product', 0.005332776807928284), (u'radioactive', 0.005332776807928284), (u'element', 0.005332776807928284), (u'title', 0.005300904038348444), (u'Christianity', 0.005300904038348444), (u'Orthodox', 0.005300904038348444), (u'equivalent', 0.005300904038348444), (u'given', 0.005300904038348444), (u'archbishop', 0.005300904038348444), (u'western', 0.005300904038348444), (u'patriarch', 0.005300904038348444), (u'Eastern', 0.005300904038348444), (u'Church', 0.005300904038348444), (u'bishop', 0.005300904038348444), (u'position', 0.005300904038348444), (u'serving', 0.005273934771780889), (u'geography', 0.005273934771780889), (u'people', 0.005273934771780889), (u'culture', 0.005273934771780889), (u'special', 0.005273934771780889), (u'boundary', 0.005273934771780889), (u'region', 0.005273934771780889), (u'indefinite', 0.005273934771780889), (u'particular', 0.005273934771780889), (u'distinguished', 0.005273934771780889), (u'geographical', 0.005273934771780889), (u'usually', 0.005273934771780889), (u'purpose', 0.005273934771780889), (u'item', 0.001373626373626374), (u'None', 0.001373626373626374), (u'use', 0.001373626373626374), (u'providing', 0.001373626373626374), (u'official', 0.001373626373626374), (u'purposes', 0.001373626373626374), (u'general', 0.001373626373626374), (u'quantity', 0.001373626373626374)]
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - connectivity of RGO Definition Graph - Mengers Theorem
==========================================================================================================
0
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - Maxflow-Mincut of RGO Definition Graph - Minimum Edge Cut
==========================================================================================================
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - Maxflow-Mincut of RGO Definition Graph - Stoer-Wagner
==========================================================================================================
16/03/23 14:23:56 INFO ShutdownHookManager: Shutdown hook called
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-511d6b14-9cf4-4806-b73a-7b3a3ce4340c
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-2614c657-2d18-4c88-85f9-33d4bf07cc70
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-b41f108c-3ab5-4ac3-9bf1-8909d26572b2
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-6b894771-7685-442a-b6e0-38c5ace3e132
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-b5a3efd0-2222-4064-a7ee-226d6b6a2e7a
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-93bdffec-ebc4-4604-a1bb-8814ea93ad76
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-15620535-08ae-4965-b94d-27712ded4d7d
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-ba958b0e-3b0d-4022-a018-7f62ce0fa5f6
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-e9a1fe12-70e2-4e7d-8b92-b11b1f9a98a0
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-23005247-04fa-46d0-915e-08868ee849ea
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-961c4317-2b52-4538-840d-32f2316ee0f0
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-f6668dfc-e2ed-4a6e-9b63-e0360bc90796
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-b4a6f6a9-2b8b-40ec-9697-4753a95e0184
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-7627f55b-7707-4820-8bd5-d454fe382618
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-1f81ab48-4bd1-4a7b-8ec2-11f54b8c6af1
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-9b4a6dc5-613a-4d7b-a20f-4ddcd94e8cf1
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-c2677cc6-2f46-4e85-a770-05cf6b075ce1
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-bb0caa88-84e9-4a56-a313-134fb1f1470c
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-e765b345-4cc2-40be-8f1d-666e3e03e4d4
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-0440994e-a9dc-4e62-b6da-6070e2aeb890
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-fd0d44c7-cd02-49e3-9072-8665e859cd3d
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-dfadd155-015e-4b88-8647-dbf517fee470
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-c6709c22-60b8-428e-95cd-5626bcb61e8b
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-728c9065-2c92-4bc6-bb7a-c27433f9650c
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-2417d30d-c4e1-4ec5-9d56-cb5f455b217d
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-669773ad-3a72-4f05-afe5-60528e2011a9
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-d2de561b-7ecb-4168-908c-ca11164a79fe
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-6ce71b99-0ab2-4ad0-b875-baa4865c25ed
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-e760e638-0e3b-42ff-b12b-4dbbaccb56ac
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-d0c9f945-7518-45b8-88dc-36b0489059e5
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-c3f1927c-2cac-4c6c-89cf-12ed96f0b9d3
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-ba41905a-1208-4e89-9b99-f9975d80aef7
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-4df0a1f8-2e6e-46c1-ba33-8b51dce8b528
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-d8e4e41a-65ce-4009-b47f-746eebb8f7ef
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-2a076a21-c0ba-4d64-bd60-922975e01a85
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-a845d5e8-6f46-4722-9ff7-c5096606b7a9
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-554c58ea-fa92-4214-8dfd-2de545226829
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-53d167b1-7c6a-4866-9dd8-3f21c1dd4502
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-de7c2927-2197-4212-909c-1b96da59ba00
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-515fd42c-c063-4bf8-b412-f9c74add6523
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-6251df74-cf2a-40f8-8a8b-40d866ed728a
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-dcd032a2-cfef-442b-a8ab-b4724c4bbe19
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-6752bf2d-c39c-4d5d-acd7-5494f819bae2
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-76f6a71f-7fc1-4d59-8b70-f118cbc32ce6
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-e9b63b3d-4d99-49b5-bdc0-95177a232767
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-711a107e-2735-491b-ab8b-2510de0d7b04
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-87e04419-6426-4f46-8f52-6374d17524d4
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-cb272ae5-10f4-4e82-b843-f8f795427605
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-e525b607-39fb-4cf0-af1a-ba6baa8bb7b6
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-53314920-d3e5-40ee-8653-9a0529e7cab6
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-1fee7760-266a-4d92-b63c-0361fb9dfc6d
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-dc79d99b-6073-42e6-adf4-854ec6ccb492
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-7b99fcb8-332f-4cee-af7a-630f4075d8bb
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-9646b75a-16d6-4206-8828-7b53d205ada9
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-1a17c22b-42b1-4555-af8f-c57502b7f0bb
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-d6dc15d2-8e5c-45fd-ab20-d83ec399657c
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-d16e2771-d4aa-4426-b44b-d42f5642ef95
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-eeb57dad-7114-49bd-a9fb-6b5d85f003b9
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-997724d1-d847-4a3c-8b29-5717a3c971fe
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-030efe83-598d-4293-ba29-ae128d3a369c
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-7abf83d0-5c10-4eec-a0df-8edee3626b3c
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-5e9132b8-6b76-4008-b105-493ce4ae97a5
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-46bdeb27-1660-4f7a-a822-248e020af8e5
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-f8047b52-46a9-4c0f-97b2-d3b8db54930e
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-1ea011e0-deb2-4c5c-990c-ede77cfedaca
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-c2daed96-c49f-49b9-b678-1fd7489d238d
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-082789fe-afc0-4539-9d7c-e4407d46e727
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-d120565d-025a-468d-bcab-029f71395866
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-48968219-e015-436e-9f8d-9825d3dd4f94
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-ffad759a-4b0a-4cc5-88af-04702d3948c6
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-c9613aa1-52bb-454b-a696-21c731fb0b52
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-7e2d8f4b-a70c-4fd4-8971-c6716b87c0d2
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-94cd6486-2a4e-4bc0-bc5c-e07e3e75b387
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-9e77e2b5-7114-4879-9e7c-f580372c1754
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-dca70bf2-e538-4550-a36f-f674ed605f93
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-4571a38e-a418-47d9-8ef0-cb9fdc6d4328
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-5248f80d-3945-46e0-b0e3-723fe3dd5089
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-405c1572-abaa-4e40-91c6-036e6876947a
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-84c771a4-f7d3-487d-8d35-1075d749576e
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-264b66bf-882b-4472-9121-8bddd8e3463e
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-b62f6e28-529a-4186-b362-f6651f65621c
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-9809f641-37fd-4f57-8d01-4d5c44a55445
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-2ec75e15-d2d1-4c9f-8745-0f14e47e5fc8
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-dcca4ac7-4d99-4788-bbf5-c5e69007a540
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-f3fab86e-175f-4707-b44d-c676f3dbc57f
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2/pyspark-23452c79-f399-4fa3-a626-caa4bfa271d2
16/03/23 14:23:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-458b04f1-77d4-417a-8866-4988e85d7af2

