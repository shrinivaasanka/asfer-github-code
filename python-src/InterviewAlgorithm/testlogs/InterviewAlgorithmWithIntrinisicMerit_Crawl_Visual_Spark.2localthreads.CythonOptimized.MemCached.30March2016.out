mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: used
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'natural', u'for', u'service', u'into', u'work', u'or', u'employ', u'purpose', u'particular', u'put', u'inherent', u';', u'its', u'make'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: meters
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u"d'Unites", u'Systeme', u')', u'of', u'under', u'adopted', u'length', u'(', u'yards', u'basic', u'approximately', u'International', u'the', u'unit', u'1.094'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: special
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: 0.621371
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: Orthodox
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'pertaining', u'Judaism', u'characteristic', u'to', u'of', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: purpose
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'your', u'an', u'intended', u'that', u'is', u'actions', u'anticipated', u'planned', u'outcome', u'guides', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: learned
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'be', u'certain', u'student', u'of', u'subject'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: degree
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'on', u'scale', u'of', u'amount', u'intensity', u'position', u'quality', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: importance
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'status', u'prominent'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: equivalent
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: attention
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'on', u')', u'whereby', u'to', u'process', u'of', u'relative', u'others', u'some', u'exclusion', u'environment', u'person', u'(', u'concentrates', u'the', u'features'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: component
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'of', u'abstract', u'part', u'something', u'an'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: thorium
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'and', u'thorite', u'is', u'as', u'used', u'sands', u'in', u'232', u'monazite', u'nuclear', u'metallic', u'source', u'silvery-white', u';', u'occurs', u'tetravalent', u'power', u'isotope', u'a', u'radioactive', u'element', u'soft', u'reactors'])
mapFunction_Parents(): adding to parents: syn =  Synset('thorium.n.01') ; keyword:  element  in syndef_tokens= set([u'and', u'thorite', u'is', u'as', u'used', u'sands', u'in', u'232', u'monazite', u'nuclear', u'metallic', u'source', u'silvery-white', u';', u'occurs', u'tetravalent', u'power', u'isotope', u'a', u'radioactive', u'element', u'soft', u'reactors'])
mapFunction_Parents(): returns= [u'thorium']
reduceFunction_Parents(): returns= ['None', u'astatine', u'thorium']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: clarify
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'and', u')', u'(', u'make', u'comprehensible', u'clear', u'more'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine', u'thorium']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: densely
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'stupid', u'manner', u'in'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine', u'thorium']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: conceal
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'prevent', u'from', u'being', u'discovered', u'seen', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine', u'thorium']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: region
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'extended', u'of', u'something', u'spatial', u'the', u'location'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine', u'thorium']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: title
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'statute', u'give', u'that', u'may', u'of', u'the', u'bill', u'brief', u'heading', u'deals', u'matters', u'names', u'it', u';', u'summary', u'with', u'or', u'legislative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine', u'thorium']
16/03/30 11:03:21 INFO PythonRunner: Times: total = 9729, boot = 500, init = 422, finish = 8807
16/03/30 11:03:21 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/30 11:03:21 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) finished in 9.819 s
16/03/30 11:03:21 INFO DAGScheduler: looking for newly runnable stages
16/03/30 11:03:21 INFO DAGScheduler: running: Set()
16/03/30 11:03:21 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/30 11:03:21 INFO DAGScheduler: failed: Set()
16/03/30 11:03:21 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/30 11:03:21 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218), which is now runnable
16/03/30 11:03:21 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=12524, maxMem=555472650
16/03/30 11:03:21 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 529.7 MB)
16/03/30 11:03:21 INFO MemoryStore: ensureFreeSpace(3058) called with curMem=17508, maxMem=555472650
16/03/30 11:03:21 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 529.7 MB)
16/03/30 11:03:21 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:59765 (size: 3.0 KB, free: 529.7 MB)
16/03/30 11:03:21 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/30 11:03:21 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:03:21 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/30 11:03:21 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9817 ms on localhost (2/2)
16/03/30 11:03:21 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/30 11:03:21 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/30 11:03:21 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/30 11:03:21 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/30 11:03:21 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/30 11:03:21 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/30 11:03:21 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/30 11:03:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/30 11:03:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
reduceFunction_Parents(): returns= ['None', u'astatine', u'thorium', 'None', u'uranium']
16/03/30 11:03:21 INFO PythonRunner: Times: total = 45, boot = -342, init = 386, finish = 1
16/03/30 11:03:21 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1312 bytes result sent to driver
16/03/30 11:03:21 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 122 ms on localhost (1/2)
16/03/30 11:03:21 INFO PythonRunner: Times: total = 282, boot = 281, init = 0, finish = 1
16/03/30 11:03:21 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/30 11:03:21 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 296 ms on localhost (2/2)
16/03/30 11:03:21 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) finished in 0.281 s
16/03/30 11:03:21 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218, took 10.150632 s
16/03/30 11:03:21 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/30 11:03:21 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218
16/03/30 11:03:21 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) with 2 output partitions
16/03/30 11:03:21 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:03:21 INFO DAGScheduler: Parents of final stage: List()
16/03/30 11:03:21 INFO DAGScheduler: Missing parents: List()
16/03/30 11:03:21 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218), which has no missing parents
16/03/30 11:03:21 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=20566, maxMem=555472650
16/03/30 11:03:21 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 529.7 MB)
16/03/30 11:03:21 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=26382, maxMem=555472650
16/03/30 11:03:21 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 529.7 MB)
16/03/30 11:03:21 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:59765 (size: 3.3 KB, free: 529.7 MB)
16/03/30 11:03:21 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/30 11:03:21 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:03:21 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/30 11:03:21 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/30 11:03:21 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2393 bytes)
16/03/30 11:03:21 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/30 11:03:21 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/30 11:03:21 INFO PythonRunner: Times: total = 62, boot = -123, init = 185, finish = 0
16/03/30 11:03:21 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/30 11:03:21 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 70 ms on localhost (1/2)
16/03/30 11:03:21 INFO PythonRunner: Times: total = 128, boot = 128, init = 0, finish = 0
16/03/30 11:03:21 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1380 bytes result sent to driver
16/03/30 11:03:21 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 140 ms on localhost (2/2)
16/03/30 11:03:21 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/30 11:03:21 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) finished in 0.142 s
16/03/30 11:03:21 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218, took 0.166689 s
16/03/30 11:03:21 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/30 11:03:21 INFO DAGScheduler: Stopping DAGScheduler
16/03/30 11:03:22 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/30 11:03:22 INFO MemoryStore: MemoryStore cleared
16/03/30 11:03:22 INFO BlockManager: BlockManager stopped
16/03/30 11:03:22 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/30 11:03:22 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/30 11:03:22 INFO SparkContext: Successfully stopped SparkContext
16/03/30 11:03:22 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/30 11:03:22 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/30 11:03:22 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/30 11:03:22 WARN AkkaRpcEndpointRef: Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@29e24d,BlockManagerId(driver, localhost, 59896))] in 2 attempts
org.apache.spark.rpc.RpcTimeoutException: Recipient[Actor[akka://sparkDriver/user/HeartbeatReceiver#-73561832]] had already been terminated.. This timeout is controlled by spark.rpc.askTimeout
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcEnv.scala:214)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcEnv.scala:229)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcEnv.scala:225)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:33)
	at scala.util.Failure$$anonfun$recover$1.apply(Try.scala:185)
	at scala.util.Try$.apply(Try.scala:161)
	at scala.util.Failure.recover(Try.scala:185)
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:324)
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:324)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at org.spark-project.guava.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$1.execute(ExecutionContextImpl.scala:133)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40)
	at scala.concurrent.impl.Promise$DefaultPromise.scala$concurrent$impl$Promise$DefaultPromise$$dispatchOrAddCallback(Promise.scala:280)
	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:270)
	at scala.concurrent.Future$class.recover(Future.scala:324)
	at scala.concurrent.impl.Promise$DefaultPromise.recover(Promise.scala:153)
	at org.apache.spark.rpc.akka.AkkaRpcEndpointRef.ask(AkkaRpcEnv.scala:319)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:100)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:77)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:452)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:472)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:472)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:472)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1699)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:472)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: akka.pattern.AskTimeoutException: Recipient[Actor[akka://sparkDriver/user/HeartbeatReceiver#-73561832]] had already been terminated.
	at akka.pattern.AskableActorRef$.ask$extension(AskSupport.scala:132)
	at org.apache.spark.rpc.akka.AkkaRpcEndpointRef.ask(AkkaRpcEnv.scala:307)
	... 15 more
graphcache_mapreduce_parents updated: <memcache.Client object at 0xb0c00a1c>
asfer_pickle_string_dump(): picklef.write(): person
16/03/30 11:03:22 INFO SparkContext: Running Spark version 1.5.2
16/03/30 11:03:22 INFO SecurityManager: Changing view acls to: root
16/03/30 11:03:22 INFO SecurityManager: Changing modify acls to: root
16/03/30 11:03:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/30 11:03:22 INFO Slf4jLogger: Slf4jLogger started
16/03/30 11:03:22 INFO Remoting: Starting remoting
16/03/30 11:03:23 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:53317]
16/03/30 11:03:23 INFO Utils: Successfully started service 'sparkDriver' on port 53317.
16/03/30 11:03:23 INFO SparkEnv: Registering MapOutputTracker
16/03/30 11:03:23 INFO SparkEnv: Registering BlockManagerMaster
16/03/30 11:03:23 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-4278c7c9-a87c-493b-9919-5f019362b667
16/03/30 11:03:23 INFO MemoryStore: MemoryStore started with capacity 529.7 MB
16/03/30 11:03:23 INFO HttpFileServer: HTTP File server directory is /tmp/spark-0e0df6d9-7161-45bf-b9ec-cf9574d76f1c/httpd-f206a8fc-c1fc-49fa-81ad-e1d6de99bc44
16/03/30 11:03:23 INFO HttpServer: Starting HTTP Server
16/03/30 11:03:23 INFO Utils: Successfully started service 'HTTP file server' on port 57713.
16/03/30 11:03:23 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/30 11:03:23 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/30 11:03:23 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/30 11:03:23 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-0e0df6d9-7161-45bf-b9ec-cf9574d76f1c/userFiles-d7acffc3-5064-4f12-be06-b02c75292cd5/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/30 11:03:23 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1459316003410
16/03/30 11:03:23 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/30 11:03:23 INFO Executor: Starting executor ID driver on host localhost
16/03/30 11:03:23 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 48790.
16/03/30 11:03:23 INFO NettyBlockTransferService: Server created on 48790
16/03/30 11:03:23 INFO BlockManagerMaster: Trying to register BlockManager
16/03/30 11:03:23 INFO BlockManagerMasterEndpoint: Registering block manager localhost:48790 with 529.7 MB RAM, BlockManagerId(driver, localhost, 48790)
16/03/30 11:03:23 INFO BlockManagerMaster: Registered BlockManager
16/03/30 11:03:23 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218
16/03/30 11:03:23 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:03:23 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) with 2 output partitions
16/03/30 11:03:23 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:03:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/30 11:03:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/30 11:03:23 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218), which has no missing parents
16/03/30 11:03:23 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555472650
16/03/30 11:03:23 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 529.7 MB)
16/03/30 11:03:23 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555472650
16/03/30 11:03:23 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 529.7 MB)
16/03/30 11:03:23 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:48790 (size: 4.1 KB, free: 529.7 MB)
16/03/30 11:03:23 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/30 11:03:23 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:03:23 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/30 11:03:23 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 3229 bytes)
16/03/30 11:03:23 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 3348 bytes)
16/03/30 11:03:23 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/30 11:03:23 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1459316003410
16/03/30 11:03:23 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/30 11:03:23 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-0e0df6d9-7161-45bf-b9ec-cf9574d76f1c/userFiles-d7acffc3-5064-4f12-be06-b02c75292cd5/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/30 11:03:23 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/30 11:03:23 INFO MemoryStore: ensureFreeSpace(934) called with curMem=10732, maxMem=555472650
16/03/30 11:03:23 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 934.0 B, free 529.7 MB)
16/03/30 11:03:23 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:48790 (size: 934.0 B, free: 529.7 MB)
16/03/30 11:03:23 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/30 11:03:23 INFO MemoryStore: ensureFreeSpace(854) called with curMem=11666, maxMem=555472650
16/03/30 11:03:23 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 854.0 B, free 529.7 MB)
16/03/30 11:03:23 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:48790 (size: 854.0 B, free: 529.7 MB)
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: kilometer
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: length
16/03/30 11:03:25 WARN AkkaRpcEndpointRef: Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@29e24d,BlockManagerId(driver, localhost, 59896))] in 3 attempts
org.apache.spark.rpc.RpcTimeoutException: Recipient[Actor[akka://sparkDriver/user/HeartbeatReceiver#-73561832]] had already been terminated.. This timeout is controlled by spark.rpc.askTimeout
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcEnv.scala:214)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcEnv.scala:229)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcEnv.scala:225)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:33)
	at scala.util.Failure$$anonfun$recover$1.apply(Try.scala:185)
	at scala.util.Try$.apply(Try.scala:161)
	at scala.util.Failure.recover(Try.scala:185)
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:324)
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:324)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at org.spark-project.guava.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$1.execute(ExecutionContextImpl.scala:133)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40)
	at scala.concurrent.impl.Promise$DefaultPromise.scala$concurrent$impl$Promise$DefaultPromise$$dispatchOrAddCallback(Promise.scala:280)
	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:270)
	at scala.concurrent.Future$class.recover(Future.scala:324)
	at scala.concurrent.impl.Promise$DefaultPromise.recover(Promise.scala:153)
	at org.apache.spark.rpc.akka.AkkaRpcEndpointRef.ask(AkkaRpcEnv.scala:319)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:100)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:77)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:452)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:472)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:472)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:472)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1699)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:472)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: akka.pattern.AskTimeoutException: Recipient[Actor[akka://sparkDriver/user/HeartbeatReceiver#-73561832]] had already been terminated.
	at akka.pattern.AskableActorRef$.ask$extension(AskSupport.scala:132)
	at org.apache.spark.rpc.akka.AkkaRpcEndpointRef.ask(AkkaRpcEnv.scala:307)
	... 15 more
16/03/30 11:03:25 WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@29e24d,BlockManagerId(driver, localhost, 59896))]
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:118)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:77)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:452)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:472)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:472)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:472)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1699)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:472)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.rpc.RpcTimeoutException: Recipient[Actor[akka://sparkDriver/user/HeartbeatReceiver#-73561832]] had already been terminated.. This timeout is controlled by spark.rpc.askTimeout
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcEnv.scala:214)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcEnv.scala:229)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcEnv.scala:225)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:33)
	at scala.util.Failure$$anonfun$recover$1.apply(Try.scala:185)
	at scala.util.Try$.apply(Try.scala:161)
	at scala.util.Failure.recover(Try.scala:185)
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:324)
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:324)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at org.spark-project.guava.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$1.execute(ExecutionContextImpl.scala:133)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40)
	at scala.concurrent.impl.Promise$DefaultPromise.scala$concurrent$impl$Promise$DefaultPromise$$dispatchOrAddCallback(Promise.scala:280)
	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:270)
	at scala.concurrent.Future$class.recover(Future.scala:324)
	at scala.concurrent.impl.Promise$DefaultPromise.recover(Promise.scala:153)
	at org.apache.spark.rpc.akka.AkkaRpcEndpointRef.ask(AkkaRpcEnv.scala:319)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:100)
	... 14 more
Caused by: akka.pattern.AskTimeoutException: Recipient[Actor[akka://sparkDriver/user/HeartbeatReceiver#-73561832]] had already been terminated.
	at akka.pattern.AskableActorRef$.ask$extension(AskSupport.scala:132)
	at org.apache.spark.rpc.akka.AkkaRpcEndpointRef.ask(AkkaRpcEnv.scala:307)
	... 15 more
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'fixed', u'from', u'linear', u'space', u'of', u'is', u'that', u'one', u'to', u'other', u'place', u'longest', u'extent', u'in', u'end', u'the', u'dimension', u';', u'something'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: act
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'deliberations', u'legislative', u'of', u'body', u'legal', u'society', u'codifying', u'committee', u'the', u'document', u'or', u'result'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: usually
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'normal', u'conditions', u'under'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: 1000
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'10', u'product', u'that', u'of', u'is', u'number', u'cardinal', u'the', u'100'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: composed
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'of', u'the', u'substance', u'form'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: formerly
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: period
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'of', u'amount', u'time', u'an'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: highly
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'degree', u'favorably', u'high', u'to', u'much', u'extent', u'respect', u';', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: thick
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'of', u'surrounded', u'other', u'location', u'things', u'the', u'by', u'something'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: unit
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'division', u'or', u'exchange', u'of', u'standard', u'as', u'measurement', u'accepted', u'any', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: city
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: given
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: area
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: stretch
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'distance', u'expanse', u'large', u'or', u'unbroken'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: populated
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'be', u'of', u'or', u'live', u'inhabitant', u'in', u';', u'an', u'inhabit'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: way
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'obtained', u'end', u'achieved', u'is', u'an', u'how', u'result', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: enlarging
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: urban
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'city', u'populated', u'concerned', u'area', u'to', u'densely', u'relating', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: continuous
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'interruption', u'space', u'in', u'continuing', u'without', u'time', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: moment
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'point', u'in', u'time', u'particular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: western
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'about', u'United', u'development', u'of', u'life', u'period', u'States', u'exploration', u'western', u'in', u'during', u'the', u'film'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: particular
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'about', u')', u'(', u'some', u'general', u'to', u'as', u'part', u'opposed', u'fact'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: white
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'of', u'member', u'race', u'the', u'Caucasoid'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: kind
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'category', u'or', u'things', u'some', u'by', u'characteristic', u'common', u'of', u'quality', u'distinguished'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: administrative
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'for', u'of', u'responsible', u'administration', u'to', u'relating', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: work
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'directed', u'doing', u'something', u'activity', u'making', u'toward', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: patriarch
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'older', u'is', u'who', u'rank', u'yourself', u'in', u'higher', u'than', u'man'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: districts
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'off', u'for', u'region', u'purposes', u'marked', u'other', u'administrative', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Church
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'own', u'have', u'of', u'who', u'one', u'forms', u'their', u'groups', u'the', u'worship', u'beliefs', u'Christians'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: male
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'babies', u'to', u'who', u'sex', u'person', u'that', u'belongs', u'can', u'have', u'not', u'the'])
mapFunction_Parents(): adding to parents: syn =  Synset('male.n.02') ; keyword:  person  in syndef_tokens= set([u'a', u'babies', u'to', u'who', u'sex', u'person', u'that', u'belongs', u'can', u'have', u'not', u'the'])
mapFunction_Parents(): returns= [u'male']
reduceFunction_Parents(): returns= ['None', u'male']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: distinguished
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'as', u'different', u'mark'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: devise
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'real', u'of', u'will', u'property', u'disposing'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: expanding
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: metric
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'function', u'them', u'for', u'that', u'of', u'space', u'equal', u',', u'topological', u'two', u'to', u'points', u'value', u'in', u'between', u'the', u'distance', u'any', u'gives'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: heaviest
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'to', u'is', u'who', u'it', u'fat', u'large', u'person', u'describes', u'but', u'usually', u'carry', u'has', u'frame'])
mapFunction_Parents(): adding to parents: syn =  Synset('fleshy.s.01') ; keyword:  person  in syndef_tokens= set([u'a', u'to', u'is', u'who', u'it', u'fat', u'large', u'person', u'describes', u'but', u'usually', u'carry', u'has', u'frame'])
mapFunction_Parents(): returns= [u'heaviest']
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: something
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: concentration
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'given', u'strength', u'of', u'solution', u'number', u'volume', u'substance', u'molecules', u'in', u'the', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: bishop
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: containing
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'component', u'as', u'have', u'contain', u';', u'include', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: things
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'possession', u'articles', u'especially', u')', u'(', u'movable', u'of', u'clothing', u'any'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: make
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'kind', u'recognizable'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: belong
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'possession', u'be', u'of', u'owned', u'by', u'in', u';', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: uranium
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'heavy', u'fuels', u'used', u'radioactive', u'and', u'for', u'many', u'isotopes', u'metallic', u'weapons', u'silvery-white', u'in', u'toxic', u'nuclear', u';', u'element', u'occurs'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: discourse
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'extended', u'verbal', u'writing', u'speech', u'in', u'expression', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: parts
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'less', u'of', u'artifact', u'something', u'human', u'the', u'whole', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: speech
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'spoken', u'of', u'communication', u'delivering', u'to', u'audience', u'act', u'the', u'an', u'formal'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: details
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'be', u'from', u'that', u'considered', u'separately', u'part', u'can', u'small', u'the', u'whole'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: geographical
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: several
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'count', u'used', u')', u'(', u'or', u'number', u'but', u'an', u'3', u'2', u'nouns', u'of', u'not', u'many', u'indefinite', u'with', u'than', u'more'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: circular
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'on', u'or', u'intended', u'for', u'wide', u')', u'(', u'an', u'leaflet', u'printed', u'advertisement', u'in', u'usually', u'distribution', u'page'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: independent
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'especially', u')', u'(', u'uncommitted', u'person', u'neutral', u'in', u'politics', u'or'])
mapFunction_Parents(): adding to parents: syn =  Synset('mugwump.n.02') ; keyword:  person  in syndef_tokens= set([u'a', u'especially', u')', u'(', u'uncommitted', u'person', u'neutral', u'in', u'politics', u'or'])
mapFunction_Parents(): returns= [u'independent']
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest', u'independent']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: product
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest', u'independent']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: elements
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'the', u'elements', u')', u'(', u'of', u'violent', u'by', u'four', u'severe', u'weather', u'caused', u'action', u'as', u'or', u'viewed'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest', u'independent']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: shelter
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'from', u'privacy', u'that', u'danger', u'protection', u'provides', u'structure'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest', u'independent']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: possible
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'be', u'done', u'something', u'can', u'that'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest', u'independent']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: meaning
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'consequence', u'as', u'logical', u'have'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest', u'independent']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: plan
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'be', u'carried', u'series', u'to', u'accomplished', u'steps', u'goals', u'of', u'or', u'out'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest', u'independent']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: tract
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'body', u'some', u'that', u'of', u'serve', u'system', u'together', u'parts', u'purpose', u'particular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest', u'independent']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: improving
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'better', u'to', u'make'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest', u'independent']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: genital
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'of', u'or', u'to', u'external', u'relating', u'sex', u'organs', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest', u'independent']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: spermatozoa
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'gamete', u'reproductive', u'cell', u'the', u'male', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest', u'independent']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: account
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'description', u'of', u'events', u'past', u'record', u'narrative', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest', u'independent']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: segment
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'one', u'a', u'fit', u'that', u'of', u'object', u'pieces', u'constitute', u'to', u'parts', u'whole', u'others', u'several', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest', u'independent']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: radioactive
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'caused', u'exhibiting', u'radioactivity', u'or', u'by'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest', u'independent']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: happening
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'happens', u'that', u'event', u'an'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest', u'independent']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: curve
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'whose', u'direction', u'trace', u'point', u'of', u'motion', u'the', u'changes'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest', u'independent']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: together
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'emotionally', u'mentally', u'stable'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest', u'independent']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: element
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'of', u'abstract', u'part', u'something', u'an'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest', u'independent']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: person
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'being', u'human'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'male', u'heaviest', u'independent']
16/03/30 11:03:36 INFO PythonRunner: Times: total = 12609, boot = 496, init = 425, finish = 11688
16/03/30 11:03:36 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/30 11:03:36 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 12765 ms on localhost (1/2)
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: set
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: bend
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: semen
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'containing', u'that', u'ejaculated', u'thick', u'white', u'fluid', u'by', u'tract', u'genital', u'spermatozoa', u'male', u'the', u'is'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: giant
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): adding to parents: syn =  Synset('colossus.n.02') ; keyword:  person  in syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= [u'giant']
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: limit
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'degree', u'of', u'possible', u'something', u'the', u'greatest'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: area
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: astatine
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: set
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: present
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: area
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: dwell
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'about', u'moodily', u'anxiously', u'or', u'something', u'think'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: screen
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'be', u'for', u'pictures', u'projected', u'surface', u'silvered', u'viewing', u'can', u'white', u'where', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: city
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: whole
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'all', u'elements', u'of', u'component', u'or', u'parts', u'including', u'something', u'its'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: focus
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'on', u'of', u'energy', u'attention', u'or', u'something', u'the', u'concentration'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: plan
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'be', u'carried', u'series', u'to', u'accomplished', u'steps', u'goals', u'of', u'or', u'out'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: development
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'of', u'act', u'by', u'refining', u'expanding', u'improving', u'enlarging', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: elaborate
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: serving
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Madras
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: ejaculated
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'impulsively', u'utter'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Bengal
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'whose', u'and', u'Bangladesh', u'eastern', u'region', u'India', u'part', u'western', u'in', u'included', u'now', u'is'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: including
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'be', u'made', u'of', u',', u'up', u'as', u'part', u'have', u'out'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: geography
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: group
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u')', u'(', u'number', u'entities', u'as', u'considered', u'members', u'of', u'any', u'unit'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: decay
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'gradual', u'charge', u'current', u'as', u'stored', u'decrease', u'of', u';', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: writing
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'creating', u'of', u'written', u'act', u'the', u'works'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: add
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'disorders', u'mostly', u')', u'(', u'behavioral', u'boys', u'characterized', u'learning', u'in', u'by', u'condition'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: halogen
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'ions', u'all', u'iodine', u'related', u'are', u'astatine', u'any', u'fluorine', u'readily', u')', u'(', u'negative', u'elements', u'form', u'that', u'bromine', u'monovalent', u'five', u'chlorine', u'of', u'nonmetallic', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: include
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'be', u'made', u'of', u',', u'up', u'as', u'part', u'have', u'out'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: exceptional
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'ability', u'used', u'from', u'mental', u'normal', u'of', u'deviating', u'children', u'below', u'widely', u'in', u'intelligence', u';', u'especially', u'or', u'norm', u'physical'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: fluid
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'substance', u'room', u'that', u'is', u'fluid', u'pressure', u'at', u'temperature'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Bay
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'smaller', u'shoreline', u'gulf', u'of', u'larger', u'cove', u'but', u'an', u'indentation', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: boundary
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: covering
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'natural', u'that', u'object', u'covers', u'envelops', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: serves
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'play', u'ball', u'puts', u'that', u')', u'(', u'sports', u'stroke', u'in', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: large
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'for', u'garment', u'large', u'person', u'size'])
mapFunction_Parents(): adding to parents: syn =  Synset('large.n.01') ; keyword:  person  in syndef_tokens= set([u'a', u'for', u'garment', u'large', u'person', u'size'])
mapFunction_Parents(): returns= [u'large']
reduceFunction_Parents(): returns= ['None', u'giant', u'large']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: miles
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'1609.344', u'of', u'exactly', u'equal', u'1,760', u'feet', u'to', u'length', u'meters', u'5,280', u'yards', u';', u'or', u'unit'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant', u'large']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: unstable
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'stability', u'fixity', u'or', u'lacking', u'firmness'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant', u'large']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: people
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant', u'large']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: series
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'happening', u'things', u'after', u'order', u'placed', u'another', u'in', u'one', u'similar', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant', u'large']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: energy
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'energy', u'are', u'physical', u'capacity', u'ergs', u'joules', u'(', u'system', u'to', u'units', u';', u'do', u'thermodynamic', u'equivalent', u'a', u'of', u'work', u')', u'the', u'physics', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant', u'large']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: idea
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'personal', u'view'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant', u'large']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant', u'large']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: culture
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant', u'large']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: used
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'natural', u'for', u'service', u'into', u'work', u'or', u'employ', u'purpose', u'particular', u'put', u'inherent', u';', u'its', u'make'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant', u'large']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: meters
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u"d'Unites", u'Systeme', u')', u'of', u'under', u'adopted', u'length', u'(', u'yards', u'basic', u'approximately', u'International', u'the', u'unit', u'1.094'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant', u'large']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: special
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant', u'large']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: 0.621371
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant', u'large']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Orthodox
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'pertaining', u'Judaism', u'characteristic', u'to', u'of', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant', u'large']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: purpose
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'your', u'an', u'intended', u'that', u'is', u'actions', u'anticipated', u'planned', u'outcome', u'guides', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant', u'large']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: learned
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'be', u'certain', u'student', u'of', u'subject'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant', u'large']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: degree
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'on', u'scale', u'of', u'amount', u'intensity', u'position', u'quality', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant', u'large']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: importance
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'status', u'prominent'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant', u'large']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: equivalent
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): adding to parents: syn =  Synset('equivalent.n.01') ; keyword:  person  in syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= [u'equivalent']
reduceFunction_Parents(): returns= ['None', u'giant', u'large', u'equivalent']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: attention
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'on', u')', u'whereby', u'to', u'process', u'of', u'relative', u'others', u'some', u'exclusion', u'environment', u'person', u'(', u'concentrates', u'the', u'features'])
mapFunction_Parents(): adding to parents: syn =  Synset('attention.n.01') ; keyword:  person  in syndef_tokens= set([u'a', u'on', u')', u'whereby', u'to', u'process', u'of', u'relative', u'others', u'some', u'exclusion', u'environment', u'person', u'(', u'concentrates', u'the', u'features'])
mapFunction_Parents(): returns= [u'attention']
reduceFunction_Parents(): returns= ['None', u'giant', u'large', u'equivalent', u'attention']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: component
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'of', u'abstract', u'part', u'something', u'an'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant', u'large', u'equivalent', u'attention']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: thorium
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'thorite', u'is', u'as', u'used', u'sands', u'in', u'232', u'monazite', u'nuclear', u'metallic', u'source', u'silvery-white', u';', u'occurs', u'tetravalent', u'power', u'isotope', u'a', u'radioactive', u'element', u'soft', u'reactors'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant', u'large', u'equivalent', u'attention']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: clarify
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u')', u'(', u'make', u'comprehensible', u'clear', u'more'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant', u'large', u'equivalent', u'attention']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: densely
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'stupid', u'manner', u'in'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant', u'large', u'equivalent', u'attention']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: conceal
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'prevent', u'from', u'being', u'discovered', u'seen', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant', u'large', u'equivalent', u'attention']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: region
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'extended', u'of', u'something', u'spatial', u'the', u'location'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant', u'large', u'equivalent', u'attention']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: title
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'statute', u'give', u'that', u'may', u'of', u'the', u'bill', u'brief', u'heading', u'deals', u'matters', u'names', u'it', u';', u'summary', u'with', u'or', u'legislative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant', u'large', u'equivalent', u'attention']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: equal
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'standing', u'group', u'of', u'is', u'who', u'equal', u'person', u'another', u'in', u'with'])
mapFunction_Parents(): adding to parents: syn =  Synset('peer.n.01') ; keyword:  person  in syndef_tokens= set([u'a', u'standing', u'group', u'of', u'is', u'who', u'equal', u'person', u'another', u'in', u'with'])
mapFunction_Parents(): returns= [u'equal']
reduceFunction_Parents(): returns= ['None', u'giant', u'large', u'equivalent', u'attention', u'equal']
16/03/30 11:03:37 INFO PythonRunner: Times: total = 13448, boot = 490, init = 409, finish = 12549
16/03/30 11:03:37 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/30 11:03:37 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 13623 ms on localhost (2/2)
16/03/30 11:03:37 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/30 11:03:37 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) finished in 13.606 s
16/03/30 11:03:37 INFO DAGScheduler: looking for newly runnable stages
16/03/30 11:03:37 INFO DAGScheduler: running: Set()
16/03/30 11:03:37 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/30 11:03:37 INFO DAGScheduler: failed: Set()
16/03/30 11:03:37 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/30 11:03:37 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218), which is now runnable
16/03/30 11:03:37 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=12520, maxMem=555472650
16/03/30 11:03:37 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 529.7 MB)
16/03/30 11:03:37 INFO MemoryStore: ensureFreeSpace(3058) called with curMem=17504, maxMem=555472650
16/03/30 11:03:37 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 529.7 MB)
16/03/30 11:03:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:48790 (size: 3.0 KB, free: 529.7 MB)
16/03/30 11:03:37 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/30 11:03:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:03:37 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/30 11:03:37 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/30 11:03:37 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/30 11:03:37 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/30 11:03:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/30 11:03:37 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/30 11:03:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/30 11:03:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/30 11:03:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
16/03/30 11:03:37 INFO PythonRunner: Times: total = 92, boot = -580, init = 671, finish = 1
16/03/30 11:03:37 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1382 bytes result sent to driver
reduceFunction_Parents(): returns= ['None', u'giant', u'large', u'equivalent', u'attention', u'equal', 'None', u'male', u'heaviest', u'independent']
16/03/30 11:03:37 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 134 ms on localhost (1/2)
16/03/30 11:03:37 INFO PythonRunner: Times: total = 215, boot = 215, init = 0, finish = 0
16/03/30 11:03:37 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/30 11:03:37 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 251 ms on localhost (2/2)
16/03/30 11:03:37 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/30 11:03:37 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) finished in 0.254 s
16/03/30 11:03:37 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218, took 13.899716 s
16/03/30 11:03:37 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218
16/03/30 11:03:37 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) with 2 output partitions
16/03/30 11:03:37 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:03:37 INFO DAGScheduler: Parents of final stage: List()
16/03/30 11:03:37 INFO DAGScheduler: Missing parents: List()
16/03/30 11:03:37 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218), which has no missing parents
16/03/30 11:03:37 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=20562, maxMem=555472650
16/03/30 11:03:37 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 529.7 MB)
16/03/30 11:03:37 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=26378, maxMem=555472650
16/03/30 11:03:37 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 529.7 MB)
16/03/30 11:03:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:48790 (size: 3.3 KB, free: 529.7 MB)
16/03/30 11:03:37 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/30 11:03:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:03:37 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/30 11:03:37 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/30 11:03:37 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2463 bytes)
16/03/30 11:03:37 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/30 11:03:37 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/30 11:03:37 INFO PythonRunner: Times: total = 228, boot = 227, init = 0, finish = 1
16/03/30 11:03:37 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1450 bytes result sent to driver
16/03/30 11:03:37 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 239 ms on localhost (1/2)
16/03/30 11:03:37 INFO PythonRunner: Times: total = 255, boot = 255, init = 0, finish = 0
16/03/30 11:03:37 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/30 11:03:37 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 266 ms on localhost (2/2)
16/03/30 11:03:37 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/30 11:03:37 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) finished in 0.247 s
16/03/30 11:03:37 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218, took 0.285026 s
16/03/30 11:03:38 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/30 11:03:38 INFO DAGScheduler: Stopping DAGScheduler
16/03/30 11:03:38 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/30 11:03:38 INFO MemoryStore: MemoryStore cleared
16/03/30 11:03:38 INFO BlockManager: BlockManager stopped
16/03/30 11:03:38 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/30 11:03:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/30 11:03:38 INFO SparkContext: Successfully stopped SparkContext
16/03/30 11:03:38 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/30 11:03:38 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/30 11:03:38 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: <memcache.Client object at 0xb0c00a1c>
asfer_pickle_string_dump(): picklef.write(): reputation
16/03/30 11:03:38 INFO SparkContext: Running Spark version 1.5.2
16/03/30 11:03:38 INFO SecurityManager: Changing view acls to: root
16/03/30 11:03:38 INFO SecurityManager: Changing modify acls to: root
16/03/30 11:03:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/30 11:03:39 INFO Slf4jLogger: Slf4jLogger started
16/03/30 11:03:39 INFO Remoting: Starting remoting
16/03/30 11:03:39 INFO Utils: Successfully started service 'sparkDriver' on port 49428.
16/03/30 11:03:39 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:49428]
16/03/30 11:03:39 INFO SparkEnv: Registering MapOutputTracker
16/03/30 11:03:39 INFO SparkEnv: Registering BlockManagerMaster
16/03/30 11:03:39 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-bc299ebc-c7ed-4a6b-a9e2-6e023a23d122
16/03/30 11:03:39 INFO MemoryStore: MemoryStore started with capacity 529.3 MB
16/03/30 11:03:39 INFO HttpFileServer: HTTP File server directory is /tmp/spark-0e0df6d9-7161-45bf-b9ec-cf9574d76f1c/httpd-1603f84f-bef9-4ec5-86d2-1cdb796e3e92
16/03/30 11:03:39 INFO HttpServer: Starting HTTP Server
16/03/30 11:03:39 INFO Utils: Successfully started service 'HTTP file server' on port 53268.
16/03/30 11:03:39 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/30 11:03:39 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/30 11:03:39 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/30 11:03:39 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-0e0df6d9-7161-45bf-b9ec-cf9574d76f1c/userFiles-da712d7b-8c9b-431c-93f0-d428b578296f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/30 11:03:39 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1459316019344
16/03/30 11:03:39 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/30 11:03:39 INFO Executor: Starting executor ID driver on host localhost
16/03/30 11:03:39 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35723.
16/03/30 11:03:39 INFO NettyBlockTransferService: Server created on 35723
16/03/30 11:03:39 INFO BlockManagerMaster: Trying to register BlockManager
16/03/30 11:03:39 INFO BlockManagerMasterEndpoint: Registering block manager localhost:35723 with 529.3 MB RAM, BlockManagerId(driver, localhost, 35723)
16/03/30 11:03:39 INFO BlockManagerMaster: Registered BlockManager
16/03/30 11:03:39 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218
16/03/30 11:03:39 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:03:39 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) with 2 output partitions
16/03/30 11:03:39 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:03:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/30 11:03:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/30 11:03:39 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218), which has no missing parents
16/03/30 11:03:39 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555047976
16/03/30 11:03:39 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 529.3 MB)
16/03/30 11:03:39 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555047976
16/03/30 11:03:39 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 529.3 MB)
16/03/30 11:03:39 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:35723 (size: 4.1 KB, free: 529.3 MB)
16/03/30 11:03:39 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/30 11:03:39 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:03:39 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/30 11:03:39 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 3229 bytes)
16/03/30 11:03:39 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 3382 bytes)
16/03/30 11:03:39 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/30 11:03:39 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1459316019344
16/03/30 11:03:39 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/30 11:03:39 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-0e0df6d9-7161-45bf-b9ec-cf9574d76f1c/userFiles-da712d7b-8c9b-431c-93f0-d428b578296f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/30 11:03:39 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/30 11:03:39 INFO MemoryStore: ensureFreeSpace(958) called with curMem=10732, maxMem=555047976
16/03/30 11:03:39 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 958.0 B, free 529.3 MB)
16/03/30 11:03:39 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:35723 (size: 958.0 B, free: 529.3 MB)
16/03/30 11:03:39 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/30 11:03:39 INFO MemoryStore: ensureFreeSpace(854) called with curMem=11690, maxMem=555047976
16/03/30 11:03:39 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 854.0 B, free 529.3 MB)
16/03/30 11:03:39 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:35723 (size: 854.0 B, free: 529.3 MB)
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: kilometer
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: length
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: set
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: bend
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: semen
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'containing', u'that', u'ejaculated', u'thick', u'white', u'fluid', u'by', u'tract', u'genital', u'spermatozoa', u'male', u'the', u'is'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: giant
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): adding to parents: syn =  Synset('colossus.n.02') ; keyword:  reputation  in syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= [u'giant']
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: limit
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'degree', u'of', u'possible', u'something', u'the', u'greatest'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: area
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: astatine
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: set
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: present
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: area
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: dwell
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'about', u'moodily', u'anxiously', u'or', u'something', u'think'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: screen
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'be', u'for', u'pictures', u'projected', u'surface', u'silvered', u'viewing', u'can', u'white', u'where', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: city
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: whole
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'all', u'elements', u'of', u'component', u'or', u'parts', u'including', u'something', u'its'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: focus
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'on', u'of', u'energy', u'attention', u'or', u'something', u'the', u'concentration'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: plan
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'be', u'carried', u'series', u'to', u'accomplished', u'steps', u'goals', u'of', u'or', u'out'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: development
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'of', u'act', u'by', u'refining', u'expanding', u'improving', u'enlarging', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: elaborate
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: serving
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Madras
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: ejaculated
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'impulsively', u'utter'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Bengal
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'whose', u'and', u'Bangladesh', u'eastern', u'region', u'India', u'part', u'western', u'in', u'included', u'now', u'is'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: including
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'be', u'made', u'of', u',', u'up', u'as', u'part', u'have', u'out'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: geography
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: group
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u')', u'(', u'number', u'entities', u'as', u'considered', u'members', u'of', u'any', u'unit'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: decay
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'gradual', u'charge', u'current', u'as', u'stored', u'decrease', u'of', u';', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: writing
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'creating', u'of', u'written', u'act', u'the', u'works'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: add
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'disorders', u'mostly', u')', u'(', u'behavioral', u'boys', u'characterized', u'learning', u'in', u'by', u'condition'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: halogen
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'ions', u'all', u'iodine', u'related', u'are', u'astatine', u'any', u'fluorine', u'readily', u')', u'(', u'negative', u'elements', u'form', u'that', u'bromine', u'monovalent', u'five', u'chlorine', u'of', u'nonmetallic', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: include
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'be', u'made', u'of', u',', u'up', u'as', u'part', u'have', u'out'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: exceptional
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'ability', u'used', u'from', u'mental', u'normal', u'of', u'deviating', u'children', u'below', u'widely', u'in', u'intelligence', u';', u'especially', u'or', u'norm', u'physical'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: fluid
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'substance', u'room', u'that', u'is', u'fluid', u'pressure', u'at', u'temperature'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Bay
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'smaller', u'shoreline', u'gulf', u'of', u'larger', u'cove', u'but', u'an', u'indentation', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: boundary
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: covering
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'natural', u'that', u'object', u'covers', u'envelops', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: serves
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'play', u'ball', u'puts', u'that', u')', u'(', u'sports', u'stroke', u'in', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: large
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'for', u'garment', u'large', u'person', u'size'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: miles
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'1609.344', u'of', u'exactly', u'equal', u'1,760', u'feet', u'to', u'length', u'meters', u'5,280', u'yards', u';', u'or', u'unit'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: unstable
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'stability', u'fixity', u'or', u'lacking', u'firmness'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: people
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: series
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'happening', u'things', u'after', u'order', u'placed', u'another', u'in', u'one', u'similar', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: energy
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'energy', u'are', u'physical', u'capacity', u'ergs', u'joules', u'(', u'system', u'to', u'units', u';', u'do', u'thermodynamic', u'equivalent', u'a', u'of', u'work', u')', u'the', u'physics', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: idea
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'personal', u'view'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: culture
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: used
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'natural', u'for', u'service', u'into', u'work', u'or', u'employ', u'purpose', u'particular', u'put', u'inherent', u';', u'its', u'make'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: meters
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u"d'Unites", u'Systeme', u')', u'of', u'under', u'adopted', u'length', u'(', u'yards', u'basic', u'approximately', u'International', u'the', u'unit', u'1.094'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: special
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: 0.621371
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Orthodox
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'pertaining', u'Judaism', u'characteristic', u'to', u'of', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: purpose
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'your', u'an', u'intended', u'that', u'is', u'actions', u'anticipated', u'planned', u'outcome', u'guides', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: learned
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'be', u'certain', u'student', u'of', u'subject'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: degree
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'on', u'scale', u'of', u'amount', u'intensity', u'position', u'quality', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: importance
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'status', u'prominent'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: equivalent
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: attention
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'on', u')', u'whereby', u'to', u'process', u'of', u'relative', u'others', u'some', u'exclusion', u'environment', u'person', u'(', u'concentrates', u'the', u'features'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: component
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'of', u'abstract', u'part', u'something', u'an'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: thorium
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'thorite', u'is', u'as', u'used', u'sands', u'in', u'232', u'monazite', u'nuclear', u'metallic', u'source', u'silvery-white', u';', u'occurs', u'tetravalent', u'power', u'isotope', u'a', u'radioactive', u'element', u'soft', u'reactors'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: clarify
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u')', u'(', u'make', u'comprehensible', u'clear', u'more'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: densely
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'stupid', u'manner', u'in'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: conceal
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'prevent', u'from', u'being', u'discovered', u'seen', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: region
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'extended', u'of', u'something', u'spatial', u'the', u'location'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: title
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'statute', u'give', u'that', u'may', u'of', u'the', u'bill', u'brief', u'heading', u'deals', u'matters', u'names', u'it', u';', u'summary', u'with', u'or', u'legislative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: equal
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'standing', u'group', u'of', u'is', u'who', u'equal', u'person', u'another', u'in', u'with'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
16/03/30 11:03:53 INFO PythonRunner: Times: total = 14136, boot = 680, init = 546, finish = 12910
16/03/30 11:03:53 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/30 11:03:53 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 14294 ms on localhost (1/2)
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'fixed', u'from', u'linear', u'space', u'of', u'is', u'that', u'one', u'to', u'other', u'place', u'longest', u'extent', u'in', u'end', u'the', u'dimension', u';', u'something'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: act
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'deliberations', u'legislative', u'of', u'body', u'legal', u'society', u'codifying', u'committee', u'the', u'document', u'or', u'result'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: usually
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'normal', u'conditions', u'under'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: 1000
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'10', u'product', u'that', u'of', u'is', u'number', u'cardinal', u'the', u'100'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: composed
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'of', u'the', u'substance', u'form'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: formerly
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: period
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'of', u'amount', u'time', u'an'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: highly
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'degree', u'favorably', u'high', u'to', u'much', u'extent', u'respect', u';', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: thick
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'of', u'surrounded', u'other', u'location', u'things', u'the', u'by', u'something'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: unit
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'division', u'or', u'exchange', u'of', u'standard', u'as', u'measurement', u'accepted', u'any', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: city
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: given
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: area
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: stretch
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'distance', u'expanse', u'large', u'or', u'unbroken'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: populated
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'be', u'of', u'or', u'live', u'inhabitant', u'in', u';', u'an', u'inhabit'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: way
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'obtained', u'end', u'achieved', u'is', u'an', u'how', u'result', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: enlarging
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: urban
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'city', u'populated', u'concerned', u'area', u'to', u'densely', u'relating', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: continuous
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'interruption', u'space', u'in', u'continuing', u'without', u'time', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: moment
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'point', u'in', u'time', u'particular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: western
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'about', u'United', u'development', u'of', u'life', u'period', u'States', u'exploration', u'western', u'in', u'during', u'the', u'film'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: particular
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'about', u')', u'(', u'some', u'general', u'to', u'as', u'part', u'opposed', u'fact'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: white
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'of', u'member', u'race', u'the', u'Caucasoid'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: kind
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'category', u'or', u'things', u'some', u'by', u'characteristic', u'common', u'of', u'quality', u'distinguished'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: administrative
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'for', u'of', u'responsible', u'administration', u'to', u'relating', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: work
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'directed', u'doing', u'something', u'activity', u'making', u'toward', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: patriarch
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'older', u'is', u'who', u'rank', u'yourself', u'in', u'higher', u'than', u'man'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: districts
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'off', u'for', u'region', u'purposes', u'marked', u'other', u'administrative', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Church
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'own', u'have', u'of', u'who', u'one', u'forms', u'their', u'groups', u'the', u'worship', u'beliefs', u'Christians'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: male
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'babies', u'to', u'who', u'sex', u'person', u'that', u'belongs', u'can', u'have', u'not', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: distinguished
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'as', u'different', u'mark'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: devise
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'real', u'of', u'will', u'property', u'disposing'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: expanding
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: metric
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'function', u'them', u'for', u'that', u'of', u'space', u'equal', u',', u'topological', u'two', u'to', u'points', u'value', u'in', u'between', u'the', u'distance', u'any', u'gives'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: heaviest
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'to', u'is', u'who', u'it', u'fat', u'large', u'person', u'describes', u'but', u'usually', u'carry', u'has', u'frame'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: something
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: concentration
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'given', u'strength', u'of', u'solution', u'number', u'volume', u'substance', u'molecules', u'in', u'the', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: bishop
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: containing
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'component', u'as', u'have', u'contain', u';', u'include', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: things
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'possession', u'articles', u'especially', u')', u'(', u'movable', u'of', u'clothing', u'any'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: make
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'kind', u'recognizable'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: belong
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'possession', u'be', u'of', u'owned', u'by', u'in', u';', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: uranium
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'heavy', u'fuels', u'used', u'radioactive', u'and', u'for', u'many', u'isotopes', u'metallic', u'weapons', u'silvery-white', u'in', u'toxic', u'nuclear', u';', u'element', u'occurs'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: discourse
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'extended', u'verbal', u'writing', u'speech', u'in', u'expression', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: parts
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'less', u'of', u'artifact', u'something', u'human', u'the', u'whole', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: speech
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'spoken', u'of', u'communication', u'delivering', u'to', u'audience', u'act', u'the', u'an', u'formal'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: details
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'be', u'from', u'that', u'considered', u'separately', u'part', u'can', u'small', u'the', u'whole'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: geographical
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: several
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'count', u'used', u')', u'(', u'or', u'number', u'but', u'an', u'3', u'2', u'nouns', u'of', u'not', u'many', u'indefinite', u'with', u'than', u'more'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: circular
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'on', u'or', u'intended', u'for', u'wide', u')', u'(', u'an', u'leaflet', u'printed', u'advertisement', u'in', u'usually', u'distribution', u'page'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: independent
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'especially', u')', u'(', u'uncommitted', u'person', u'neutral', u'in', u'politics', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: product
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: elements
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'the', u'elements', u')', u'(', u'of', u'violent', u'by', u'four', u'severe', u'weather', u'caused', u'action', u'as', u'or', u'viewed'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: shelter
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'from', u'privacy', u'that', u'danger', u'protection', u'provides', u'structure'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: possible
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'be', u'done', u'something', u'can', u'that'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: meaning
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'consequence', u'as', u'logical', u'have'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: plan
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'be', u'carried', u'series', u'to', u'accomplished', u'steps', u'goals', u'of', u'or', u'out'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: tract
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'body', u'some', u'that', u'of', u'serve', u'system', u'together', u'parts', u'purpose', u'particular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: improving
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'better', u'to', u'make'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: genital
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'of', u'or', u'to', u'external', u'relating', u'sex', u'organs', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: spermatozoa
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'gamete', u'reproductive', u'cell', u'the', u'male', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: account
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'description', u'of', u'events', u'past', u'record', u'narrative', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: segment
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'one', u'a', u'fit', u'that', u'of', u'object', u'pieces', u'constitute', u'to', u'parts', u'whole', u'others', u'several', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: radioactive
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'caused', u'exhibiting', u'radioactivity', u'or', u'by'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: happening
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'happens', u'that', u'event', u'an'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: curve
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'whose', u'direction', u'trace', u'point', u'of', u'motion', u'the', u'changes'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: together
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'emotionally', u'mentally', u'stable'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: element
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'of', u'abstract', u'part', u'something', u'an'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: person
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'being', u'human'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: reputation
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'has', u'for', u'that', u'general', u'person', u'the', u'estimation', u'public'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/30 11:03:54 INFO PythonRunner: Times: total = 14995, boot = 674, init = 1109, finish = 13212
16/03/30 11:03:54 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/30 11:03:54 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 15117 ms on localhost (2/2)
16/03/30 11:03:54 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/30 11:03:54 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) finished in 15.105 s
16/03/30 11:03:54 INFO DAGScheduler: looking for newly runnable stages
16/03/30 11:03:54 INFO DAGScheduler: running: Set()
16/03/30 11:03:54 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/30 11:03:54 INFO DAGScheduler: failed: Set()
16/03/30 11:03:54 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/30 11:03:54 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218), which is now runnable
16/03/30 11:03:54 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=12544, maxMem=555047976
16/03/30 11:03:54 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 529.3 MB)
16/03/30 11:03:54 INFO MemoryStore: ensureFreeSpace(3058) called with curMem=17528, maxMem=555047976
16/03/30 11:03:54 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 529.3 MB)
16/03/30 11:03:54 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:35723 (size: 3.0 KB, free: 529.3 MB)
16/03/30 11:03:54 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/30 11:03:54 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:03:54 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/30 11:03:54 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/30 11:03:54 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/30 11:03:54 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/30 11:03:54 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/30 11:03:54 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/30 11:03:54 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/30 11:03:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
16/03/30 11:03:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
reduceFunction_Parents(): returns= ['None', u'giant', 'None']
16/03/30 11:03:54 INFO PythonRunner: Times: total = 46, boot = -633, init = 678, finish = 1
16/03/30 11:03:54 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1281 bytes result sent to driver
16/03/30 11:03:54 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 93 ms on localhost (1/2)
16/03/30 11:03:54 INFO PythonRunner: Times: total = 243, boot = 242, init = 1, finish = 0
16/03/30 11:03:54 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/30 11:03:54 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 275 ms on localhost (2/2)
16/03/30 11:03:54 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/30 11:03:54 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) finished in 0.242 s
16/03/30 11:03:54 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218, took 15.416570 s
16/03/30 11:03:55 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218
16/03/30 11:03:55 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) with 2 output partitions
16/03/30 11:03:55 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:03:55 INFO DAGScheduler: Parents of final stage: List()
16/03/30 11:03:55 INFO DAGScheduler: Missing parents: List()
16/03/30 11:03:55 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218), which has no missing parents
16/03/30 11:03:55 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=20586, maxMem=555047976
16/03/30 11:03:55 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 529.3 MB)
16/03/30 11:03:55 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=26402, maxMem=555047976
16/03/30 11:03:55 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 529.3 MB)
16/03/30 11:03:55 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:35723 (size: 3.3 KB, free: 529.3 MB)
16/03/30 11:03:55 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/30 11:03:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:03:55 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/30 11:03:55 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/30 11:03:55 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2362 bytes)
16/03/30 11:03:55 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/30 11:03:55 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/30 11:03:55 INFO PythonRunner: Times: total = 66, boot = -51, init = 117, finish = 0
16/03/30 11:03:55 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/30 11:03:55 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 75 ms on localhost (1/2)
16/03/30 11:03:55 INFO PythonRunner: Times: total = 102, boot = 102, init = 0, finish = 0
16/03/30 11:03:55 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1349 bytes result sent to driver
16/03/30 11:03:55 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 118 ms on localhost (2/2)
16/03/30 11:03:55 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/30 11:03:55 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) finished in 0.119 s
16/03/30 11:03:55 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218, took 0.137190 s
16/03/30 11:03:55 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/30 11:03:55 INFO DAGScheduler: Stopping DAGScheduler
16/03/30 11:03:55 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/30 11:03:55 INFO MemoryStore: MemoryStore cleared
16/03/30 11:03:55 INFO BlockManager: BlockManager stopped
16/03/30 11:03:55 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/30 11:03:55 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/30 11:03:55 INFO SparkContext: Successfully stopped SparkContext
16/03/30 11:03:55 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/30 11:03:55 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/30 11:03:55 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: <memcache.Client object at 0xb0c00a1c>
asfer_pickle_string_dump(): picklef.write(): greatest
16/03/30 11:03:56 INFO SparkContext: Running Spark version 1.5.2
16/03/30 11:03:56 INFO SecurityManager: Changing view acls to: root
16/03/30 11:03:56 INFO SecurityManager: Changing modify acls to: root
16/03/30 11:03:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/30 11:03:56 INFO Slf4jLogger: Slf4jLogger started
16/03/30 11:03:56 INFO Remoting: Starting remoting
16/03/30 11:03:56 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:43347]
16/03/30 11:03:56 INFO Utils: Successfully started service 'sparkDriver' on port 43347.
16/03/30 11:03:56 INFO SparkEnv: Registering MapOutputTracker
16/03/30 11:03:56 INFO SparkEnv: Registering BlockManagerMaster
16/03/30 11:03:56 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e382c41e-56e5-4f72-bba2-f523b00cf47d
16/03/30 11:03:56 INFO MemoryStore: MemoryStore started with capacity 529.3 MB
16/03/30 11:03:56 INFO HttpFileServer: HTTP File server directory is /tmp/spark-0e0df6d9-7161-45bf-b9ec-cf9574d76f1c/httpd-c0d51c1c-88df-42cb-8ce3-1b7ea74d2a21
16/03/30 11:03:56 INFO HttpServer: Starting HTTP Server
16/03/30 11:03:56 INFO Utils: Successfully started service 'HTTP file server' on port 54680.
16/03/30 11:03:56 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/30 11:03:56 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/30 11:03:56 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/30 11:03:56 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-0e0df6d9-7161-45bf-b9ec-cf9574d76f1c/userFiles-7bde2986-c687-40d8-81dc-d5af2d42d1f7/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/30 11:03:56 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1459316036569
16/03/30 11:03:56 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/30 11:03:56 INFO Executor: Starting executor ID driver on host localhost
16/03/30 11:03:56 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33586.
16/03/30 11:03:56 INFO NettyBlockTransferService: Server created on 33586
16/03/30 11:03:56 INFO BlockManagerMaster: Trying to register BlockManager
16/03/30 11:03:56 INFO BlockManagerMasterEndpoint: Registering block manager localhost:33586 with 529.3 MB RAM, BlockManagerId(driver, localhost, 33586)
16/03/30 11:03:56 INFO BlockManagerMaster: Registered BlockManager
16/03/30 11:03:56 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218
16/03/30 11:03:56 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:03:56 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) with 2 output partitions
16/03/30 11:03:56 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:03:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/30 11:03:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/30 11:03:56 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218), which has no missing parents
16/03/30 11:03:56 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555047976
16/03/30 11:03:56 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 529.3 MB)
16/03/30 11:03:56 INFO MemoryStore: ensureFreeSpace(4159) called with curMem=6576, maxMem=555047976
16/03/30 11:03:56 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 529.3 MB)
16/03/30 11:03:56 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:33586 (size: 4.1 KB, free: 529.3 MB)
16/03/30 11:03:56 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/30 11:03:56 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:03:56 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/30 11:03:56 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 3242 bytes)
16/03/30 11:03:56 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 3367 bytes)
16/03/30 11:03:56 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/30 11:03:56 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1459316036569
16/03/30 11:03:56 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/30 11:03:56 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-0e0df6d9-7161-45bf-b9ec-cf9574d76f1c/userFiles-7bde2986-c687-40d8-81dc-d5af2d42d1f7/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/30 11:03:57 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/30 11:03:57 INFO MemoryStore: ensureFreeSpace(951) called with curMem=10735, maxMem=555047976
16/03/30 11:03:57 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 951.0 B, free 529.3 MB)
16/03/30 11:03:57 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:33586 (size: 951.0 B, free: 529.3 MB)
16/03/30 11:03:57 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/30 11:03:57 INFO MemoryStore: ensureFreeSpace(865) called with curMem=11686, maxMem=555047976
16/03/30 11:03:57 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 865.0 B, free 529.3 MB)
16/03/30 11:03:57 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:33586 (size: 865.0 B, free: 529.3 MB)
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: act
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'deliberations', u'legislative', u'of', u'body', u'legal', u'society', u'codifying', u'committee', u'the', u'document', u'or', u'result'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: usually
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'normal', u'conditions', u'under'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: 1000
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'and', u'10', u'product', u'that', u'of', u'is', u'number', u'cardinal', u'the', u'100'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: composed
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'of', u'the', u'substance', u'form'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: formerly
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: period
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'of', u'amount', u'time', u'an'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: highly
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'degree', u'favorably', u'high', u'to', u'much', u'extent', u'respect', u';', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: thick
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'of', u'surrounded', u'other', u'location', u'things', u'the', u'by', u'something'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: unit
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'division', u'or', u'exchange', u'of', u'standard', u'as', u'measurement', u'accepted', u'any', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: city
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: given
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: area
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: Chennai
mapFunction_Parents(): keyword=mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: stretch
 greatest ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: set
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'and', u'distance', u'expanse', u'large', u'or', u'unbroken'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: populated
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'be', u'of', u'or', u'live', u'inhabitant', u'in', u';', u'an', u'inhabit'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: way
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'obtained', u'end', u'achieved', u'is', u'an', u'how', u'result', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: mapFunction_Parents(): keyword=enlarging
 greatest ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: bend
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: urban
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'city', u'populated', u'concerned', u'area', u'to', u'densely', u'relating', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: continuous
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'interruption', u'space', u'in', u'continuing', u'without', u'time', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: moment
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'point', u'in', u'time', u'particular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: western
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: semen
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'containing', u'that', u'ejaculated', u'thick', u'white', u'fluid', u'by', u'tract', u'genital', u'spermatozoa', u'male', u'the', u'is'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: giant
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'and', u'about', u'United', u'development', u'of', u'life', u'period', u'States', u'exploration', u'western', u'in', u'during', u'the', u'film'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: particular
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: limit
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'about', u')', u'(', u'some', u'general', u'to', u'as', u'part', u'opposed', u'fact'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: white
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'degree', u'of', u'possible', u'something', u'the', u'greatest'])
mapFunction_Parents(): adding to parents: syn =  Synset('limit.n.01') ; keyword:  greatest  in syndef_tokens= set([u'degree', u'of', u'possible', u'something', u'the', u'greatest'])
mapFunction_Parents(): returns= [u'limit']
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: area
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: astatine
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: set
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'of', u'member', u'race', u'the', u'Caucasoid'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: kind
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'category', u'or', u'things', u'some', u'by', u'characteristic', u'common', u'of', u'quality', u'distinguished'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: administrative
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'for', u'of', u'responsible', u'administration', u'to', u'relating', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: work
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'directed', u'doing', u'something', u'activity', u'making', u'toward', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: patriarch
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'and', u'older', u'is', u'who', u'rank', u'yourself', u'in', u'higher', u'than', u'man'])['None', 
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
u'limit']asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: districts

asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: present
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'off', u'for', u'region', u'purposes', u'marked', u'other', u'administrative', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: Church
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'and', u'own', u'have', u'of', u'who', u'one', u'forms', u'their', u'groups', u'the', u'worship', u'beliefs', u'Christians'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: male
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'babies', u'to', u'who', u'sex', u'person', u'that', u'belongs', u'can', u'have', u'not', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: distinguished
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'as', u'different', u'mark'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: devise
mapFunction_Parents(): keyword=mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'real', u'of', u'will', u'property', u'disposing'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
 greatest ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines():asfer_pickle_string_load(): picklef.readlines():  greatest
mapFunction_Parents(): keyword:greatest
 greatest ; prevleveltokens: area
mapFunction_Parents(): keyword: greatest ; prevleveltokens: expanding
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: metric
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: dwell
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'function', u'them', u'for', u'that', u'of', u'space', u'equal', u',', u'topological', u'two', u'to', u'points', u'value', u'in', u'between', u'the', u'distance', u'any', u'gives'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: heaviest
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'about', u'moodily', u'anxiously', u'or', u'something', u'think'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: screen
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'to', u'is', u'who', u'it', u'fat', u'large', u'person', u'describes', u'but', u'usually', u'carry', u'has', u'frame'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: something
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: concentration
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'be', u'for', u'pictures', u'projected', u'surface', u'silvered', u'viewing', u'can', u'white', u'where', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: city
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'given', u'strength', u'of', u'solution', u'number', u'volume', u'substance', u'molecules', u'in', u'the', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: bishop
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: containing
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'component', u'as', u'have', u'contain', u';', u'include', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: things
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: whole
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'possession', u'articles', u'especially', u')', u'(', u'movable', u'of', u'clothing', u'any'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: make
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'all', u'elements', u'of', u'component', u'or', u'parts', u'including', u'something', u'its'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: focus
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'on', u'of', u'energy', u'attention', u'or', u'something', u'the', u'concentration'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: plan
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'be', u'carried', u'series', u'to', u'accomplished', u'steps', u'goals', u'of', u'or', u'out'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: development
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'of', u'act', u'by', u'refining', u'expanding', u'improving', u'enlarging', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: elaborate
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: serving
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: Madras
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: ejaculated
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'impulsively', u'utter'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: Bengal
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'whose', u'and', u'Bangladesh', u'eastern', u'region', u'India', u'part', u'western', u'in', u'included', u'now', u'is'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: including
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'kind', u'recognizable'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: belong
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'be', u'made', u'of', u',', u'up', u'as', u'part', u'have', u'out'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: geography
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: group
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'possession', u'be', u'of', u'owned', u'by', u'in', u';', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: uranium
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u')', u'(', u'number', u'entities', u'as', u'considered', u'members', u'of', u'any', u'unit'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: decay
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'gradual', u'charge', u'current', u'as', u'stored', u'decrease', u'of', u';', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: writing
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'heavy', u'fuels', u'used', u'radioactive', u'and', u'for', u'many', u'isotopes', u'metallic', u'weapons', u'silvery-white', u'in', u'toxic', u'nuclear', u';', u'element', u'occurs'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: discourse
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'extended', u'verbal', u'writing', u'speech', u'in', u'expression', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: parts
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'creating', u'of', u'written', u'act', u'the', u'works'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: add
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'and', u'disorders', u'mostly', u')', u'(', u'behavioral', u'boys', u'characterized', u'learning', u'in', u'by', u'condition'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: halogen
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'and', u'ions', u'all', u'iodine', u'related', u'are', u'astatine', u'any', u'fluorine', u'readily', u')', u'(', u'negative', u'elements', u'form', u'that', u'bromine', u'monovalent', u'five', u'chlorine', u'of', u'nonmetallic', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: include
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'be', u'made', u'of', u',', u'up', u'as', u'part', u'have', u'out'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= greatestmapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'less', u'of', u'artifact', u'something', u'human', u'the', u'whole', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: speech
 ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: exceptional
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'spoken', u'of', u'communication', u'delivering', u'to', u'audience', u'act', u'the', u'an', u'formal'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: details
mapFunction_Parents(): keyword= greatest ; syndef_tokens= mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'be', u'from', u'that', u'considered', u'separately', u'part', u'can', u'small', u'the', u'whole'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: geographical
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: several
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'count', u'used', u')', u'(', u'or', u'number', u'but', u'an', u'3', u'2', u'nouns', u'of', u'not', u'many', u'indefinite', u'with', u'than', u'more'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: circular
set([u'a', u'ability', u'used', u'from', u'mental', u'normal', u'of', u'deviating', u'children', u'below', u'widely', u'in', u'intelligence', u';', u'especially', u'or', u'norm', u'physical'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: fluid
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'on', u'or', u'intended', u'for', u'wide', u')', u'(', u'an', u'leaflet', u'printed', u'advertisement', u'in', u'usually', u'distribution', u'page'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: independent
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'especially', u')', u'(', u'uncommitted', u'person', u'neutral', u'in', u'politics', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: product
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: elements
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'and', u'substance', u'room', u'that', u'is', u'fluid', u'pressure', u'at', u'temperature'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: Bay
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'the', u'elements', u')', u'(', u'of', u'violent', u'by', u'four', u'severe', u'weather', u'caused', u'action', u'as', u'or', u'viewed'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: shelter
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'smaller', u'shoreline', u'gulf', u'of', u'larger', u'cove', u'but', u'an', u'indentation', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword:mapFunction_Parents(): keyword= greatest ; syndef_tokens=  greatest ; prevleveltokens: boundary
set([u'a', u'and', u'from', u'privacy', u'that', u'danger', u'protection', u'provides', u'structure'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: possible
mapFunction_Parents(): keyword=mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'be', u'done', u'something', u'can', u'that'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: meaning
 greatest ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: covering
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'consequence', u'as', u'logical', u'have'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: plan
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'be', u'carried', u'series', u'to', u'accomplished', u'steps', u'goals', u'of', u'or', u'out'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: tract
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'body', u'some', u'that', u'of', u'serve', u'system', u'together', u'parts', u'purpose', u'particular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: improving
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'better', u'to', u'make'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: genital
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'of', u'or', u'to', u'external', u'relating', u'sex', u'organs', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: spermatozoa
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'gamete', u'reproductive', u'cell', u'the', u'male', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: account
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'natural', u'that', u'object', u'covers', u'envelops', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: serves
mapFunction_Parents(): keyword=mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'description', u'of', u'events', u'past', u'record', u'narrative', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: segment
 greatest ; syndef_tokens= set([u'a', u'play', u'ball', u'puts', u'that', u')', u'(', u'sports', u'stroke', u'in', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: large
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'one', u'a', u'fit', u'that', u'of', u'object', u'pieces', u'constitute', u'to', u'parts', u'whole', u'others', u'several', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: radioactive
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'caused', u'exhibiting', u'radioactivity', u'or', u'by'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: happening
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'for', u'garment', u'large', u'person', u'size'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: miles
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'happens', u'that', u'event', u'an'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: curve
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'1609.344', u'of', u'exactly', u'equal', u'1,760', u'feet', u'to', u'length', u'meters', u'5,280', u'yards', u';', u'or', u'unit'])
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'whose', mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns=u'direction',  ['Nu'trace', u'point', u'of', u'motion', u'the', u'changes'])
mapFunction_Parents(): returns= []one', u'limit']

reduceFunction_Parents(): returns= ['Nasfer_pickle_string_load(): picklef.readlines():one greatest
mapFunction_Parents(): keyword:']
 greatest ; prevleveltokens: unstable
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: together
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'and', u'emotionally', u'mentally', u'stable'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: element
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'stability', u'fixity', u'or', u'lacking', u'firmness'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: people
mapFunction_Parents(): keyword=mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'of', u'abstract', u'part', u'something', u'an'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: person
 greatest ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: series
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'being', u'human'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: reputation
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'has', u'for', u'that', u'general', u'person', u'the', u'estimation', u'public'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: greatest
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'happening', u'things', u'after', u'order', u'placed', u'another', u'in', u'one', u'similar', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: energy
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'energy', u'are', u'physical', u'capacity', u'ergs', u'joules', u'(', u'system', u'to', u'units', u';', u'do', u'thermodynamic', u'equivalent', u'a', u'of', u'work', u')', u'the', u'physics', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: idea
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'personal', u'view'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: culture
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: used
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'highest', u'quality', u'in'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'natural', u'for', u'service', u'into', u'work', u'or', u'employ', u'purpose', u'particular', u'put', u'inherent', u';', u'its', u'make'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: meters
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u"d'Unites", u'Systeme', u')', u'of', u'under', u'adopted', u'length', u'(', u'yards', u'basic', u'approximately', u'International', u'the', u'unit', u'1.094'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: special
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: 0.621371
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: Orthodox
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'pertaining', u'Judaism', u'characteristic', u'to', u'of', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: purpose
16/03/30 11:04:10 INFO PythonRunner: Times: total = 13315, boot = 560, init = 419, finish = 12336
16/03/30 11:04:10 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
mapFunction_Parents(): keyword=16/03/30 11:04:10 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 13449 ms on localhost (1/2)
 greatest ; syndef_tokens= set([u'your', u'an', u'intended', u'that', u'is', u'actions', u'anticipated', u'planned', u'outcome', u'guides', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: learned
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'be', u'certain', u'student', u'of', u'subject'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: degree
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'on', u'scale', u'of', u'amount', u'intensity', u'position', u'quality', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: importance
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'status', u'prominent'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: equivalent
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: attention
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'on', u')', u'whereby', u'to', u'process', u'of', u'relative', u'others', u'some', u'exclusion', u'environment', u'person', u'(', u'concentrates', u'the', u'features'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: component
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'of', u'abstract', u'part', u'something', u'an'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: thorium
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'and', u'thorite', u'is', u'as', u'used', u'sands', u'in', u'232', u'monazite', u'nuclear', u'metallic', u'source', u'silvery-white', u';', u'occurs', u'tetravalent', u'power', u'isotope', u'a', u'radioactive', u'element', u'soft', u'reactors'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: clarify
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'and', u')', u'(', u'make', u'comprehensible', u'clear', u'more'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: densely
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'stupid', u'manner', u'in'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: conceal
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'prevent', u'from', u'being', u'discovered', u'seen', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: region
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'extended', u'of', u'something', u'spatial', u'the', u'location'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: title
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'statute', u'give', u'that', u'may', u'of', u'the', u'bill', u'brief', u'heading', u'deals', u'matters', u'names', u'it', u';', u'summary', u'with', u'or', u'legislative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: equal
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'a', u'standing', u'group', u'of', u'is', u'who', u'equal', u'person', u'another', u'in', u'with'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
asfer_pickle_string_load(): picklef.readlines(): greatest
mapFunction_Parents(): keyword: greatest ; prevleveltokens: length
mapFunction_Parents(): keyword= greatest ; syndef_tokens= set([u'fixed', u'from', u'linear', u'space', u'of', u'is', u'that', u'one', u'to', u'other', u'place', u'longest', u'extent', u'in', u'end', u'the', u'dimension', u';', u'something'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'limit']
16/03/30 11:04:10 INFO PythonRunner: Times: total = 13523, boot = 561, init = 437, finish = 12525
16/03/30 11:04:10 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/30 11:04:10 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) finished in 13.642 s
16/03/30 11:04:10 INFO DAGScheduler: looking for newly runnable stages
16/03/30 11:04:10 INFO DAGScheduler: running: Set()
16/03/30 11:04:10 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/30 11:04:10 INFO DAGScheduler: failed: Set()
16/03/30 11:04:10 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/30 11:04:10 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218), which is now runnable
16/03/30 11:04:10 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=12551, maxMem=555047976
16/03/30 11:04:10 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 529.3 MB)
16/03/30 11:04:10 INFO MemoryStore: ensureFreeSpace(3058) called with curMem=17535, maxMem=555047976
16/03/30 11:04:10 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 529.3 MB)
16/03/30 11:04:10 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 13656 ms on localhost (2/2)
16/03/30 11:04:10 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/30 11:04:10 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:33586 (size: 3.0 KB, free: 529.3 MB)
16/03/30 11:04:10 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/30 11:04:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:04:10 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/30 11:04:10 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/30 11:04:10 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/30 11:04:10 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/30 11:04:10 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/30 11:04:10 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/30 11:04:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/03/30 11:04:10 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/30 11:04:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
reduceFunction_Parents(): returns= ['None', u'limit', 'None']
16/03/30 11:04:10 INFO PythonRunner: Times: total = 232, boot = 229, init = 1, finish = 2
16/03/30 11:04:10 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1281 bytes result sent to driver
16/03/30 11:04:10 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 267 ms on localhost (1/2)
16/03/30 11:04:10 INFO PythonRunner: Times: total = 303, boot = 302, init = 0, finish = 1
16/03/30 11:04:10 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/30 11:04:10 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 346 ms on localhost (2/2)
16/03/30 11:04:10 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) finished in 0.342 s
16/03/30 11:04:10 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218, took 14.043397 s
16/03/30 11:04:10 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/30 11:04:11 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218
16/03/30 11:04:11 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) with 2 output partitions
16/03/30 11:04:11 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:04:11 INFO DAGScheduler: Parents of final stage: List()
16/03/30 11:04:11 INFO DAGScheduler: Missing parents: List()
16/03/30 11:04:11 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218), which has no missing parents
16/03/30 11:04:11 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=20593, maxMem=555047976
16/03/30 11:04:11 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 529.3 MB)
16/03/30 11:04:11 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=26409, maxMem=555047976
16/03/30 11:04:11 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 529.3 MB)
16/03/30 11:04:11 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:33586 (size: 3.3 KB, free: 529.3 MB)
16/03/30 11:04:11 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/30 11:04:11 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:04:11 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/30 11:04:11 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/30 11:04:11 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2362 bytes)
16/03/30 11:04:11 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/30 11:04:11 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/30 11:04:11 INFO PythonRunner: Times: total = 87, boot = 86, init = 1, finish = 0
16/03/30 11:04:11 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/30 11:04:11 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 98 ms on localhost (1/2)
16/03/30 11:04:11 INFO PythonRunner: Times: total = 224, boot = 224, init = 0, finish = 0
16/03/30 11:04:11 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1349 bytes result sent to driver
16/03/30 11:04:11 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 239 ms on localhost (2/2)
16/03/30 11:04:11 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/30 11:04:11 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) finished in 0.241 s
16/03/30 11:04:11 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218, took 0.255233 s
16/03/30 11:04:11 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/30 11:04:11 INFO DAGScheduler: Stopping DAGScheduler
16/03/30 11:04:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/30 11:04:11 INFO MemoryStore: MemoryStore cleared
16/03/30 11:04:11 INFO BlockManager: BlockManager stopped
16/03/30 11:04:11 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/30 11:04:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/30 11:04:11 INFO SparkContext: Successfully stopped SparkContext
16/03/30 11:04:11 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/30 11:04:11 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/30 11:04:11 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: <memcache.Client object at 0xb0c00a1c>
asfer_pickle_string_dump(): picklef.write(): refining
16/03/30 11:04:12 INFO SparkContext: Running Spark version 1.5.2
16/03/30 11:04:12 INFO SecurityManager: Changing view acls to: root
16/03/30 11:04:12 INFO SecurityManager: Changing modify acls to: root
16/03/30 11:04:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/30 11:04:12 INFO Slf4jLogger: Slf4jLogger started
16/03/30 11:04:12 INFO Remoting: Starting remoting
16/03/30 11:04:12 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:54526]
16/03/30 11:04:12 INFO Utils: Successfully started service 'sparkDriver' on port 54526.
16/03/30 11:04:12 INFO SparkEnv: Registering MapOutputTracker
16/03/30 11:04:12 INFO SparkEnv: Registering BlockManagerMaster
16/03/30 11:04:12 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5e65b4f5-2f30-4d63-8301-5890c8f3d777
16/03/30 11:04:12 INFO MemoryStore: MemoryStore started with capacity 530.4 MB
16/03/30 11:04:12 INFO HttpFileServer: HTTP File server directory is /tmp/spark-0e0df6d9-7161-45bf-b9ec-cf9574d76f1c/httpd-c37b79cd-37ae-48ea-8eb0-2c26ecad6418
16/03/30 11:04:12 INFO HttpServer: Starting HTTP Server
16/03/30 11:04:12 INFO Utils: Successfully started service 'HTTP file server' on port 45887.
16/03/30 11:04:12 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/30 11:04:13 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/30 11:04:13 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/30 11:04:13 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-0e0df6d9-7161-45bf-b9ec-cf9574d76f1c/userFiles-24150634-0caa-44de-b946-872d74fe79bd/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/30 11:04:13 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1459316053164
16/03/30 11:04:13 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/30 11:04:13 INFO Executor: Starting executor ID driver on host localhost
16/03/30 11:04:13 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36220.
16/03/30 11:04:13 INFO NettyBlockTransferService: Server created on 36220
16/03/30 11:04:13 INFO BlockManagerMaster: Trying to register BlockManager
16/03/30 11:04:13 INFO BlockManagerMasterEndpoint: Registering block manager localhost:36220 with 530.4 MB RAM, BlockManagerId(driver, localhost, 36220)
16/03/30 11:04:13 INFO BlockManagerMaster: Registered BlockManager
16/03/30 11:04:13 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218
16/03/30 11:04:13 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:04:13 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) with 2 output partitions
16/03/30 11:04:13 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:04:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/30 11:04:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/30 11:04:13 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218), which has no missing parents
16/03/30 11:04:13 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=556180439
16/03/30 11:04:13 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.4 MB)
16/03/30 11:04:13 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=556180439
16/03/30 11:04:13 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.4 MB)
16/03/30 11:04:13 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:36220 (size: 4.1 KB, free: 530.4 MB)
16/03/30 11:04:13 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/30 11:04:13 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:04:13 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/30 11:04:13 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 3242 bytes)
16/03/30 11:04:13 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 3399 bytes)
16/03/30 11:04:13 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/30 11:04:13 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1459316053164
16/03/30 11:04:13 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/30 11:04:13 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-0e0df6d9-7161-45bf-b9ec-cf9574d76f1c/userFiles-24150634-0caa-44de-b946-872d74fe79bd/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/30 11:04:13 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/30 11:04:13 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/30 11:04:13 INFO MemoryStore: ensureFreeSpace(976) called with curMem=10732, maxMem=556180439
16/03/30 11:04:13 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 976.0 B, free 530.4 MB)
16/03/30 11:04:13 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:36220 (size: 976.0 B, free: 530.4 MB)
16/03/30 11:04:13 INFO MemoryStore: ensureFreeSpace(865) called with curMem=11708, maxMem=556180439
16/03/30 11:04:13 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 865.0 B, free 530.4 MB)
16/03/30 11:04:13 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:36220 (size: 865.0 B, free: 530.4 MB)
asfer_pickle_string_load(): picklef.readlines():asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: act
 refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: set
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: bend
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: semen
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'containing', u'that', u'ejaculated', u'thick', u'white', u'fluid', u'by', u'tract', u'genital', u'spermatozoa', u'male', u'the', u'is'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: giant
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: limit
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'degree', u'of', u'possible', u'something', u'the', u'greatest'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: area
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: astatine
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: set
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: present
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: area
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: dwell
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'about', u'moodily', u'anxiously', u'or', u'something', u'think'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: screen
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'deliberations', u'legislative', u'of', u'body', u'legal', u'society', u'codifying', u'committee', u'the', u'document', u'or', u'result'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: usually
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'normal', u'conditions', u'under'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: 1000
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'be', u'for', u'pictures', u'projected', u'surface', u'silvered', u'viewing', u'can', u'white', u'where', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: city
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'and', u'10', u'product', u'that', u'of', u'is', u'number', u'cardinal', u'the', u'100'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: composed
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: whole
mapFunction_Parents(): keyword=mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'all', u'elements', u'of', u'component', u'or', u'parts', u'including', u'something', u'its'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: focus
 refining ; syndef_tokens= set([u'of', u'the', u'substance', u'form'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'on', u'of', u'energy', u'attention', u'or', u'something', u'the', u'concentration'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: plan

asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: formerly
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: period
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'be', u'carried', u'series', u'to', u'accomplished', u'steps', u'goals', u'of', u'or', u'out'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: development
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'of', u'act', u'by', u'refining', u'expanding', u'improving', u'enlarging', u'or'])
mapFunction_Parents(): adding to parents: syn =  Synset('development.n.01') ; keyword:  refining  in syndef_tokens= set([u'of', u'act', u'by', u'refining', u'expanding', u'improving', u'enlarging', u'or'])
mapFunction_Parents(): returns= [u'development']
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: elaborate
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'of', u'amount', u'time', u'an'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: serving
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: highly
mapFunction_Parents(): keyword=mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: Madras
 refining ; syndef_tokens= set([u'a', u'degree', u'favorably'mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: ejaculated
, u'high', u'to', u'much', u'extent', u'respect', u';', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None'mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'impulsively', u'utter'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
]asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: Bengal

asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: thick
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'whose', u'and', u'Bangladesh', u'eastern', u'region', u'India', u'part', u'western', u'in', u'included', u'now', u'is'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: including
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'be', u'made', u'of', u',', u'up', u'as', u'part', u'have', u'out'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: geography
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: group
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u')', u'(', u'number', u'entities', u'as', u'considered', u'members', u'of', u'any', u'unit'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: decay
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'of', u'surrounded', u'other', u'location', u'things', u'the', u'by', u'something'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'gradual', u'charge', u'current', u'as', u'stored', u'decrease', u'of', u';', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: writing
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'creating', u'of', u'written', u'act', u'the', u'works'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: add
[]
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: unit
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'and', u'disorders', u'mostly', u')', u'(', u'behavioral', u'boys', u'characterized', u'learning', u'in', u'by', u'condition'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: halogen
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'and', u'ions', u'all', u'iodine', u'related', u'are', u'astatine', u'any', u'fluorine', u'readily', u')', u'(', u'negative', u'elements', u'form', u'that', u'bromine', u'monovalent', u'five', u'chlorine', u'of', u'nonmetallic', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: include
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'division', u'or', u'exchange', u'of', u'standard', u'as', mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'be', u'made', u'of', u',', u'up', u'as', u'part', u'measurement', u'accepted'u'have', u'out'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: Tamil
, u'any', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: exceptional
; prevleveltokens: city
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'ability', u'used', u'from', u'mental', u'normal', u'of', u'deviating', u'children', u'below', u'widely', u'in', u'intelligence', u';', u'especially', u'or', u'norm', u'physical'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: fluid
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include'mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'and', u'substance', u'room', u'that', u'is', u'fluid', u'pressure', u'at', u'temperature'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: Bay
, u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: given
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'smaller', u'shoreline', u'gulf', u'of', u'larger', u'cove', u'but', u'an', u'indentation', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: boundary
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: covering
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'natural', u'that', u'object', u'covers', u'envelops', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: serves
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'play', u'ball', u'puts', u'that', u')', u'(', u'sports', u'stroke', u'in', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: large
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: area
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'for', u'garment', u'large', u'person', u'size'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: miles
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'by', u'serving'mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'1609.344', u'of', u'exactly', u'equal', u'1,760', u'feet', u'to', u'length', u'meters', u'5,280', u'yards', u';', u'or', u'unit'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: unstable
, u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: stretchmapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'stability', u'fixity', u'or', u'lacking', u'firmness'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: people

mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: series
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'happening', u'things', u'after', u'order', u'placed', u'another', u'in', u'one', u'similar', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: energy
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'energy', u'are', u'physical', u'capacity', u'ergs', u'joules', u'(', u'system', u'to', u'units', u';', u'do', u'thermodynamic', u'equivalent', u'a', u'of', u'work', u')', u'the', u'physics', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: idea
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'personal', u'view'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: culture
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'and', u'distance', u'expanse', u'large', u'or', u'unbroken'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refiningmapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: used

mapFunction_Parents(): keyword: refining ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: populated
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'natural', u'for', u'service', u'into', u'work', u'or', u'employ', u'purpose', u'particular', u'put', u'inherent', u';', u'its', u'make'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: meters
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'be', u'of', u'or', u'live', u'inhabitant', u'in', mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u"d'Unites", u'Systeme', u')', u'of', u'under', u'adopted', u'length', u'(', u'yards', u'basic', u'approximately', u'International', u'the', u'unit', u'1.094'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: special
u';', u'an', u'inhabit'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
'Noasfer_pickle_string_load(): picklef.readlines(): refining
nmapFunction_Parents(): keyword: refining ; prevleveltokens: 0.621371
e'mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
]asfer_pickle_string_load(): picklef.readlines(): 
refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: Orthodox
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: way
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'pertaining', u'Judaism', u'characteristic', u'to', u'of', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: purpose
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'your', u'an', u'intended', u'that', u'is', u'actions', u'anticipated', u'planned', u'outcome', u'guides', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: learned
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'obtained', u'end', u'achieved', u'is', u'an', u'how', u'result', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: enlarging
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'be', u'certain', u'student', u'of', u'subject'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: degree
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add'mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'on', u'scale', u'of', u'amount', u'intensity', u'position', u'quality', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: importance
, u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually'mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'status', u'prominent'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: equivalent
, u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: urban
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: attention
mapFunction_Parents(): keyword=mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'on', u')', u'whereby', u'to', u'process', u'of', u'relative', u'others', u'some', u'exclusion', u'environment', u'person', u'(', u'concentrates', u'the', u'features'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: component
 refining ; syndef_tokens= set([u'a', u'city', u'populated', u'concerned', u'area', u'to', u'densely', u'relating', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: continuous
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'of', u'abstract', u'part', u'something', u'an'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: thorium
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'and', u'thorite', u'is', u'as', u'used', u'sands', u'in', u'232', u'monazite', u'nuclear', u'metallic', u'source', u'silvery-white', u';', u'occurs', u'tetravalent', u'power', u'isotope', u'a', u'radioactive', u'element', u'soft', u'reactors'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: clarify
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'and', u')', u'(', u'make', u'comprehensible', u'clear', u'more'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: densely
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'stupid', u'manner', u'in'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: conceal
mapFunction_Parents(): keyword= refining mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'prevent', u'from', u'being', u'discovered', u'seen', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: region
; syndef_tokens= set([u'interruption', u'space', u'in', u'continuing', u'without', u'time', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: moment
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'extended', u'of', u'something', u'spatial', u'the', u'location'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: title
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'point', u'in', u'time', u'particular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: western
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'statute', u'give', u'that', u'may', u'of', u'the', u'bill', u'brief', u'heading', u'deals', u'matters', u'names', u'it', u';', u'summary', u'with', u'or', u'legislative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: equal
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'and', u'about', u'United', u'development', u'of', u'life', u'period', u'States', u'exploration', u'western'mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'standing', u'group', u'of', u'is', u'who', u'equal', u'person', u'another', u'in', u'with'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: length
, u'in', u'during', u'the', u'film'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'fixed', u'from', u'linear', u'space', u'of', u'is', u'that', u'one', u'to', u'other', u'place', u'longest', u'extent', u'in', u'end', u'the', u'dimension', u';', u'something'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'development']
refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: particular
16/03/30 11:04:23 INFO PythonRunner: Times: total = 10022, boot = 500, init = 668, finish = 8854
16/03/30 11:04:23 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'about', u')', u'(', u'some', u'general', u'to', u'as', u'part', u'opposed', u'fact'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: white
16/03/30 11:04:23 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 10123 ms on localhost (1/2)
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'of', u'member', u'race', u'the', u'Caucasoid'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: kind
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'category', u'or', u'things', u'some', u'by', u'characteristic', u'common', u'of', u'quality', u'distinguished'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: administrative
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'for', u'of', u'responsible', u'administration', u'to', u'relating', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: work
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'directed', u'doing', u'something', u'activity', u'making', u'toward', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: patriarch
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'and', u'older', u'is', u'who', u'rank', u'yourself', u'in', u'higher', u'than', u'man'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: districts
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'off', u'for', u'region', u'purposes', u'marked', u'other', u'administrative', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: Church
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'and', u'own', u'have', u'of', u'who', u'one', u'forms', u'their', u'groups', u'the', u'worship', u'beliefs', u'Christians'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: male
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'babies', u'to', u'who', u'sex', u'person', u'that', u'belongs', u'can', u'have', u'not', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: distinguished
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'as', u'different', u'mark'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: devise
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'real', u'of', u'will', u'property', u'disposing'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: expanding
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: metric
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'function', u'them', u'for', u'that', u'of', u'space', u'equal', u',', u'topological', u'two', u'to', u'points', u'value', u'in', u'between', u'the', u'distance', u'any', u'gives'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: heaviest
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'to', u'is', u'who', u'it', u'fat', u'large', u'person', u'describes', u'but', u'usually', u'carry', u'has', u'frame'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: something
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: concentration
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'given', u'strength', u'of', u'solution', u'number', u'volume', u'substance', u'molecules', u'in', u'the', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: bishop
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: containing
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'component', u'as', u'have', u'contain', u';', u'include', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: things
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'possession', u'articles', u'especially', u')', u'(', u'movable', u'of', u'clothing', u'any'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: make
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'kind', u'recognizable'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: belong
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'possession', u'be', u'of', u'owned', u'by', u'in', u';', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: uranium
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'heavy', u'fuels', u'used', u'radioactive', u'and', u'for', u'many', u'isotopes', u'metallic', u'weapons', u'silvery-white', u'in', u'toxic', u'nuclear', u';', u'element', u'occurs'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: discourse
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'extended', u'verbal', u'writing', u'speech', u'in', u'expression', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: parts
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'less', u'of', u'artifact', u'something', u'human', u'the', u'whole', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: speech
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'spoken', u'of', u'communication', u'delivering', u'to', u'audience', u'act', u'the', u'an', u'formal'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: details
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'be', u'from', u'that', u'considered', u'separately', u'part', u'can', u'small', u'the', u'whole'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: geographical
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: several
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'count', u'used', u')', u'(', u'or', u'number', u'but', u'an', u'3', u'2', u'nouns', u'of', u'not', u'many', u'indefinite', u'with', u'than', u'more'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: circular
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'on', u'or', u'intended', u'for', u'wide', u')', u'(', u'an', u'leaflet', u'printed', u'advertisement', u'in', u'usually', u'distribution', u'page'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: independent
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'especially', u')', u'(', u'uncommitted', u'person', u'neutral', u'in', u'politics', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: product
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: elements
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'the', u'elements', u')', u'(', u'of', u'violent', u'by', u'four', u'severe', u'weather', u'caused', u'action', u'as', u'or', u'viewed'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: shelter
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'and', u'from', u'privacy', u'that', u'danger', u'protection', u'provides', u'structure'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: possible
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'be', u'done', u'something', u'can', u'that'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: meaning
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'consequence', u'as', u'logical', u'have'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: plan
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'be', u'carried', u'series', u'to', u'accomplished', u'steps', u'goals', u'of', u'or', u'out'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: tract
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'body', u'some', u'that', u'of', u'serve', u'system', u'together', u'parts', u'purpose', u'particular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: improving
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'better', u'to', u'make'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: genital
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'of', u'or', u'to', u'external', u'relating', u'sex', u'organs', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: spermatozoa
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'gamete', u'reproductive', u'cell', u'the', u'male', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: account
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'description', u'of', u'events', u'past', u'record', u'narrative', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: segment
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'one', u'a', u'fit', u'that', u'of', u'object', u'pieces', u'constitute', u'to', u'parts', u'whole', u'others', u'several', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: radioactive
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'caused', u'exhibiting', u'radioactivity', u'or', u'by'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: happening
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'happens', u'that', u'event', u'an'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: curve
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'whose', u'direction', u'trace', u'point', u'of', u'motion', u'the', u'changes'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: together
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'and', u'emotionally', u'mentally', u'stable'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: element
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'of', u'abstract', u'part', u'something', u'an'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: person
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'being', u'human'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: reputation
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'a', u'has', u'for', u'that', u'general', u'person', u'the', u'estimation', u'public'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: greatest
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'highest', u'quality', u'in'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): refining
mapFunction_Parents(): keyword: refining ; prevleveltokens: refining
mapFunction_Parents(): keyword= refining ; syndef_tokens= set([u'oil', u'from', u')', u'process', u'of', u'removing', u'metals', u'impurities', u'etc', u'as', u'(', u'the', u'sugar', u'.', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/30 11:04:24 INFO PythonRunner: Times: total = 10628, boot = 495, init = 677, finish = 9456
16/03/30 11:04:24 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/30 11:04:24 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) finished in 10.724 s
16/03/30 11:04:24 INFO DAGScheduler: looking for newly runnable stages
16/03/30 11:04:24 INFO DAGScheduler: running: Set()
16/03/30 11:04:24 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/30 11:04:24 INFO DAGScheduler: failed: Set()
16/03/30 11:04:24 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/30 11:04:24 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218), which is now runnable
16/03/30 11:04:24 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=12573, maxMem=556180439
16/03/30 11:04:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.4 MB)
16/03/30 11:04:24 INFO MemoryStore: ensureFreeSpace(3058) called with curMem=17557, maxMem=556180439
16/03/30 11:04:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.4 MB)
16/03/30 11:04:24 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 10722 ms on localhost (2/2)
16/03/30 11:04:24 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/30 11:04:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:36220 (size: 3.0 KB, free: 530.4 MB)
16/03/30 11:04:24 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/30 11:04:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:04:24 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/30 11:04:24 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/30 11:04:24 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/30 11:04:24 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/30 11:04:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/30 11:04:24 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/30 11:04:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/30 11:04:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/30 11:04:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
16/03/30 11:04:24 INFO PythonRunner: Times: total = 54, boot = -421, init = 474, finish = 1
16/03/30 11:04:24 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1287 bytes result sent to driver
reduceFunction_Parents(): returns= ['None', u'development', 'None']
16/03/30 11:04:24 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 85 ms on localhost (1/2)
16/03/30 11:04:24 INFO PythonRunner: Times: total = 258, boot = 257, init = 1, finish = 0
16/03/30 11:04:24 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/30 11:04:24 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 282 ms on localhost (2/2)
16/03/30 11:04:24 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/30 11:04:24 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) finished in 0.282 s
16/03/30 11:04:24 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218, took 11.037425 s
16/03/30 11:04:24 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218
16/03/30 11:04:24 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) with 2 output partitions
16/03/30 11:04:24 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:04:24 INFO DAGScheduler: Parents of final stage: List()
16/03/30 11:04:24 INFO DAGScheduler: Missing parents: List()
16/03/30 11:04:24 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218), which has no missing parents
16/03/30 11:04:24 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=20615, maxMem=556180439
16/03/30 11:04:24 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.4 MB)
16/03/30 11:04:24 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=26431, maxMem=556180439
16/03/30 11:04:24 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.4 MB)
16/03/30 11:04:24 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:36220 (size: 3.3 KB, free: 530.4 MB)
16/03/30 11:04:24 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/30 11:04:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:04:24 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/30 11:04:24 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/30 11:04:24 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2368 bytes)
16/03/30 11:04:24 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/30 11:04:24 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/30 11:04:24 INFO PythonRunner: Times: total = 73, boot = -45, init = 118, finish = 0
16/03/30 11:04:24 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1355 bytes result sent to driver
16/03/30 11:04:24 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 87 ms on localhost (1/2)
16/03/30 11:04:24 INFO PythonRunner: Times: total = 116, boot = 116, init = 0, finish = 0
16/03/30 11:04:24 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/30 11:04:24 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 130 ms on localhost (2/2)
16/03/30 11:04:24 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/30 11:04:24 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) finished in 0.112 s
16/03/30 11:04:24 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218, took 0.147857 s
16/03/30 11:04:24 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/30 11:04:24 INFO DAGScheduler: Stopping DAGScheduler
16/03/30 11:04:24 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/30 11:04:24 INFO MemoryStore: MemoryStore cleared
16/03/30 11:04:24 INFO BlockManager: BlockManager stopped
16/03/30 11:04:24 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/30 11:04:24 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/30 11:04:24 INFO SparkContext: Successfully stopped SparkContext
16/03/30 11:04:24 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/30 11:04:24 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/30 11:04:24 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: <memcache.Client object at 0xb0c00a1c>
asfer_pickle_string_dump(): picklef.write(): time
16/03/30 11:04:25 INFO SparkContext: Running Spark version 1.5.2
16/03/30 11:04:25 INFO SecurityManager: Changing view acls to: root
16/03/30 11:04:25 INFO SecurityManager: Changing modify acls to: root
16/03/30 11:04:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/30 11:04:25 INFO Slf4jLogger: Slf4jLogger started
16/03/30 11:04:25 INFO Remoting: Starting remoting
16/03/30 11:04:25 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:53227]
16/03/30 11:04:25 INFO Utils: Successfully started service 'sparkDriver' on port 53227.
16/03/30 11:04:25 INFO SparkEnv: Registering MapOutputTracker
16/03/30 11:04:25 INFO SparkEnv: Registering BlockManagerMaster
16/03/30 11:04:25 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c29010aa-b32e-44f8-9d7d-21213bcb19a5
16/03/30 11:04:25 INFO MemoryStore: MemoryStore started with capacity 530.4 MB
16/03/30 11:04:25 INFO HttpFileServer: HTTP File server directory is /tmp/spark-0e0df6d9-7161-45bf-b9ec-cf9574d76f1c/httpd-63f2d2b8-8fc9-44a6-97a2-b194be2af99c
16/03/30 11:04:25 INFO HttpServer: Starting HTTP Server
16/03/30 11:04:25 INFO Utils: Successfully started service 'HTTP file server' on port 49393.
16/03/30 11:04:25 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/30 11:04:26 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/30 11:04:26 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/30 11:04:26 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-0e0df6d9-7161-45bf-b9ec-cf9574d76f1c/userFiles-0d5ca6c1-65c2-4e57-b74d-6a502b7b3ed2/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/30 11:04:26 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1459316066507
16/03/30 11:04:26 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/30 11:04:26 INFO Executor: Starting executor ID driver on host localhost
16/03/30 11:04:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39032.
16/03/30 11:04:26 INFO NettyBlockTransferService: Server created on 39032
16/03/30 11:04:26 INFO BlockManagerMaster: Trying to register BlockManager
16/03/30 11:04:26 INFO BlockManagerMasterEndpoint: Registering block manager localhost:39032 with 530.4 MB RAM, BlockManagerId(driver, localhost, 39032)
16/03/30 11:04:26 INFO BlockManagerMaster: Registered BlockManager
16/03/30 11:04:26 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218
16/03/30 11:04:26 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:04:26 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) with 2 output partitions
16/03/30 11:04:26 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:04:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/30 11:04:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/30 11:04:26 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218), which has no missing parents
16/03/30 11:04:26 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=556180439
16/03/30 11:04:26 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.4 MB)
16/03/30 11:04:26 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=556180439
16/03/30 11:04:26 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.4 MB)
16/03/30 11:04:26 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:39032 (size: 4.1 KB, free: 530.4 MB)
16/03/30 11:04:26 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/30 11:04:26 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:04:26 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/30 11:04:26 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 3252 bytes)
16/03/30 11:04:26 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 3383 bytes)
16/03/30 11:04:26 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/30 11:04:26 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1459316066507
16/03/30 11:04:26 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/30 11:04:26 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-0e0df6d9-7161-45bf-b9ec-cf9574d76f1c/userFiles-0d5ca6c1-65c2-4e57-b74d-6a502b7b3ed2/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/30 11:04:26 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/30 11:04:26 INFO MemoryStore: ensureFreeSpace(873) called with curMem=10732, maxMem=556180439
16/03/30 11:04:26 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 873.0 B, free 530.4 MB)
16/03/30 11:04:26 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:39032 (size: 873.0 B, free: 530.4 MB)
16/03/30 11:04:26 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/30 11:04:26 INFO MemoryStore: ensureFreeSpace(965) called with curMem=11605, maxMem=556180439
16/03/30 11:04:26 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 965.0 B, free 530.4 MB)
16/03/30 11:04:26 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:39032 (size: 965.0 B, free: 530.4 MB)
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: kilometer
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: usually
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: set
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: bend
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: semen
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'containing', u'that', u'ejaculated', u'thick', u'white', u'fluid', u'by', u'tract', u'genital', u'spermatozoa', u'male', u'the', u'is'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: giant
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: limit
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'degree', u'of', u'possible', u'something', u'the', u'greatest'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: area
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: astatine
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: set
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: present
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  time  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: area
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: dwell
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'about', u'moodily', u'anxiously', u'or', u'something', u'think'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: screen
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'be', u'for', u'pictures', u'projected', u'surface', u'silvered', u'viewing', u'can', u'white', u'where', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: city
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: whole
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'all', u'elements', u'of', u'component', u'or', u'parts', u'including', u'something', u'its'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: focus
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'on', u'of', u'energy', u'attention', u'or', u'something', u'the', u'concentration'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: plan
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'be', u'carried', u'series', u'to', u'accomplished', u'steps', u'goals', u'of', u'or', u'out'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: development
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'of', u'act', u'by', u'refining', u'expanding', u'improving', u'enlarging', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: elaborate
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: serving
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Madras
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: ejaculated
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'impulsively', u'utter'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Bengal
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'whose', u'and', u'Bangladesh', u'eastern', u'region', u'India', u'part', u'western', u'in', u'included', u'now', u'is'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: including
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'be', u'made', u'of', u',', u'up', u'as', u'part', u'have', u'out'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: geography
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: group
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u')', u'(', u'number', u'entities', u'as', u'considered', u'members', u'of', u'any', u'unit'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: decay
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'normal', u'conditions', u'under'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: 1000
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'10', u'product', u'that', u'of', u'is', u'number', u'cardinal', u'the', u'100'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: composed
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'gradual', u'charge', u'current', u'as', u'stored', u'decrease', u'of', u';', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: writing
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'creating', u'of', u'written', u'act', u'the', u'works'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: add
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'of', u'the', u'substance', u'form'])
mapFunction_Parents(): returns= [mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'disorders', u'mostly', u')', u'(', u'behavioral', u'boys', u'characterized', u'learning', u'in', u'by', u'condition'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: halogen
]
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword:mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'ions', u'all', u'iodine', u'related', u'are', u'astatine', u'any', u'fluorine', u'readily', u')', u'(', u'negative', u'elements', u'form', u'that', u'bromine', u'monovalent', u'five', u'chlorine', u'of', u'nonmetallic', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
 asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: include
time ; prevleveltokens: formerly
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u';', u'time'mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'be', u'made', u'of', u',', u'up', u'as', u'part', u'have', u'out'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Tamil
, u'at', u'previous'])
mapFunction_Parents(): adding to parents: syn =  Synset('once.r.03') ; keyword:  time  in syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: exceptional
])
mapFunction_Parents(): returns= [u'formerly']
reduceFunction_Parents(): returns= ['None', u'formerly']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: period
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'ability', u'used', u'from', u'mental', u'normal', u'of', u'deviating', u'children', u'below', u'widely', u'in', u'intelligence', u';', u'especially', u'or', u'norm', u'physical'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: fluid
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'substance', u'room', u'that', u'is', u'fluid', u'pressure', u'at', u'temperature'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Bay
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'smaller', u'shoreline', u'gulf', u'of', u'larger', u'cove', u'but', u'an', u'indentation', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: boundary
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: covering
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'of', u'amount', u'time', u'an'])
mapFunction_Parents(): adding to parents: syn =  Synset('time_period.n.01') ; keyword:  time  in syndef_tokens= set([u'of', u'amount', u'time', u'an'])
mapFunction_Parents(): returns= [u'period']
reduceFunction_Parents(): returns= ['None', u'formerly', u'period']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: highly
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'degree', u'favorably', u'high', u'to', u'much', u'extent', u'respect', u';', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: thick
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'natural', u'that', u'object', u'covers', u'envelops', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: serves
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'of', u'surrounded', u'other', u'location', u'things', u'the', u'by'mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'play', u'ball', u'puts', u'that', u')', u'(', u'sports', u'stroke', u'in', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: large
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'for', u'garment', u'large', u'person', u'size'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: miles
, u'something'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'1609.344', u'of', u'exactly', u'equal', u'1,760', u'feet', u'to', u'length', u'meters', u'5,280', u'yards', u';', u'or', u'unit'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: unstable
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly'mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'stability', u'fixity', u'or', u'lacking', u'firmness'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: people
, u'period']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: unit
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: series
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'division', u'or', u'exchange', u'of', u'standard', u'as', u'measurement', u'accepted', u'any', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'happening', u'things', u'after', u'order', u'placed', u'another', u'in', u'one', u'similar', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: energy
mapFunction_Parents(): keyword: time ; prevleveltokens: city
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'energy', u'are', u'physical', u'capacity', u'ergs', u'joules', u'(', u'system', u'to', u'units', u';', u'do', u'thermodynamic', u'equivalent', u'a', u'of', u'work', u')', u'the', u'physics', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: idea
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'personal', u'view'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: culture
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): adding to parents: syn =  Synset('culture.n.01') ; keyword:  time  in syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= [u'culture']
reduceFunction_Parents(): returns= ['None', u'present', u'culture']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: used
u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: given
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'natural', u'for', u'service', u'into', u'work', u'or', u'employ', u'purpose', u'particular', u'put', u'inherent', u';', u'its', u'make'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present', u'culture']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: meters
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u"d'Unites", u'Systeme', u')', u'of', u'under', u'adopted', u'length', u'(', u'yards', u'basic', u'approximately', u'International', u'the', u'unit', u'1.094'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present', u'culture']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: special
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present', u'culture']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: 0.621371
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present', u'culture']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Orthodox
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'pertaining', u'Judaism', u'characteristic', u'to', u'of', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present', u'culture']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: purpose
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'your', u'an', u'intended', u'that', u'is', u'actions', u'anticipated', u'planned', u'outcome', u'guides', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present', u'culture']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: learned
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'be', u'certain', u'student', u'of', u'subject'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present', u'culture']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: degree
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'on', u'scale', u'of', u'amount', u'intensity', u'position', u'quality', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present', u'culture']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: importance
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'status', u'prominent'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present', u'culture']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: equivalent
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present', u'culture']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: attention
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'on', u')', u'whereby', u'to', u'process', u'of', u'relative', u'others', u'some', u'exclusion', u'environment', u'person', u'(', u'concentrates', u'the', u'features'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present', u'culture']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: component
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'for', u'that', u'is', mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'of', u'abstract', u'part', u'something', u'an'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present', u'culture']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: thorium
u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['NonemapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'thorite', u'is', u'as', u'used', u'sands', u'in', u'232', u'monazite', u'nuclear', u'metallic', u'source', u'silvery-white', u';', u'occurs', u'tetravalent', u'power', u'isotope', u'a', u'radioactive', u'element', u'soft', u'reactors'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present', u'culture']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: clarify
', u'formerly', u'period']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: area
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u')', u'(', u'make', u'comprehensible', u'clear', u'more'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present', u'culture']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: densely
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'stupid', u'manner', u'in'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present', u'culture']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: conceal
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'prevent', u'from', u'being', u'discovered', u'seen', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present', u'culture']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: region
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished'mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'extended', u'of', u'something', u'spatial', u'the', u'location'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present', u'culture']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: title
, u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: stretch
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'statute', u'give', u'that', u'may', u'of', u'the', u'bill', u'brief', u'heading', u'deals', u'matters', u'names', u'it', u';', u'summary', u'with', u'or', u'legislative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present', u'culture']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: equal
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'standing', u'group', u'of', u'is', u'who', u'equal', u'person', u'another', u'in', u'with'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present', u'culture']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: length
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'fixed', u'from', u'linear', u'space', u'of', u'is', u'that', u'one', u'to', u'other', u'place', u'longest', u'extent', u'in', u'end', u'the', u'dimension', u';', u'something'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present', u'culture']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: act
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'distance', u'expanse', u'large', u'or', u'unbroken'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: populated
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'deliberations', u'legislative', u'of', u'body', u'legal', u'society', u'codifying', u'committee', u'the', u'document', u'or', u'result'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present', u'culture']
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'be', u'of', u'or', u'live', u'inhabitant', u'in', u';', u'an', u'inhabit'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword:16/03/30 11:04:36 INFO PythonRunner: Times: total = 9733, boot = 491, init = 444, finish = 8798
16/03/30 11:04:36 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
 time ; prevleveltokens: way
16/03/30 11:04:36 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9821 ms on localhost (1/2)
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'obtained', u'end', u'achieved', u'is', u'an', u'how', u'result', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: enlarging
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: urban
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'city', u'populated', u'concerned', u'area', u'to', u'densely', u'relating', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: continuous
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'interruption', u'space', u'in', u'continuing', u'without', u'time', u'or'])
mapFunction_Parents(): adding to parents: syn =  Synset('continuous.a.01') ; keyword:  time  in syndef_tokens= set([u'interruption', u'space', u'in', u'continuing', u'without', u'time', u'or'])
mapFunction_Parents(): returns= [u'continuous']
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: moment
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'point', u'in', u'time', u'particular'])
mapFunction_Parents(): adding to parents: syn =  Synset('moment.n.01') ; keyword:  time  in syndef_tokens= set([u'a', u'point', u'in', u'time', u'particular'])
mapFunction_Parents(): returns= [u'moment']
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: western
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'about', u'United', u'development', u'of', u'life', u'period', u'States', u'exploration', u'western', u'in', u'during', u'the', u'film'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: particular
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'about', u')', u'(', u'some', u'general', u'to', u'as', u'part', u'opposed', u'fact'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: white
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'of', u'member', u'race', u'the', u'Caucasoid'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: kind
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'category', u'or', u'things', u'some', u'by', u'characteristic', u'common', u'of', u'quality', u'distinguished'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: administrative
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'for', u'of', u'responsible', u'administration', u'to', u'relating', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: work
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'directed', u'doing', u'something', u'activity', u'making', u'toward', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: patriarch
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'older', u'is', u'who', u'rank', u'yourself', u'in', u'higher', u'than', u'man'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: districts
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'off', u'for', u'region', u'purposes', u'marked', u'other', u'administrative', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Church
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'own', u'have', u'of', u'who', u'one', u'forms', u'their', u'groups', u'the', u'worship', u'beliefs', u'Christians'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: male
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'babies', u'to', u'who', u'sex', u'person', u'that', u'belongs', u'can', u'have', u'not', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: distinguished
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'as', u'different', u'mark'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: devise
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'real', u'of', u'will', u'property', u'disposing'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: expanding
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: metric
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'function', u'them', u'for', u'that', u'of', u'space', u'equal', u',', u'topological', u'two', u'to', u'points', u'value', u'in', u'between', u'the', u'distance', u'any', u'gives'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: heaviest
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'to', u'is', u'who', u'it', u'fat', u'large', u'person', u'describes', u'but', u'usually', u'carry', u'has', u'frame'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: something
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: concentration
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'given', u'strength', u'of', u'solution', u'number', u'volume', u'substance', u'molecules', u'in', u'the', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: bishop
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: containing
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'component', u'as', u'have', u'contain', u';', u'include', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: things
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'possession', u'articles', u'especially', u')', u'(', u'movable', u'of', u'clothing', u'any'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: make
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'kind', u'recognizable'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: belong
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'possession', u'be', u'of', u'owned', u'by', u'in', u';', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: uranium
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'heavy', u'fuels', u'used', u'radioactive', u'and', u'for', u'many', u'isotopes', u'metallic', u'weapons', u'silvery-white', u'in', u'toxic', u'nuclear', u';', u'element', u'occurs'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: discourse
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'extended', u'verbal', u'writing', u'speech', u'in', u'expression', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: parts
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'less', u'of', u'artifact', u'something', u'human', u'the', u'whole', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: speech
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'spoken', u'of', u'communication', u'delivering', u'to', u'audience', u'act', u'the', u'an', u'formal'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: details
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'be', u'from', u'that', u'considered', u'separately', u'part', u'can', u'small', u'the', u'whole'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: geographical
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: several
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'count', u'used', u')', u'(', u'or', u'number', u'but', u'an', u'3', u'2', u'nouns', u'of', u'not', u'many', u'indefinite', u'with', u'than', u'more'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: circular
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'on', u'or', u'intended', u'for', u'wide', u')', u'(', u'an', u'leaflet', u'printed', u'advertisement', u'in', u'usually', u'distribution', u'page'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: independent
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'especially', u')', u'(', u'uncommitted', u'person', u'neutral', u'in', u'politics', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: product
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: elements
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'the', u'elements', u')', u'(', u'of', u'violent', u'by', u'four', u'severe', u'weather', u'caused', u'action', u'as', u'or', u'viewed'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: shelter
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'from', u'privacy', u'that', u'danger', u'protection', u'provides', u'structure'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: possible
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'be', u'done', u'something', u'can', u'that'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: meaning
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'consequence', u'as', u'logical', u'have'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: plan
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'be', u'carried', u'series', u'to', u'accomplished', u'steps', u'goals', u'of', u'or', u'out'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: tract
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'body', u'some', u'that', u'of', u'serve', u'system', u'together', u'parts', u'purpose', u'particular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: improving
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'better', u'to', u'make'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: genital
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'of', u'or', u'to', u'external', u'relating', u'sex', u'organs', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: spermatozoa
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'gamete', u'reproductive', u'cell', u'the', u'male', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: account
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'description', u'of', u'events', u'past', u'record', u'narrative', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: segment
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'one', u'a', u'fit', u'that', u'of', u'object', u'pieces', u'constitute', u'to', u'parts', u'whole', u'others', u'several', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: radioactive
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'caused', u'exhibiting', u'radioactivity', u'or', u'by'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: happening
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'happens', u'that', u'event', u'an'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: curve
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'whose', u'direction', u'trace', u'point', u'of', u'motion', u'the', u'changes'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: together
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'emotionally', u'mentally', u'stable'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: element
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'of', u'abstract', u'part', u'something', u'an'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: person
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'being', u'human'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: reputation
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'has', u'for', u'that', u'general', u'person', u'the', u'estimation', u'public'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: greatest
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'highest', u'quality', u'in'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: refining
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'oil', u'from', u')', u'process', u'of', u'removing', u'metals', u'impurities', u'etc', u'as', u'(', u'the', u'sugar', u'.', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: time
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'event', u'for', u'some', u'an', u'instance', u'single', u'occasion', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'formerly', u'period', u'continuous', u'moment']
16/03/30 11:04:37 INFO PythonRunner: Times: total = 10458, boot = 485, init = 653, finish = 9320
16/03/30 11:04:37 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/30 11:04:37 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) finished in 10.550 s
16/03/30 11:04:37 INFO DAGScheduler: looking for newly runnable stages
16/03/30 11:04:37 INFO DAGScheduler: running: Set()
16/03/30 11:04:37 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/30 11:04:37 INFO DAGScheduler: failed: Set()
16/03/30 11:04:37 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/30 11:04:37 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218), which is now runnable
16/03/30 11:04:37 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=12570, maxMem=556180439
16/03/30 11:04:37 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.4 MB)
16/03/30 11:04:37 INFO MemoryStore: ensureFreeSpace(3058) called with curMem=17554, maxMem=556180439
16/03/30 11:04:37 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.4 MB)
16/03/30 11:04:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:39032 (size: 3.0 KB, free: 530.4 MB)
16/03/30 11:04:37 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/30 11:04:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:04:37 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/30 11:04:37 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 10548 ms on localhost (2/2)
16/03/30 11:04:37 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/30 11:04:37 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/30 11:04:37 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/30 11:04:37 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/30 11:04:37 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/30 11:04:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/30 11:04:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/30 11:04:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/30 11:04:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'present', u'culture', 'None', u'formerly', u'period', u'continuous', u'moment']
16/03/30 11:04:37 INFO PythonRunner: Times: total = 21, boot = -545, init = 566, finish = 0
16/03/30 11:04:37 INFO PythonRunner: Times: total = 381, boot = 258, init = 122, finish = 1
16/03/30 11:04:37 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1355 bytes result sent to driver
16/03/30 11:04:37 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:39032 in memory (size: 4.1 KB, free: 530.4 MB)
16/03/30 11:04:37 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/30 11:04:37 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 456 ms on localhost (1/2)
16/03/30 11:04:37 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 462 ms on localhost (2/2)
16/03/30 11:04:37 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/30 11:04:37 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) finished in 0.445 s
16/03/30 11:04:37 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218, took 11.038166 s
16/03/30 11:04:37 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218
16/03/30 11:04:37 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) with 2 output partitions
16/03/30 11:04:37 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:04:37 INFO DAGScheduler: Parents of final stage: List()
16/03/30 11:04:37 INFO DAGScheduler: Missing parents: List()
16/03/30 11:04:37 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218), which has no missing parents
16/03/30 11:04:37 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=9880, maxMem=556180439
16/03/30 11:04:37 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.4 MB)
16/03/30 11:04:37 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=15696, maxMem=556180439
16/03/30 11:04:37 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.4 MB)
16/03/30 11:04:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:39032 (size: 3.3 KB, free: 530.4 MB)
16/03/30 11:04:37 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/30 11:04:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:04:37 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/30 11:04:37 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/30 11:04:37 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2436 bytes)
16/03/30 11:04:37 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/30 11:04:37 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/30 11:04:37 INFO PythonRunner: Times: total = 90, boot = -139, init = 229, finish = 0
16/03/30 11:04:37 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/30 11:04:37 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 102 ms on localhost (1/2)
16/03/30 11:04:38 INFO PythonRunner: Times: total = 197, boot = 197, init = 0, finish = 0
16/03/30 11:04:38 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1423 bytes result sent to driver
16/03/30 11:04:38 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 212 ms on localhost (2/2)
16/03/30 11:04:38 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/30 11:04:38 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) finished in 0.192 s
16/03/30 11:04:38 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218, took 0.222240 s
16/03/30 11:04:38 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/30 11:04:38 INFO DAGScheduler: Stopping DAGScheduler
16/03/30 11:04:38 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/30 11:04:38 INFO MemoryStore: MemoryStore cleared
16/03/30 11:04:38 INFO BlockManager: BlockManager stopped
16/03/30 11:04:38 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/30 11:04:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/30 11:04:38 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/30 11:04:38 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/30 11:04:38 INFO SparkContext: Successfully stopped SparkContext
16/03/30 11:04:38 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: <memcache.Client object at 0xb0c00a1c>
asfer_pickle_string_dump(): picklef.write(): position
16/03/30 11:04:39 INFO SparkContext: Running Spark version 1.5.2
16/03/30 11:04:39 INFO SecurityManager: Changing view acls to: root
16/03/30 11:04:39 INFO SecurityManager: Changing modify acls to: root
16/03/30 11:04:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/30 11:04:39 INFO Slf4jLogger: Slf4jLogger started
16/03/30 11:04:39 INFO Remoting: Starting remoting
16/03/30 11:04:39 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:57108]
16/03/30 11:04:39 INFO Utils: Successfully started service 'sparkDriver' on port 57108.
16/03/30 11:04:39 INFO SparkEnv: Registering MapOutputTracker
16/03/30 11:04:39 INFO SparkEnv: Registering BlockManagerMaster
16/03/30 11:04:39 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2d339207-e6ad-465d-9e93-cd85605538b3
16/03/30 11:04:39 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
16/03/30 11:04:39 INFO HttpFileServer: HTTP File server directory is /tmp/spark-0e0df6d9-7161-45bf-b9ec-cf9574d76f1c/httpd-d135eff1-c94d-44ad-83ff-cc89146a2868
16/03/30 11:04:39 INFO HttpServer: Starting HTTP Server
16/03/30 11:04:39 INFO Utils: Successfully started service 'HTTP file server' on port 41577.
16/03/30 11:04:39 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/30 11:04:39 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/30 11:04:39 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/30 11:04:39 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-0e0df6d9-7161-45bf-b9ec-cf9574d76f1c/userFiles-26f9ded0-e0d6-44b6-8754-5ea34ef4d9ad/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/30 11:04:39 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1459316079909
16/03/30 11:04:39 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/30 11:04:39 INFO Executor: Starting executor ID driver on host localhost
16/03/30 11:04:39 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54647.
16/03/30 11:04:39 INFO NettyBlockTransferService: Server created on 54647
16/03/30 11:04:39 INFO BlockManagerMaster: Trying to register BlockManager
16/03/30 11:04:39 INFO BlockManagerMasterEndpoint: Registering block manager localhost:54647 with 530.0 MB RAM, BlockManagerId(driver, localhost, 54647)
16/03/30 11:04:39 INFO BlockManagerMaster: Registered BlockManager
16/03/30 11:04:40 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218
16/03/30 11:04:40 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:04:40 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) with 2 output partitions
16/03/30 11:04:40 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:04:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/30 11:04:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/30 11:04:40 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218), which has no missing parents
16/03/30 11:04:40 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555755765
16/03/30 11:04:40 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)
16/03/30 11:04:40 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555755765
16/03/30 11:04:40 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)
16/03/30 11:04:40 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:54647 (size: 4.1 KB, free: 530.0 MB)
16/03/30 11:04:40 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/30 11:04:40 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:04:40 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/30 11:04:40 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 3252 bytes)
16/03/30 11:04:40 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 3415 bytes)
16/03/30 11:04:40 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/30 11:04:40 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1459316079909
16/03/30 11:04:40 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/30 11:04:40 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-0e0df6d9-7161-45bf-b9ec-cf9574d76f1c/userFiles-26f9ded0-e0d6-44b6-8754-5ea34ef4d9ad/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/30 11:04:40 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/30 11:04:40 INFO MemoryStore: ensureFreeSpace(873) called with curMem=10732, maxMem=555755765
16/03/30 11:04:40 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 873.0 B, free 530.0 MB)
16/03/30 11:04:40 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:54647 (size: 873.0 B, free: 530.0 MB)
16/03/30 11:04:40 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/30 11:04:40 INFO MemoryStore: ensureFreeSpace(989) called with curMem=11605, maxMem=555755765
16/03/30 11:04:40 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 989.0 B, free 530.0 MB)
16/03/30 11:04:40 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:54647 (size: 989.0 B, free: 530.0 MB)
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: kilometer
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: usually
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: set
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'normal', u'conditions', u'under'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: 1000
mapFunction_Parents(): keyword: position ; prevleveltokens: bend
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'10', u'product', u'that', u'of', u'is', u'number', u'cardinal', u'the', u'100'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: composed
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: semen
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'containing', u'that', u'ejaculated', u'thick', u'white', u'fluid', u'by', u'tract', u'genital', u'spermatozoa', mapFunction_Parents(): keyword=u'male' position ; syndef_tokens= set([u'of', u'the', u'substance', u'form'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: formerly
, u'the', u'is'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: period
'None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: giant
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'of', u'amount', u'time', u'an'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: highly
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'degree', u'favorably', u'high', u'to', u'much', u'extent', u'respect', u';', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: thick
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: limit
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'of', u'surrounded', u'other', u'location', u'things', u'the', u'by', u'something'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: unit
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'degree', u'of', u'possible', u'something', u'the', u'greatest'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  position  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: area
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'division', u'or', u'exchange', u'of', u'standard', u'as', u'measurement', u'accepted', u'any', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: city
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: given

reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: astatine
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: set
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: present
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: area
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: stretch
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  position  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: area
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: dwell
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'about', u'moodily', u'anxiously', u'or', u'something', u'think'])
mapFunction_Parents(): returns=mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'distance', u'expanse', u'large', u'or', u'unbroken'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: archbishop
 []
reduceFunction_Parents(): returns= ['NonemapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: populated
', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: screen
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'be', u'of', u'or', u'live', u'inhabitant', u'in', u';', u'an', u'inhabit'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: way
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'obtained', u'end', u'achieved', u'is', u'an', u'how', u'result', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: enlarging
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'be', u'for', u'pictures', u'projected', u'surface', u'silvered', u'viewing', u'can', u'white', u'where', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: city
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: urban
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: wholemapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'city', u'populated', u'concerned', u'area', u'to', u'densely', u'relating', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: continuous

mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'interruption', u'space', u'in', u'continuing', u'without', u'time', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: moment
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'point', u'in', u'time', u'particular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: western
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'all', u'elements', u'of', u'component', u'or', u'parts', u'including', u'something', u'its'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan'mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'about', u'United', u'development', u'of', u'life', u'period', u'States', u'exploration', u'western', u'in', u'during', u'the', u'film'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: particular
, u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: focus
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'about', u')', u'(', u'some', u'general', u'to', u'as', u'part', u'opposed', u'fact'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: white
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'on', u'of', u'energy', u'attention', u'or', u'something', u'the', u'concentration'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: plan
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'be', u'carried', u'series', u'to', u'accomplished', u'steps', u'goals', u'of', u'or', u'out'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: development
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'of', u'act', u'by', u'refining', u'expanding', u'improving', u'enlarging', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: elaborate
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'of', u'member', u'race', u'the', u'Caucasoid'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: kind
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'category', u'or', u'things', u'some', u'by', u'characteristic', u'common', u'of', u'quality', u'distinguished'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: administrative
mapFunction_Parents(): keyword= position ; syndef_tokens= set([mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'for', u'of', u'responsible', u'administration', u'to', u'relating', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: work
u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: serving
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Madras
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: ejaculated
mapFunction_Parents(): keyword= positionmapFunction_Parents(): keyword= position ; syndef_tokens= set([u'directed', u'doing', u'something', u'activity', u'making', u'toward', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: patriarch
 ; syndef_tokens= set([u'impulsively', u'utter'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: BengalmapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'older', u'is', u'who', u'rank', u'yourself', u'in', u'higher', u'than', u'man'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: districts

mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a'mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'off', u'for', u'region', u'purposes', u'marked', u'other', u'administrative', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Eastern
, u'whose', u'and', u'Bangladesh', u'eastern', u'region', u'India', u'part', u'western', u'in', u'included', u'now', u'is'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: including
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Church
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'own', u'have', u'of', u'who', u'one', u'forms', u'their', u'groups', u'the', u'worship', u'beliefs', u'Christians'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: male
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'be', u'made', u'of', u',', u'up', u'as', u'part', u'have', u'out'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: geography
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: group
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u')', u'(', u'number', u'entities', u'as', u'considered', u'members', u'of', u'any', u'unit'mapFunction_Parents(): keyword=]) position ; syndef_tokens= set([u'a', u'babies', u'to', u'who', u'sex', u'person', u'that', u'belongs', u'can', u'have', u'not', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']

mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns=asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: distinguished
 ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: decay
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'gradual', u'charge', u'current', u'as', u'stored', u'decrease', u'of', u';', mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'as', u'different', u'mark'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: devise
u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: writing
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'real', u'of', u'will', u'property', u'disposing'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: expanding
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: metric
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'function', u'them', u'for', u'that', u'of', u'space', u'equal', u',', u'topological', u'two', u'to', u'points', u'value', u'in', u'between', u'the', u'distance', u'any', u'gives'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: heaviest
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'creating', u'of', u'written', u'act', u'the', u'works'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: add
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'disorders', u'mostly', u')', u'(', u'behavioral', u'boys', u'characterized', u'learning', u'in', u'by', u'condition'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: halogen
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'ions', u'all', u'iodine', u'related', u'are', u'astatine', u'any', u'fluorine', u'readily', u')', u'(', u'negative', u'elements', u'form', u'that', u'bromine', u'monovalent', u'five', u'chlorine', u'of', u'nonmetallic', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: include
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'be', u'made', u'of', u',', u'up', u'as', u'part', u'have', u'out'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'to', u'is', u'who', u'it', u'fat', u'large', u'person', u'describes', u'but', u'usually', u'carry', u'has', u'frame'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: something
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: concentration
u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: exceptional
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'given', u'strength', u'of', u'solution', u'number', u'volume', u'substance', u'molecules', u'in', u'the', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: bishop
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'ability', u'used', u'from', u'mental', u'normal', u'of', mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: containing
u'deviating', u'children', u'below', u'widely', u'in', u'intelligence', u';', u'especially', u'or', u'norm', u'physical'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: fluid
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'substance', u'room', u'that', u'is', u'fluid', u'pressure', u'at', u'temperature'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Bay
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'component', u'as', u'have', u'contain', u';', u'include', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: things
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'smaller', u'shoreline', u'gulf', u'of', u'larger', u'cove', u'but', u'an', u'indentation', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= mapFunction_Parents(): keyword=[ position ; syndef_tokens= set([u'possession', u'articles', u'especially', u')', u'(', u'movable', u'of', u'clothing', u'any'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: make
'None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: boundary
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: covering
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'natural', u'that', u'object', u'covers', u'envelops', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: serves
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'play', u'ball'mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'kind', u'recognizable'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: belong
, u'puts', u'that', u')', u'(', u'sports', u'stroke', u'in', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: large
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'possession', u'be', u'of', u'owned', u'by', u'in', u';', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: uranium
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'heavy', u'fuels', u'used', u'radioactive', u'and', u'for', u'many', u'isotopes', u'metallic', u'weapons', u'silvery-white', u'in', u'toxic', u'nuclear', u';', u'element', u'occurs'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: discourse
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'extended', u'verbal', u'writing', u'speech', u'in', u'expression', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: parts
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'for', u'garment', u'large', u'person', u'size'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: miles
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'1609.344', u'of', u'exactly', u'equal', u'1,760', u'feet', u'to', u'length', u'meters', u'5,280', u'yards', u';', u'or', u'unit'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: unstable
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'stability', u'fixity', u'or', u'lacking', u'firmness'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None'mapFunction_Parents(): keyword=,  position ; syndef_tokens= set([u'a', u'less', u'of', u'artifact', u'something', u'human', u'the', u'whole', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: speech
u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: people
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'spoken', u'of', u'communication', u'delivering', u'to', u'audience', u'act', u'the', u'an', u'formal'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: details
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan'mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'be', u'from', u'that', u'considered', u'separately', u'part', u'can', u'small', u'the', u'whole'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: geographical
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: several
]
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: series
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'count', u'used', u')', u'(', u'or', u'number', u'but', u'an', u'3', u'2', u'nouns', u'of', u'not', u'many', u'indefinite', u'with', u'than', u'more'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'happening', u'things', u'after', u'order', u'placed', u'another', u'in', u'one', u'similar', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: energy
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: circular
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'on', u'or', u'intended', u'for', u'wide', u')', u'(', u'an', u'leaflet', u'printed', u'advertisement', u'in', u'usually', u'distribution', u'page'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: independent
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'energy', u'are', u'physical', u'capacity', u'ergs', u'joules', u'(', u'system', u'to', u'units', u';', u'do', u'thermodynamic', u'equivalent', u'a', u'of', u'work', u')', u'the', u'physics', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: idea
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'personal', u'view'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan'mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'especially', u')', u'(', u'uncommitted', u'person', u'neutral', u'in', u'politics', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: product
, u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', mapFunction_Parents(): keyword=u'the' position ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: elements
, u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: culture
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'the', u'elements', u')', u'(', u'of', u'violent', u'by', u'four', u'severe', u'weather', u'caused', u'action', u'as', u'or', u'viewed'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: shelter
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: used
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'from', u'privacy', u'that', u'danger', u'protection', u'provides', u'structure'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: possible
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'natural', u'for', u'service', u'into', u'work', u'or', u'employ', u'purpose', u'particular', u'put', u'inherent', u';', u'its'mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'be', u'done', u'something', u'can', u'that'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: meaning
, u'make'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: meters
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'consequence', u'as', u'logical', u'have'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: plan
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u"d'Unites", u'Systeme', u')', u'of', u'under', u'adopted', u'length', u'(', u'yards', u'basic', u'approximately', u'International', u'the', u'unit', u'1.094'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: special
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'be', u'carried', u'series', u'to', u'accomplished', u'steps', u'goals', u'of', u'or', u'out'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: tract
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'body', u'some', u'that', u'of', u'serve', u'system', u'together', u'parts', u'purpose', u'particular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: improving
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'better', u'to', u'make'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: genital
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'of', u'or', u'to', u'external', u'relating', u'sex', u'organs', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: spermatozoa
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'gamete', u'reproductive', u'cell', u'the', u'male', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: account
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: 0.621371
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Orthodox
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'pertaining', u'Judaism', u'characteristic', u'to', u'of', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: purpose
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'your', u'an', u'intended', u'that', u'is', u'actions', u'anticipated', u'planned', u'outcome', u'guides', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: learned
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'description', u'of', u'events', u'past', u'record', u'narrative', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: segment
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'be', u'certain', u'student', u'of', u'subject'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: degree
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'one', u'a', u'fit', u'that', u'of', u'object', u'pieces', u'constitute', u'to', u'parts', u'whole', u'others', u'several', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: radioactive
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'caused', u'exhibiting', u'radioactivity', u'or', u'by'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: happening
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'on', u'scale', u'of', u'amount', u'intensity', u'position', u'quality', u'or'])
mapFunction_Parents(): adding to parents: syn =  Synset('degree.n.01') ; keyword:  position  in syndef_tokens= set([u'a', u'on', u'scale', u'of', u'amount', u'intensity', u'position', u'quality', u'or'])
mapFunction_Parents(): returns= [u'degree']
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan', u'degree']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: importance
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'status', u'prominent'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan', u'degree']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: equivalent
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [mapFunction_Parents(): keyword=' position ; syndef_tokens= set([u'happens', u'that', u'event', u'an'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
Noasfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword:n position ; prevleveltokens: curve
e', u'metropolitan', u'metropolitan', u'degree']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: attention
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'on', u')', u'whereby', u'to', u'process', u'of', u'relative', u'others', u'some', u'exclusion', u'environment', u'person', u'(', u'concentrates', u'the', u'features'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan', u'degree']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: component
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'of', u'abstract', u'part', u'something', u'an'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan', u'degree']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: thorium
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'thorite', u'is', u'as', u'used', u'sands', u'in', u'232', u'monazite', u'nuclear', u'metallic', u'source', u'silvery-white', u';', u'occurs', u'tetravalent', u'power', u'isotope', u'a', u'radioactive', u'element', u'soft', u'reactors'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan', u'degree']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'whose', u'direction', u'trace', u'point', u'of', u'motion', u'the', u'changes'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: together
mapFunction_Parents(): keyword: position ; prevleveltokens: clarify
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u')', u'(', u'make', u'comprehensible', u'clear', u'more'])mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'emotionally', u'mentally', u'stable'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: element

mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan', u'degree']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: densely
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'of', u'abstract', u'part', u'something', u'an'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: person
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'stupid', u'manner', u'in'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan', u'degree']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: conceal
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'being', u'human'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: reputation
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'has', u'for', u'that', u'general', u'person', u'the', u'estimation', u'public'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: greatest
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'prevent', u'from', u'being', u'discovered', u'seen', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan', u'degree']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: region
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'highest', u'quality', u'in'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: refining
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'extended', u'of', u'something', u'spatial', u'the', u'location'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan', u'degree']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: title
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'statute', u'give', u'that', u'may', u'of', u'the', u'bill', u'brief', mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'oil', u'from', u')', u'process', u'of', u'removing', u'metals', u'impurities', u'etc', u'as', u'(', u'the', u'sugar', u'.', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: time
u'heading', u'deals', u'matters', u'names', u'it', u';', u'summary', u'with', u'or', u'legislative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan', u'degree']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: equal
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'standing'mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'event', u'for', u'some', u'an', u'instance', u'single', u'occasion', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: position
, u'group', u'of', u'is', u'who', u'equal', u'person', u'another', u'in', u'with'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan', u'degree']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: length
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'fixed', u'from', u'linear', u'space', u'of', u'is', u'that', u'one', u'to', u'other', u'place', u'longest', u'extent', u'in', u'end', u'the', u'dimension', u';', u'something'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan', u'degree']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: act
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'deliberations', u'legislative', u'of', u'body', u'legal', u'society', u'codifying', u'committee', u'the', u'document', u'or', u'result'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan', u'degree']
16/03/30 11:04:49 INFO PythonRunner: Times: total = 9750, boot = 479, init = 436, finish = 8835
16/03/30 11:04:49 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/30 11:04:49 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9842 ms on localhost (1/2)
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'space', u'of', u'portion', u'something', u'particular', u'the', u'occupied', u'by'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/30 11:04:49 INFO PythonRunner: Times: total = 9821, boot = 484, init = 468, finish = 8869
16/03/30 11:04:49 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/30 11:04:50 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9939 ms on localhost (2/2)
16/03/30 11:04:50 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/30 11:04:50 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) finished in 9.946 s
16/03/30 11:04:50 INFO DAGScheduler: looking for newly runnable stages
16/03/30 11:04:50 INFO DAGScheduler: running: Set()
16/03/30 11:04:50 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/30 11:04:50 INFO DAGScheduler: failed: Set()
16/03/30 11:04:50 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/30 11:04:50 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218), which is now runnable
16/03/30 11:04:50 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=12594, maxMem=555755765
16/03/30 11:04:50 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.0 MB)
16/03/30 11:04:50 INFO MemoryStore: ensureFreeSpace(3058) called with curMem=17578, maxMem=555755765
16/03/30 11:04:50 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.0 MB)
16/03/30 11:04:50 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:54647 (size: 3.0 KB, free: 530.0 MB)
16/03/30 11:04:50 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/30 11:04:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:04:50 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/30 11:04:50 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/30 11:04:50 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/30 11:04:50 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/30 11:04:50 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/30 11:04:50 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/30 11:04:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/03/30 11:04:50 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/30 11:04:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
reduceFunction_Parents(): returns= ['None', u'metropolitan', u'metropolitan', u'degree', 'None']
16/03/30 11:04:50 INFO PythonRunner: Times: total = 188, boot = 186, init = 1, finish = 1
16/03/30 11:04:50 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1303 bytes result sent to driver
16/03/30 11:04:50 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 215 ms on localhost (1/2)
16/03/30 11:04:50 INFO PythonRunner: Times: total = 269, boot = 268, init = 1, finish = 0
16/03/30 11:04:50 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/30 11:04:50 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) finished in 0.284 s
16/03/30 11:04:50 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218, took 10.279519 s
16/03/30 11:04:50 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 303 ms on localhost (2/2)
16/03/30 11:04:50 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/30 11:04:50 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218
16/03/30 11:04:50 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) with 2 output partitions
16/03/30 11:04:50 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:04:50 INFO DAGScheduler: Parents of final stage: List()
16/03/30 11:04:50 INFO DAGScheduler: Missing parents: List()
16/03/30 11:04:50 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218), which has no missing parents
16/03/30 11:04:50 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=20636, maxMem=555755765
16/03/30 11:04:50 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.0 MB)
16/03/30 11:04:50 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=26452, maxMem=555755765
16/03/30 11:04:50 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
16/03/30 11:04:50 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:54647 (size: 3.3 KB, free: 530.0 MB)
16/03/30 11:04:50 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/30 11:04:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218)
16/03/30 11:04:50 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/30 11:04:50 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/30 11:04:50 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2384 bytes)
16/03/30 11:04:50 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/30 11:04:50 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/30 11:04:50 INFO PythonRunner: Times: total = 129, boot = 129, init = 0, finish = 0
16/03/30 11:04:50 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1388 bytes result sent to driver
16/03/30 11:04:50 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 138 ms on localhost (1/2)
16/03/30 11:04:50 INFO PythonRunner: Times: total = 185, boot = 185, init = 0, finish = 0
16/03/30 11:04:50 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/30 11:04:50 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 194 ms on localhost (2/2)
16/03/30 11:04:50 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/30 11:04:50 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218) finished in 0.179 s
16/03/30 11:04:50 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:218, took 0.208147 s
16/03/30 11:04:50 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/30 11:04:50 INFO DAGScheduler: Stopping DAGScheduler
16/03/30 11:04:50 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/30 11:04:50 INFO MemoryStore: MemoryStore cleared
16/03/30 11:04:50 INFO BlockManager: BlockManager stopped
16/03/30 11:04:50 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/30 11:04:50 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/30 11:04:50 INFO SparkContext: Successfully stopped SparkContext
16/03/30 11:04:50 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/30 11:04:50 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/30 11:04:50 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: <memcache.Client object at 0xb0c00a1c>
InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:freqterms1= [u'serving', u'Madras', u'ejaculated', u'Bengal', u'including', u'geography', u'group', u'decay', u'writing', u'add', u'halogen', u'include', u'Tamil', u'exceptional', u'fluid', u'Bay', u'boundary', u'covering', u'serves', u'large', u'miles', u'unstable', u'people', u'series', u'energy', u'idea', u'Christianity', u'culture', u'used', u'meters', u'special', u'0.621371', u'Orthodox', u'purpose', u'learned', u'degree', u'importance', u'equivalent', u'attention', u'component', u'thorium', u'clarify', u'densely', u'conceal', u'region', u'title', u'equal', u'length', u'act', u'usually', u'1000', u'composed', u'formerly', u'period', u'highly', u'thick', u'indefinite', u'unit', u'city', u'given', u'area', u'stretch', u'archbishop', u'populated', u'way', u'enlarging', u'urban', u'continuous', u'moment', u'western', u'particular', u'white', u'kind', u'administrative', u'work', u'patriarch', u'districts', u'Eastern', u'Church', u'male', u'distinguished', u'devise', u'expanding', u'metric', u'heaviest', u'something', u'concentration', u'bishop', u'containing', u'things', u'make', u'belong', u'uranium', u'discourse', u'parts', u'speech', u'details', u'geographical', u'several', u'Nadu', u'circular', u'independent', u'product', u'elements', u'shelter', u'possible', u'meaning', u'plan', u'tract', u'improving', u'genital', u'spermatozoa', u'account', u'segment', u'radioactive', u'happening', u'curve', u'together', u'element', u'person', u'reputation', u'greatest', u'refining', u'time', u'position']
16/03/30 11:04:51 INFO SparkContext: Running Spark version 1.5.2
16/03/30 11:04:51 INFO SecurityManager: Changing view acls to: root
16/03/30 11:04:51 INFO SecurityManager: Changing modify acls to: root
16/03/30 11:04:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/30 11:04:51 INFO Slf4jLogger: Slf4jLogger started
16/03/30 11:04:51 INFO Remoting: Starting remoting
16/03/30 11:04:51 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:39555]
16/03/30 11:04:51 INFO Utils: Successfully started service 'sparkDriver' on port 39555.
16/03/30 11:04:51 INFO SparkEnv: Registering MapOutputTracker
16/03/30 11:04:51 INFO SparkEnv: Registering BlockManagerMaster
16/03/30 11:04:51 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9c49811b-c0c1-45e4-89e6-9eb6a5926869
16/03/30 11:04:51 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
16/03/30 11:04:51 INFO HttpFileServer: HTTP File server directory is /tmp/spark-0e0df6d9-7161-45bf-b9ec-cf9574d76f1c/httpd-4a854cc9-0fc3-4d3a-b4f9-3e6077c94507
16/03/30 11:04:51 INFO HttpServer: Starting HTTP Server
16/03/30 11:04:51 INFO Utils: Successfully started service 'HTTP file server' on port 53678.
16/03/30 11:04:51 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/30 11:04:52 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/30 11:04:52 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/30 11:04:52 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-0e0df6d9-7161-45bf-b9ec-cf9574d76f1c/userFiles-3e431ac0-cfd7-4f11-b388-9fa378bcca7f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/30 11:04:52 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1459316092576
16/03/30 11:04:52 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/30 11:04:52 INFO Executor: Starting executor ID driver on host localhost
16/03/30 11:04:52 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50037.
16/03/30 11:04:52 INFO NettyBlockTransferService: Server created on 50037
16/03/30 11:04:52 INFO BlockManagerMaster: Trying to register BlockManager
16/03/30 11:04:52 INFO BlockManagerMasterEndpoint: Registering block manager localhost:50037 with 530.0 MB RAM, BlockManagerId(driver, localhost, 50037)
16/03/30 11:04:52 INFO BlockManagerMaster: Registered BlockManager
Spark_MapReduce(): wordsatthislevel: [u'serving', u'Madras', u'ejaculated', u'Bengal', u'including', u'geography', u'group', u'decay', u'writing', u'add', u'halogen', u'include', u'Tamil', u'exceptional', u'fluid', u'Bay', u'boundary', u'covering', u'serves', u'large', u'miles', u'unstable', u'people', u'series', u'energy', u'idea', u'Christianity', u'culture', u'used', u'meters', u'special', u'0.621371', u'Orthodox', u'purpose', u'learned', u'degree', u'importance', u'equivalent', u'attention', u'component', u'thorium', u'clarify', u'densely', u'conceal', u'region', u'title', u'equal', u'length', u'act', u'usually', u'1000', u'composed', u'formerly', u'period', u'highly', u'thick', u'indefinite', u'unit', u'city', u'given', u'area', u'stretch', u'archbishop', u'populated', u'way', u'enlarging', u'urban', u'continuous', u'moment', u'western', u'particular', u'white', u'kind', u'administrative', u'work', u'patriarch', u'districts', u'Eastern', u'Church', u'male', u'distinguished', u'devise', u'expanding', u'metric', u'heaviest', u'something', u'concentration', u'bishop', u'containing', u'things', u'make', u'belong', u'uranium', u'discourse', u'parts', u'speech', u'details', u'geographical', u'several', u'Nadu', u'circular', u'independent', u'product', u'elements', u'shelter', u'possible', u'meaning', u'plan', u'tract', u'improving', u'genital', u'spermatozoa', u'account', u'segment', u'radioactive', u'happening', u'curve', u'together', u'element', u'person', u'reputation', u'greatest', u'refining', u'time', u'position']
16/03/30 11:04:52 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:241
16/03/30 11:04:52 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:241)
16/03/30 11:04:52 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:241) with 2 output partitions
16/03/30 11:04:52 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:241)
16/03/30 11:04:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/30 11:04:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/30 11:04:52 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:241), which has no missing parents
16/03/30 11:04:52 INFO MemoryStore: ensureFreeSpace(6560) called with curMem=0, maxMem=555755765
16/03/30 11:04:52 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)
16/03/30 11:04:52 INFO MemoryStore: ensureFreeSpace(4147) called with curMem=6560, maxMem=555755765
16/03/30 11:04:52 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 530.0 MB)
16/03/30 11:04:52 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:50037 (size: 4.0 KB, free: 530.0 MB)
16/03/30 11:04:52 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/30 11:04:52 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:241)
16/03/30 11:04:52 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/30 11:04:52 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 3156 bytes)
16/03/30 11:04:52 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 3246 bytes)
16/03/30 11:04:52 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/30 11:04:52 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1459316092576
16/03/30 11:04:52 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/30 11:04:52 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-0e0df6d9-7161-45bf-b9ec-cf9574d76f1c/userFiles-3e431ac0-cfd7-4f11-b388-9fa378bcca7f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/30 11:04:52 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/30 11:04:52 INFO MemoryStore: ensureFreeSpace(849) called with curMem=10707, maxMem=555755765
16/03/30 11:04:52 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 849.0 B, free 530.0 MB)
16/03/30 11:04:52 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:50037 (size: 849.0 B, free: 530.0 MB)
16/03/30 11:04:52 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/30 11:04:52 INFO MemoryStore: ensureFreeSpace(789) called with curMem=11556, maxMem=555755765
16/03/30 11:04:52 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 789.0 B, free 530.0 MB)
16/03/30 11:04:52 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:50037 (size: 789.0 B, free: 530.0 MB)
mapFunction(): freqterms1: archbishop
mapFunction(): freqterms1: serving
mapFunction(): freqterms1: populated
mapFunction(): freqterms1: way
mapFunction(): freqterms1: enlarging
mapFunction(): freqterms1: urban
mapFunction(): freqterms1: continuous
mapFunction(): freqterms1: moment
mapFunction(): freqterms1: western
mapFunction(): freqterms1: particular
mapFunction(): freqterms1: white
mapFunction(): freqterms1: kind
mapFunction(): freqterms1: administrative
mapFunction(): freqterms1: work
mapFunction(): freqterms1: Madras
mapFunction(): freqterms1: ejaculated
mapFunction(): freqterms1: Bengal
mapFunction(): freqterms1: including
mapFunction(): freqterms1: geography
mapFunction(): freqterms1: group
mapFunction(): freqterms1: decay
mapFunction(): freqterms1: writing
mapFunction(): freqterms1: patriarch
mapFunction(): freqterms1: districts
mapFunction(): freqterms1: Eastern
mapFunction(): freqterms1:mapFunction(): freqterms1: Church
 add
mapFunction(): freqterms1: male
mapFunction(): freqterms1: halogen
mapFunction(): freqterms1: distinguished
mapFunction(): freqterms1: include
mapFunction(): freqterms1: devise
mapFunction(): freqterms1: Tamil
mapFunction(): freqterms1: mapFunction(): freqterms1: exceptional
expanding
mapFunction(): freqterms1: fluid
mapFunction(): freqterms1: metric
mapFunction(): freqterms1: heaviest
mapFunction(): freqterms1: Bay
mapFunction(): freqterms1: boundary
mapFunction(): freqterms1: covering
mapFunction(): freqterms1: serves
mapFunction(): freqterms1: something
mapFunction(): freqterms1: concentration
mapFunction(): freqterms1: bishop
mapFunction(): freqterms1: large
mapFunction(): freqterms1: containing
mapFunction(): freqterms1: things
mapFunction(): freqterms1: miles
mapFunction(): freqterms1: unstable
mapFunction(): freqterms1: people
mapFunction(): freqterms1: make
mapFunction(): freqterms1: series
mapFunction(): freqterms1: energy
mapFunction(): freqterms1: idea
mapFunction(): freqterms1: Christianity
mapFunction(): freqterms1: culture
mapFunction(): freqterms1: used
mapFunction(): freqterms1: meters
mapFunction(): freqterms1: belong
mapFunction(): freqterms1: special
mapFunction(): freqterms1: 0.621371
mapFunction(): freqterms1: Orthodox
mapFunction(): freqterms1: purpose
mapFunction(): freqterms1: uranium
mapFunction(): freqterms1: discourse
mapFunction(): freqterms1: learned
mapFunction(): freqterms1: parts
mapFunction(): freqterms1: degree
mapFunction(): freqterms1: importance
mapFunction(): freqterms1: equivalent
mapFunction(): freqterms1: attention
mapFunction(): freqterms1: speech
mapFunction(): freqterms1: component
mapFunction(): freqterms1: thorium
mapFunction(): freqterms1: details
mapFunction(): freqterms1: clarify
mapFunction(): freqterms1: densely
mapFunction(): freqterms1: geographical
mapFunction(): freqterms1: conceal
mapFunction(): freqterms1: region
mapFunction(): freqterms1: title
mapFunction(): freqterms1: several
mapFunction(): freqterms1: Nadu
mapFunction(): freqterms1: circular
mapFunction(): freqterms1: independent
mapFunction(): freqterms1: equal
mapFunction(): freqterms1: length
mapFunction(): freqterms1: product
mapFunction(): freqterms1: act
mapFunction(): freqterms1: elements
mapFunction(): freqterms1: usually
mapFunction(): freqterms1: 1000
mapFunction(): freqterms1: shelter
mapFunction(): freqterms1: composed
mapFunction(): freqterms1: possible
mapFunction(): freqterms1: formerly
mapFunction(): freqterms1:mapFunction(): freqterms1: meaning
 period
mapFunction(): freqterms1: highly
mapFunction(): freqterms1: thick
mapFunction(): freqterms1: plan
mapFunction(): freqterms1: indefinite
mapFunction(): freqterms1: unit
mapFunction(): freqterms1: tract
mapFunction(): freqterms1: city
mapFunction(): freqterms1: improving
mapFunction(): freqterms1: given
mapFunction(): freqterms1: genital
mapFunction(): freqterms1: spermatozoa
mapFunction(): freqterms1: account
mapFunction(): freqterms1: segment
mapFunction(): freqterms1: radioactive
mapFunction(): freqterms1: happening
mapFunction(): freqterms1: area
mapFunction(): freqterms1: curve
mapFunction(): freqterms1: stretch
mapFunction(): freqterms1: together
mapFunction(): freqterms1: element
mapFunction(): freqterms1: person
16/03/30 11:05:02 INFO PythonRunner: Times: total = 9382, boot = 505, init = 400, finish = 8477
16/03/30 11:05:02 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
mapFunction(): freqterms1: reputation
mapFunction(): freqterms1: greatest
mapFunction(): freqterms1: refining
16/03/30 11:05:02 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9497 ms on localhost (1/2)
mapFunction(): freqterms1: time
mapFunction(): freqterms1: position
16/03/30 11:05:02 INFO PythonRunner: Times: total = 9508, boot = 507, init = 403, finish = 8598
16/03/30 11:05:02 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/30 11:05:02 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9612 ms on localhost (2/2)
16/03/30 11:05:02 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:241) finished in 9.614 s
16/03/30 11:05:02 INFO DAGScheduler: looking for newly runnable stages
16/03/30 11:05:02 INFO DAGScheduler: running: Set()
16/03/30 11:05:02 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/30 11:05:02 INFO DAGScheduler: failed: Set()
16/03/30 11:05:02 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/30 11:05:02 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:241), which is now runnable
16/03/30 11:05:02 INFO MemoryStore: ensureFreeSpace(4976) called with curMem=12345, maxMem=555755765
16/03/30 11:05:02 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.0 MB)
16/03/30 11:05:02 INFO MemoryStore: ensureFreeSpace(3050) called with curMem=17321, maxMem=555755765
16/03/30 11:05:02 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.0 MB)
16/03/30 11:05:02 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:50037 (size: 3.0 KB, free: 530.0 MB)
16/03/30 11:05:02 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/30 11:05:02 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/30 11:05:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:241)
16/03/30 11:05:02 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/30 11:05:02 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/30 11:05:02 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/30 11:05:02 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/30 11:05:02 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/30 11:05:02 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/30 11:05:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/30 11:05:02 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/30 11:05:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/03/30 11:05:02 INFO PythonRunner: Times: total = 164, boot = 160, init = 0, finish = 4
16/03/30 11:05:02 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 12419 bytes result sent to driver
16/03/30 11:05:02 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 192 ms on localhost (1/2)
16/03/30 11:05:02 INFO PythonRunner: Times: total = 271, boot = 271, init = 0, finish = 0
16/03/30 11:05:02 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/30 11:05:02 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:241) finished in 0.275 s
16/03/30 11:05:02 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:241, took 9.943629 s
16/03/30 11:05:02 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 294 ms on localhost (2/2)
16/03/30 11:05:02 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/30 11:05:02 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:241
16/03/30 11:05:02 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:241) with 2 output partitions
16/03/30 11:05:02 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:241)
16/03/30 11:05:02 INFO DAGScheduler: Parents of final stage: List()
16/03/30 11:05:02 INFO DAGScheduler: Missing parents: List()
16/03/30 11:05:02 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:241), which has no missing parents
16/03/30 11:05:02 INFO MemoryStore: ensureFreeSpace(5872) called with curMem=20371, maxMem=555755765
16/03/30 11:05:02 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.0 MB)
16/03/30 11:05:02 INFO MemoryStore: ensureFreeSpace(3419) called with curMem=26243, maxMem=555755765
16/03/30 11:05:02 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
16/03/30 11:05:02 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:50037 (size: 3.3 KB, free: 530.0 MB)
16/03/30 11:05:02 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/30 11:05:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:241)
16/03/30 11:05:02 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/30 11:05:02 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/30 11:05:02 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 13363 bytes)
16/03/30 11:05:02 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/30 11:05:02 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/30 11:05:02 INFO PythonRunner: Times: total = 89, boot = 87, init = 1, finish = 1
16/03/30 11:05:02 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 12739 bytes result sent to driver
16/03/30 11:05:02 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 118 ms on localhost (1/2)
16/03/30 11:05:03 INFO PythonRunner: Times: total = 237, boot = 237, init = 0, finish = 0
16/03/30 11:05:03 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/30 11:05:03 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 247 ms on localhost (2/2)
16/03/30 11:05:03 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/30 11:05:03 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:241) finished in 0.233 s
16/03/30 11:05:03 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:241, took 0.256778 s
graphcache_mapreduce updated: <memcache.Client object at 0xb0c00a1c>
16/03/30 11:05:03 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/30 11:05:03 INFO DAGScheduler: Stopping DAGScheduler
16/03/30 11:05:03 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/30 11:05:03 INFO MemoryStore: MemoryStore cleared
16/03/30 11:05:03 INFO BlockManager: BlockManager stopped
16/03/30 11:05:03 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/30 11:05:03 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/30 11:05:03 INFO SparkContext: Successfully stopped SparkContext
16/03/30 11:05:03 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/30 11:05:03 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/30 11:05:03 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:tokensofthislevel: [u'individual', u'quantity', u'food', u'drink', u'taken', u'part', u'meal', u'state', u'southeastern', u'India', u'Bay', u'Bengal', u'south', u'Andhra', u'Pradesh', u'formerly', u'Madras', u'utter', u'impulsively', u'region', u'whose', u'eastern', u'part', u'Bangladesh', u'whose', u'western', u'part', u'included', u'India', u'part', u'made', u'study', u'earth', u'surface', u'includes', u'people', u'responses', u'topography', u'climate', u'soil', u'vegetation', u'number', u'entities', u'members', u'considered', u'unit', u'gradual', u'decrease', u'stored', u'charge', u'current', u'act', u'creating', u'written', u'works', u'condition', u'mostly', u'boys', u'characterized', u'behavioral', u'learning', u'disorders', u'five', u'related', u'nonmetallic', u'elements', u'fluorine', u'chlorine', u'bromine', u'iodine', u'astatine', u'monovalent', u'readily', u'form', u'negative', u'ions', u'part', u'made', u'member', u'mixed', u'Dravidian', u'Caucasian', u'people', u'southern', u'India', u'Sri', u'Lanka', u'deviating', u'widely', u'norm', u'physical', u'mental', u'ability', u'used', u'especially', u'children', u'normal', u'intelligence', u'substance', u'fluid', u'room', u'temperature', u'pressure', u'indentation', u'shoreline', u'larger', u'cove', u'smaller', u'gulf', u'line', u'determining', u'limits', u'area', u'natural', u'object', u'covers', u'envelops', u'sports', u'stroke', u'puts', u'ball', u'play', u'garment', u'size', u'large', u'person', u'unit', u'length', u'equal', u'1,760', u'yards', u'5,280', u'feet', u'exactly', u'1609.344', u'meters', u'lacking', u'stability', u'fixity', u'firmness', u'plural', u'group', u'human', u'beings', u'men', u'women', u'children', u'collectively', u'similar', u'things', u'placed', u'order', u'happening', u'one', u'another', u'physics', u'thermodynamic', u'quantity', u'equivalent', u'capacity', u'physical', u'system', u'work', u'units', u'energy', u'joules', u'ergs', u'personal', u'view', u'monotheistic', u'system', u'beliefs', u'practices', u'based', u'Old', u'Testament', u'teachings', u'Jesus', u'embodied', u'New', u'Testament', u'emphasizing', u'role', u'Jesus', u'savior', u'particular', u'society', u'particular', u'time', u'place', u'put', u'service', u'make', u'work', u'employ', u'particular', u'purpose', u'inherent', u'natural', u'purpose', u'basic', u'unit', u'length', u'adopted', u'Systeme', u'International', u"d'Unites", u'approximately', u'1.094', u'yards', u'special', u'offering', u'usually', u'temporary', u'reduced', u'price', u'featured', u'advertising', u'pertaining', u'characteristic', u'Judaism', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions', u'student', u'certain', u'subject', u'position', u'scale', u'intensity', u'amount', u'quality', u'prominent', u'status', u'person', u'thing', u'equal', u'another', u'value', u'measure', u'force', u'effect', u'significance', u'etc', u'process', u'whereby', u'person', u'concentrates', u'features', u'environment', u'relative', u'exclusion', u'others', u'abstract', u'part', u'something', u'soft', u'silvery-white', u'tetravalent', u'radioactive', u'metallic', u'element', u'isotope', u'232', u'used', u'power', u'source', u'nuclear', u'reactors', u'occurs', u'thorite', u'monazite', u'sands', u'make', u'clear', u'comprehensible', u'stupid', u'manner', u'prevent', u'seen', u'discovered', u'extended', u'spatial', u'location', u'something', u'heading', u'names', u'statute', u'legislative', u'bill', u'give', u'brief', u'summary', u'matters', u'deals', u'person', u'equal', u'standing', u'another', u'group', u'linear', u'extent', u'space', u'one', u'end', u'longest', u'dimension', u'something', u'fixed', u'place', u'legal', u'document', u'codifying', u'result', u'deliberations', u'committee', u'society', u'legislative', u'body', u'normal', u'conditions', u'cardinal', u'number', u'product', u'10', u'100', u'form', u'substance', u'previous', u'time', u'amount', u'time', u'high', u'degree', u'extent', u'favorably', u'much', u'respect', u'location', u'something', u'surrounded', u'things', u'vague', u'clearly', u'defined', u'stated', u'division', u'quantity', u'accepted', u'standard', u'measurement', u'exchange', u'large', u'densely', u'populated', u'urban', u'area', u'include', u'several', u'independent', u'administrative', u'districts', u'assumption', u'taken', u'granted', u'particular', u'geographical', u'region', u'indefinite', u'boundary', u'usually', u'serving', u'special', u'purpose', u'distinguished', u'people', u'culture', u'geography', u'large', u'unbroken', u'expanse', u'distance', u'bishop', u'highest', u'rank', u'inhabit', u'live', u'inhabitant', u'result', u'obtained', u'end', u'achieved', u'add', u'details', u'account', u'idea', u'clarify', u'meaning', u'discourse', u'learned', u'way', u'usually', u'writing', u'relating', u'concerned', u'city', u'densely', u'populated', u'area', u'continuing', u'time', u'space', u'without', u'interruption', u'particular', u'point', u'time', u'film', u'life', u'western', u'United', u'States', u'period', u'exploration', u'development', u'fact', u'part', u'opposed', u'general', u'member', u'Caucasoid', u'race', u'category', u'things', u'distinguished', u'common', u'characteristic', u'quality', u'relating', u'responsible', u'administration', u'activity', u'directed', u'toward', u'making', u'something', u'man', u'older', u'higher', u'rank', u'region', u'marked', u'administrative', u'purposes', u'lying', u'toward', u'situated', u'east', u'one', u'groups', u'Christians', u'beliefs', u'forms', u'worship', u'person', u'belongs', u'sex', u'babies', u'mark', u'different', u'disposing', u'real', u'property', u'add', u'details', u'account', u'idea', u'clarify', u'meaning', u'discourse', u'learned', u'way', u'usually', u'writing', u'function', u'topological', u'space', u'gives', u'two', u'points', u'space', u'value', u'equal', u'distance', u'usually', u'describes', u'large', u'person', u'fat', u'large', u'frame', u'carry', u'strength', u'solution', u'number', u'molecules', u'substance', u'given', u'volume', u'senior', u'member', u'Christian', u'clergy', u'spiritual', u'administrative', u'authority', u'appointed', u'Christian', u'churches', u'oversee', u'priests', u'ministers', u'considered', u'churches', u'successors', u'twelve', u'Apostles', u'Christ', u'include', u'contain', u'component', u'movable', u'possession', u'especially', u'articles', u'clothing', u'recognizable', u'kind', u'owned', u'possession', u'heavy', u'toxic', u'silvery-white', u'radioactive', u'metallic', u'element', u'occurs', u'many', u'isotopes', u'used', u'nuclear', u'fuels', u'nuclear', u'weapons', u'extended', u'verbal', u'expression', u'speech', u'writing', u'something', u'less', u'whole', u'human', u'artifact', u'act', u'delivering', u'formal', u'spoken', u'communication', u'audience', u'small', u'part', u'considered', u'separately', u'whole', u'relating', u'science', u'geography', u'used', u'count', u'nouns', u'indefinite', u'number', u'2', u'3', u'many', u'advertisement', u'usually', u'printed', u'page', u'leaflet', u'intended', u'wide', u'distribution', u'neutral', u'uncommitted', u'person', u'especially', u'politics', u'commodities', u'offered', u'sale', u'violent', u'severe', u'weather', u'viewed', u'caused', u'action', u'four', u'elements', u'structure', u'provides', u'privacy', u'protection', u'danger', u'something', u'done', u'logical', u'consequence', u'series', u'steps', u'carried', u'goals', u'accomplished', u'system', u'body', u'parts', u'together', u'serve', u'particular', u'purpose', u'make', u'better', u'relating', u'external', u'sex', u'organs', u'male', u'reproductive', u'cell', u'male', u'gamete', u'record', u'narrative', u'description', u'past', u'events', u'one', u'several', u'parts', u'pieces', u'fit', u'others', u'constitute', u'whole', u'object', u'exhibiting', u'caused', u'radioactivity', u'event', u'happens', u'trace', u'point', u'whose', u'direction', u'motion', u'changes', u'mentally', u'emotionally', u'stable', u'abstract', u'part', u'something', u'human', u'general', u'estimation', u'public', u'person', u'highest', u'quality', u'process', u'removing', u'impurities', u'oil', u'metals', u'sugar', u'etc', u'instance', u'single', u'occasion', u'event', u'particular', u'portion', u'space', u'occupied', u'something']
prevlevelsynsets: [Synset('archbishop.n.01'), Synset('populate.v.01'), Synset('means.n.01'), Synset('elaborate.v.01'), Synset('urban.a.01'), Synset('continuous.a.01'), Synset('moment.n.01'), Synset('western.n.01'), Synset('particular.n.01'), Synset('white.n.01'), Synset('kind.n.01'), Synset('administrative.a.01'), Synset('helping.n.01'), Synset('tamil_nadu.n.01'), Synset('blurt_out.v.01'), Synset('bengal.n.01'), Synset('include.v.01'), Synset('geography.n.01'), Synset('group.n.01'), Synset('decay.n.01'), Synset('work.n.01'), Synset('patriarch.n.01'), Synset('district.n.01'), Synset('writing.n.01'), Synset('eastern.s.01'), Synset('church.n.01'), Synset('attention_deficit_disorder.n.01'), Synset('male.n.01'), Synset('halogen.n.01'), Synset('distinguish.v.01'), Synset('include.v.01'), Synset('devise.n.01'), Synset('tamil.n.01'), Synset('exceeding.s.01'), Synset('elaborate.v.01'), Synset('metric_function.n.01'), Synset('fluid.n.01'), Synset('bay.n.01'), Synset('boundary.n.01'), Synset('covering.n.01'), Synset('fleshy.s.01'), Synset('concentration.n.01'), Synset('serve.n.01'), Synset('bishop.n.01'), Synset('integrate.v.01'), Synset('large.n.01'), Synset('mile.n.01'), Synset('unstable.a.01'), Synset('things.n.01'), Synset('people.n.01'), Synset('series.n.01'), Synset('energy.n.01'), Synset('idea.n.01'), Synset('christianity.n.01'), Synset('culture.n.01'), Synset('use.n.01'), Synset('trade_name.n.01'), Synset('meter.n.01'), Synset('special.n.01'), Synset('orthodox.a.01'), Synset('belong.v.01'), Synset('uranium.n.01'), Synset('purpose.n.01'), Synset('discourse.n.01'), Synset('learn.v.01'), Synset('degree.n.01'), Synset('importance.n.01'), Synset('equivalent.n.01'), Synset('part.n.01'), Synset('attention.n.01'), Synset('component.n.01'), Synset('address.n.01'), Synset('thorium.n.01'), Synset('clarify.v.01'), Synset('detail.n.01'), Synset('dumbly.r.01'), Synset('hide.n.01'), Synset('region.n.01'), Synset('geographic.a.01'), Synset('several.s.01'), Synset('circular.n.01'), Synset('title.n.01'), Synset('peer.n.01'), Synset('mugwump.n.01'), Synset('length.n.01'), Synset('merchandise.n.01'), Synset('act.n.01'), Synset('normally.r.01'), Synset('elements.n.01'), Synset('thousand.n.01'), Synset('shelter.n.01'), Synset('compose.v.01'), Synset('possible.n.01'), Synset('once.r.01'), Synset('time_period.n.01'), Synset('highly.r.01'), Synset('entail.n.01'), Synset('midst.n.01'), Synset('indefinite.a.01'), Synset('plan.n.01'), Synset('unit_of_measurement.n.01'), Synset('tract.n.01'), Synset('city.n.01'), Synset('better.n.01'), Synset('genital.a.01'), Synset('sperm.n.01'), Synset('history.n.01'), Synset('section.n.01'), Synset('radioactive.a.01'), Synset('given.n.01'), Synset('happening.n.01'), Synset('area.n.01'), Synset('curve.n.01'), Synset('together.s.01'), Synset('stretch.n.01'), Synset('component.n.01'), Synset('person.n.01'), Synset('repute.n.01'), Synset('greatest.s.01'), Synset('refining.n.01'), Synset('time.n.01'), Synset('position.n.01')]
defaultdict(<type 'list'>, {u'serving': [u'None', u'area', u'None', u'area'], u'Madras': [u'Chennai', u'Chennai', u'Chennai', u'Chennai', u'Chennai', u'Madras'], u'ejaculated': [u'None', u'semen', u'None'], u'Bengal': [u'Chennai', u'Chennai', u'Chennai', u'Chennai', u'Chennai', u'Madras'], u'including': [u'None', u'present', u'None', u'whole'], u'geography': [u'None', u'area', u'area'], u'group': [u'None', u'set', u'set', u'None'], u'decay': [u'None', u'astatine', u'None'], u'writing': [u'None', u'None', u'elaborate'], u'add': [u'None', u'None', u'elaborate'], u'halogen': [u'None', u'astatine', u'None'], u'include': [u'None', u'city'], u'Tamil': [u'Chennai', u'Chennai', u'Chennai', u'Chennai', u'Chennai', u'None'], u'exceptional': [u'None', u'giant', u'None'], u'fluid': [u'None', u'semen', u'None', u'fluid'], u'Bay': [u'Chennai', u'Chennai', u'Chennai', u'Chennai', u'Chennai', u'None', u'Madras'], u'learned': [u'None', u'elaborate', u'None'], u'meaning': [u'None', u'elaborate', u'None', u'enlarging', u'expanding'], u'covering': [u'None', u'None'], u'serves': [u'None', u'None'], u'large': [u'None', u'city', u'None', u'large'], u'miles': [u'kilometer', u'None'], u'unstable': [u'None', u'astatine', u'None'], u'people': [u'None', u'area', u'area', u'None', u'geography', u'Tamil'], u'series': [u'None', u'astatine', u'plan', u'None'], u'energy': [u'None', u'focus', u'None', u'energy'], u'idea': [u'None', u'elaborate', u'None'], u'Christianity': [u'None', u'metropolitan', u'metropolitan', u'None'], u'culture': [u'None', u'area', u'area', u'None'], u'elements': [u'None', u'whole', u'halogen', u'None', u'elements'], u'meters': [u'kilometer', u'None', u'miles'], u'special': [u'None', u'area', u'area', u'None', u'special'], u'0.621371': [u'kilometer', u'None'], u'Orthodox': [u'None', u'metropolitan', u'metropolitan', u'None'], u'boundary': [u'None', u'area', u'area', u'None'], u'degree': [u'None', u'limit', u'None'], u'importance': [u'None', u'giant', u'None'], u'equivalent': [u'None', u'metropolitan', u'metropolitan', u'None', u'energy'], u'attention': [u'None', u'focus', u'None'], u'component': [u'None', u'whole', u'None'], u'thorium': [u'None', u'astatine', u'None'], u'clarify': [u'None', u'elaborate', u'None'], u'densely': [u'None', u'city', u'None'], u'conceal': [u'None', u'None'], u'region': [u'None', u'area', u'area', u'Bengal', u'None'], u'title': [u'None', u'metropolitan', u'metropolitan', u'None'], u'equal': [u'kilometer', u'None', u'miles', u'equivalent', u'equal'], u'length': [u'kilometer', u'None', u'miles', u'meters'], u'act': [u'None', u'development', u'writing', u'None'], u'usually': [u'None', u'area', u'area', u'elaborate', u'None', u'special'], u'1000': [u'kilometer', u'None'], u'composed': [u'None', u'None'], u'formerly': [u'Chennai', u'Chennai', u'Chennai', u'Chennai', u'Chennai', u'Madras', u'None'], u'period': [u'None', u'present', u'None'], u'highly': [u'None', u'astatine', u'None'], u'thick': [u'None', u'semen', u'None'], u'indefinite': [u'None', u'area', u'area', u'None'], u'unit': [u'kilometer', u'group', u'None', u'miles', u'meters'], u'city': [u'Chennai', u'Chennai', u'Chennai', u'Chennai', u'Chennai', u'None'], u'given': [u'None', u'metropolitan', u'metropolitan', u'None'], u'area': [u'None', u'city', u'boundary', u'None', u'city'], u'stretch': [u'None', u'present', u'None'], u'archbishop': [u'None', u'metropolitan', u'metropolitan', u'None'], u'populated': [u'None', u'city', u'None', u'city'], u'plan': [u'None', u'None'], u'way': [u'None', u'elaborate', u'None'], u'enlarging': [u'None', u'development', u'None'], u'urban': [u'None', u'city', u'None', u'city'], u'continuous': [u'None', u'present', u'None'], u'western': [u'None', u'metropolitan', u'metropolitan', u'Bengal', u'None', u'western'], u'particular': [u'None', u'area', u'area', u'None', u'culture', u'used', u'area', u'moment'], u'white': [u'None', u'semen', u'screen', u'None'], u'kind': [u'None', u'set', u'set', u'None'], u'administrative': [u'None', u'city', u'None', u'city'], u'work': [u'None', u'energy', u'used'], u'patriarch': [u'None', u'metropolitan', u'metropolitan', u'None'], u'districts': [u'None', u'city', u'None', u'city'], u'Eastern': [u'None', u'metropolitan', u'metropolitan', u'None'], u'Church': [u'None', u'metropolitan', u'metropolitan', u'None'], u'male': [u'None', u'semen', u'None'], u'distinguished': [u'None', u'area', u'area', u'None', u'area', u'kind'], u'devise': [u'None', u'None'], u'expanding': [u'None', u'development', u'None'], u'metric': [u'kilometer', u'None'], u'heaviest': [u'None', u'astatine', u'None'], u'something': [u'None', u'limit', u'dwell', u'whole', u'focus', u'None', u'component', u'region', u'length', u'thick', u'work'], u'concentration': [u'None', u'focus', u'None'], u'bishop': [u'None', u'metropolitan', u'metropolitan', u'None', u'archbishop'], u'containing': [u'None', u'semen', u'None'], u'things': [u'None', u'set', u'set', u'series', u'None', u'thick', u'kind'], u'make': [u'None', u'used', u'None', u'clarify'], u'belong': [u'None', u'set', u'set', u'None'], u'uranium': [u'None', u'astatine', u'None'], u'discourse': [u'None', u'elaborate', u'None', u'enlarging', u'expanding'], u'parts': [u'None', u'whole', u'None'], u'speech': [u'None', u'present', u'None', u'discourse'], u'details': [u'None', u'elaborate', u'None', u'enlarging', u'expanding'], u'geographical': [u'None', u'area', u'area', u'None', u'area'], u'several': [u'None', u'city', u'None', u'city'], u'Nadu': [u'Chennai', u'Chennai', u'Chennai', u'Chennai', u'Chennai', u'None'], u'circular': [u'None', u'bend', u'None'], u'independent': [u'None', u'city', u'None', u'city'], u'product': [u'None', u'astatine', u'None', u'1000'], u'used': [u'None', u'set', u'set', u'None', u'exceptional'], u'shelter': [u'None', u'None'], u'possible': [u'None', u'limit', u'None'], u'moment': [u'None', u'present', u'None'], u'purpose': [u'None', u'area', u'area', u'None', u'used'], u'tract': [u'None', u'semen', u'None'], u'improving': [u'None', u'development', u'None'], u'genital': [u'None', u'semen', u'None'], u'spermatozoa': [u'None', u'semen', u'None'], u'account': [u'None', u'elaborate', u'None', u'enlarging', u'expanding'], u'segment': [u'None', u'bend', u'None'], u'radioactive': [u'None', u'astatine', u'thorium', u'None', u'uranium'], u'happening': [u'None', u'present', u'series', u'None'], u'curve': [u'None', u'bend', u'None'], u'together': [u'None', u'set', u'set', u'None', u'tract'], u'element': [u'None', u'astatine', u'thorium', u'None', u'uranium'], u'person': [u'None', u'giant', u'large', u'equivalent', u'attention', u'equal', u'None', u'male', u'heaviest', u'independent'], u'reputation': [u'None', u'giant', u'None'], u'greatest': [u'None', u'limit', u'None'], u'refining': [u'None', u'development', u'None'], u'time': [u'None', u'present', u'culture', u'None', u'formerly', u'period', u'continuous', u'moment'], u'position': [u'None', u'metropolitan', u'metropolitan', u'degree', u'None']})
ksynset= Synset('helping.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('helping.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('helping.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('helping.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('tamil_nadu.n.01')
ksynset= Synset('blurt_out.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('blurt_out.v.01')
lsynset= Synset('semen.n.01')
ksynset= Synset('blurt_out.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('tamil_nadu.n.01')
ksynset= Synset('include.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('include.v.01')
lsynset= Synset('present.n.01')
ksynset= Synset('include.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('include.v.01')
lsynset= Synset('whole.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('group.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('group.n.01')
lsynset= Synset('set.n.01')
ksynset= Synset('group.n.01')
lsynset= Synset('set.n.01')
ksynset= Synset('group.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('decay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('decay.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('decay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('writing.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('writing.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('writing.n.01')
lsynset= Synset('elaborate.v.01')
ksynset= Synset('attention_deficit_disorder.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('attention_deficit_disorder.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('attention_deficit_disorder.n.01')
lsynset= Synset('elaborate.v.01')
ksynset= Synset('halogen.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('halogen.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('halogen.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('include.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('include.v.01')
lsynset= Synset('city.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('exceeding.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('exceeding.s.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('exceeding.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('fluid.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('fluid.n.01')
lsynset= Synset('semen.n.01')
ksynset= Synset('fluid.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('fluid.n.01')
lsynset= Synset('fluid.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('tamil_nadu.n.01')
ksynset= Synset('learn.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('learn.v.01')
lsynset= Synset('elaborate.v.01')
ksynset= Synset('learn.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('meaning.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('meaning.n.01')
lsynset= Synset('elaborate.v.01')
ksynset= Synset('meaning.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('meaning.n.01')
lsynset= Synset('enlarge.v.01')
ksynset= Synset('meaning.n.01')
lsynset= Synset('expand.v.01')
ksynset= Synset('covering.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('covering.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('serve.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('serve.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('large.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('large.n.01')
lsynset= Synset('city.n.01')
ksynset= Synset('large.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('large.n.01')
lsynset= Synset('large.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unstable.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unstable.a.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('unstable.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('geography.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('tamil.n.01')
ksynset= Synset('series.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('series.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('series.n.01')
lsynset= Synset('plan.n.01')
ksynset= Synset('series.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('energy.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('energy.n.01')
lsynset= Synset('focus.n.01')
ksynset= Synset('energy.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('energy.n.01')
lsynset= Synset('energy.n.01')
ksynset= Synset('idea.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('idea.n.01')
lsynset= Synset('elaborate.v.01')
ksynset= Synset('idea.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('elements.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('elements.n.01')
lsynset= Synset('whole.n.01')
ksynset= Synset('elements.n.01')
lsynset= Synset('halogen.n.01')
ksynset= Synset('elements.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('elements.n.01')
lsynset= Synset('elements.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('mile.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('special.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('degree.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('degree.n.01')
lsynset= Synset('limit.n.01')
ksynset= Synset('degree.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('importance.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('importance.n.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('importance.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('energy.n.01')
ksynset= Synset('attention.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('attention.n.01')
lsynset= Synset('focus.n.01')
ksynset= Synset('attention.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('whole.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thorium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thorium.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('thorium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('clarify.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('clarify.v.01')
lsynset= Synset('elaborate.v.01')
ksynset= Synset('clarify.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('dumbly.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('dumbly.r.01')
lsynset= Synset('city.n.01')
ksynset= Synset('dumbly.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('hide.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('hide.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('bengal.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('mile.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('equivalent.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('peer.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('mile.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('meter.n.01')
ksynset= Synset('act.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('act.n.01')
lsynset= Synset('development.n.01')
ksynset= Synset('act.n.01')
lsynset= Synset('writing.n.01')
ksynset= Synset('act.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('area.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('area.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('elaborate.v.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('special.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('compose.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('compose.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('chennai.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('chennai.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('chennai.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('chennai.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('chennai.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('tamil_nadu.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('none.n.01')
ksynset= Synset('time_period.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time_period.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('time_period.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('highly.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('highly.r.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('highly.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('midst.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('midst.n.01')
lsynset= Synset('semen.n.01')
ksynset= Synset('midst.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('group.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('mile.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('meter.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('area.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('area.n.01')
lsynset= Synset('city.n.01')
ksynset= Synset('area.n.01')
lsynset= Synset('boundary.n.01')
ksynset= Synset('area.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('area.n.01')
lsynset= Synset('city.n.01')
ksynset= Synset('stretch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('stretch.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('stretch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('populate.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('populate.v.01')
lsynset= Synset('city.n.01')
ksynset= Synset('populate.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('populate.v.01')
lsynset= Synset('city.n.01')
ksynset= Synset('plan.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('plan.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('manner.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('manner.n.01')
lsynset= Synset('elaborate.v.01')
ksynset= Synset('manner.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('enlarge.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('enlarge.v.01')
lsynset= Synset('development.n.01')
ksynset= Synset('enlarge.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('urban.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('urban.a.01')
lsynset= Synset('city.n.01')
ksynset= Synset('urban.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('urban.a.01')
lsynset= Synset('city.n.01')
ksynset= Synset('continuous.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('continuous.a.01')
lsynset= Synset('present.n.01')
ksynset= Synset('continuous.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('bengal.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('western.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('culture.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('use.v.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('moment.n.01')
ksynset= Synset('white.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('white.n.01')
lsynset= Synset('semen.n.01')
ksynset= Synset('white.n.01')
lsynset= Synset('screen.n.01')
ksynset= Synset('white.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('kind.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('kind.n.01')
lsynset= Synset('set.n.01')
ksynset= Synset('kind.n.01')
lsynset= Synset('set.n.01')
ksynset= Synset('kind.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('administrative.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('administrative.a.01')
lsynset= Synset('city.n.01')
ksynset= Synset('administrative.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('administrative.a.01')
lsynset= Synset('city.n.01')
ksynset= Synset('work.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('work.n.01')
lsynset= Synset('energy.n.01')
ksynset= Synset('work.n.01')
lsynset= Synset('use.v.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('district.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('district.n.01')
lsynset= Synset('city.n.01')
ksynset= Synset('district.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('district.n.01')
lsynset= Synset('city.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('male.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('male.n.01')
lsynset= Synset('semen.n.01')
ksynset= Synset('male.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('area.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('area.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('area.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('kind.n.01')
ksynset= Synset('devise.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('devise.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('expand.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('expand.v.01')
lsynset= Synset('development.n.01')
ksynset= Synset('expand.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('heavy.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('heavy.a.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('heavy.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('concentration.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('concentration.n.01')
lsynset= Synset('focus.n.01')
ksynset= Synset('concentration.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('archbishop.n.01')
ksynset= Synset('incorporate.v.02')
lsynset= Synset('none.n.01')
ksynset= Synset('incorporate.v.02')
lsynset= Synset('semen.n.01')
ksynset= Synset('incorporate.v.02')
lsynset= Synset('none.n.01')
ksynset= Synset('things.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('things.n.01')
lsynset= Synset('set.n.01')
ksynset= Synset('things.n.01')
lsynset= Synset('set.n.01')
ksynset= Synset('things.n.01')
lsynset= Synset('series.n.01')
ksynset= Synset('things.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('things.n.01')
lsynset= Synset('midst.n.01')
ksynset= Synset('things.n.01')
lsynset= Synset('kind.n.01')
ksynset= Synset('brand.n.02')
lsynset= Synset('none.n.01')
ksynset= Synset('brand.n.02')
lsynset= Synset('use.v.01')
ksynset= Synset('brand.n.02')
lsynset= Synset('none.n.01')
ksynset= Synset('brand.n.02')
lsynset= Synset('clarify.v.01')
ksynset= Synset('belong.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('belong.v.01')
lsynset= Synset('set.n.01')
ksynset= Synset('belong.v.01')
lsynset= Synset('set.n.01')
ksynset= Synset('belong.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('uranium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('uranium.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('uranium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('discourse.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('discourse.n.01')
lsynset= Synset('elaborate.v.01')
ksynset= Synset('discourse.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('discourse.n.01')
lsynset= Synset('enlarge.v.01')
ksynset= Synset('discourse.n.01')
lsynset= Synset('expand.v.01')
ksynset= Synset('parts.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('parts.n.01')
lsynset= Synset('whole.n.01')
ksynset= Synset('parts.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('address.n.03')
lsynset= Synset('none.n.01')
ksynset= Synset('address.n.03')
lsynset= Synset('present.n.01')
ksynset= Synset('address.n.03')
lsynset= Synset('none.n.01')
ksynset= Synset('address.n.03')
lsynset= Synset('discourse.n.01')
ksynset= Synset('details.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('details.n.01')
lsynset= Synset('elaborate.v.01')
ksynset= Synset('details.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('details.n.01')
lsynset= Synset('enlarge.v.01')
ksynset= Synset('details.n.01')
lsynset= Synset('expand.v.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('several.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('several.s.01')
lsynset= Synset('city.n.01')
ksynset= Synset('several.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('several.s.01')
lsynset= Synset('city.n.01')
ksynset= Synset('circular.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('circular.n.01')
lsynset= Synset('bend.n.01')
ksynset= Synset('circular.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('mugwump.n.02')
lsynset= Synset('none.n.01')
ksynset= Synset('mugwump.n.02')
lsynset= Synset('city.n.01')
ksynset= Synset('mugwump.n.02')
lsynset= Synset('none.n.01')
ksynset= Synset('mugwump.n.02')
lsynset= Synset('city.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('thousand.n.01')
ksynset= Synset('use.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('use.v.01')
lsynset= Synset('set.n.01')
ksynset= Synset('use.v.01')
lsynset= Synset('set.n.01')
ksynset= Synset('use.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('use.v.01')
lsynset= Synset('exceeding.s.01')
ksynset= Synset('shelter.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('shelter.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('possible.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('possible.n.01')
lsynset= Synset('limit.n.01')
ksynset= Synset('possible.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('moment.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('moment.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('moment.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('use.v.01')
ksynset= Synset('tract.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tract.n.01')
lsynset= Synset('semen.n.01')
ksynset= Synset('tract.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('better.v.02')
lsynset= Synset('none.n.01')
ksynset= Synset('better.v.02')
lsynset= Synset('development.n.01')
ksynset= Synset('better.v.02')
lsynset= Synset('none.n.01')
ksynset= Synset('genital.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('genital.a.01')
lsynset= Synset('semen.n.01')
ksynset= Synset('genital.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('sperm.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('sperm.n.01')
lsynset= Synset('semen.n.01')
ksynset= Synset('sperm.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('history.n.02')
lsynset= Synset('none.n.01')
ksynset= Synset('history.n.02')
lsynset= Synset('elaborate.v.01')
ksynset= Synset('history.n.02')
lsynset= Synset('none.n.01')
ksynset= Synset('history.n.02')
lsynset= Synset('enlarge.v.01')
ksynset= Synset('history.n.02')
lsynset= Synset('expand.v.01')
ksynset= Synset('section.n.04')
lsynset= Synset('none.n.01')
ksynset= Synset('section.n.04')
lsynset= Synset('bend.n.01')
ksynset= Synset('section.n.04')
lsynset= Synset('none.n.01')
ksynset= Synset('radioactive.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('radioactive.a.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('radioactive.a.01')
lsynset= Synset('thorium.n.01')
ksynset= Synset('radioactive.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('radioactive.a.01')
lsynset= Synset('uranium.n.01')
ksynset= Synset('happening.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('happening.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('happening.n.01')
lsynset= Synset('series.n.01')
ksynset= Synset('happening.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('curve.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('curve.n.01')
lsynset= Synset('bend.n.01')
ksynset= Synset('curve.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('together.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('together.s.01')
lsynset= Synset('set.n.01')
ksynset= Synset('together.s.01')
lsynset= Synset('set.n.01')
ksynset= Synset('together.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('together.s.01')
lsynset= Synset('tract.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('thorium.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('uranium.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('large.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('equivalent.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('attention.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('peer.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('male.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('heavy.a.01')
ksynset= Synset('person.n.01')
lsynset= Synset('mugwump.n.02')
ksynset= Synset('repute.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('repute.n.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('repute.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('greatest.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('greatest.s.01')
lsynset= Synset('limit.n.01')
ksynset= Synset('greatest.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('refining.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('refining.n.01')
lsynset= Synset('development.n.01')
ksynset= Synset('refining.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('time.n.01')
lsynset= Synset('culture.n.01')
ksynset= Synset('time.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time.n.01')
lsynset= Synset('once.r.03')
ksynset= Synset('time.n.01')
lsynset= Synset('time_period.n.01')
ksynset= Synset('time.n.01')
lsynset= Synset('continuous.a.01')
ksynset= Synset('time.n.01')
lsynset= Synset('moment.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('degree.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('none.n.01')
Core number (sorted) : [(u'area', 14), (u'city', 12), (u'metropolitan', 12), (u'astatine', 11), (u'elaborate', 11), (u'semen', 9), (u'something', 9), (u'Chennai', 8), (u'kilometer', 8), (u'present', 8), (u'person', 8), (u'miles', 7), (u'set', 7), (u'meters', 7), (u'equivalent', 7), (u'equal', 7), (u'length', 7), (u'unit', 7), (u'enlarging', 7), (u'expanding', 7), (u'discourse', 7), (u'development', 7), (u'used', 7), (u'time', 7), (u'Madras', 6), (u'focus', 6), (u'Bengal', 6), (u'meaning', 6), (u'series', 6), (u'energy', 6), (u'culture', 6), (u'thorium', 6), (u'region', 6), (u'whole', 6), (u'formerly', 6), (u'thick', 6), (u'particular', 6), (u'work', 6), (u'things', 6), (u'uranium', 6), (u'details', 6), (u'moment', 6), (u'account', 6), (u'radioactive', 6), (u'element', 6), (u'giant', 5), (u'usually', 5), (u'kind', 5), (u'limit', 5), (u'including', 4), (u'geography', 4), (u'group', 4), (u'writing', 4), (u'halogen', 4), (u'Tamil', 4), (u'exceptional', 4), (u'Bay', 4), (u'large', 4), (u'people', 4), (u'elements', 4), (u'special', 4), (u'degree', 4), (u'attention', 4), (u'component', 4), (u'clarify', 4), (u'act', 4), (u'1000', 4), (u'period', 4), (u'archbishop', 4), (u'continuous', 4), (u'western', 4), (u'male', 4), (u'distinguished', 4), (u'heaviest', 4), (u'bishop', 4), (u'make', 4), (u'speech', 4), (u'independent', 4), (u'product', 4), (u'purpose', 4), (u'tract', 4), (u'happening', 4), (u'together', 4), (u'position', 4), (u'white', 3), (u'bend', 3), (u'serving', 2), (u'ejaculated', 2), (u'title', 2), (u'add', 2), (u'include', 2), (u'fluid', 2), (u'learned', 2), (u'unstable', 2), (u'idea', 2), (u'Christianity', 2), (u'0.621371', 2), (u'Orthodox', 2), (u'boundary', 2), (u'screen', 2), (u'importance', 2), (u'densely', 2), (u'decay', 2), (u'highly', 2), (u'indefinite', 2), (u'given', 2), (u'stretch', 2), (u'populated', 2), (u'plan', 2), (u'way', 2), (u'dwell', 2), (u'urban', 2), (u'administrative', 2), (u'patriarch', 2), (u'districts', 2), (u'Eastern', 2), (u'Church', 2), (u'metric', 2), (u'concentration', 2), (u'containing', 2), (u'belong', 2), (u'parts', 2), (u'geographical', 2), (u'several', 2), (u'Nadu', 2), (u'circular', 2), (u'possible', 2), (u'improving', 2), (u'genital', 2), (u'spermatozoa', 2), (u'segment', 2), (u'curve', 2), (u'reputation', 2), (u'greatest', 2), (u'refining', 2), (u'covering', 0), (u'serves', 0), (u'None', 0), (u'conceal', 0), (u'composed', 0), (u'devise', 0), (u'shelter', 0)]
=============================================================================================================
Unsupervised Classification based on top percentile Core numbers of the definition graph(subgraph of WordNet)
=============================================================================================================
This document belongs to class: area ,core number= 14
This document belongs to class: city ,core number= 12
This document belongs to class: metropolitan ,core number= 12
This document belongs to class: astatine ,core number= 11
This document belongs to class: elaborate ,core number= 11
This document belongs to class: semen ,core number= 9
This document belongs to class: something ,core number= 9
This document belongs to class: Chennai ,core number= 8
This document belongs to class: kilometer ,core number= 8
This document belongs to class: present ,core number= 8
This document belongs to class: person ,core number= 8
This document belongs to class: miles ,core number= 7
This document belongs to class: set ,core number= 7
This document belongs to class: meters ,core number= 7
This document belongs to class: equivalent ,core number= 7
This document belongs to class: equal ,core number= 7
max_core_number 14
===================================================================
Page Rank of the vertices of RGO Definition Graph
===================================================================
[(u'metropolitan', 0.034341122890468756), (u'area', 0.03264149776435159), (u'city', 0.03002259170750697), (u'semen', 0.026574277023036393), (u'elaborate', 0.026190893560877164), (u'astatine', 0.026155500666697376), (u'something', 0.020596364487739646), (u'person', 0.01874719756933613), (u'present', 0.01798008271700652), (u'kilometer', 0.017135278870812603), (u'Chennai', 0.016246999392470467), (u'set', 0.014336889725339554), (u'bend', 0.014091688846608094), (u'used', 0.013752783278762141), (u'time', 0.012895515390740787), (u'development', 0.012831123761453863), (u'whole', 0.012557808648702448), (u'limit', 0.011869801493016797), (u'giant', 0.011424496312308532), (u'enlarging', 0.011035259418543287), (u'expanding', 0.011035259418543287), (u'series', 0.010098108680690502), (u'focus', 0.01008454224203267), (u'miles', 0.010069868111700506), (u'things', 0.009508840604606925), (u'equivalent', 0.009412641488237169), (u'Bengal', 0.009351022856635898), (u'Madras', 0.009133264578267651), (u'discourse', 0.00897076404271351), (u'particular', 0.008862609786042825), (u'equal', 0.008627208315107517), (u'unit', 0.008475885140962083), (u'length', 0.008323941892078544), (u'meters', 0.008204944157344844), (u'thick', 0.007579085058072095), (u'people', 0.007511166315925552), (u'kind', 0.007350192964887966), (u'usually', 0.007298393290146962), (u'energy', 0.0072424919675165705), (u'radioactive', 0.00720845659105402), (u'element', 0.00720845659105402), (u'thorium', 0.007208456591054019), (u'uranium', 0.007208456591054019), (u'white', 0.00712378405013264), (u'work', 0.007048264990738531), (u'region', 0.007016832087728922), (u'details', 0.006880052791012496), (u'meaning', 0.006880052791012496), (u'account', 0.006880052791012496), (u'formerly', 0.006842942875596264), (u'culture', 0.006794466745990618), (u'moment', 0.00672295471850115), (u'degree', 0.006257223953670874), (u'position', 0.00619475910055472), (u'archbishop', 0.006148094655484146), (u'bishop', 0.006148094655484146), (u'tract', 0.006034881083425767), (u'together', 0.005697791320497383), (u'act', 0.0056284288284269395), (u'male', 0.005605048025068771), (u'elements', 0.00557111408532442), (u'western', 0.00552237801532493), (u'writing', 0.005519591249032545), (u'halogen', 0.005491478480868502), (u'exceptional', 0.005478358131769676), (u'large', 0.005414714536291453), (u'independent', 0.005414714536291453), (u'clarify', 0.0053986608061264586), (u'make', 0.005344890803707827), (u'product', 0.005328488834445963), (u'attention', 0.005237526305974809), (u'geography', 0.005212474068284366), (u'Tamil', 0.005203456330619378), (u'1000', 0.005187737124981292), (u'component', 0.005182625187860422), (u'distinguished', 0.005166868836060332), (u'happening', 0.0051585530562126385), (u'special', 0.005151998338709003), (u'including', 0.00514758371805895), (u'heaviest', 0.005115759194750855), (u'circular', 0.005103088894815554), (u'segment', 0.005103088894815554), (u'curve', 0.005103088894815554), (u'purpose', 0.0050326203368832355), (u'Bay', 0.005016103725419375), (u'group', 0.0049345733778657155), (u'speech', 0.00491859062430894), (u'period', 0.00483965915307082), (u'continuous', 0.00483965915307082), (u'screen', 0.004129374102784344), (u'possible', 0.0036246570664551867), (u'greatest', 0.0036246570664551867), (u'ejaculated', 0.0036129805582727605), (u'fluid', 0.0036129805582727605), (u'containing', 0.0036129805582727605), (u'genital', 0.0036129805582727605), (u'spermatozoa', 0.0036129805582727605), (u'title', 0.0035352035982602575), (u'Christianity', 0.0035352035982602575), (u'Orthodox', 0.0035352035982602575), (u'given', 0.0035352035982602575), (u'patriarch', 0.0035352035982602575), (u'Eastern', 0.0035352035982602575), (u'Church', 0.0035352035982602575), (u'importance', 0.00353006982526984), (u'reputation', 0.00353006982526984), (u'include', 0.0034226470694954424), (u'densely', 0.0034226470694954424), (u'populated', 0.0034226470694954424), (u'urban', 0.0034226470694954424), (u'administrative', 0.0034226470694954424), (u'districts', 0.0034226470694954424), (u'several', 0.0034226470694954424), (u'improving', 0.003283186767869823), (u'refining', 0.003283186767869823), (u'plan', 0.0032482688857332605), (u'concentration', 0.003245458839178799), (u'parts', 0.003237299547579572), (u'belong', 0.003133481270634062), (u'add', 0.003126887179700291), (u'idea', 0.003126887179700291), (u'learned', 0.003126887179700291), (u'way', 0.003126887179700291), (u'unstable', 0.003123691727954845), (u'decay', 0.003123691727954845), (u'highly', 0.003123691727954845), (u'serving', 0.0030843320303833997), (u'boundary', 0.0030843320303833997), (u'indefinite', 0.0030843320303833997), (u'geographical', 0.0030843320303833997), (u'Nadu', 0.0030753142927184107), (u'dwell', 0.0030478614726954043), (u'stretch', 0.003012820002893931), (u'0.621371', 0.0029231664941149777), (u'metric', 0.0029231664941149777), (u'covering', 0.0011025358324145535), (u'serves', 0.0011025358324145535), (u'None', 0.0011025358324145535), (u'conceal', 0.0011025358324145535), (u'composed', 0.0011025358324145535), (u'devise', 0.0011025358324145535), (u'shelter', 0.0011025358324145535)]
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - connectivity of RGO Definition Graph - Mengers Theorem
==========================================================================================================
0
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - Maxflow-Mincut of RGO Definition Graph - Minimum Edge Cut
==========================================================================================================
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - Maxflow-Mincut of RGO Definition Graph - Stoer-Wagner
==========================================================================================================

